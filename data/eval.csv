post,label
"<p>Is there a simple way to make a nice plot of the following data in R, without using many commands?</p>

<pre><code> Region1 Region2
2007 17 55
2008 26 43
2009 53 70
2010 96 58
</code></pre>

<p>I do know how to plot the data, but it uses too many commands and parameters, and the result still looks absolutely terrible (see <a href=""""http://i50.tinypic.com/30nklfm.png"""" rel=""""nofollow noreferrer"""">here</a>):</p>

<pre><code>&gt; test &lt;- read.table(""""/tmp/data.txt"""")
&gt; png(filename=""""/tmp/test.png"""", height=1000, width=750, bg=""""white"""", res=300)
&gt; plot(test$Region1, type=""""b"""", col=""""blue"""", ylim=c(0,100), lwd=3)
&gt; lines(test$Region2, type=""""b"""", col=""""red"""", lwd=3)
&gt; dev.off()
</code></pre>

<p>It took me a while to figure out all the commands, and I still have to get the x axis labels (2007, 2008, ...), using the <code>axis</code> command (but how do I access the <code>test</code> x axis labels?), etc. </p>

<p>In Keynote (or Powerpoint) I can just give it the same table (transposed) and it produces a nice graph from it (see <a href=""""http://i45.tinypic.com/b3tw08.jpg"""" rel=""""nofollow noreferrer"""">here</a>).</p>

<p>My question is really: Is there a higher-level command that draws such typical data nicely? Also, how can I separate the drawing logic (draw 2 lines from that specific data, etc.) from the layout (use specific colors and line types for the graph, etc.)? Ideally, I'd hope there were different libraries for different layouts of the graph, e.g. called <code>NiceKeynoteLayout</code>, which I just could use like this (or similar):</p>

<pre><code>&gt; d &lt;- read.table(""""/tmp/data.txt"""")
&gt; png &lt;- png(filename=""""/tmp/test.png"""", height=1000, width=750)
&gt; myLayout &lt;- loadPredefinedLayout(""""NiceKeynoteLayout"""")
&gt; coolplot(d, layout=myLayout, out=png)
</code></pre>
",1
"<p>I'm trying to import some data into R and not having much luck grouping together rows of related data. </p>

<p>Example:
There a set of problems such as {A, B, C, D}. Each problem has two variables of interest which are being measured: """"x"""" and """"y"""". 
Each variable is analysed in terms of some simple statistics: min, max, mean, stddev.</p>

<p>So, my input data has the form:</p>

<pre><code>      Min  Max  Mean  StdDev
A
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
B
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
C
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
D
  x   3    10   6.6   2.1 
  y   2    5    3.2   1.7
</code></pre>

<p>Is there any way to preserve the structure of this data in R?
A similar problem is creating groups of columns (flip the table by 90 degrees to the right for example).</p>
",1
"<p>I've spent a few weeks learning some R and I'm floored at just how slick and powerful it is. I'm using it to plot some data returned from an SQL query, and I'd like to be able to share those plots with others I work with through a web portal. </p>

<p>I realize I can create a cron job to run the R scripts on the webserver to create the plots daily to be viewed from the website as images. But is there any way I can set things up such that the images are created only when the user views the page? That way I could make a web interface that lets the user select date ranges, etc for the SQL query. (and then have R analyse the data and plot it)</p>

<p>Any advice?</p>
",1
"<p>I have a text file that I'd like to import into <code>R</code>. Problem is, the file looks like this:</p>

<pre><code>x1,x2,x3,x4,x5,x6,x7,x8,x9,10,x11
   1953.00       7.40000       159565.       16.6680       8883.00    
   47.2000       26.7000       16.8000       37.7000       29.7000    
   19.4000    
   1954.00       7.80000       162391.       17.0290       8685.00    
   46.5000       22.7000       18.0000       36.8000       29.7000    
   20.0000
</code></pre>

<p>and so on.</p>

<p>I tried <code>&gt; data &lt;- read.table(""""clipboard"""", header=TRUE)</code> but that didn't work.</p>
",1
"<p>As a fairly new R programmer I seem to have run into a strange problem - probably my inexperience with R</p>

<p>After reading and merging successive files into a single data frame, I find that order does not sort the data as expected. </p>

<p>I have multiple references in each file but each file refers to measurement data obtained at a different time.</p>

<p>Here's the code</p>

<pre><code>library(reshape)
# Enter file name to Read &amp; Save data
FileName=readline(""""Enter File name:\n"""")
# Find first occurance of file
for ( round1 in 1 : 6) {
ReadFile=paste(round1,""""C_"""",FileName,""""_Stats.csv"""", sep="""""""")
if (file.exists(ReadFile))
break
}

x = data.frame(read.csv(ReadFile, header=TRUE),rnd=round1)
for ( round2 in (round1+1) : 6) {
#
ReadFile=paste(round2,""""C_"""",FileName,""""_Stats.csv"""", sep="""""""")
if (file.exists(ReadFile)) {
y = data.frame(read.csv(ReadFile, header=TRUE),rnd = round2)
    if (round2 == (round1 +1))
    z=data.frame(merge(x,y,all=TRUE))
    z=data.frame(merge(y,z,all=TRUE))
}
}
ordered = order(z$lab_id)

results = z[ordered,]

res = data.frame( lab=results[,""""lab_id""""],bw=results[,""""ZBW""""],wi=results[,""""ZWI""""],pf_zbw=0,pf_zwi=0,r = results[,""""rnd""""])


#
# Establish no of samples recorded
nsmpls = length(res[,c(""""lab"""")])

# Evaluate Z_scores for Between Lab Results
for ( i in 1 : nsmpls) {
if (res[i,""""bw""""] &gt; 3 | res[i,""""bw""""] &lt; -3)
res[i,""""pf_zbw""""]=1
}
# Evaluate Z_scores for Within Lab Results
for ( i in 1 : nsmpls) {
if (res[i,""""wi""""] &gt; 3 | res[i,""""wi""""] &lt; -3)
res[i,""""pf_zwi""""]=1
}

dd = melt(res, id=c(""""lab"""",""""r""""), """"pf_zbw"""")
b = cast(dd, lab ~ r)
</code></pre>

<p>If anyone could see why the ordering only works for about 55 of 70 records and could steer me in the right direction I would be obliged</p>

<p>Thanks very much</p>
",1
"<p>I am attempting to retrieve email addresses of contributing package authors and maintainers to the R-Project.  The function reads as follows:</p>

<pre><code>availpkgs &lt;- available.packages(contriburl = contrib.url(getOption(""""repos""""), type),
    method, fields = NULL, type = getOption(""""pkgType""""),
    filters = NULL)
</code></pre>

<p>I've attempted different character values in the <code>fields</code> parameter to retrieve Maintainer and Author info from the 'PACKAGES' files, but have not been had luck.  Does anyone know how I might approach this?  Thank you in advance for your time.</p>
",1
"<p>My script use an access to mysql to get command arguments to launch Rscript.
Its use is as follows : Rscript $RFILE $ARGUMENTS (RFILE corresponding to path to Rscript, and ARGUMENTS corresponding to path file used and agr).</p>

<p>I try, different way, but I still have errors, here a copy of my bash script :</p>

<pre><code>#!/usr/bin/env bash
# Execute R process
# -----------------
### Mysql Setup ###
USER=...
PASS=...
HOST=...
DB=...

# Get Job ID process
# Use to retrieve args in my DB
ID=$1

# Get script name
RFILE=$(mysql -u$USER -p$PASS -e """"SELECT script_name FROM JobProcess WHERE script_run_id=$ID;"""" $DB)
SUBSTRING=""""script_name""""
RFILE=""""${RFILE//$SUBSTRING}""""

# Get script_args
ARGUMENTS=$(mysql -u$USER -p$PASS -e """"SELECT script_args FROM JobProcess WHERE script_run_id=$ID;"""" $DB)
SUBSTRING2=""""script_args""""
ARGUMENTS=""""${ARGUMENTS//$SUBSTRING2}""""

RUN=""""Rscript $RFILE $ARGUMENTS""""

# Try Different execute process
Rscript $RFILE $ARGUMENTS
#eval """"$RUN""""
#`Rscript $RFILE $ARGUMENTS`
#$RUN
</code></pre>

<p>I verified my command line (via echo), and if I made a copy-paste to my shell I can run my R script. But from my bash, I can't execute my script (but command line is good).</p>

<p>By using : Rscript $RFILE $ARGUMENTS, <code>Rscript $RFILE $ARGUMENTS</code> and $RUN, I have this error : </p>

<pre><code>Error in parse(text = args[[i]]) : 
  unexpected end of input in """"""""path_in='/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level""""
Calls: eval -&gt; parse
Execution halted
</code></pre>

<p>By using : eval """"$RUN"""", I have this error :</p>

<pre><code>/Users/GR/web-app/Rproject/Scripts/Rscript.sh: line 38: /Users/GR/web-app/Rproject/Scripts/arg_file_test.R: Permission denied
/Users/GR/web-app/Rproject/Scripts/Rscript.sh: line 44: path_in&lt;-""""/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level Description for Modules.csv"""": No such file or directory
</code></pre>

<p>If I try this in my shell script, all works fine :</p>

<pre><code>SCRIPT=""""/Users/GR/web-app/Rproject/Scripts/arg_file_test.R""""
FILE1=""""path_in='/Users/GR/web-app/Rproject/Inputs/Rscript/Gene-level Description for Modules.csv'""""
FILE2=""""path_in2='/Users/GR/web-app/Rproject/Inputs/Rscript/Template_Auto.csv'""""
FILES=""""\""""$FILE1\"""" \""""$FILE2\""""""""
ARG=""""l=32 w=33""""
RUN=""""Rscript $SCRIPT $FILES $ARG""""
</code></pre>

<p>Someone has an idea ?</p>

<p>Thanks</p>
",1
"<p>I'd like to save a plot image directly to the database.</p>

<p>Is the best way in R to do this:</p>

<ol>
<li>Write the plot image (png) to the filesystem</li>
<li>Read the file that was written</li>
<li>Send the file to the database via query (RODBC)</li>
</ol>

<p>Ideally I'd like to combine steps 1 and 2 above by simply write the png image to a binary connection.  Does R support this?</p>
",1
"<p>I have a dataset in R, which contains the results of a rapid diagnostic test.  The test has a visible line if it is working properly (control line) and a visible line for each of the two parasite species it detects, if they are present in the patient sample.</p>

<p>The dataset contains a logical column for each test line, as follows:
(database is called RDTbase)</p>

<pre><code>   Control  Pf    Pv
1. TRUE     TRUE  FALSE
2. TRUE     FALSE TRUE
3. FALSE    FALSE FALSE
4. TRUE     TRUE  TRUE
5. TRUE     FALSE FALSE
</code></pre>

<p>I would like to add a new column which contains a single result for each rapid test.  The results are designated according to the different logical conditions met by the three lines.  For the example above the new column would look like this:</p>

<pre><code>Control  Pf     Pv     Result
1. TRUE  TRUE   FALSE  Pf
2. TRUE  FALSE  TRUE   Pv
3. FALSE FALSE  FALSE  Invalid
4. TRUE  TRUE   TRUE   Mixed
5. TRUE  FALSE  FALSE  Negative
</code></pre>

<p>I am able to create the new column, but it takes a lot of coding and I think there has to be a much simpler (and shorter) way to do this.</p>

<p>Here is my current (long) method:</p>

<pre><code>R.Pf &lt;- RDTbase[which(Control == """"TRUE"""" &amp; Pf == """"TRUE"""" &amp; Pv == """"FALSE""""),]
R.Pv &lt;- RDTbase[which(Control == """"TRUE"""" &amp; Pf == """"FALSE"""" &amp; Pv == """"TRUE""""),]
R.inv &lt;- RDTbase[which(Control == """"FALSE""""),]
R.mix &lt;- RDTbase[which(Control == """"TRUE"""" &amp; Pf == """"TRUE"""" &amp; Pv == """"TRUE""""),]
R.neg &lt;- RDTbase[which(Control == """"TRUE"""" &amp; Pf == """"FALSE"""" &amp; Pv == """"FALSE""""),]

R.Pf$Result &lt;- c(""""Pf"""")
R.Pv$Result &lt;- c(""""Pv"""")
R.inv$Result &lt;- c(""""Invalid"""")
R.mix$Result &lt;- c(""""Mixed"""")
R.neg$Result &lt;- c(""""Negative"""")

RDTbase2 &lt;- rbind(R.Pf, R.Pv, R.inv, R.mix, R.neg)
</code></pre>

<p>Any ideas on how to simplify and shorten this code would be greatly appreciated, as I have to do this kind of thing to my databases alot.</p>

<p>Many thanks,
Amy</p>
",1
"<p>I'm creating a series of plots in R (I'm using ggplot2, but that's not essential) and I want to be able to save my output so I can then edit it for furthur use, For instance, I might want to move legends about, or adjust colours etc.  I have seen that ggplot2 has a save command but that seems to produce pdf's or bitmaps, neither of which are particularly editable</p>

<p>How do other people do this ?  Any good ideas ?</p>

<p>Here's some sample code to produce a sample plot;</p>

<pre><code>library(ggplot2)
dataframe&lt;-data.frame(fac=factor(c(1:4)),data1=rnorm(400,100,sd=15))
dataframe$data2&lt;-dataframe$data1*c(0.25,0.5,0.75,1)
dataframe
testplot&lt;-qplot(x=fac, y=data2,data=dataframe, colour=fac, geom=c(""""boxplot"""", """"jitter""""))
testplot
</code></pre>

<p>Thanks</p>

<p>Paul.</p>
",1
"<p>I am using ggplot2 to explore the result of some testing on an agent-based model.  The model can end in one of three rounds per realization, and as such I am interested in how player utilities differ in terms of what round the game ends and their relative position in 2D space.</p>

<p>All this is to say that I have generated a facet_wrap plot to show this for each round, but I would also like to annotate each plot with the cor(x,y) for the subset of data represented in each facet.  Is there a way to tell ggplot2 that I would like the annotation to use the subset of data generated by facet_wrap?  Here is the code I have so far, and what it is producing</p>

<pre><code>library(ggplot2)

# Load data
abm.data&lt;-read.csv(""""ABM_results.csv"""")

# Create new colun for area of Pareto set
attach(abm.data)
area&lt;-abs(((x3*(y2-y1))+(x2*(y1-y3))+(x1*(y3-y2)))/2)
abm.data&lt;-transform(abm.data,area=area)
detach(abm.data)

# Compare area of Pareto set with player utility
png(""""area_p1.png"""",res=100,pointsize=20,height=500,width=1600)
area.p1&lt;-ggplot(abm.data,aes(x=area))+geom_point(aes(y=U1_2,colour=""""Player 1"""",alpha=0.4))+facet_wrap(~round,ncol=3)+
    annotate(""""text"""",0.375,-1.25,label=paste(""""rho="""",round(cor(abm.data$area,abm.data$U1_2),2)), parse=TRUE)+
    scale_colour_manual(values=c(""""Player 1""""=""""red""""))
area.p1+xlab(""""Area of Pareto Set"""")+ylab(""""Player Utility at Game End"""")+
    opts(title=""""Final Player 1 Utility by Pareto Set Size and Round Game Ends"""",legend.position=""""none"""")
dev.off()
</code></pre>

<p><a href=""""http://www.drewconway.com/zia/wp-content/uploads/2010/01/area_p1.png"""">area_p1 http://www.drewconway.com/zia/wp-content/uploads/2010/01/area_p1.png</a></p>

<p>As you can see, there are two problems:</p>

<ol>
<li>The \rho value is of the full dataset, rather than the subsets by 'round'.  Is there a way to get the cor(x,y) to print based on only the data shown in each plot?</li>
<li>The annotation should read """"\rho=some_value"""" but instead I get """"=(\rho,value);"""" is there a way to fix this?  </li>
</ol>
",1
"<p>Brief background: Many (most?) contemporary programming languages in widespread use have at least a handful of ADTs [abstract data types] in common, in particular,</p>

<ul>
<li><p><strong>string</strong> (a sequence comprised of characters)</p></li>
<li><p><strong>list</strong> (an ordered collection of values), and</p></li>
<li><p><strong>map-based type</strong> (an unordered array that maps keys to values)</p></li>
</ul>

<p>In the R programming language, the first two are implemented as <code>character</code> and <code>vector</code>, respectively.</p>

<p>When I began learning R, two things were obvious almost from the start: <code>list</code> is the most important data type in R (because it is the parent class for the R <code>data.frame</code>), and second, I just couldn't understand how they worked, at least not well enough to use them correctly in my code.</p>

<p>For one thing, it seemed to me that R's <code>list</code> data type was a straightforward implementation of the map ADT (<code>dictionary</code> in Python, <code>NSMutableDictionary</code> in Objective C, <code>hash</code> in Perl and Ruby, <code>object literal</code> in Javascript, and so forth).</p>

<p>For instance, you create them just like you would a Python dictionary, by passing key-value pairs to a constructor (which in Python is <code>dict</code> not <code>list</code>):</p>

<pre><code>x = list(""""ev1""""=10, """"ev2""""=15, """"rv""""=""""Group 1"""")
</code></pre>

<p>And you access the items of an R List just like you would those of a Python dictionary, e.g., <code>x['ev1']</code>. Likewise, you can retrieve just the <em>'keys'</em> or just the <em>'values'</em> by: </p>

<pre><code>names(x)    # fetch just the 'keys' of an R list
# [1] """"ev1"""" """"ev2"""" """"rv""""

unlist(x)   # fetch just the 'values' of an R list
#   ev1       ev2        rv 
#  """"10""""      """"15"""" """"Group 1"""" 

x = list(""""a""""=6, """"b""""=9, """"c""""=3)  

sum(unlist(x))
# [1] 18
</code></pre>

<p>but R <code>list</code>s are also <strong><em>unlike</em></strong> other map-type ADTs (from among the languages I've learned anyway). My guess is that this is a consequence of the initial spec for S, i.e., an intention to design a data/statistics DSL [domain-specific language] from the ground-up. </p>

<p><em>three</em> significant differences between R <code>list</code>s and mapping types in other languages in widespread use (e.g,. Python, Perl, JavaScript):</p>

<p><em>first</em>, <code>list</code>s in R are an <em>ordered</em> collection, just like vectors, even though the values are keyed (ie, the keys can be any hashable value not just sequential integers). Nearly always, the mapping data type in other languages is <em>unordered</em>.</p>

<p><em>second</em>, <code>list</code>s can be returned from functions even though you never passed in a <code>list</code> when you called the function, and <em>even though</em> the function that returned the <code>list</code> doesn't contain an (explicit) <code>list</code> constructor (Of course, you can deal with this in practice by wrapping the returned result in a call to <code>unlist</code>):</p>

<pre><code>x = strsplit(LETTERS[1:10], """""""")     # passing in an object of type 'character'

class(x)                            # returns 'list', not a vector of length 2
# [1] list
</code></pre>

<p>A <em>third</em> peculiar feature of R's <code>list</code>s: it doesn't seem that they can be members of another ADT, and if you try to do that then the primary container is coerced to a <code>list</code>. E.g.,</p>

<pre><code>x = c(0.5, 0.8, 0.23, list(0.5, 0.2, 0.9), recursive=TRUE)

class(x)
# [1] list
</code></pre>

<p>my intention here is not to criticize the language or how it is documented; likewise, I'm not suggesting there is anything wrong with the <code>list</code> data structure or how it behaves. All I'm after is to correct is my understanding of how they work so I can correctly use them in my code. </p>

<p>Here are the sorts of things I'd like to better understand:</p>

<ul>
<li><p>What are the rules which determine when a function call will return a <code>list</code> (e.g., <code>strsplit</code> expression recited above)?</p></li>
<li><p>If I don't explicitly assign names to a <code>list</code> (e.g., <code>list(10,20,30,40)</code>) are the default names just sequential integers beginning with 1?  (I assume, but I am far from certain that the answer is yes, otherwise we wouldn't be able to coerce this type of <code>list</code> to a vector w/ a call to <code>unlist</code>.)</p></li>
<li><p>Why do these two different operators, <code>[]</code>, and <code>[[]]</code>, return the <em>same</em> result?</p>

<p><code>x = list(1, 2, 3, 4)</code></p>

<p>both expressions return """"1"""":</p>

<p><code>x[1]</code></p>

<p><code>x[[1]]</code></p></li>
<li><p>why do these two expressions <strong>not</strong> return the same result?</p>

<p><code>x = list(1, 2, 3, 4)</code></p>

<p><code>x2 = list(1:4)</code></p></li>
</ul>

<p>Please don't point me to the R Documentation (<a href=""""http://www.inside-r.org/r-doc/base/list"""" rel=""""nofollow noreferrer""""><code>?list</code></a>, <a href=""""http://cran.r-project.org/doc/manuals/r-devel/R-intro.html#Lists"""" rel=""""nofollow noreferrer""""><code>R-intro</code></a>)--I have read it carefully and it does not help me answer the type of questions I recited just above.</p>

<p>(lastly, I recently learned of and began using an R Package (available on CRAN) called <a href=""""http://mran.revolutionanalytics.com/packages/info/?hash"""" rel=""""nofollow noreferrer""""><code>hash</code></a> which implements <em>conventional</em> map-type behavior via an S4 class; I can certainly recommend this Package.)</p>
",1
"<p>I am trying to replace values in a R dataframe by column. I would like to loop though a given list of columns of the dataframe and replace all """"Yes"""" values by 1 and all the other values by 0.</p>

<p>I tried to do this using transform() and ifelse() functions with the something like this:</p>

<pre><code># List of selected Columns:
ColumnNames = c(""""Frigori"""", """"Microond"""" , """"Arca"""", """"Aspira"""")

# Replace Values in dataframe
for(i in 1:length(ColumnNames)){
dataframe &lt;- transform(dataframe, ColumnNames[i] = ifelse(Columnames[i] == """"Yes"""", 1, 0))
}
</code></pre>

<p>This piece of code works fine with explicit column names outside the loop, but with the array it will give me the following error:</p>

<pre><code>Error: unexpected '=' in:
""""for(i in 1:length(Appliances)){
dataframe &lt;- transform(dataframe, ColumnNames[i] =""""
</code></pre>

<p>I don't know what goes wrong here, but the problem has to be related with the variable substitution.</p>
",1
"<p>What datatype choices do we have to handle large numbers in R? By default, the size of an integer seems to be 32bit, so bigint numbers from sql server as well as any large numbers passed from python via rpy2 get mangled.</p>

<pre><code>&gt; 123456789123
[1] 123456789123
&gt; 1234567891234
[1] 1.234568e+12
</code></pre>

<p>When reading a bigint value of 123456789123456789 using RODBC, it comes back as 123456789123456784 (see the last digit), and the same number when deserialized via RJSONIO, comes back as -1395630315L (which seems like an additional bug/limitation of RJSONIO).</p>

<pre><code>&gt; fromJSON('[1234567891]')
[1] 1234567891
&gt; fromJSON('[12345678912]')
[1] -539222976
</code></pre>

<p>Actually, I do need to be able to handle large numbers coming from JSON, so with RJSONIO's limitation, I may not have a workaround except for finding a better JSON library (which seems like a non-option right now). I would like to hear what experts have to say on this as well as in general.</p>
",1
"<p>I am trying to use the <strong>outer</strong> function with <strong>predict</strong> in some classification code in R.  For ease, we will assume in this post that we have two vectors named <strong>alpha</strong> and <strong>beta</strong> each containing ONLY 0 and 1. I am looking for a simple yet efficient way to pass all combinations of <strong>alpha</strong> and <strong>beta</strong> to <strong>predict</strong>.</p>

<p>I have constructed the code below to mimic the lda function from the MASS library, so rather than """"lda"""", I am using """"classifier"""". It is important to note that the prediction method within <strong>predict</strong> depends on an (<strong>alpha</strong>, <strong>beta</strong>) pair.</p>

<p>Of course, I could use a nested for loop to do this, but I am trying to avoid this method.</p>

<p>Here is what I would like to do ideally:</p>

<pre><code>alpha &lt;- seq(0, 1)
beta &lt;- seq(0, 1)
classifier.out &lt;- classifier(training.data, labels)
outer(X=alpha, Y=beta, FUN=""""predict"""", classifier.out, validation.data)
</code></pre>

<p>This is a problem because <strong>alpha</strong> and <strong>beta</strong> are not the first two parameters in <strong>predict</strong>.</p>

<p>So, in order to get around this, I changed the last line to</p>

<pre><code>outer(X=alpha, Y=beta, FUN=""""predict"""", object=classifier.out, data=validation.data)
</code></pre>

<p>Note that my validation data has 40 observations, and also that there are 4 possible pairs of <strong>alpha</strong> and <strong>beta</strong>. I get an error though saying</p>

<pre><code>dims [product 4] do not match the length of object [40]
</code></pre>

<p>I have tried a few other things, some of which work but are far from simple. Any suggestions?</p>
",1
"<p>We want to log the commands and results of a R script into a text report file. The pipe into the text file works well with <code>sink()</code>, but not within a for loop.</p>

<p>The script is called with</p>

<pre><code>source(""""myscript.r"""",echo=TRUE)
</code></pre>

<p>We need the loop to extract all rows of a <code>data.frame</code> consecutively into a vector and do some vector based analysis with each vector.
Here's a short example:</p>

<pre><code>#pipe output to file
sink(""""myfile.txt"""",append=TRUE,split=TRUE)
#some data
c1&lt;-rnorm(10,mean=90,sd=10) 
c2&lt;-rnorm(10,mean=75,sd=8)
c3&lt;-rnorm(10,mean=98,sd=12)
#data in a data.frame
cData&lt;-data.frame(c1,c2,c3)
#print data.frame
cData  
#loop over frame 
for (i in 1:ncol(cData))  
{
  #extract vector
  x&lt;-cData[,i]
  #do something with vector
  n = length(x)
  #... more code
  #print result
  print(n)    
}
#close output
sink()
</code></pre>

<p>I tried it with <code>sink()</code> and <code>txtStart()</code> but <code>sink()</code> truncates the commands and puts results after the loop, <code>txtStart()</code> seems to repeat the commands but not the results. </p>

<p>I looked also at brew, but I just need a text file, nothing formatted.</p>
",1
"<p>What are the numbers of parameters to be penalized for when using information criterions(BIC or AIC or..) for selecting the best models? Let's say that we have 3 models: 1. Simple exponential smoothing 2. Holt's method(level+trend) 3. Holt Winters(L+T+S), where we have monthly seasonality. How many parameters for penalization does have each model?</p>
",1
"<p>I am fairly new to R, but the more use it, the more I see how powerful it really is over SAS or SPSS.  Just one of the major benefits, as I see them, is the ability to get and analyze data from the web.  I imagine this is possible (and maybe even straightforward), but I am looking to parse JSON data that is publicly available on the web.  I am not programmer by any stretch, so any help and instruction you can provide will be greatly appreciated.  Even if you point me to a basic working example, I probably can work through it.</p>
",1
"<p>Does anyone know of a function that can create an lm object given a dataset and coefficients?</p>

<p>I'm interested in this because I started playing with Bayesian model averaging (BMA) and I'd like to be able to create an lm object out of the results of bicreg.  I'd like to have access to all of the nice generic lm functions like diagnostic plotting, predict, cv.lm etc.</p>

<p>If you are pretty sure such a function doesn't exist that's also very helpful to know!</p>

<pre><code>library(BMA)
mtcars_y &lt;- mtcars[, 1] #mpg
mtcars_x &lt;- as.matrix(mtcars[,-1])
res &lt;- bicreg(mtcars_x, mtcars_y)

summary(res)
res$postmean # bma coefficients

# The approximate form of the function
# I'm looking for
lmObject &lt;- magicFunction(data=mtcars, coefficients=res$postmean)
</code></pre>
",1
"<p>I'm running a monte-carlo simulation and the output is in the form:</p>

<pre><code>&gt; d = data.frame(iter=seq(1, 2), k1 = c(0.2, 0.6), k2=c(0.3, 0.4))
&gt; d
iter  k1   k2
1     0.2  0.3
2     0.6  0.4
</code></pre>

<p>The plots I want to generate are:</p>

<pre><code>plot(d$iter, d$k1)
plot(density(d$k1))
</code></pre>

<p>I know how to do equivalent plots using ggplot2,  convert to data frame</p>

<pre><code>new_d = data.frame(iter=rep(d$iter, 2), 
                   k = c(d$k1, d$k2), 
                   label = rep(c('k1', 'k2'), each=2))
</code></pre>

<p>then plotting is easy. However the number of iterations can be very large and the number of k's can also be large. This means messing about with a very large data frame.</p>

<p>Is there anyway I can avoid creating this new data frame?</p>

<p>Thanks</p>
",1
"<p>I'm trying to learn R's <code>XML</code> package. I'm trying to create a data.frame from books.xml sample xml data file. Here's what I get:</p>

<pre><code>library(XML)
books &lt;- """"http://www.w3schools.com/XQuery/books.xml""""
doc &lt;- xmlTreeParse(books, useInternalNodes = TRUE)
doc
xpathApply(doc, """"//book"""", function(x) do.call(paste, as.list(xmlValue(x))))
xpathSApply(doc, """"//book"""", function(x) strsplit(xmlValue(x), """" """"))
xpathSApply(doc, """"//book/child::*"""", xmlValue)
</code></pre>

<p>Each of these xpathSApply's don't get me even close to my intention. How should one proceed toward a well formed data.frame?</p>
",1
"<p>I'm having difficulties reading in a .shp (esri shape file) into R. I have tried several options in R, and tried to convert the shape file in ArcMap to something that correctly reads in the shape file but nothing worked yet. (In ArcMap I corrected the geometry, converted from single to multipolygon, etc which was probably not necessary or relevant)</p>

<p>It probably has something to with the fact that my shape file contains 'regions' (multi-polygons) instead of 'polygons'... </p>

<p>How can I read that type of shape file correctly in R for plotting? (it looks like a normal shape in ArcMap)</p>

<p>In ArcMap the shape file looks like this:
<a href=""""http://bfast.r-forge.r-project.org/arcmapshape.jpg"""" rel=""""noreferrer"""">http://bfast.r-forge.r-project.org/arcmapshape.jpg</a></p>

<p>(shows a shape file with polygons within other polygons)</p>

<p>In R it looks like this:
<img src=""""https://i.stack.imgur.com/jRwBp.jpg"""" alt=""""enter image description here""""></p>

<p>(shows a shape file where some polygons are wrongly filled)</p>

<p>I used the following code in R:</p>

<pre><code>require(maptools)
require(rgdal)

newproj &lt;- """"+proj=utm +zone=55 +south +ellps=GRS80 +units=m""""
shape&lt;- readShapeSpatial(pdir, proj4string = CRS(newproj),repair=TRUE,force_ring=T,verbose=TRUE) # without any errors
plot(shape, col=""""gray"""",border=""""blue"""", axes=TRUE)

# via rgdal
folder &lt;- c(""""spatial"""")
lyr &lt;- c(""""clipped_forest_mga"""")
shp &lt;- readOGR(dsn=folder,layer=lyr)
plot(shp, col=""""gray"""",border=""""blue"""", axes=TRUE)
</code></pre>

<p>Both plot() commands give the same R result. No errors occur. only the following message</p>

<pre><code>OGR data source with driver: ESRI Shapefile 
Source: """"P:/Victoria_DSE/BFAST_spatial/vector/PLM_excl_fire03_09_GDA94LL/mgaz94z55/clipped_EG"""", layer: """"clipped_forest_mga""""
with 1 features and 4 fields
Feature type: wkbMultiPolygon with 2 dimensions
</code></pre>

<p>How can this be solved?</p>
",1
"<p>1) long to wide question:</p>

<p>I have a dataset with 3 columns:
person, event, frequency.
If the frequency is zero, the row is not in the table. Is there a simple way using basic R functions or libraries to convert this table to wide format, with one row per person and one column per event with the frequency as the value in table. </p>

<p>2) rattle question: </p>

<p>On a related note, is this even necessary for Rattle to understand as an input?</p>

<p>I am trying to import some data into R to explore some of Rattle's machine learning algorithms.</p>

<p>Thanks!
Patrick McCann</p>
",1
"<p>I like the plyr syntax. Any time I have to use one of the *apply() commands I end up kicking the dog and going on a 3 day bender. So for the sake of my dog and my liver, what's concise syntax for doing a ddply operation on every row of a data frame?</p>

<p>Here's an example that works well for a simple case:</p>

<pre><code>x &lt;- rnorm(10)
y &lt;- rnorm(10)
df &lt;- data.frame(x,y)
ddply(df,names(df) ,function(df) max(df$x,df$y))
</code></pre>

<p>that works fine and gives me what I want. But if things get more complex this causes plyr to get funky (and not like Bootsy Collins) because plyr is chewing on making """"levels"""" out of all those floating point values</p>

<pre><code>x &lt;- rnorm(1000)
y &lt;- rnorm(1000)
z &lt;- rnorm(1000)
myLetters &lt;- sample(letters, 1000, replace=T)
df &lt;- data.frame(x,y, z, myLetters)
ddply(df,names(df) ,function(df) max(df$x,df$y))
</code></pre>

<p>on my box this chews for a few minutes and then returns:</p>

<pre><code>Error: memory exhausted (limit reached?)
In addition: Warning messages:
1: In paste(rep(l, each = ll), rep(lvs, length(l)), sep = sep) :
  Reached total allocation of 1535Mb: see help(memory.size)
2: In paste(rep(l, each = ll), rep(lvs, length(l)), sep = sep) :
  Reached total allocation of 1535Mb: see help(memory.size)
</code></pre>

<p>I think I am totally abusing plyr and I am not saying this is a bug in plyr, but rather abusive behavior by me (liver and dog notwithstanding).</p>

<p>So in short, is there syntax shortcut for using ddply to operate on every row as a substitute for <code>apply(X, 1, ...)</code>?</p>

<p>The workaround I've been using is to create a """"key"""" that gives a unique value for every row and then I can join back to it. </p>

<pre><code> x &lt;- rnorm(1000)
 y &lt;- rnorm(1000)
 z &lt;- rnorm(1000)
 myLetters &lt;- sample(letters, 1000, replace=T)
 df &lt;- data.frame(x,y, z, myLetters)
  #make the key
 df$myKey &lt;- 1:nrow(df)
 myOut &lt;- merge(df, ddply(df,""""myKey"""" ,function(df) max(df$x,df$y)))
  #knock out the key
 myOut$myKey &lt;- NULL
</code></pre>

<p>But I keep thinking that """"There Has to Be a Better Way""""</p>

<p>Thanks! </p>
",1
"<p>I've been trying to dig into what the time-hogs are in some R code I've written, so I'm using <code>Rprof</code>.  The output isn't yet very helpful though:</p>

<pre><code>&gt; summaryRprof()
$by.self
                      self.time self.pct total.time total.pct
""""$&lt;-.data.frame""""           2.38     23.2       2.38      23.2
""""FUN""""                      2.04     19.9      10.20      99.6
""""[.data.frame""""             1.74     17.0       5.54      54.1
""""[.factor""""                 1.42     13.9       2.90      28.3
...
</code></pre>

<p>Is there some way to dig deeper and find out which specific invocations of <code>$&lt;-.data.frame</code>, and <code>FUN</code> (which is probably from <code>by()</code>), etc. are actually the culprits?  Or will I need to refactor the code and make smaller functional chunks in order to get more fine-grained results?</p>

<p>The only reason I'm resisting refactoring is that I'd have to pass data structures into the functions, and all the passing is by value, so that seems like a step in the wrong direction.</p>

<p>Thanks.</p>
",1
"<p>I've got a dataset that looks like this...</p>

<blockquote>
<pre><code>mine tonnes week
AA   112    41
AA   114    41
AA   119    41
BB   108    41 
BB   112    41
AA   110    42
AA   109    42
AA   102    43
AA   101    43
</code></pre>
</blockquote>

<p>And I want to create a boxplot in ggplot2 to show the distribution of tonnes for each week. But I only want results from mine AA.</p>

<p>I thought it would work like this....</p>

<pre><code>qplot(factor(week), tonnes[mine == """"AA""""], data = sql_results, geom = """"boxplot"""")
</code></pre>

<p>But instead, I get this error.</p>

<pre><code>Error in data.frame(x = c(13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L,  :

  arguments imply differing number of rows: 423100, 109436
</code></pre>

<p>It's probably dead simple, but I'm not having much luck figuring the right way to do this.</p>
",1
"<p>I have some shapefiles I want to plot over Google Maps tiles. What's the most efficient way to do this? One path might be to use the pkg RgoogleMaps, however, it is still unclear to me how to do this. I assume using PlotonStaticMap with some combination of reformatting the shapefile data</p>
",1
"<p>I have a guest list that has a last name in one column and then in another column I have the first names or the full names (first space last) of each person in the family. I am wanting to get the other column to just have the first names. </p>

<pre><code>gsub(guest.w$Last.Name,"""""""",guest.w$Party.Name.s.)
</code></pre>

<p>That would work perfectly if I just had one row but how do it do it for each row in the dataframe. Do I have to write a for loop? Is there a way to do it in parallel similarly to the way pmax() relates to max().</p>

<p>My problem is similar in a way to a <a href=""""https://stackoverflow.com/questions/1355355/how-to-avoid-a-loop-in-r-selecting-items-from-a-list"""">previously asked question by JD Long</a> but that question was a piece of cake compared to mine. </p>

<h2>Example</h2>

<p>:</p>

<p>Smith;  Joe Smith, Kevin Smith, Jane Smith<br>
Alter; Robert Alter, Mary Alter, Ronald Alter  </p>

<p>Becomes</p>

<p>Smith; Joe, Kevin, Jane<br>
Alter; Robert, Mary, Ronald  </p>
",1
"<p>I am reading Elements of Statistical Learning <a href=""""http://www-stat.stanford.edu/~tibs/ElemStatLearn/"""" rel=""""nofollow noreferrer"""">ESLII</a> and in chapter 2, they have a gaussian mixture data set to illustrate some learning algorithms. To generate this data set, they first generate 10 means from a bivariate gaussian distribution N((1,0)', I). I am not sure what they mean?</p>

<p>How can you generate 10 means from a bivariate distribution having mean(1,0)?</p>
",1
"<p>I have a list containing 98 items. But each item contains 0, 1, 2, 3, 4 or 5 character strings.</p>

<p>I know how to get the length of the list and in fact <a href=""""https://stackoverflow.com/questions/1740524/r-count-number-of-objects-in-list"""">someone has asked the question before</a> and got voted down for presumably asking such an easy question.</p>

<p>But I want a vector that is 98 elements long with each element being an integer from 0 to 5 telling me how many character strings there are in each list item.
I was expecting the following to work but it did not.</p>

<pre><code>lapply(name.of.list,length())
</code></pre>

<p>From my question you will see that I do not really know the nomeclature of lists and items. Feel free to straighten me out.</p>
",1
"<p>Is there a way - other than a for loop - to generate new variables in an R dataframe, which will be all the possible 2-way interactions between the existing ones?
i.e. supposing a dataframe with three numeric variables V1, V2, V3, I would like to generate the following new variables:</p>

<pre><code>Inter.V1V2 (= V1 * V2) 
Inter.V1V3 (= V1 * V3)
Inter.V2V3 (= V2 * V3)
</code></pre>

<p>Example using for loop :</p>

<pre><code>x &lt;- read.table(textConnection('
   V1 V2 V3 V4
1  9   25   18
2  5   20   10
3  4   30   12
4  4   34   16'
), header=TRUE)

dim.init &lt;- dim(x)[2]
for (i in 1: (dim.init - 1) ) {
        for (j in (i + 1) : (dim.init) ) {
                x[dim(x)[2] + 1]    &lt;- x[i] * x[j]
                names(x)[dim(x)[2]] &lt;- paste(""""Inter.V"""",i,""""V"""",j,sep="""""""")

        }
}
</code></pre>
",1
"<p>Has anybody used ggplot2 along with rpanel to produce interactive plots. Here is a piece of code that I adapted from rpanel to plot a Poisson distribution and have a slider to change the parameter value.</p>

<p>However, the plot changes too slowly as I change the parameters using the slider. When I change the plot function to use Lattice, it is much faster. Is this a limitation of ggplot2 in terms of speed? Is there a way to overcome this?</p>

<pre><code>poisson.draw = function(panel) {
  with(panel, {
     x = seq(0,n, by = 1)
     library(ggplot2)
     y = dpois(x, lambda)
     d = data.frame(cbind(x,y))
     p1 = ggplot(d, aes(x,y)) + geom_point()
     print(p1)
  })
  panel
}
panel &lt;- rp.control(""""Poisson distribution"""", n = 30, lambda = 3, 
  ylim = 0.5)
rp.slider(panel, lambda, 1, 30, poisson.draw)
</code></pre>
",1
"<p>I want to submit my submissions to <a href=""""http://analyticsx.com/"""" rel=""""nofollow noreferrer"""">this competition</a> automatically from my code. I need to log-in on <a href=""""http://analyticsx.com/analyticsx/Login"""" rel=""""nofollow noreferrer"""">this page</a> and then submit a file on <a href=""""http://analyticsx.com/analyticsx/Controller?REQUEST_COMMAND=User&amp;REQUEST_SUB_COMMAND=SubmitPred"""" rel=""""nofollow noreferrer"""">this page</a>. I'd like to use cURL since it integrates with both of the languages that I am using (R and Python). </p>

<p>I am just wondering if this procedure is possible in cURL? and my another question is if I can use cURL inside MS Excel?</p>
",1
"<p>Q1: 
I have been trying to get the AUC value for a classification problem and have been trying to use e1071 and ROCR packages in R for this. ROCR has a nice example """"ROCR.simple"""" which has prediction values and label values.</p>

<pre><code>library(ROCR)
data(ROCR.simple)
pred&lt;-prediction(ROCR.simpe$predictions, ROCR.simple$labels)
auc&lt;-performance(pred,""""auc"""")
</code></pre>

<p>This gives the AUC value, no problem.
MY PROBLEM is: How do I get the type of data given by <code>ROCR.simple$predictions</code> in the above example?
I run my analysis like</p>

<pre><code>library(e1071)
data(iris)
y&lt;-Species
x&lt;-iris[,1:2]
model&lt;-svm(x,y)
pred&lt;-predict(model,x)
</code></pre>

<p>Upto here I'm ok. 
Then how do I get the kind of predictions that <code>ROCR.simpe$predictions</code> give?</p>

<p>Q2:</p>

<p>there is a nice example involving <code>ROCR.xvals</code>. This is a problem with 10 cross validations.</p>

<p>They run</p>

<pre><code>pred&lt;-prediction(ROCR.xval$predictions,ROCR.xval$labels)
auc&lt;-performance(pred,""""auc"""")
</code></pre>

<p>This gives results for all 10 cross validations.</p>

<p>My problem is:</p>

<p>How do I use </p>

<pre><code>model&lt;-svm(x,y,cross=10)     # where x and y are as given in Q1
</code></pre>

<p>and get all 10 results of predictions and labels into a list as given in <code>ROCR.xvals</code>?</p>
",1
"<p>After performing a cluster analysis to my dataset (a dataframe named <em>data.matrix</em>), I added a new column, named <em>cluster</em>, at the end (col 27) containing the cluster name that each instance belongs to.</p>

<p>What I want now, is a representative instance from each cluster. I tried to find the instance having the smallest euclidean distance from the cluster's centroid (and repeat the procedure for each one of my clusters)</p>

<p>This is what I did. Can you think of other -perhaps more elegant- ways? (assume numeric columns with no nulls). </p>

<pre><code>clusters &lt;- levels(data.matrix$cluster)
cluster_col = c(27)

for (j in 1:length(clusters)) {
    # get the subset for cluster j
    data = data.matrix[data.matrix$cluster == clusters[j],]

    # remove the cluster column
    data &lt;- data[,-cluster_col]

    # calculate the centroid
    cent &lt;- mean(data)

    # copy data to data.matrix_cl, attaching a distance column at the end
    data.matrix_cl &lt;- cbind(data, dist = apply(data, 1, function(x) {sqrt(sum((x - cent)^2))}))

    # get instances with min distance
    candidates &lt;- data.matrix_cl[data.matrix_cl$dist == min(data.matrix_cl$dist),]

    # print their rownames
    print(paste(""""Candidates for cluster """",j))
    print(rownames(candidates))
}
</code></pre>
",1
"<p>I'm using Emacs 23.1 with ESS 5.4 to edit an Sweave file.  I'd like to turn off the default AUCTeX indentation behavior in the buffer (to avoid annoyances with code chunks contained in itemized lists), so at the top of the file I have <code>% -*- LaTeX-indent-level: 0; LaTeX-item-indent: 0; -*-</code>.  When I open the buffer and run <code>C-h v LaTeX-indent-level</code>, I get what I wanted:</p>

<pre><code>LaTeX-indent-level is a variable defined in `latex.el'.
Its value is 0
Local in buffer test.Rnw; global value is 2

  This variable is a file local variable.
</code></pre>

<p>However, after I edit a code chunk, it returns to the default behavior. <code>C-h v LaTeX-indent-level</code> now yields:</p>

<pre><code>LaTeX-indent-level is a variable defined in `latex.el'.
Its value is 2
</code></pre>

<p>I tried the fix suggested in <a href=""""http://www.cs.tufts.edu/~nr/noweb/FAQ.html#toc6"""" rel=""""nofollow noreferrer"""">the noweb-mode FAQ</a>, which suggests adding</p>

<pre><code>(add-hook 'noweb-select-mode-hook
              '(lambda () (hack-local-variables-prop-line)))
</code></pre>

<p>to my .emacs.  The behavior described above persisted when I did this.</p>

<p>Is there any way I can get buffer-local variables to work in this situation?  I would prefer not to have to change my .emacs to set <code>LaTeX-indent-level</code> to 0 in all Sweave/noweb buffers.</p>
",1
"<p>Is there a simple way to programmatically determine if an R script is being executed in Windows vs. Linux?</p>
",1
"<p>If I have a vector of type character in R, how can I concatenate the values into string? Here's how I would do it with paste():</p>

<pre><code>sdata = c('a', 'b', 'c')
paste(sdata[1], sdata[2], sdata[3], sep='')
</code></pre>

<p>yielding """"abc"""".  But of course, that only works if I know the length of sdata ahead of time.</p>
",1
"<p>I have an ultra short question about R</p>

<p>My aim is to assign a common title to a multi-panel plot generated using par, e.g.</p>

<pre><code>par(mfrow=c(1,2))
plot(rnorm(1000))
plot(rnorm(1000))
</code></pre>

<p>So, something like """"main"""" for the plot function, but extended to both plots. Is there a canonical way to do this?</p>

<p>Thanks for any answer :-)</p>
",1
"<p>I have a 16x16 matrix of grayscale values representing handwriting digits. Is there a plot in R that I can use to visualize it?</p>

<p>Matlab has pcolor, I am looking for something along those lines.
<a href=""""http://www.mathworks.com/access/helpdesk/help/techdoc/ref/pcolor.html"""" rel=""""nofollow noreferrer"""">pcolor</a></p>
",1
"<p>I have filenames named <code>&lt;InputData&gt;.&lt;TestName&gt;.csv</code> and I'd like to make graphs for each test.  The best way I can see to do this is to make one R table for each TestName.  Each test produces the same columns of data, so I'd like to pull in all the data for each test into an R datatable with an extra column for the inputdata.  </p>

<p>I'd like to do:</p>

<pre><code>read.tables(c(""""B217.SE.csv"""", """"C10.SE.csv""""), sep="""","""")
</code></pre>

<p>produces (for example):</p>

<pre><code>       Filename  col1   col2
1   B217.SE.csv     1      2
2   B217.SE.csv     2      4
3   C10.SE.csv      3      1
4   C10.SE.csv      4      5
</code></pre>

<p>What's the right way to do this?  Some existing function I don't know about?  Writing it out in the R language using a for loop?</p>
",1
"<p>I'm having a strange problem with the output window in RGui (under Win XP). I should see a plot like the one below...</p>

<p><a href=""""http://img402.imageshack.us/img402/7483/ss20100121153931.png"""">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p>... when I run this script:</p>

<pre><code>library(ggplot2)
x &lt;- rnorm(100,0,1)
y &lt;- rnorm(100,0,1)
z &lt;- data.frame(x,y) 
g &lt;- ggplot(z, aes(x,y)) + geom_point() + theme_gray()
</code></pre>

<p>Instead, in the plot window it shows a white background and white grid lines, like below.</p>

<p><strong>R Plot Window</strong></p>

<p><a href=""""http://img192.imageshack.us/img192/5349/ss20100121160230.png"""">alt text http://img192.imageshack.us/img192/5349/ss20100121160230.png</a></p>

<p>When I export the plot to .png and I """"preview"""" it in windows explorer - it doesn't show a background or grid lines. </p>

<p><strong>Png in Windows</strong></p>

<p><a href=""""http://img192.imageshack.us/img192/5349/ss20100121160230.png"""">alt text http://img192.imageshack.us/img192/5349/ss20100121160230.png</a></p>

<p><strong>Same Png in Gimp</strong></p>

<p><a href=""""http://img402.imageshack.us/img402/7483/ss20100121153931.png"""">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p><strong>Same Png uploaded to image hosting</strong></p>

<p><a href=""""http://img402.imageshack.us/img402/7483/ss20100121153931.png"""">alt text http://img402.imageshack.us/img402/7483/ss20100121153931.png</a></p>

<p>Any ideas about what's going on? How can I get the plot to display correctly in RGui?</p>
",1
"<p>I used the information from this post to create a histogram with logarithmic scale:
<a href=""""https://stackoverflow.com/questions/1245273/histogram-with-logarithmic-scale"""">Histogram with Logarithmic Scale</a></p>

<p>However, the output from plot looks nothing like the output from hist. Does anyone know how to configure the output from plot to resemble the output from hist? Thanks for the help.</p>
",1
"<p>I have a ggplot2 plot that looks like this:</p>

<p><a href=""""http://img69.imageshack.us/img69/9704/plot.png"""" rel=""""noreferrer"""">alt text http://img69.imageshack.us/img69/9704/plot.png</a></p>

<p>from the following R code:</p>

<pre><code>ggplot(newdata, aes(benefit, cost, colour = factor(opt), shape = factor(roster)))

+ facet_grid(. ~ location)
</code></pre>

<p>It's exactly what I need, except that the graph is too wide to be clearly read. </p>

<p>I'd like to be able to take the four rightmost locations and place them under the four leftmost, such that the scatter plots are ordered like this.</p>

<blockquote>
<pre><code>Adelaide   Brisbane   Cairns      Canberra

Darwin     Hobart     Melbourne   Sydney
</code></pre>
</blockquote>

<p>Can I do this with facet_grid()? Or should I just create two plots and line them up in GIMP?</p>

<p>The documentation on <a href=""""http://had.co.nz/ggplot2/facet_grid.htmltwo"""" rel=""""noreferrer"""">facet_grid()</a> doesn't seem to indicate that it's possible.</p>

<p>Thanks for the help :-)</p>
",1
"<p>I would like to program a time series class. The idea is that I instantiate an object with an expression and some other time series objects, for instance</p>

<p>(two time series)  </p>

<pre><code>x &lt;- ts(rnorm(10), frequency = 4, start = c(1959, 2))  
y &lt;- ts(rnorm(10), frequency = 4, start = c(1959, 2))  
</code></pre>

<p>(a time series, defined to be the sum of x and y)  </p>

<pre><code>z &lt;- exprTs(""""x+y"""", parents=list(x=x, y=y)) 
</code></pre>

<p>(get some part of the series)  </p>

<pre><code>window(z, start=1960, end=1960.75)
</code></pre>

<p>The problem is, how can I evaluate the expression? I tried the following:</p>

<pre><code>#(constructor for class)  
exprTs &lt;- function(expr, parents) {  
  res = list(expr=expr, parents=parents)  
  class(res) &lt;- """"exprTs""""  
  res  
}  

#(window method)  
window.exprTs &lt;- function(z, ...) {  
  eval(substitute(z$expr, lapply(z$parents, window, ...)))  
  #do.call(z$expr, lapply(z$parents, window, ...))  
}  
</code></pre>

<p>I can not get the window method to work.</p>

<p>If you could guide me to how to use substitute, eval, do.call appropriately, that would be very helpful.</p>
",1
"<p>I have a data.frame, d1, that has 7 columns, the 5th through 7th column are supposed to be numeric: </p>

<pre><code>str(d1[5])
'data.frame':   871 obs. of  1 variable:
 $ Latest.Assets..Mns.: num  14008 1483 11524 1081 2742 ... 

is.numeric(d1[5])
[1] FALSE

as.numeric(d1[5])
Error: (list) object cannot be coerced to type 'double'
</code></pre>

<p>How can this be? If str identifies it as numeric, how can it not be numeric? I'm importing from CSV. </p>
",1
"<p>This is a bit of a shot in the dark, but I have a script that does exactly what I expect it to do, yet, at the very end of the script I get an error like this: </p>

<pre><code>Error in `[&lt;-.data.frame`(`*tmp*`, """"label"""", value = c(1L, 0L)) : 
  replacement has 2 rows, data has 0
</code></pre>

<p>In terms of an answer, I'm looking for general suggestions on how to track errors like this in R, best practices for using loops and double checking that they """"made it through"""". </p>

<p>Any thoughts, suggestions, or past experiences that could relegate or inform an error message like this? </p>
",1
"<p>I have a nearly-boxplot like jitter-plot:</p>

<pre><code>dt &lt;- rbind(se,cb,cb.se)
qplot(ds, size, data=dt, geom=""""jitter"""", colour=root, facets = test ~ .)
</code></pre>

<p><a href=""""http://i50.tinypic.com/1zbfjih.png"""">plot http://i50.tinypic.com/1zbfjih.png</a></p>

<p>I'd love to put a summary label for each group in the middle of the plot - for example the size totals here:</p>

<pre><code> aggregate(list(size=dt$size), list(dt$ds, dt$test), sum)

   Group.1  Group.2   size
1     b217       se   9847
2      c10       se  97296
3     c613       se  21633
4       c7       se 207540
...
</code></pre>

<p>I've tried using <code>+ geom_text(aes(x=ds, y=128, label=sum(size)), size=2)</code> to add labels, but I get the same label on each position - how can I get the sum of just that section of data?</p>

<p><strong>Edit:</strong>
Here's where I'm at now - maybe I'm just going in the wrong direction</p>

<pre><code>data &lt;- rbind(se,cb,cb.se)
labels &lt;-ddply(data, c(""""ds"""", """"test""""), function(df) sum(df$size))
ggplot(data=data, aes(x=ds)) +
  geom_jitter(aes(y=size, colour=root)) +
  geom_text(data=labels, aes(x=ds, y=600, label=V1), size=3) +
  facet_wrap(test ~ .)
</code></pre>

<p>This code doesn't work - I get an <code>undefined columns selected</code> error... somewhere.  Maybe it's because of the multiple <code>data=</code> sections?  </p>
",1
"<p>I have a 2-D array in R which represents value data for a grid of rows and columns.  It looks like this:</p>

<pre><code>     [,1] [,2] [,3] [,4]
[1,]    1    1    2    1
[2,]    1    5    6    3
[3,]    2    3    2    1
[4,]    1    1    1    1
</code></pre>

<p>I want to """"smooth"""" these values.  At this proof-of-concept point, I am fine with using any popular smoothing function.  I am currently attempting to use the <code>smooth.spline</code> function:</p>

<pre><code>smooth.spline(x, y = NULL, w = NULL, df, spar = NULL,
              cv = FALSE, all.knots = FALSE, nknots = NULL,
              keep.data = TRUE, df.offset = 0, penalty = 1,
              control.spar = list())
</code></pre>

<p>by (naively) calling</p>

<pre><code>smoothed &lt;- smooth.spline(myarray)
</code></pre>

<p>When I run this, I get this error:</p>

<blockquote>
  <p>Error in smooth.spline(a) : need at least four unique 'x' values</p>
</blockquote>

<p>My array has four or more unique values in each dimension, so I am thinking that I do not know how to properly format the input data.  Can someone give me some pointers to this kind of thing?  The examples for <code>smooth</code>-like functions seem to work with single-dimension vectors, and I can't seem to extrapolate to the 2-D world.  I am an R novice, so please feel free to correct my misuse of terms here!</p>
",1
"<p>I wish to perform a social network analysis on a bunch of blogs, plotting who is linking to who (not just by their blogroll but also inside their posts). What software can perform such crawling/data-collecting/mapping ?</p>

<p>Thanks!</p>
",1
"<p>In python lists can be sliced like this <code>x[4:-1]</code> to get from the fourth to the last element.</p>

<p>In R something similar can be accomplished for vectors with <code>x[4:length(x)]</code> and for multidimensional arrays with something like <code>x[,,,,4:dim(x)[5],,,]</code>.  Is this more elegant syntax for array slicing for a particular dimension from an element in the middle to the last element?</p>

<p>Thanks    </p>
",1
"<p>I have a data frame with about 40 columns, the second column, data[2] contains the name of the company that the rest of the row data describes. However, the names of the companies are different depending on the year (trailing 09 for 2009 data, nothing for 2010). </p>

<p>I would like to be able to subset the data such that I can pull in both years at once. Here is an example of what I'm trying to do...</p>

<pre><code>subset(data, data[2] == """"Company Name 09"""" | """"Company Name"""", drop = T) 
</code></pre>

<p>Essentially, I'm having difficulty using the OR operator within the subset function. </p>

<p>However, I have tried other alternatives:</p>

<pre><code>subset(data, data[[2]] == grep(""""Company Name"""", data[[2]]))
</code></pre>

<p>Perhaps there's an easier way to do it using a string function? </p>

<p>Any thoughts would be appreicated.</p>
",1
"<p>I used the data, aml in survival package in R and computed a survival function by
""""survfit"""". Since the result of survfit doesn't show the mean value,
I used the following code to print the mean:</p>

<pre><code>&gt; print(survfit(Surv(aml1$time,aml1$status)~1),show.rmean=T)
</code></pre>

<p>(the data I used is, <code>aml1 &lt;-aml[aml$x=""""Maintained"""",]</code>)</p>

<p>The code above worked in my friend pc, but not mine.
So, I thought about downloading  some extra package to use <code>print(...show.rmean=T)</code>.
But, """"print"""" is basic, so I don't need anything to run  print.
Then why I can't get the mean value?</p>
",1
"<p>I want to create a histogram from a number of observations (i.e. d &lt;- c(1,2.1,3.4,4.5) ) and then highlight the bin that a particular observation falls in, such that I have an output that looks like this:
<a href=""""http://img686.imageshack.us/img686/5061/observationhist.png"""">alt text http://img686.imageshack.us/img686/5061/observationhist.png</a></p>

<p>how do I do this in R?</p>
",1
"<p>How can I create a new on-screen R plot window with a particular width and height (in pixels, etc.)?</p>
",1
"<p>I have imported data with a five minute interval into a zoo object, where the index is a chron with both date and time:</p>

<pre>
> d
(09/09/09 16:45:10)  13.2  5.8
(09/09/09 16:50:10)   8.3  0.7
(09/09/09 16:55:10)   4.7  0.7
(09/09/09 17:00:10)   6.6  0.7
(09/09/09 17:05:10)   4.6  0.7
</pre>

<p>I am trying to aggregate by quarter hour intervals.</p>

<p>I found way to do so by converting back to a string, but the output is no longer a zoo.</p>

<pre>
> r =data.frame(aggregate(d,trunc(chron(times=substr(as.character(index(d)),11,18)),""""00:15:00""""), mean)
> r
00:00:00   0.5644444
00:15:00   0.5400000
00:30:00   0.5488889
00:45:00   0.6155556
01:00:00   0.3422222
</pre>

<p>While I can plot this, I was trying to do this natively. I found that aggregate with zoo could do day and hour, but I could not subdivide the hour.</p>
",1
"<p>One of the most important issues in using factor analysis is its interpretation. Factor analysis often uses factor rotation to enhance its interpretation. After a satisfactory rotation, the rotated factor loading matrix <strong>L'</strong> will have the same ability to represent the correlation matrix and it can be used as the factor loading matrix, instead of the unrotated matrix <strong>L</strong>.</p>

<p>The purpose of rotation is to make the rotated factor loading matrix have some desirable properties. One of the methods used is to rotate the factor loading matrix such that the rotated matrix will have a <strong>simple structure</strong>.</p>

<p>L. L. Thurstone introduced the Principle of Simple Structure, as a general guide for factor rotation:</p>

<h2>Simple Structure Criteria:</h2>

<ol>
<li>Each row of the factor matrix should contain at least one zero</li>
<li>If there are m common factors, each column of the factor matrix should have at least m zeros</li>
<li>For every pair of columns in the factor matrix, there should be several variables for which entries approach zero in the one column but not in the other</li>
<li>For every pair of columns in the factor matrix, a large proportion of the variables should have entries approaching zero in both columns when there are four or more factors</li>
<li>For every pair of columns in the factor matrix, there should be only a small number of variables with nonzero entries in both columns</li>
</ol>

<p>The ideal simple structure is such that:</p>

<ol>
<li>each item has a high, or meaningful, loading on one factor only and</li>
<li>each factor have high, or meaningful, loadings for only some of the items.</li>
</ol>

<p>The problem is that, trying several combinations of rotation methods along with the parameters that each one accepts (especially for oblique ones), the number of candidate matrices increases and it is very difficult to see which one better meets the above criteria.</p>

<p>When I first faced that problem I realized that I was unable to select the best match by merely 'looking' at them, and that I needed an algorithm to help me decide. Under the stress of project's deadlines, the most I could do was to write the following code in MATLAB, which accepts one rotation matrix at a time and returns (under some assumptions) whether each criterion is met or not.
A new version (If I would ever tried to upgrade it) would accept a 3d matrix (a set of 2d matrices) as an argument, and the algorithm should return the one that better fits the above criteria.</p>

<p>I am just asking for your opinions (I also think that there's been criticism over the usefulness of the method by itself) and perhaps better approaches to the rotation matrix selection problem. If someone wants to provide some code, I would prefer R or MATLAB. </p>

<p>P.S. The above <a href=""""http://books.google.gr/books?id=5Jyaa2LQWbQC&amp;pg=PA132&amp;lpg=PA132&amp;dq=%22The+criteria+of+simple+structure+was+originally+proposed%22&amp;source=bl&amp;ots=OXsCeU0Nzi&amp;sig=qfiLMUyXsgwPunWBgNdSEeBNm34&amp;hl=el&amp;ei=huZeS5nkApTE4gaC67HsCw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CAcQ6AEwAA#v=onepage&amp;q=%22The%20criteria%20of%20simple%20structure%20was%20originally%20proposed%22&amp;f=false"""" rel=""""nofollow noreferrer"""">Simple Structure Criteria formulation</a> can be found in the book <em>""""Making Sense of Factor Analysis""""</em> by PETT, M., LACKEY, N., SULLIVAN, J.</p>

<p>P.S.2 (from the same book): <em>""""A test of successful factor analysis is the extent to which it can reproduce the original corr matrix. If you also used oblique solutions, among all select the one that generated the greatest number of highest and lowest factor loadings.""""</em> 
This sounds like another constraint that the algorithm could use.</p>

<pre><code>function [] = simple_structure_criteria (my_pattern_table)
%Simple Structure Criteria
%Making Sense of Factor Analysis, page 132

disp(' ');
disp('Simple Structure Criteria (Thurstone):');
disp('1. Each row of the factor matrix should contain at least one zero');
disp( '2. If there are m common factors, each column of the factor matrix should have at least m zeros');
disp( '3. For every pair of columns in the factor matrix, there should be several variables for which entries approach zero in the one column but not in the other');
disp( '4. For every pair of columns in the factor matrix, a large proportion of the variables should have entries approaching zero in both columns when there are four or more factors');
disp( '5. For every pair of columns in the factor matrix, there should be only a small number of variables with nonzero entries in both columns');
disp(' ');
disp( '(additional by Pedhazur and Schmelkin) The ideal simple structure is such that:');
disp( '6. Each item has a high, or meaningful, loading on one factor only and');
disp( '7. Each factor have high, or meaningful, loadings for only some of the items.');

disp('')
disp('Start checking...')

%test matrix
%ct=[76,78,16,7;19,29,10,13;2,6,7,8];
%test it by giving: simple_structure_criteria (ct)

ct=abs(my_pattern_table);

items=size(ct,1);
factors=size(ct,2);
my_zero = 0.1;
approach_zero = 0.2;
several = floor(items / 3);
small_number = ceil(items / 4);
large_proportion = 0.30;
meaningful = 0.4;
some_bottom = 2;
some_top = floor(items / 2);

% CRITERION 1
disp(' ');
disp('CRITERION 1');
for i = 1 : 1 : items
    count = 0;
    for j = 1 : 1 : factors
        if (ct(i,j) &lt; my_zero)
            count = count + 1;
            break
        end
    end
    if (count == 0)
        disp(['Criterion 1 is NOT MET for item ' num2str(i)])
    end
end


% CRITERION 2
disp(' ');
disp('CRITERION 2');
for j = 1 : 1 : factors 
    m=0;
    for i = 1 : 1 : items
        if (ct(i,j) &lt; my_zero)
            m = m + 1;
        end
    end
    if (m &lt; factors)
        disp(['Criterion 2 is NOT MET for factor ' num2str(j) '. m = ' num2str(m)]);
    end
end

% CRITERION 3
disp(' ');
disp('CRITERION 3');
for c1 = 1 : 1 : factors - 1
    for c2 = c1 + 1 : 1 : factors
        test_several = 0;
        for i = 1 : 1 : items
            if ( (ct(i,c1)&gt;my_zero &amp;&amp; ct(i,c2)&lt;my_zero) || (ct(i,c1)&lt;my_zero &amp;&amp; ct(i,c2)&gt;my_zero) ) % approach zero in one but not in the other
                test_several = test_several + 1;
            end
        end
        disp(['several = ' num2str(test_several) ' for factors ' num2str(c1) ' and ' num2str(c2)]);
        if (test_several &lt; several)
            disp(['Criterion 3 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2)]);
        end
    end
end

% CRITERION 4
disp(' ');
disp('CRITERION 4');
if (factors &gt; 3)
    for c1 = 1 : 1 : factors - 1
        for c2 = c1 + 1 : 1 : factors
            test_several = 0;
            for i = 1 : 1 : items
                if (ct(i,c1)&lt;approach_zero &amp;&amp; ct(i,c2)&lt;approach_zero) % approach zero in both
                    test_several = test_several + 1;
                end
            end
            disp(['large proportion = ' num2str((test_several / items)*100) '% for factors ' num2str(c1) ' and ' num2str(c2)]);
            if ((test_several / items) &lt; large_proportion)
                pr = sprintf('%4.2g',  (test_several / items) * 100 );
                disp(['Criterion 4 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2) '. Proportion is ' pr '%']);
            end
        end
    end
end

% CRITERION 5
disp(' ');
disp('CRITERION 5');
for c1 = 1 : 1 : factors - 1
    for c2 = c1 + 1 : 1 : factors
        test_number = 0;
        for i = 1 : 1 : items
            if (ct(i,c1)&gt;approach_zero &amp;&amp; ct(i,c2)&gt;approach_zero) % approach zero in both
                test_number = test_number + 1;
            end
        end
        disp(['small number = ' num2str(test_number) ' for factors ' num2str(c1) ' and ' num2str(c2)]);
        if (test_number &gt; small_number)
            disp(['Criterion 5 is NOT MET for factors ' num2str(c1) ' and ' num2str(c2)]);
        end
    end
end

% CRITERION 6
disp(' ');
disp('CRITERION 6');
for i = 1 : 1 : items
    count = 0;
    for j = 1 : 1 : factors
        if (ct(i,j) &gt; meaningful)
            count = count + 1;
        end
    end
    if (count == 0 || count &gt; 1)
        disp(['Criterion 6 is NOT MET for item ' num2str(i)])
    end
end

% CRITERION 7
disp(' ');
disp('CRITERION 7');
for j = 1 : 1 : factors 
    m=0;
    for i = 1 : 1 : items
        if (ct(i,j) &gt; meaningful)
            m = m + 1;
        end
    end
    disp(['some items = ' num2str(m) ' for factor ' num2str(j)]);
    if (m &lt; some_bottom || m &gt; some_top)
        disp(['Criterion 7 is NOT MET for factor ' num2str(j)]);
    end
end
disp('')
disp('Checking completed.')
return
</code></pre>
",1
"<p>I'm using the SQlite package to interface with a database from R. However, I'm running into the issue that the results from exactly the same query are different when I run it in R or from the command-line interface. 
For instance, the minimum value in a column is 0, but R somehow gives the result -2147332296. As I just copy-n-paste the query, I don't think the problem is in the query. The only thing I can think of is that there might be a problem with conversion between datatypes. The maximum value in that same column is 147031553000 and the type of the column is """"integer"""". Perhaps this value is too big for the datatype which R uses and this results in the negative value?</p>

<p>However, there is one more problem. For the same query, R reports less results than when I run the query in the command-line interface. Does anyone here have an idea as to why things might be going wrong?</p>
",1
"<p>Is there a way, in R, to pop up an error message if a function uses a variable
not declared in the body of the function: i.e, i want someone to flag this type of functions</p>

<pre><code>aha&lt;-function(p){
  return(p+n)
}
</code></pre>

<p>see; if there happens to be a """"n"""" variable lying somewhere, aha(p=2) will give me an """"answer"""" since R will just take """"n"""" from that mysterious place called the """"environment""""</p>
",1
"<p>Among the choices I have for quickly parallelizing simple code (<a href=""""http://cran.revolution-computing.com/web/packages/snowfall/index.html"""" rel=""""noreferrer"""">snowfall</a>, <a href=""""http://cran.revolution-computing.com/web/packages/foreach/index.html"""" rel=""""noreferrer"""">foreach</a>, and <a href=""""http://cran.revolution-computing.com/web/views/HighPerformanceComputing.html"""" rel=""""noreferrer"""">so on</a>), what are my options for showing the progress of all the slave processes?  Do any of the offerings excel in this regard?</p>

<p>I've seen that snowfall 1.70 has <code>sfCat()</code>, but it doesn't seem to cat output to the master R session.  </p>
",1
"<p>I would like to place the value for each bar in barchart (lattice) at the top of each bar. However, I cannot find any option with which I can achieve this. I can only find options for the axis.</p>
",1
"<p>How do I use <code>strptime</code> or any other functions to parse time stamps with milliseconds in R?</p>

<pre><code>time[1]
# [1] """"2010-01-15 13:55:23.975""""
strptime(time[1], format=""""%Y-%m-%d %H:%M:%S.%f"""")
# [1] NA
strptime(time[1], format=""""%Y-%m-%d %H:%M:%S"""")
# [1] """"2010-01-15 13:55:23""""`
</code></pre>
",1
"<p>I have a bunch of Stata .dta files that I would like to use in R.</p>

<p>My problem is that the variable names are not helpful to me as they are like """"q0100,"""" """"q0565,"""" """"q0500,"""" and """"q0202.""""  However, they are labelled like """"psu,"""" """"number of pregnant,"""" """"head of household,"""" and """"waypoint.""""</p>

<p>I would like to be able to grab the labels (""""psu,"""" """"waypoint,"""" etc. . .) and use them as my variable/column names as those will be easier for me to work with.</p>

<p>Is there a way to do this, either preferably in R, or through Stata itself?  I know of read.dta in library(foreign) but don't know if it can convert the labels into variable names.</p>
",1
"<p>I've got a R script for which I'd like to be able to supply several command-line parameters (rather than hardcode parameter values in the code itself).  The script runs on Windows.</p>

<p>I can't find info on how to read parameters supplied on the command-line into my R script.  I'd be surprised if it can't be done, so maybe I'm just not using the best keywords in my Google search...</p>

<p>Any pointers or recommendations?</p>
",1
"<p>I always have difficulty in finding all available alternative ways to produce a specific graph, either one that I have already decided to use (looking for different variations) or one that I have not yet thought of.</p>

<p>The <a href=""""http://bm2.genes.nig.ac.jp/RGM2/index.php?clear=all"""" rel=""""nofollow noreferrer"""">R Graphical Manual</a> site provides a complete list of samples of R's graphics functions, however it's easier for me to search providing a package name (how else -for example- can I get a resultset including <code>superbarplot</code> function, when I want to look for barplots?. Let alone that the superbarplot graph does not appear in the results even if I try searching for it's package: <code>UsingR</code>)</p>

<p>The <a href=""""http://sites.google.com/site/r4statistics/add-on-modules"""" rel=""""nofollow noreferrer"""">R-SAS-SPSS Add-on Module Comparison</a> - and especially on topic <code>Graphics, Static</code> in the table provided - gave me the idea that it would be nice to have a place where all relevant packages are listed by topic.</p>

<p>Do you have any idea about something like that?</p>
",1
"<p>Im trying to check for constance of variance for residuals  with boxplots .
But when I ran the following expression in R: </p>

<pre><code>boxplot(split(model$res,parental))
</code></pre>

<p>I get this error:</p>

<pre><code>Error in split.default(model$res, parental) : object 'parental' not found
</code></pre>

<p>What is it about ? </p>
",1
"<p>I am searching for good R package to allign multiple spectra.</p>

<p>Thanks.</p>
",1
"<p>How do I write R code that allows me to execute a different path in my code if an error condition happens? I'm using a function that tends to throw an error. When it meets an error condition I would like to execute a different function. Here's a specific example:</p>

<pre><code>require(SuppDists)
parms &lt;- structure(list(gamma = -0.841109044800762, delta = 0.768672140584442, 
    xi = -0.359199299528801, lambda = 0.522761187947026, type = """"SB""""), .Names = c(""""gamma"""", 
""""delta"""", """"xi"""", """"lambda"""", """"type""""))
pJohnson(.18, parms)
</code></pre>

<p>the pJohnson function should fail with the following error:</p>

<pre><code> Error in pJohnson(0.18, parms) :
 Sb values out of range.
</code></pre>

<p>I can make the error go silent by using:</p>

<pre><code>try( pJohnson(.18, parms), silent=T)
</code></pre>

<p>but what I really want to do is execute the function <code>alternativeFunction()</code> if <code>pJohnson(.18, parms)</code> returns an error. </p>

<p>It seems like the <code>withCallingHandlers()</code> function should help me out, but I can't figure out how to capture the error and make it run the <code>alternativeFunction()</code> only upon an error condition. </p>
",1
"<p>I have some data that looks like the following. It is grouped by variable """"Year"""" and I want to extract the percentiles of <em>each</em> observation of Score, with respect to the Year it is from, preferably as a vector.</p>

<pre><code>Year   Score
2001   89
2001   70
2001   72
2001   ...
..........
2004   87
2004   90
</code></pre>

<p>etc.</p>

<p>How can I do this? aggregate will not work, and I do not think apply will work either.</p>
",1
"<p>How can I create a chart like</p>

<p><a href=""""http://junkcharts.typepad.com/junk_charts/2010/01/leaving-ink-traces.html"""" rel=""""noreferrer"""">http://junkcharts.typepad.com/junk_charts/2010/01/leaving-ink-traces.html</a></p>

<p>where several time series (one per country) are displayed horizontally as symmetric areas?</p>

<p>I think if I could display one time series in this way, it is easy to generalize to several using mfrow.</p>

<p>Sample data:  </p>

<pre><code>#Solar energy production in Europe, by country (EC),(1 000 toe)  
Country,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007  
Belgium,1,1,1,1,1,1,2,2,3,3,3,5  
Bulgaria,-,-,-,-,-,-,-,-,-,-,-,-  
Czech Republic,0,0,0,0,0,0,0,0,2,2,3,4  
Denmark,6,7,7,8,8,8,9,9,9,10,10,11  
Germany (including ex-GDR from 1991),57,70,83,78,96,150,184,216,262,353,472,580  
Estonia,-,-,-,-,-,-,-,-,-,-,-,-  
Ireland,0,0,0,0,0,0,0,0,0,0,1,1  
Greece,86,89,93,97,99,100,99,99,101,102,109,160  
Spain,26,23,26,29,33,38,43,48,58,65,83,137  
France,15,16,17,18,26,19,19,18,19,22,29,37  
Italy,8,9,11,11,12,14,16,18,21,30,38,56  
Cyprus,32,33,34,35,35,34,35,36,40,41,43,54  
Latvia,-,-,-,-,-,-,-,-,-,-,-,-  
Lithuania,-,-,-,-,-,-,-,-,-,-,-,-  
Luxembourg (Grand-Duch),0,0,0,0,0,0,0,0,1,2,2,2  
Hungary,0,0,0,0,0,1,2,2,2,2,2,3  
Netherlands,6,7,8,10,12,14,16,19,20,22,22,23  
Austria,42,48,55,58,64,69,74,80,86,92,101,108  
Poland,0,0,0,0,0,0,0,0,0,0,0,0  
Portugal,16,16,17,18,18,19,20,21,21,23,24,28  
Romania,0,0,0,0,0,0,0,0,0,0,0,0  
Slovenia,-,-,-,-,-,-,-,-,-,-,-,-  
Slovakia,0,0,0,0,0,0,0,0,0,0,0,0  
Finland,0,0,0,0,1,1,1,1,1,1,1,1  
Sweden,4,4,5,5,5,6,4,5,5,6,6,9  
United Kingdom,6,6,7,7,11,13,16,20,25,30,37,46  
Croatia,0,0,0,0,0,0,0,0,0,0,0,1  
Turkey,159,179,210,236,262,287,318,350,375,385,402,420  
Iceland,-,-,-,-,-,-,-,-,-,-,-,-  
Norway,0,0,0,0,0,0,0,0,0,0,0,0  
Switzerland,18,19,21,23,24,26,23,24,25,26,28,30  
#-='Not applicable' or 'Real zero' or 'Zero by default' :=Not available """"
#Source of Data:,Eurostat, http://spreadsheets.google.com/ccc?key=0Agol553XfuDZdFpCQU1CUVdPZ3M0djJBSE1za1NGV0E&amp;hl=en_GB  
#Last Update:,30.04.2009  
#Date of extraction:,17 Aug 2009 07:41:12 GMT, http://epp.eurostat.ec.europa.eu/tgm/table.do?tab=table&amp;init=1&amp;plugin=1&amp;language=en&amp;pcode=ten00082
</code></pre>
",1
"<p>I've recently started using <a href=""""http://www.stat.uni-muenchen.de/~leisch/Sweave/"""" rel=""""noreferrer"""">Sweave</a>* for creating reports of analyses run with R, and am now looking to do the same with my python scripts. </p>

<p>I've found references to <a href=""""http://romainfrancois.blog.free.fr/index.php?post/2009/01/21/Python-and-Sweave"""" rel=""""noreferrer"""">embedding python in Sweave</a> docs, but that seems like a bit of a hack. Has anyone worked out a better solution, or is there an equivalent for python I'm not aware of?</p>

<p>* <em>Sweave is a tool that allows to embed the R code for complete data analyses in latex documents</em></p>
",1
"<p>If I have data like this</p>

<pre><code>DF &lt;- data.frame(
  date = seq(Sys.Date()-1000, len=1000, by=""""1 day"""")[sample(1000, 500)],
  price = runif(500)
)
</code></pre>

<p>How do I plot e.g. mean of price in the function of time, e.g. in months, using ggplot2?</p>
",1
"<p>Given I have a zoo dataset, I'd like to perform a sliding operation against it with the result being another zoo dataset.</p>

<pre>
> x
                      Y
(09/24/09 08:00:13)   3.1
(09/24/09 08:05:13)   4.2
(09/24/09 08:10:13)   4.5
(09/24/09 08:15:13)   9.4
(09/24/09 08:20:13)   9.8
(09/24/09 08:25:13)   7.7
(09/24/09 08:30:13)  13.3
(09/24/09 08:35:13)   6.5
(09/24/09 08:40:13)  14.7
(09/24/09 08:45:13)  23.5
(09/24/09 08:50:13)  20.9
(09/24/09 08:55:13)   8.5
</pre>

<p>My goal is to produce a """"smooth"""" average by iterating through each time interval and obtaining the mean for the set of Y points that are +/- 15 minutes of the current point.</p>

<p>I have a bucketing method of averaging working, but it reduces the resolution of the data. I haven't worked out how to make relative subsets out of zoo with artibrary math, window should help but accessing the index is being difficult.</p>

<p>Thanks.</p>
",1
"<p>Is it possible to use a TTF font in R?</p>

<p>Is the cairo package intended for this task? How would a minimal example look like?</p>
",1
"<p>I'm trying to alter the functionality of a few commands in a package in R. It's easy enough to see the source of the commands. However the function calls other functions that are in the package namespace. These functions are not exported objects. So how can I access them?</p>

<p>specific example:
How would I access the asCall() function that is used in copula::rmvdc?</p>

<pre><code>require(copula)
copula::rmvdc
getAnywhere(""""asCall"""")
</code></pre>

<p>so <code>as.Call()</code> exists in the copula package, but how do I access it? </p>

<pre><code>&gt; copula::asCall
Error: 'asCall' is not an exported object from 'namespace:copula'
</code></pre>
",1
"<p>The following R commands will install all CRAN packages:</p>

<pre><code>availablePackages &lt;- available.packages()[,1]
install.packages(availablePackages)
</code></pre>

<p>And the following command will list all installed packages:</p>

<pre><code>installedPackages &lt;- .packages(all.available = TRUE)
</code></pre>

<p>My question is: <b>How do I instruct R to install all CRAN packages that are not already installed?</b></p>
",1
"<p>When installing R packages (say <code>mcmcpack</code> in this example) under Ubuntu I have the choice between the following two methods of installation:</p>

<pre><code># Let the distribution's packaging system take care of installation/upgrades
apt-get install r-cran-mcmcpack

# Let R take care of installation/upgrades
install.packages(""""mcmcpack"""")
</code></pre>

<p>Questions:</p>

<ul>
<li>Is any of the two ways of installing R packages considered """"best practice""""?</li>
<li>Assume that I first <code>install.packages(""""mcmcpack"""")</code> and later on <code>apt-get install r-cran-mcmcpack</code> - should I expect trouble?</li>
<li>Assume that I first <code>apt-get install r-cran-mcmcpack</code> and later on <code>install.packages(""""mcmcpack"""")</code> - should I expect trouble?</li>
</ul>
",1
"<p>How can I view the definition of a S4 function? For instance, I would like to see the definition of TSconnect in package TSdbi. The command</p>

<pre><code>showMethods(""""TSconnect"""")
</code></pre>

<p>reveals that there is, among others, a function for drv=""""histQuoteDriver"""", dbname=""""character"""".</p>

<p>How can I see the definition of this function? If it were a S3 function, there would be only the first argument definable (drv), which could be inspected with print(TSconnect.histQuoteDriver).</p>

<p><strong>Edit</strong>: From r-forge I found out the desired output:</p>

<pre><code>setMethod(""""TSconnect"""",   signature(drv=""""histQuoteDriver"""", dbname=""""character""""),
  definition= function(drv, dbname, user="""""""", password="""""""", host="""""""", ...){
   #  user / password / host  for future consideration
   if (is.null(dbname)) stop(""""dbname must be specified"""")
   if (dbname == """"yahoo"""") {
      con &lt;- try(url(""""http://quote.yahoo.com""""), silent = TRUE)
      if(inherits(con, """"try-error"""")) 
         stop(""""Could not establish TShistQuoteConnection to """",  dbname)
      close(con)
      }
   else if (dbname == """"oanda"""") {
      con &lt;- try(url(""""http://www.oanda.com""""),   silent = TRUE)
      if(inherits(con, """"try-error"""")) 
         stop(""""Could not establish TShistQuoteConnection to """",  dbname)
      close(con)
      }
   else 
      warning(dbname, """"not recognized. Connection assumed working, but not tested."""")

   new(""""TShistQuoteConnection"""", drv=""""histQuote"""", dbname=dbname, hasVintages=FALSE, hasPanels=FALSE,
        user = user, password = password, host = host ) 
   } )
</code></pre>

<p>Is there a way to get this definition from within an R session?</p>
",1
"<p>my R code ends up containing plethora of statements of the form:</p>

<pre><code>if (!is.null(aVariable)) { 
     do whatever 
}
</code></pre>

<p>But this kind of statement is hard to read because it contains two negations. I would prefer something like: </p>

<pre><code> if (is.defined(aVariable)) { 
      do whatever 
 }
</code></pre>

<p>Does a <code>is.defined</code> type function that does the opposite of !is.null exist standard in R?</p>

<p>cheers,
yannick</p>
",1
"<p>What's the best way to call R functionality from within Java? </p>

<p>I'm looking for a quick, easy and reliable way to make standard 2d scatter plots and histograms in R using my Java applications. I was wondering which packages/interfaces that came up in a quick Google search would be most convenient to use. </p>

<p>I look forward to your suggestions!</p>
",1
"<p>Is there some way to use a specific small image as a point in a scatterplot with ggplot2.  Ideally I will want to resize the images based on an variable.</p>

<p>Here's an example:</p>

<pre><code>library(ggplot2)
p &lt;- ggplot(mtcars, aes(wt, mpg))
p + geom_point(aes(size = qsec, shape = factor(cyl)))
</code></pre>

<p>So I basically want to know if there is a way to supply a specific image as the shape?</p>
",1
"<p>I'm using R to call a mySQL statement, where I define the variable outside the statement e.g.</p>

<pre><code>foo = 23;
dbGetQuery(con, """"select surname from names WHERE age = '.foo.' ;"""")
</code></pre>

<p>But this returns an empty set, I've googled around and tried'.&amp;foo.'   """".foo.""""   '"""".&amp;&amp;foo.""""' 
 and many different combinations, but none of them work, I think this should be a mysql question rather than an R specific problem I'm having, but not sure.  Normally variables have $values but not in R.</p>
",1
"<p>At some point in my script I like to see the number of <code>missing values</code>
in my <code>data.frame</code> and display them.
In my case I have:</p>

<pre><code>out &lt;- read.csv(file=""""...../OUT.csv"""", na.strings=""""NULL"""")

sum(is.na(out$codeHelper))

out[is.na(out$codeHelper),c(1,length(colnames(out)))]
</code></pre>

<p>It works perfectly fine.
However, the last command obviously gives me the whole <code>data.frame</code> where the <code>NA</code> is <code>TRUE</code>, eg:</p>

<pre><code>5561                  Yemen (PDR) &lt;NA&gt;
5562                  Yemen (PDR) &lt;NA&gt;
5563                  Yemen (PDR) &lt;NA&gt;
5564                  Yemen (PDR) &lt;NA&gt;
5565                  Yemen (PDR) &lt;NA&gt;
5566                  Yemen (PDR) &lt;NA&gt;
5567                  Yemen (PDR) &lt;NA&gt;
5568                  Yemen (PDR) &lt;NA&gt;
5601 Zaire (Democ Republic Congo) &lt;NA&gt;
5602 Zaire (Democ Republic Congo) &lt;NA&gt;
5603 Zaire (Democ Republic Congo) &lt;NA&gt;
5604 Zaire (Democ Republic Congo) &lt;NA&gt;
5605 Zaire (Democ Republic Congo) &lt;NA&gt;
</code></pre>

<p>With a big frame and a lot of NAs that looks pretty messy.
Important to me is only where the NA occurs i.e which country 
(in the second column) has a missing value in the third column.</p>

<p>So how can i only display a single row for each country?</p>

<p>It should look something like this:</p>

<pre><code>    1                  Yemen (PDR) &lt;NA&gt;
    2 Zaire (Democ Republic Congo) &lt;NA&gt;
    3                          USA &lt;NA&gt;
    4                     W. Samoa &lt;NA&gt;
</code></pre>
",1
"<p>I have some trouble to convert my <code>data.frame</code> from a wide table to a long table.
At the moment it looks like this:</p>

<pre><code>wide &lt;- read.table(textConnection(
""""Code Country        1950    1951    1952    1953    1954
AFG  Afghanistan    20,249  21,352  22,532  23,557  24,555
ALB  Albania        8,097   8,986   10,058  11,123  12,246""""), header=TRUE)
</code></pre>

<p>Which yields data.frame <code>wide</code> looking like this:</p>

<pre><code>Code Country        1950    1951    1952    1953    1954
AFG  Afghanistan    20,249  21,352  22,532  23,557  24,555
ALB  Albania        8,097   8,986   10,058  11,123  12,246
</code></pre>

<p>I want to transform <code>wide</code> into a long <code>data.frame</code> e.g:</p>

<pre><code>Code Country        Year    Value
AFG  Afghanistan    1950    20,249
AFG  Afghanistan    1951    21,352
AFG  Afghanistan    1952    22,532
AFG  Afghanistan    1953    23,557
AFG  Afghanistan    1954    24,555
ALB  Albania        1950    8,097
ALB  Albania        1951    8,986
ALB  Albania        1952    10,058
ALB  Albania        1953    11,123
ALB  Albania        1954    12,246
</code></pre>

<p>As of 2016, options include <code>reshape2::melt()</code>, as well as <code>tidyr::gather()</code> and <code>data.table::melt()</code> solutions and the older <code>reshape::reshape()</code> function. However, so far I only get messy results trying to use these multiple similar-but-different functions.</p>

<p>If it is possible I would like to do it with the <code>reshape()</code> function since
it looks a little bit nicer to handle, but examples/rationales for using other packages appreciated.</p>
",1
"<p>I'm working on a project now that's rather unlike anything I've done before.  I have two tests with binary results that will be administered to the same sample, which is drawn from a clustered population (i.e., some subjects will be from the same family).  I'd like to compare proportions of positive test results, but the clustering makes McNemar's test inappropriate so I've been reading up on alternative approaches.  The two main routes seem to be 1) the clustering-adjusted McNemar alternatives by Rao and Scott (1992), Eliasziw and Donner (1991), and Obuchowski (1998), and 2) GEE.</p>

<p>Do you know of any implementations of the Rao-Obuchowski lineage in R (or, I suppose, SAS)?  GEE is easy to find, but have you had a positive or negative experience with any particular packages?  Is there another route to analyzing these data that I'm completely missing?</p>

<p>Thanks in advance for your help - let me know if any clarification is needed.</p>
",1
"<p>In R's <code>DBI</code> package, I'm not finding a facility for using bound variables.  I did find a document (the original vignette from 2002) that says about bound variables, """"Perhaps the DBI could at some point in the future implement this feature"""", but it looks like so far that's left undone.</p>

<p>What do people in R use for a substitute?  Just concatenate strings right into the SQL?  That's got some obvious problems for safety &amp; performance.</p>

<p>EDIT:</p>

<p>Here's an example of how placeholders could work:</p>

<pre><code>query &lt;- """"SELECT numlegs FROM animals WHERE color=?""""
result &lt;- dbGetQuery(caseinfo, query, bind=""""green"""")
</code></pre>

<p>That's not a very well-thought-out interface, but the idea is that you can use a value for <code>bind</code> and the driver handles the details of escaping (if the underlying API doesn't handle bound variables natively) without the caller having to reimplement it [badly].</p>
",1
"<p>Basically I want an autoincremented id column based on my cohorts - in this case .(kmer, cvCut)</p>

<pre><code>    &gt; myDataFrame
       size kmer cvCut   cumsum
1      8132   23    10     8132
10000   778   23    10 13789274
30000   324   23    10 23658740
50000   182   23    10 28534840
100000   65   23    10 33943283
200000   25   23    10 37954383
250000  584   23    12 16546507
300000  110   23    12 29435303
400000   28   23    12 34697860
600000  127   23     2 47124443
600001  127   23     2 47124570
</code></pre>

<p>I want a column added that has new row names based on the kmer/cvCut group</p>

<pre><code>    &gt; myDataFrame
       size kmer cvCut   cumsum  newID
1      8132   23    10     8132      1
10000   778   23    10 13789274      2
30000   324   23    10 23658740      3
50000   182   23    10 28534840      4
100000   65   23    10 33943283      5 
200000   25   23    10 37954383      6
250000  584   23    12 16546507      1
300000  110   23    12 29435303      2
400000   28   23    12 34697860      3
600000  127   23     2 47124443      1
600001  127   23     2 47124570      2
</code></pre>
",1
"<p>I have data points that represent a logarithmic function.</p>

<p>Is there an approach where I can just estimate the function that describes this data using R?</p>

<p>Thanks.</p>
",1
"<p>I want to show a block ASCII character  (it's ASCII code is 219), </p>

<p>How can I show it in terminal?</p>

<p>I am using RGui on WinXP</p>
",1
"<p>I previously asked this <a href=""""https://stackoverflow.com/questions/1853703/plotting-functions-in-r"""">question</a> which was useful in plotting a function. I want to try and plot twenty functions on the same axes to illustrate how a function varies between two ranges.  I have successfully done this using individually specified functions, but I wanted to do this using a loop.</p>

<p>What I have attempted doing is:</p>

<pre><code>## add ggplot2
library(ggplot2)
library(lattice)

# Declare local variables
inPath = """"D:/R_Analysis/""""
inFile = """"sample.txt""""

outPath = """"D:/R_Analysis/""""
outFile = """"processed_sample.txt""""

pdfOutPath = """"D:/R_Analysis/""""
pdfOutFile = """"processed_sample.pdf""""

# Declare Chart values
y_label = """"x-axis""""
x_label = """"y-axis""""
chart_title = """"..."""" 

#####################################################################
## Read in data;  
analysis &lt;- 
read.table(paste(inPath, inFile, sep=""""""""), header=TRUE, sep="""","""", 
na.strings=""""NA"""",  dec=""""."""", strip.white=TRUE)

# Setup pdf
pdf(paste(pdfOutPath, pdfOutFile, sep=""""""""),height=6,width=9)

# make plot object    
p &lt;- qplot(
data = data.frame(x = x, y = y), x, y, xlab = x_label, ylab = y_label, 
enter code herexlim = x_range, main = chart_title  )

# make empty function
eq_dummy = function(x){ 0 }
d = stat_function(fun = eq_dummy)

##############
# LOOP #######

for(i in 1 : 21){                                            

        # Specify Variables
        intercept = analysis[i,2]
        slope = analysis[i,3]    

        # Define Curve    
        eq &lt;- function(x) { slope * log(x) + intercept }

        # Make plot object            
        composite &lt;- stat_function(fun=eq)        
        composite = composite + d       

}

print(p + composite)  

# Show warnings
warnings()

# close the PDF file
dev.off() 
</code></pre>

<p>Any suggestions about syntax improvement, or programming structure would be appreciated. Thank you.</p>
",1
"<p>I've been looking around for some data about naming trends in USA. I managed to get top 1000 names for babies born in 2008. The data is formated in this manor:</p>

<pre><code> male.name n.male female.name n.female
 Jacob 22272 Emma 18587
 Michael 20298 Isabella 18377
 Ethan 20004 Emily 17217
 Joshua 18924 Madison 16853
 Daniel 18717 Ava 16850
 Alexander 18423 Olivia 16845
 Anthony 18158 Sophia 15887
 William 18149 Abigail 14901
 Christopher 17783 Elizabeth 11815
 Matthew 17337 Chloe 11699
</code></pre>

<p>I want to get a <code>data.frame</code> with 2 variables: <code>name</code> and <code>gender</code>.
This can be done with looping, but I consider it rather inefficient way of solving this problem. I reckon that some <code>reshape</code> function will suite my needs.</p>

<p>Let's presuppose that this tab-delimited data is saved into a <code>data.frame</code> named <code>bnames</code>. Looping can be done with function:</p>

<pre><code> tmp &lt;- character()
  for (i in 1:nrow(bnames)) {
  tmp &lt;- c(tmp, rep(bnames[i,1], bnames[i,2]))
 }
</code></pre>

<p>But I want to achieve this with vector-based approach. Any suggestions?</p>
",1
"<p>In R, what is the most efficient/idiomatic way to count the number of <code>TRUE</code> values in a logical vector? I can think of two ways:</p>

<pre><code>z &lt;- sample(c(TRUE, FALSE), 1000, rep = TRUE)
sum(z)
# [1] 498

table(z)[""""TRUE""""]
# TRUE 
#  498 
</code></pre>

<p>Which do you prefer? Is there anything even better?</p>
",1
"<p>I'm trying to extract a number from a string.</p>

<p>And do something like this [0-9]+  on this string """"aaaa12xxxx"""" and get """"12"""".</p>

<p>I thought it would be something like:</p>

<pre><code>&gt; grep(""""[0-9]+"""",""""aaa12xxx"""", value=TRUE)
[1] """"aaa12xxx""""
</code></pre>

<p>And then I figured... </p>

<pre><code>&gt; sub(""""[0-9]+"""", """"\\1"""", """"aaa12xxxx"""")
[1] """"aaa12xxx""""
</code></pre>

<p>But I got some form of response doing:</p>

<pre><code>&gt; sub(""""[0-9]+"""", """"ARGH!"""", """"aaa12xxxx"""")
[1] """"aaaARGH!xxx""""
</code></pre>

<p>There's a small detail I'm missing Please advice :-)</p>

<p>I'm using R version 2.10.1 (2009-12-14)</p>

<p>Thanks !</p>

<hr>

<p><strong>Comments on the solution</strong></p>

<p>The best solution is to ignore the standard functions and install Hadley Wickham's <strong><em>stringr</em></strong> package to get something that actually makes sense.</p>

<p>Kudos to Marek for figuring out how the standard library worked.</p>
",1
"<p>is there any way to display a message when a user loads <code>library(myCustomLibrary)</code>?
Upon loading, I want to display a message that tells the user how to run all the test functions.</p>
",1
"<p>The classic and brilliant Programming Perl reference book has a section in which the authors provide a list of advice for how to write Perl that is maximally <em>computationally efficient</em>, followed by a list of advice for how to write Perl that is maximally <em>programmer efficient</em>, followed by more advice for <em>maintainer efficient</em>, <em>porter efficient</em>, and <em>user efficient</em>. The advice is usually completely contradictory. (E.g., """"use globals"""", """"don't use globals."""")</p>

<p>I thought of this while working on turning some """"programmer efficient"""" R code into """"computationally and maintainer efficient"""" code.</p>

<p>What are some interesting and useful tips for R style along these lines? What practices are maximally programmer efficient, and what are the equivalent practices that address other notions of efficiency?</p>
",1
"<p>I am not sure there are any R users out there, but just in case:</p>

<p>I am a novice at R and was kindly """"handed down"""" the following R code snippet:</p>

<pre><code>Beta &lt;- exp(as.matrix(read.table('beta.transpose')))
WordFreq &lt;- read.table('freq-matrix')
WordProbs &lt;- WordFreq$V1 / sum(WordFreq)

infile &lt;- file('freq-matrix')
outfile &lt;- file('doc_topic_prob_matrix', 'w')

open(infile)
open(outfile)

for (i in 1:93049) {
  vec &lt;- t(scan(infile, nlines=1))
  topics &lt;- (vec/WordProbs) %*% Beta
  write.table(topics, outfile, append=T, row.names=F, col.names=F)
  }
</code></pre>

<p>When I tried running this on my dataset, the system thrashed and swapped like crazy. Now I realize that has a simple reason: the file freq-matrix holds a large (22GB) matrix and I was trying to read it into memory.</p>

<p>I have been told to use the <a href=""""http://cran.r-project.org/web/packages/Matrix/Matrix.pdf"""" rel=""""nofollow noreferrer"""">Matrix</a> package, because freq-matrix has many, many zeros all over the place and it handles such cases well. Will that help? If so, any hints on how to change this code would be most welcome. I have no R experience and just started reading through the introduction PDF available on the site.</p>

<p>Many thanks</p>

<p>~l</p>
",1
"<p>I'm looking to create a static dashboard viewable in a web browser. And I'd like to create something like what Stephen Few does in his book <a href=""""http://rads.stackoverflow.com/amzn/click/0596100167"""" rel=""""nofollow noreferrer"""">Information Dashboard Design</a>. (see example at bottom)</p>

<ol>
<li><strong>Ggplot2</strong>: Shouldn't be any issue producing the graphs below, right?</li>
<li><strong>Dashboard Layout</strong>: Is grid suitable? Or should I lay things out in html/css? </li>
</ol>

<p>If grid can do this easily enough, do you know of any good resources for learning how to us it? I've read the manual but I'm not finding it too helpful. I've seen the LearnR blog's <a href=""""http://learnr.wordpress.com/2009/04/09/ggplot2-sales-dashboard/"""" rel=""""nofollow noreferrer"""">ggplot2 sales dashboard</a> (it uses grid) and I'm having trouble understanding the grid and layout part of things. </p>

<p><a href=""""http://img251.imageshack.us/img251/1029/fewciodashboard800.png"""" rel=""""nofollow noreferrer"""">dasboard sample http://img251.imageshack.us/img251/1029/fewciodashboard800.png</a></p>
",1
"<p>I am trying to <code>merge</code> several <code>data.frames</code> into one <code>data.frame</code>. Since I have a whole list of files I am trying to do it with a loop structure.</p>

<p>So far the loop approach works fine. However, it looks pretty inefficient and I am wondering if there is a faster and easier approach.</p>

<p>Here is the scenario:
I have a directory with several <code>.csv</code> files. Each file contains the same identifier which can be used as the merger variable. Since the files are rather large in size I thought to read each file one at a time into R instead of reading all files at once.
So I get all the files of the directory with <code>list.files</code> and read in the first two files. Afterwards I use <code>merge</code> to get one <code>data.frame</code>.</p>

<pre><code>FileNames &lt;- list.files(path="""".../tempDataFolder/"""")
FirstFile &lt;- read.csv(file=paste("""".../tempDataFolder/"""", FileNames[1], sep=""""""""),
             header=T, na.strings=""""NULL"""")
SecondFile &lt;- read.csv(file=paste("""".../tempDataFolder/"""", FileNames[2], sep=""""""""),
              header=T, na.strings=""""NULL"""")
dataMerge &lt;- merge(FirstFile, SecondFile, by=c(""""COUNTRYNAME"""", """"COUNTRYCODE"""", """"Year""""),
             all=T)
</code></pre>

<p>Now I use a <code>for</code> loop to get all the remaining <code>.csv</code> files and <code>merge</code> them into the already existing <code>data.frame</code>:</p>

<pre><code>for(i in 3:length(FileNames)){ 
ReadInMerge &lt;- read.csv(file=paste("""".../tempDataFolder/"""", FileNames[i], sep=""""""""),
               header=T, na.strings=""""NULL"""")
dataMerge &lt;- merge(dataMerge, ReadInMerge, by=c(""""COUNTRYNAME"""", """"COUNTRYCODE"""", """"Year""""),
             all=T)
}
</code></pre>

<p>Even though it works just fine I was wondering if there is a more elegant way to get the job done?</p>
",1
"<p>I have two dendrograms which I wish to compare to each other in order to find out how """"similar"""" they are. But I don't know of any method to do so (let alone a code to implement it, say, in R).</p>

<p>Any leads ?</p>

<p><strong>UPDATE</strong> (2014-09-13):</p>

<p>Since asking this question, I have written an R package called <a href=""""http://cran.r-project.org/web/packages/dendextend/"""" rel=""""noreferrer"""">dendextend</a>, for the visualization, manipulation and <strong>comparison</strong> of dendrogram. This package is on <a href=""""http://cran.r-project.org/web/packages/dendextend/"""" rel=""""noreferrer"""">CRAN</a> and comes with a <a href=""""http://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html"""" rel=""""noreferrer"""">detailed vignette</a>. It includes functions such as <code>cor_cophenetic</code>, <code>cor_bakers_gamma</code> and <code>Bk</code> / <code>Bk_plot</code>. As well as a <code>tanglegram</code> function for visually comparing two trees.</p>
",1
"<p>Is there a way of plotting a univariate time series of class """"ts"""" using ggplot that sets up the time axis automatically? I want something similar to plot.ts() of base graphics.</p>

<p>Also it seems to me that the coarsest time granularity is a day. Is that right? In my work I have to work with monthly and quarterly data and assigning each observation to the beginning/end of the month/quarter would cause the observations to be irregularly spaced horizontally since months/quarters are of unequal length. That may make more sense, but my audience is used to seeing months/quarters regularly spaced.</p>

<p>I know I can solve all of the above by manually setting up the x-axis as a time axis or as a numeric axis with my own labels. I am specifically looking for a method that does this automatically by using the time information in the ts object..</p>
",1
"<p>I have a list of character vectors in R that represents sets of cooccuring words. From this, I would like to extract a character vector capturing all the words that appear in the list of character vectors. I think I know how to efficiently go from a character vector of words to a unique character vector of the words that appeared. What I don't know how to do is efficiently collapse the list of character vectors into a single character vector.  Any tips on how to approach this or the overall problem efficiently would be great appreciated! </p>
",1
"<p>Is there any way to generate a dendrogram where each level of the graph represents a generation and only sons of the same father are connected at each level?</p>

<p>I'm attempting to use R's hclust and plot functions to generate a dendrogram of father-son lineage.  The desired result is a dendrogram where each generation of sons is placed on the same line, under their father.  </p>

<p>I was hoping that hclust and the """"complete"""" method would allow me to use the dissimilarity matrix to assign sons of the same father a 0 dissimilarity score and then be placed on the same hierarchical level, exclusive from any other entities in the dataset.  This doesn't work, there are sons of different generations on the same level.</p>

<p>Any help is greatly appreciated!</p>

<p>Here is some example data:</p>

<p>father,son<br>
A,C<br>
A,D<br>
A,E<br>
B,F<br>
B,G<br>
C,H<br>
C,I<br>
F,J<br>
F,K<br>
G,L  </p>

<p>Agent A has three sons: C, D, and E; and two grandsons through C: H and I.</p>

<p>Agent B has two sons: F and G; and a total of three grandsons: J, K, and L.</p>
",1
"<p>R can read files on a web server using convenient syntax such as</p>

<pre><code>data &lt;- read.delim(""""http://remoteserver.com/file.dat"""")
</code></pre>

<p>I wonder if there is a way to do something similar with a file on an ssh server with passwordless-ssh already in place?</p>
",1
"<p>I can create a compose operator in R:</p>

<pre><code> `%c%` = function(x,y)function(...)x(y(...)) 
</code></pre>

<p>To be used like this:</p>

<pre><code> &gt; numericNull = is.null %c% numeric
 &gt; numericNull(myVec)
 [2] TRUE FALSE
</code></pre>

<p>but I would like to know if there is an official set of functions to do this kind of thing and other operations such as currying in R.  Largely this is to reduce the number of brackets, function keywords etc in my code.</p>

<p>My curry function:</p>

<pre><code>&gt; curry=function(...){
    z1=z0=substitute(...);z1[1]=call(""""list"""");
    function(...){do.call(as.character(z0[[1]]),
                          as.list(c(eval(z1),list(...))))}}
&gt; p = curry(paste(collapse=""""""""))
&gt; p(letters[1:10])
[1] """"abcdefghij""""
</code></pre>

<p>This is especially nice for e.g. aggregate:</p>

<pre><code>&gt; df = data.frame(l=sample(1:3,10,rep=TRUE), t=letters[1:10])
&gt; aggregate(df$t,df[""""l""""],curry(paste(collapse="""""""")) %c% toupper)
  l    x
1 1  ADG
2 2  BCH
3 3 EFIJ
</code></pre>

<p>Which I find much more elegant and editable than:</p>

<pre><code>&gt; aggregate(df$t, df[""""l""""], function(x)paste(collapse="""""""",toupper(x)))
  l    x
1 1  ADG
2 2  BCH
3 3 EFIJ
</code></pre>

<p>Basically I want to know - has this already been done for R?</p>
",1
"<p><strong>DESCRIPTION</strong> </p>

<p>I have two datasets with information that I need to merge. The only common fields that I have are strings that do not perfectly match and a numerical field that can be substantially different </p>

<p>The only way to explain the problem is to show you the data. Here is <a href=""""http://bertelsen.ca/R/a.csv"""" rel=""""nofollow noreferrer"""">a.csv</a> and <a href=""""http://bertelsen.ca/R/b.csv"""" rel=""""nofollow noreferrer"""">b.csv</a>. I am trying to merge B to A.</p>

<p>There are three fields in B and four in A. Company Name (File A Only), Fund Name, Asset Class, and Assets. So far, my focus has been on attempting to match the Fund Names by replacing words or parts of the strings to create exact matches and then using: </p>

<pre><code>a &lt;- read.table(file = """"http://bertelsen.ca/R/a.csv"""",header=TRUE, sep="""","""", na.strings=F, strip.white=T, blank.lines.skip=F, stringsAsFactors=T) 
b &lt;- read.table(file = """"http://bertelsen.ca/R/b.csv"""",header=TRUE, sep="""","""", na.strings=F, strip.white=T, blank.lines.skip=F, stringsAsFactors=T)
merge(a,b, by=""""Fund.Name"""") 
</code></pre>

<p>However, this only brings me to about 30% matching. The rest I have to do by hand. </p>

<p>Assets is a numerical field that is not always correct in either and can vary wildly if the fund has low assets. Asset Class is a string field that is """"generally"""" the same in both files, however, there are discrepancies. </p>

<p>Adding to the complication are the different series of funds, in File B. For example: </p>

<blockquote>
  <p>AGF Canadian Value </p>
  
  <p>AGF Canadian Value-D</p>
</blockquote>

<p>In these cases, I have to choose the one that is not seried, or choose the one that is called """"A"""", """"-A"""", or """"Advisor"""" as the match. </p>

<p><strong>QUESTION</strong></p>

<p>What would you say is the best approach? This excercise is something that I have to do on a monthly basis and matching them manually is incredibly time consuming. Examples of code would be instrumental. </p>

<p><strong>IDEAS</strong></p>

<p>One method that I think may work is normalizing the strings based on the first capitalized letter of each word in the string. But I haven't been able to figure out how to pull that off using R.</p>

<p>Another method I considered was creating an index of matches based on a combination of assets, fund name, asset class and company. But again, I'm not sure how to do this with R. Or, for that matter, if it's even possible.</p>

<p>Examples of code, comments, thoughts and direction are greatly appreciated!   </p>
",1
"<p><em>note: this question and the following answers refer to data.table versions &lt; 1.5.3; v. 1.5.3 was released in Feb 2011 to resolve this issue.</em> see more recent treatment (03-2012): <a href=""""https://stackoverflow.com/questions/9914734/translating-sql-joins-on-foreign-keys-to-r-data-table-syntax"""">Translating SQL joins on foreign keys to R data.table syntax</a></p>

<hr>

<p>I've been digging through the documentation for the <a href=""""http://cran.r-project.org/web/packages/data.table/index.html"""" rel=""""nofollow noreferrer"""">data.table package</a> (a replacement for data.frame that's much more efficient for certain operations), including <a href=""""http://files.meetup.com/1406240/Data%20munging%20with%20SQL%20and%20R.pdf"""" rel=""""nofollow noreferrer"""">Josh Reich's presentation on SQL and data.table at the NYC R Meetup</a> (pdf), but can't figure this totally trivial operation out.</p>

<pre><code>&gt; x &lt;- DT(a=1:3, b=2:4, key='a')
&gt; x
     a b
[1,] 1 2
[2,] 2 3
[3,] 3 4
&gt; y &lt;- DT(a=1:3, c=c('a','b','c'), key='a')
&gt; y
     a c
[1,] 1 a
[2,] 2 b
[3,] 3 c
&gt; x[y]
     a b
[1,] 1 2
[2,] 2 3
[3,] 3 4
&gt; merge(x,y)
  a b c
1 1 2 a
2 2 3 b
3 3 4 c
</code></pre>

<p>The docs say """"When [the first argument] is itself a data.table, a join is invoked similar to base::merge but uses binary search on the sorted key."""" Clearly this is not the case. Can I get the other columns from y into the result of x[y] with data.tables? It seems like it's just taking the rows of x where the key matches the key of y, but ignoring the rest of y entirely...</p>
",1
"<p>a statement that checks if something is true and if not prints a given error message and exits</p>
",1
"<p>Using ggplot, is there a way of graphing several functions on the same plot? I want to use parameters from a text file as arguments for my functions and overlay these on the same plot.</p>

<p>I understand <a href=""""https://stackoverflow.com/questions/1853703/plotting-functions-in-r/1853866#1853866"""">this</a> but I do not know how to add the visualized function together if I loop through.</p>
",1
"<p>I'm using R, and I'm a beginner. I have two large lists (30K elements each). One is called <code>descriptions</code> and where each element is (maybe) a tokenized string. The other is called <code>probes</code> where each element is a number. I need to make a dictionary that maps<code>probes</code> to something in <code>descriptions</code>, if that something is there. Here's how I'm going about this:</p>

<pre><code>probe2gene &lt;- list()
for (i in 1:length(probes)){
 strings&lt;-strsplit(descriptions[i]), '//')
 if (length(strings[[1]]) &gt; 1){ 
  probe2gene[probes[i]] = strings[[1]][2]
 }
}
</code></pre>

<p>Which works fine, but seems slow, much slower than the roughly equivalent python:</p>

<pre><code>probe2gene = {}
for p,d in zip(probes, descriptions):
    try:
     probe2gene[p] = descriptions.split('//')[1]
    except IndexError:
     pass
</code></pre>

<p>My question: is there an """"R-thonic"""" way of doing what I'm trying to do? The <a href=""""http://cran.r-project.org/doc/manuals/R-intro.html#Repetitive-execution"""" rel=""""nofollow noreferrer"""">R manual entry on for loops</a> suggests that such loops are rare. Is there a better solution?</p>

<p>Edit: a typical good """"description"""" looks like this:</p>

<pre><code>""""NM_009826 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421 /// AB070619 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421 /// ENSMUST00000027040 // Rb1cc1 // RB1-inducible coiled-coil 1 // 1 A2 // 12421""""
</code></pre>

<p>a bad """"description: looks like this</p>

<pre><code>""""-----""""
</code></pre>

<p>though it can quite easily be some other not-very-helpful string. Each probe is simply a number. The <code>probe</code> and <code>description</code> vectors are the same length, and completely correspond to each other, i.e. <code>probe[i]</code> maps to <code>description[i]</code>.</p>
",1
"<p>I ran a Pig job on a Hadoop cluster that crunched a bunch of data down into something R can handle to do a cohort analysis.  I have the following script, and as of the second to last line I have the data in the format:</p>

<pre><code>&gt; names(data)
[1] """"VisitWeek"""" """"ThingAge""""    """"MyMetric""""
</code></pre>

<p>VisitWeek is a Date.  ThingAge and MyMetric are integers.</p>

<p>The data looks like:</p>

<pre><code>2010-02-07     49  12345
</code></pre>

<p>The script I have so far is:</p>

<pre><code># Load ggplot2 for charting 
library(ggplot2);

# Our file has headers - column names
data = read.table('weekly_cohorts.tsv',header=TRUE,sep=""""\t"""");

# Print the names
names(data)

# Convert to dates
data$VisitWeek = as.Date(data$VisitWeek)
data$ThingCreation = as.Date(data$ThingCreation)

# Fill in the age column
data$ThingAge = as.integer(data$VisitWeek - data$ThingCreation)

# Filter data to thing ages lt 10 weeks (70 days) + a sanity check for gt 0, and drop the creation week column
data = subset(data, data$ThingAge &lt;= 70, c(""""VisitWeek"""",""""ThingAge"""",""""MyMetric""""))
data = subset(data, data$ThingAge &gt;= 0)

print(ggplot(data, aes(x=VisitWeek, y=MyMetric, fill=ThingAge)) + geom_area())
</code></pre>

<p>This last line does not work.  I've tried lots of variations, bars, histograms, but as usual R docs defeat me.</p>

<p>I want it to show a standard Excel style stacked area chart - one time series for each ThingAge stacked across the weeks in the x axis, with the date on the y axis.  An example of this kind of chart is here: <a href=""""http://upload.wikimedia.org/wikipedia/commons/a/a1/Mk_Zuwanderer.png"""" rel=""""nofollow noreferrer"""">http://upload.wikimedia.org/wikipedia/commons/a/a1/Mk_Zuwanderer.png</a></p>

<p>I've read the docs here: <a href=""""http://had.co.nz/ggplot2/geom_area.html"""" rel=""""nofollow noreferrer"""">http://had.co.nz/ggplot2/geom_area.html</a> and <a href=""""http://had.co.nz/ggplot2/geom_histogram.html"""" rel=""""nofollow noreferrer"""">http://had.co.nz/ggplot2/geom_histogram.html</a> and this blog <a href=""""http://chartsgraphs.wordpress.com/2008/10/05/r-lattice-plot-beats-excel-stacked-area-trend-chart/"""" rel=""""nofollow noreferrer"""">http://chartsgraphs.wordpress.com/2008/10/05/r-lattice-plot-beats-excel-stacked-area-trend-chart/</a> but I can't quite make it work for me.</p>

<p>How can I achieve this?</p>
",1
"<p>preface: i'm an os x user coming to linux, so excuse my ignorance in advance</p>

<p>I've installed R using synaptic and now i'm trying to install packages.</p>

<p>I open R then try </p>

<pre><code>install.packages(""""some_package"""")
</code></pre>

<p>system tries to default to <code>/site-library</code>, then tells me it's not writable, then asks about making a personal library?</p>

<p>Should I just make site-library writable? Or is there something more to this?</p>
",1
"<p>Say I have a data frame with the contents:</p>

<pre><code>Trial Person Time
1     John   1.2
2     John   1.3
3     John   1.1
1     Bill   2.3
2     Bill   2.5
3     Bill   2.7
</code></pre>

<p>and another data frame with the contents:</p>

<pre><code>Person Offset
John   0.5
Bill   1.0
</code></pre>

<p>and I want to modify the original frame based on the appropriate value from the second. I could do this easily in any other language or in SQL, and I'm sure I could manage using for loops and what, but with everything else I see in R, I'm guessing it has special syntax to do this as a one-liner. So, if so, how? And if not, could you show how it could be done using loops. I haven't actually got around to learning looping in R yet since it has amazing things to simply extract and manipulate whatever values.</p>

<p>For reference, the output would:</p>

<pre><code>Trial Person Time
1     John   0.7
2     John   0.8
3     John   0.6
1     Bill   1.3
2     Bill   1.5
3     Bill   1.7 
</code></pre>
",1
"<p>I'm trying to fit a curve over (the tail of) the following data:</p>

<pre>
 [1]   1   1   1   1   1   1   2   1   2   2   3   2   1   1   4   3   2  11   6   2  16   7  17  36
[25]  27  39  41  33  42  66  92 138 189 249 665 224 309 247 641 777 671 532 749 506 315 292 281 130
[49] 137  91  40  27  34  19   1
</pre>

<p>I'm using the following function in R to accomplish this:</p>

<blockquote>
  <p>nls(y~a<em>x</em>exp(-b*x^2),start=list(a=1,b=1),trace=TRUE)</p>
</blockquote>

<p>However, I'm getting the following error:</p>

<blockquote>
  <p>3650202 :  1 1</p>
  
  <p>Error in numericDeriv(form[[3L]], names(ind), env) :
    Missing value or an infinity produced when evaluating the model</p>
</blockquote>

<p>When using the following, artificial values for x and y, everything works just fine:</p>

<blockquote>
  <p>y=x*exp(-.5*x^2)+rnorm(length(x),0,0.1)</p>
</blockquote>

<pre>
x
  [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90
 [20] 0.95 1.00 1.05 1.10 1.15 1.20 1.25 1.30 1.35 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85
 [39] 1.90 1.95 2.00 2.05 2.10 2.15 2.20 2.25 2.30 2.35 2.40 2.45 2.50 2.55 2.60 2.65 2.70 2.75 2.80
 [58] 2.85 2.90 2.95 3.00 3.05 3.10 3.15 3.20 3.25 3.30 3.35 3.40 3.45 3.50 3.55 3.60 3.65 3.70 3.75
 [77] 3.80 3.85 3.90 3.95 4.00 4.05 4.10 4.15 4.20 4.25 4.30 4.35 4.40 4.45 4.50 4.55 4.60 4.65 4.70
 [96] 4.75 4.80 4.85 4.90 4.95 5.00
y
  [1] -0.080214106  0.075247488  0.076355116 -0.020087646  0.181314038  0.075832658  0.248303254
  [8]  0.364244010  0.453655908  0.347854869  0.514373164  0.384051249  0.618584696  0.515684390
 [15]  0.534737770  0.609279111  0.618936091  0.534443863  0.739118585  0.677679546  0.526011452
 [22]  0.645645150  0.578274968  0.589619834  0.476186241  0.621638333  0.601663144  0.535981735
 [29]  0.518434367  0.581735107  0.423872948  0.445335110  0.340884242  0.317121065  0.342683141
 [36]  0.278351104  0.402947372  0.429483276  0.276655872  0.108164828  0.389994138  0.372300257
 [43] -0.057320612  0.131271986  0.226212869  0.131171973  0.245970674  0.009926555  0.173465207
 [50]  0.141220590  0.280616078  0.108515613  0.117697407  0.130700771  0.058540888  0.251613512
 [57]  0.168094899 -0.058382571  0.123306762 -0.048605186 -0.010131767  0.076701962 -0.051982924
 [64]  0.058427540  0.144665070  0.063998841 -0.010495697  0.119868854  0.114447318  0.006759691
 [71]  0.025041761 -0.178145771  0.041547126  0.122084819  0.034283141  0.209140060  0.197024853
 [78] -0.005491966 -0.033260219 -0.028123314 -0.005775553 -0.040781462  0.090024896  0.116390743
 [85] -0.017811031  0.094039200 -0.147064060 -0.057249278  0.211587898 -0.066153592  0.032100332
 [92] -0.092756136 -0.125906598  0.136937364  0.046453010  0.002000336 -0.134047101  0.089748847
 [99] -0.019355567 -0.042158950  0.149594368
</pre>

<p>Can anyone point out what I'm doing wrong? Thanks for your help.</p>
",1
"<p>I have an object containing a text string:</p>

<pre><code>x &lt;- """"xxyyxyxy""""
</code></pre>

<p>and I want to turn that into a vector with each element containing two letters:</p>

<pre><code>[1] """"xx"""" """"yy"""" """"xy"""" """"xy""""
</code></pre>

<p>it seems like the strsplit() should be my ticket, but since I have no regular expression foo, I can't figure out how to make this function chop the string up the way I want it. How should I do this?</p>
",1
"<p>I'm trying to iteratively generate some functions using a For Loop:</p>

<pre><code># Create a list to hold the functions
funcs &lt;- list()
funcs[]

# loop through to define functions
for(i in 1:21){

    # Make function name
    funcName &lt;- paste( 'func', i, sep = '' )

    # make function
    func = function(x){x * i}

    funcs[[funcName]] = func

    }
</code></pre>

<p>However, it's not working as I hoped as the i value is not being evaluated within each function. I want to try and define the function to equal x * 1; x * 2; etc, but what I end up with is a function that is x * i; where i is 21.</p>

<p>I tried using the eval() function and that just resulted in x * eval(i) being stored.</p>
",1
"<p>I have a two vectors of numbers of equal length. How do I plot the first vector while using the corresponding element in the second vector as the printing character? (Background: I sorted the first column and the second column holds the original indices. I want to use the indices as the printable character so that I can see which data points are outliers, since each number represents one run of data).</p>

<pre><code> &gt; x
$x
 [1]   25   29   30   34   38  572  700  733  870  879  899  934  982 1054 1135 1258
[17] 1315 1491 1685 1700 2069 2131 2284 3498 3506 4467 4656 5633 6642 8348

$ix
 [1] 23  3 18 30 13  8  4 14 11 17 12 29  9 15 19 16  7  1 20  2  6 28 21 10  5 22 24 26
[29] 25 27
</code></pre>

<p>First vector is x$x, second vector is x$ix (results of calling sort with index.return = TRUE)</p>

<p>I've tried plot(x$x, pch=str(x$ix)) but that treats x$ix numerically. If this were Python I would do something like strings = [str(x) for x in x$ix]. but this is R and I've forgotten most of what I used to know.</p>

<p>I found that you can do as.character(x$ix) in order to get the strings,</p>

<pre><code>&gt; as.character(x$ix)
 [1] """"23"""" """"3""""  """"18"""" """"30"""" """"13"""" """"8""""  """"4""""  """"14"""" """"11"""" """"17"""" """"12"""" """"29"""" """"9""""  """"15"""" """"19"""" """"16""""
[17] """"7""""  """"1""""  """"20"""" """"2""""  """"6""""  """"28"""" """"21"""" """"10"""" """"5""""  """"22"""" """"24"""" """"26"""" """"25"""" """"27""""
</code></pre>

<p>and I can use this as the input to pch.  But only the first character is used (and according to the docs, that's normal).</p>

<p>I know there's a way to do this; I did it in college.  But I can't for the life of me remember how I did it.</p>

<p>Chart without labels:
<a href=""""http://i47.tinypic.com/2aep88.png"""">alt text http://i47.tinypic.com/2aep88.png</a></p>

<p>Chart with labels, but incorrect:
<a href=""""http://i50.tinypic.com/2cicxtu.png"""">alt text http://i50.tinypic.com/2cicxtu.png</a></p>
",1
"<p>I have a plain hashmap with numeric values and would like to retrieve its content, ideally in a list (but that can be worked out). </p>

<p>Can it be done?</p>
",1
"<p>I'm using qplot to plot a function and I want to position the legend within the plot. I've used </p>

<pre><code>opts( legend.position = c(0.7,0.7) )
</code></pre>

<p>to move the legend where I want it to be.</p>

<p>However there is a white border around the legend and that shows up on the gray background. </p>

<p>For example:</p>

<pre><code>library(ggplot2)
x = c(1:20)
y = c(1:20)

p &lt;- qplot(x,y, color = """"blue"""")

p &lt;- p + scale_colour_identity(""""Example"""", breaks=c(""""blue""""), labels=c(""""dots""""))

p &lt;- p + opts(legend.position = c(0.6, 0.4))

print(p)
</code></pre>

<p>I would like to know how to remove this border from the legend. Thank you.</p>
",1
"<p>Using ggplot2 I am plotting several functions and a series of points. I cannot figure out how to represent the points on the legend. I realize I need to use an aes() function, but I don't fully understand how to do this. I apologize that the example is so long, but I don't know how else to illustrate it.</p>

<pre><code>## add ggplot2
library(ggplot2)

# Declare Chart values
y_label = expression(""""y_axis""""~~bgroup(""""("""",val / km^{2},"""")""""))
x_label = """"x_axis""""

#############################
## Define functions
# Create a list to hold the functions
funcs &lt;- list()
funcs[]

# loop through to define functions
for(k in 1:21){

# Make function name
funcName &lt;- paste('func', k, sep = '' )

# make function
func = paste('function(x){exp(', k, ') * exp(x*0.01)}', sep = '')

funcs[[funcName]] = eval(parse(text=func))

}

    # Specify values
    yval = c(1:20)                              
    xval = c(1:20)                                

    # make a dataframe
    d = data.frame(xval,yval)

    # Specify Range
    x_range &lt;- range(1,51)

# make plot
p &lt;-qplot(data = d,
        x=xval,y=yval,        
        xlab = x_label, 
        ylab = y_label,
        xlim = x_range
        )+ geom_point(colour=""""green"""")


for(j in 1:length(funcs)){

p &lt;- p + stat_function(aes(y=0),fun = funcs[[j]], colour=""""blue"""", alpha=I(1/5))

}

# make one function red
p &lt;- p + stat_function(fun = funcs[[i]], aes(color=""""red""""), size = 1) +
    scale_colour_identity("""""""", breaks=c(""""red"""", """"green"""",""""blue""""),
    labels=c(""""Fitted Values"""", """"Measured values"""",""""All values"""")) 

# position legend and make remove frame
p &lt;- p + opts(legend.position = c(0.85,0.7), legend.background = theme_rect(col = 0)) 

print(p)     
</code></pre>

<p>Thank you in advance - I have learned I a lot from this community over the last few days.</p>
",1
"<p>I have 30 runs of data, each stored in a separate CSV file, runi.csv, i = 0:29.</p>

<p>Let's say I want to collect them all into a list.  Best way I know how to do this is</p>

<pre><code>runs = list()
for (i in 1:30) { runs[[i]] = read.csv(paste(""""run"""", i-1, """".csv"""")); }
</code></pre>

<p>Now let's further say that each of these data frames stored in the list has the same column layouts and that I'm interested in the column identified by """"x"""" and the column identified by """"y"""".</p>

<p>What is the easiest way to plot all 30 runs' worth of (x, y) pairs?  Here's how I would currently do it (and I feel there <em>must</em> be a better way):</p>

<pre><code>xList = list()
yList = list()
for (i in 1:30) { xList[[i]] = runs[[i]]$x; yList[[i]] = runs[[i]]$y; }
matplot(x=as.data.frame(xList), y=as.data.frame(yList))
</code></pre>

<p>This gets even more painful when I'm trying to do transformations to the data; I can't figure out how to apply a function to a specific column of each data frame stored in a list.</p>

<p>Any help here would be extremely helpful.</p>
",1
"<p>Say I have a data frame with the contents:</p>

<pre><code>Trial Person 
1     John   
2     John   
3     John   
4     John
1     Bill 
2     Bill
3     Bill
4     Bill
</code></pre>

<p>and I want to transform this to</p>

<pre><code>Trial Person Day
1     John   1
2     John   1
3     John   2
4     John   2
1     Bill   1
2     Bill   1
3     Bill   2
4     Bill   2
</code></pre>

<p>I can very easily make it</p>

<pre><code>Trial Person Day
1     John   TRUE
2     John   TRUE
3     John   FALSE
4     John   FALSE
1     Bill   TRUE
2     Bill   TRUE
3     Bill   FALSE
4     Bill   FALSE
</code></pre>

<p>by doing <code>d$day=d$trial&lt;3</code> but how can I get to what I want?</p>
",1
"<p>I'm trying to build folders to store data pulls. I want to label the folders with the day of that data in the pull.</p>

<p>Ex. I pull 5 days ago data from mysql i want to name the folder the date from 5 days ago.</p>

<p>MySQL can easily handle date arithmetic. I'm not sure exactly how R does it. Should i just subtract the appropriate number of seconds in POSIXct and then convert to POSIXlt to name the folder MM_DD_YYYY?</p>

<p>Or is there a better way?</p>
",1
"<p>I have a process in R that creates a bunch of objects, serializes them, and puts them into plain text files. This seemed like a really good way to handle things since I am working with Hadoop and all output needs to stream through stdin and stdout. </p>

<p>The problem I am left with is how to read these objects out of the text file and back into R on my desktop machine. Here's a working example that illustrates the challenge:</p>

<p>Let's create a tmp file and write a single object into it. This object is just a vector:</p>

<pre><code>outCon &lt;- file(""""c:/tmp"""", """"w"""")
mychars &lt;- rawToChar(serialize(1:10, NULL, ascii=T))
cat(mychars, file=outCon)
close(outCon)
</code></pre>

<p>The mychars object looks like this:</p>

<pre><code>&gt; mychars
[1] """"A\n2\n133633\n131840\n13\n10\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n""""
</code></pre>

<p>when written to the text file it looks like this:</p>

<pre><code>A
2
133633
131840
13
10
1
2
3
4
5
6
7
8
9
10
</code></pre>

<p>I'm probably overlooking something terribly obvious, but how do I read this file back into R and unserialize the object? When I try scan() or readLines() both want to treat the new line characters as record delimiters and I end up with a vector where each element is a row from the text file. What I really want is a text string with the whole contents of the file. Then I can unserialize the string. </p>

<p>Perl will read line breaks back into a string, but I can't figure out how to override the way R treats line breaks. </p>
",1
"<p>After some research I found the way to prevent an uninformative legend from displaying</p>

<pre><code>... + theme(legend.position = """"none"""")
</code></pre>

<p>Where can I find all of the available <code>theme</code> options and their default values for ggplot2?</p>
",1
"<p>In <code>R</code>, how can I overwrite the first values of a long vector with values obtained from a file, where the file contains possibly fewer values?</p>

<p>Example:</p>

<pre><code># fill with n=100 values
vec1 &lt;- runif(100)

# read m values, where m &lt;= n
vec2 &lt;- scan(""""myfile"""", sep=""""\n"""")

# now want to set the first m values of vec1 
# to the values in vec2
</code></pre>

<p>I could walk through <code>vec2</code> and copy the values into <code>vec1</code>, but I think there should be a more efficient way?</p>
",1
"<p>I have experimental data expressed as dicts of key-value pairs for each experiment. A set of related experiments is serialized as a list of these dicts in JSON. This is parseable in in R via the <code>rjson</code> package, but the data is loaded in a form which is challenging to analyze </p>

<pre><code>data &lt;- fromJSON('[{""""k1"""":""""v1"""",""""k2"""":""""v2""""}, {""""k1"""":""""v3"""",""""k2"""":""""v4""""}]')
</code></pre>

<p>yields</p>

<pre><code>[[1]]
[[1]]$k1
[1] """"v1""""

[[1]]$k2
[1] """"v2""""


[[2]]
[[2]]$k1
[1] """"v3""""

[[2]]$k2
[1] """"v4""""
</code></pre>

<p>Attempting to turn this into a <code>data.frame</code> directly with <code>as.data.frame(data)</code> yields:</p>

<pre><code>  k1 k2 k1.1 k2.1
1 v1 v2   v3   v4
</code></pre>

<p>clearly viewing the the sequence of key/value pairs across all experiments as a flat 1-dimensional list.</p>

<p>What I want is a more conventional table with a row for each experiment, and a column for each unique key:</p>

<pre><code>  k1 k2
1 v1 v2
2 v3 v4
</code></pre>

<p>How can I cleanly express this transform in R?</p>
",1
"<p>I am having some troubles with leading and trailing whitespace in a data.frame.
Eg I like to take a look at a specific <code>row</code> in a <code>data.frame</code> based on a certain condition:</p>

<pre><code>&gt; myDummy[myDummy$country == c(""""Austria""""),c(1,2,3:7,19)] 

[1] codeHelper     country        dummyLI    dummyLMI       dummyUMI       
[6] dummyHInonOECD dummyHIOECD    dummyOECD      
&lt;0 rows&gt; (or 0-length row.names)
</code></pre>

<p>I was wondering why I didn't get the expected output since the country Austria obviously existed in my <code>data.frame</code>. After looking through my code history and trying to figure out what went wrong I tried:</p>

<pre><code>&gt; myDummy[myDummy$country == c(""""Austria """"),c(1,2,3:7,19)]
   codeHelper  country dummyLI dummyLMI dummyUMI dummyHInonOECD dummyHIOECD
18        AUT Austria        0        0        0              0           1
   dummyOECD
18         1
</code></pre>

<p>All I have changed in the command is an additional whitespace after Austria. </p>

<p>Further annoying problems obviously arise. Eg when I like to merge two frames based on the country column. One <code>data.frame</code> uses <code>""""Austria """"</code> while the other frame has <code>""""Austria""""</code>. The matching doesn't work.</p>

<ol>
<li>Is there a nice way to 'show' the whitespace on my screen so that i am aware of the problem? </li>
<li>And can I remove the leading and trailing whitespace in R?</li>
</ol>

<p>So far I used to write a simple <code>Perl</code> script which removes the whitespace but it would be nice if I can somehow do it inside R.</p>
",1
"<p>I'm using <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer""""><strong>R</strong></a> language and the manuals on the R site are really informative. However, I'd like to see some more examples and implementations with R which can help me develop my knowledge faster. Any suggestions?</p>
",1
"<p>This question is for those of you who happen to use R, on a Mac, in combination with Macromate's [Textmate](http://macromates.com/) text editor and the """"R"""" Bundle. All of which are nifty, needless to say, but that's beside the point for now :-)</p>

<p>I've got a .RProfile file sitting in my default """"~"""" startup directory, and it's got a number of useful functions in it I like to have access to when writing R scripts. But I also use Textmate for most of my writing, and the cmd-R functionality to to run my scripts within Textmate.</p>

<h3>At the moment, I don't know how to tell Textmate where my .Rprofile is.</h3>

<p>Is there a way--most likely through Textmate's Bundle settings--that I can point Textmate to my .RProfile so I don't have to write my functions into every script on a per-script basis?</p>

<p>OR</p>

<p>Is it actually better to include any custom functions in any script I write, so that anyone with a basic R setup can source and run my scripts?</p>

<p>I feel like I must be missing a dead-easy setting or config file here within either Textmate or the R environment it calls to run my scripts.</p>

<p>Thanks so much in advance!</p>
",1
"<p>I have a 114 row by 16 column data frame where the rows are individuals, and the columns are either their names or NA. For example, the first 3 rows looks like this:</p>

<pre><code>            name name.1      name.2 name.3       name.4 name.5       name.6 name.7       name.8 name.9       name.10 name.11       name.12 name.13        name.14 name.15
1           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;      Aanestad    &lt;NA&gt;      Aanestad    &lt;NA&gt;       Aanestad    &lt;NA&gt;
2           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;     Ackerman   &lt;NA&gt;      Ackerman    &lt;NA&gt;      Ackerman    &lt;NA&gt;       Ackerman    &lt;NA&gt;
3           &lt;NA&gt;   &lt;NA&gt;        &lt;NA&gt;   &lt;NA&gt;         &lt;NA&gt;   &lt;NA&gt;      Alarcon   &lt;NA&gt;      Alarcon   &lt;NA&gt;       Alarcon    &lt;NA&gt;       Alarcon    &lt;NA&gt;           &lt;NA&gt;    &lt;NA&gt;
</code></pre>

<p>I want to generate a list (if multiple unique names per row) or vector (if only one unique name per row) of all the unique names, with length 114.</p>

<p>When I try <code>apply(x,1,unique)</code> I get a 2xNcol array where sometimes the first row cell is NA and sometimes the second row cell is NA.</p>

<pre><code>    [,1]       [,2]       [,3]      [,4]     [,5]      [,6]      [,7]    [,8]   [,9]    
[1,] NA         NA         NA        NA       """"Alquist"""" NA        """"Ayala"""" NA     NA      
[2,] """"Aanestad"""" """"Ackerman"""" """"Alarcon"""" """"Alpert"""" NA        """"Ashburn"""" NA      """"Baca"""" """"Battin""""
</code></pre>

<p>When what I'd like is just:</p>

<pre><code>Aanestad
Ackerman
Alarcon
...
</code></pre>

<p>I can't seem to figure out how to apply unique() while ignoring NA. na.rm, na.omit etc don't seem to work. I feel like I'm missing something real simple ...</p>

<p>Thanks!</p>
",1
"<p>I'm using ggplot2 to explore the effects of different military operations on murder rates. To show the effect I draw a vertical line when the operation occurred and a smoothed line of the murder rate before and after the operation. </p>

<p>I've written a facet_wrap plot to show this for a whole bunch of counties. It works beautifully, but when converted to a function I get an error when using a local variable to draw the vertical line. </p>

<p>Here's some example code:</p>

<pre><code>drawTS &lt;- function(df, dates, text) {
    p &lt;- ggplot(df, aes(date, murders)) +
      facet_wrap(~ county, ncol = 1,
                 scale=""""free_y"""") +
      scale_x_date() +
      geom_smooth(aes(group = group), se = FALSE)
    for(i in 1:length(dates)) {
      #If it's not a global variable I get an object not found error
      temp[i] &lt;&lt;- dates[i]
      p &lt;- p + geom_text(aes(x,y), label = text[i],
                  data = data.frame(x = dates[i], y = -10),
                  size = 3, hjust = 1, vjust = 0) +
           #Here's the problem
           geom_vline(xintercept=temp[i], alpha=.4)
    }
    p
}

library(ggplot2)
df &lt;- data.frame(date = rep(seq(as.Date(""""2007/1/01""""),
                          length=36, by='1 month'),4),
               murders = round(runif(36*4) * 100),
               county = rep(rep(factor(1:4),9),each=4),
               group = rep(c(rep(1,6), rep(2,12),rep(3,18))), each=4)
dates &lt;- c(as.Date(""""2007/6/15""""), as.Date(""""2008/6/15""""))
temp &lt;- c()
drawTS(df, dates, c(""""Op 1"""",""""Op 2""""))
</code></pre>

<p>There's no error with the global variable, but it looks ugly.</p>

<p>If instead of the <code>temp[i]</code> variable I use <code>dates[i]</code> inside <code>geom_vline()</code>, I get this: </p>

<blockquote>
  <p><em>Error in NextMethod(""""["""") : object 'i' not found</em></p>
</blockquote>

<p>If I wrap the variable <code>dates[i]</code> in <code>aes()</code>, I get: </p>

<blockquote>
  <p><em>Error in eval(expr, envir, enclos) : object 'county' not found</em></p>
</blockquote>

<p>Anybody know how to fix this?</p>
",1
"<p>I have a barplot for which the second half should fit to this formula:
<code>y~a<em>x</em>exp(-b*x^2)</code>. Now I want to plot the entire barplot and display the fitted model over the last part of the barplot as it only holds for that part. However, I cannot find a way to display the line-graph only over the second half. If I just do something like</p>

<pre><code>
submitted=c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 2L, 2L, 3L, 2L, 1L, 1L, 4L, 
3L, 2L, 11L, 6L, 2L, 16L, 7L, 17L, 36L, 27L, 39L, 41L, 33L, 42L, 
66L, 92L, 138L, 189L, 249L, 665L, 224L, 309L, 247L, 641L, 777L, 
671L, 532L, 749L, 506L, 315L, 292L, 281L, 130L, 137L, 91L, 40L, 
27L, 34L, 19L, 1L)
x=seq(0:(length(submitted)-1))
y1=rs$submitted[30:(length(submitted)-1)]
x1=seq(0:(length(y1)-1))
fit1=nls(y1~a*x1*exp(-b*x1^2),start=list(a=500,b=.01),trace=TRUE)
barplot(submitted,names.arg=x, las=2, cex.axis=0.8, cex=0.8)
lines(predict(fit1))
</code></pre>

<p>The line is displayed, but in the wrong position. So how can I control where the line is drawn?</p>
",1
"<p>I use windows XP and R for my desktop use. And a shared hosting account (at some company) for my web hosting needs.</p>

<p>I wish to create an R web application and I understand that one such way is by using R with Apache through <a href=""""http://biostat.mc.vanderbilt.edu/rapache/"""" rel=""""nofollow noreferrer"""">RApache</a> , but since my current shared hosting plan doesn't allow me to install RApache I am a bit stuck.</p>

<p>So... (and here's my question) what would be the easiest/fastest/cost-effective way to get started?</p>

<ul>
<li><p>Buying a more expensive hosting package ?</p></li>
<li><p>Hosting the thing myself? (on windows ?!)</p></li>
<li><p>switch to some other hosting company that permits the use of RApache?</p></li>
</ul>

<p>Any suggestion will be most helpful.</p>
",1
"<p>...regarding execution time and / or memory.</p>

<p>If this is not true, prove it with a code snippet. Note that speedup by vectorization does not count. The speedup must come from <code>apply</code> (<code>tapply</code>, <code>sapply</code>, ...) itself.</p>
",1
"<p>Given data     </p>

<pre><code>s&lt;-c(1,0,0,0,1,0,0,0,0,0,1,1,1,0,0)
</code></pre>

<p>I can count 1s and 0s with table or ftable</p>

<pre><code>ftable(s,row.vars =1:1)
</code></pre>

<p>and the totals of 11s,01s,10s,00s occurred in s with</p>

<pre><code>table(s[-length(s)],s[-1]).
</code></pre>

<p>What would be the clever way to count occurrences of 111s, 011s, ..., 100s, 000s? Ideally, I want a table of counts x like </p>

<pre><code>   0 1
11 x x
01 x x
10 x x
00 x x
</code></pre>

<p>Is there a general way to compute the total occurrences for all possible sub-sequences of length k=1,2,3,4, ... occurred in data? Thanks. </p>
",1
"<p>What is the difference between a vector and a data frame in R? Under what circumstances vectors should be converted to data frames?</p>
",1
"<p>I'm using Tinn-R version 2.2.0.2 and I want to upgrade to the latest version 2.3.4.4. I couldn't find any upgrade options in the menus of Tinn-R. So my question is: Is it safe to download and just install the new version? Will it overwrite my current Tinn-R settings?</p>
",1
"<p>Do the following function pairs generate exactly the same results?</p>

<p>Pair 1) <code>names()</code> &amp; <code>colnames()</code>  </p>

<p>Pair 2) <code>rownames()</code> &amp; <code>row.names()</code></p>
",1
"<p>Suppose I have a bivariate discrete distribution, i.e. a table of probability values P(X=i,Y=j), for i=1,...n and j=1,...m. How do I generate a random sample (X_k,Y_k), k=1,...N from such distribution? Maybe there is a ready R function like:</p>

<pre><code>sample(100,prob=biprob)
</code></pre>

<p>where biprob is 2 dimensional matrix? </p>

<p>One intuitive way to sample is the following. Suppose we have a data.frame</p>

<pre><code>dt=data.frame(X=x,Y=y,P=pij)
</code></pre>

<p>Where x and y come from</p>

<pre><code>expand.grid(x=1:n,y=1:m)
</code></pre>

<p>and pij are the P(X=i,Y=j). </p>

<p>Then we get our sample (Xs,Ys) of size N, the following way:</p>

<pre><code>set.seed(1000) 
Xs &lt;- sample(dt$X,size=N,prob=dt$P)
set.seed(1000)
Ys &lt;- sample(dt$Y,size=N,prob=dt$P)
</code></pre>

<p>I use set.seed() to simulate the """"bivariateness"""". Intuitively I should get something similar to what I need. I am not sure that this is correct way though. Hence the question :) </p>

<p>Another way is to use Gibbs sampling, marginal distributions are easy to compute. </p>

<p>I tried googling, but nothing really relevant came up.</p>
",1
"<p>I am working with NppToR as an extension allowing the use of notepad++ to be an IDE for R.</p>

<p>But there are a few features I didn't yet see implemented (I compiled the list from another IDE solution, which is not open source) :</p>

<p><strong>Object Browser</strong> - Allow users to see all the data and function objects that are available, including those in loaded and installed R packages.  Context menus provide the capability to quickly edit and plot data or load a package.</p>

<p><strong>Full-featured Visual Debugger</strong> - Debug R scripts, with step-in, step-over, and step-out capability, allowing users to inspect and modify R objects as they are debugging</p>

<p><strong>A Visual Solution Explorer</strong> - Organize, view, add, remove, rearrange, and deploy R scripts. Users can create their own Project Templates for automatic creation of a set of customized scripts for a new R project. Dockable, Floating, and Tabbed Tool Windows. for Creating personally customized workspaces.</p>

<p><strong>Enhanced Help</strong> - Complete search capabilities and hover-over tooltips for functions and data objects.</p>

<p><strong>R Code Snippets</strong> - Automatically generate fill-in-the-blank sections of R code for a variety of analyses. Tooltip help gives guidance in filling out the snippet.</p>

<p>Any Idea on how to get some of these already in notepad++ through some other noteps++ extensions or R packages ?</p>

<p>Thanks,
Tal</p>
",1
"<p>All,</p>

<p>I am starting to write object-oriented R code for the first time and anticipate having multiple R files with dependencies in between.  I'm new to R and have not yet wrote anything outside of a single massive script to test ideas.  Are there resources online that give tips on how one ought to organize code?  Short of descriptions on how to build packages, I'm failing to find such guidance.  At this point, I just want to organize the code in such a way that it makes loading and interacting with the collection of routines as straightforward as possible.  </p>

<p>Appreciate any guidance you can provide.  </p>

<p>Chris</p>
",1
"<p>When one wishes to compare (test) multiple groups (as is the case, for example, when doing anova), one is confronted with the issue of multiple comparisons. The same applys if we wish to plot the comparisons.</p>

<p>My question is thus, <strong>what tools (in R) do you know of that allow plotting that reflects multiple comparisons?</strong></p>

<p>Currently, I know of only two (although I am sure there are more):</p>

<ol>
<li>TukeyHSD( ) combined with plot( )</li>
<li>The way boxplot chooses the """"notches""""</li>
</ol>
",1
"<p>I remember coming across R users writing that they use """"Revision control"""" (<a href=""""https://stackoverflow.com/questions/1056912/source-control-vs-revision-control"""">e.g: """"Source control""""</a>), and I am curious to know: How do you combine """"Revision control"""" with your statistical analysis workflow?</p>

<p>Two (very) interesting discussions talk about how to deal with the workflow. But neither of them refer to the revision control element:</p>

<ul>
<li><a href=""""https://stackoverflow.com/questions/1266279/how-to-organize-large-r-programs"""">How to organize large R programs?</a></li>
<li><a href=""""https://stackoverflow.com/questions/1429907/workflow-for-statistical-analysis-and-report-writing"""">Workflow for statistical analysis and report writing</a></li>
</ul>

<p><strong>A Long Update To The Question</strong>: Following some of the people's answers, and Dirk's question in the comment, I would like to direct my question a bit more.</p>

<p>After reading the Wiki article about """"<a href=""""http://en.wikipedia.org/wiki/Revision_control"""" rel=""""nofollow noreferrer"""">revision control</a>"""" (which I was previously not familiar with), it was clear to me that when using revision control, what one does is to build a <strong>development structure</strong> of his code. This structure either leads to a """"final product"""" or to several branches.</p>

<p>When building something like, let's say, a website. There is usually one end product you work towards (the website), with some prototypes along the way.</p>

<p>But when doing a statistical analysis, the work (to my view) is different. Sometimes you know where you want to get to. But more often, you explore. Explore cleaning the dataset. Explore different methods for statistical analysis, and ask various questions of your data (and I am writing this, knowing how Frank Harrell, and other experience statisticians feels about <a href=""""http://en.wikipedia.org/wiki/Data_dredging"""" rel=""""nofollow noreferrer"""">Data dredging</a>).</p>

<p>That is why the workflow question with statistical programming is (in my view) a serious and deep question, raising many issues, The simpler ones are technical:</p>

<ul>
<li>Which revision control software do you use (and why) ?</li>
<li>Which IDE do you use(and why) ? 
The more interesting question are about work process:</li>
<li>How do you structure your files?</li>
<li>What do you keep as a separate file and what as a revision? or asking in a different way - What should be a """"branch"""" and what should be a """"sub project"""" in your code? For example: When starting to explore your data, should a plot be creating and then erased because it didn't lead any where (but kept as a revision) or should there be a backup file of that path?</li>
</ul>

<p>How <strong>you</strong> solve this tension was my initial curiosity. The second question is """"what might I be missing?"""". What rules (of thumb) should one follow so to avoid common pitfalls doing statistical programming with version control?</p>

<p>In my <strong>intuition</strong>, I feel that statistical programming is inherently different then software development (I am writing this without being a real expert in statistical programming, and even less so in software development). That's way I am unsure which of the lessons I have read here about version control would be applicable.</p>

<p>Thanks a lot,
Tal</p>
",1
"<p>I have the following code snippet:</p>

<pre><code>require(lattice)
f.barchart &lt;- function(...) {
    barchart(...,
        panel = function(x, y, ...) {
            panel.barchart(x, y, ...)
        }
    )
}

x &lt;- data.frame(a = c(1,1,2,2), b = c(1,2,3,4), c = c(1,2,2,1))
f.barchart(a ~ b, data = x, groups = c)
</code></pre>

<p>Which results in the following error being thrown:</p>

<pre><code>..3 used in an incorrect context, no ... to look in
</code></pre>

<p>When I use the following definition:</p>

<pre><code>f.barchart &lt;- function(...) {
    substitute(barchart(...,
        panel = function(x, y, ...) {
            panel.barchart(x, y, ...)
        }
    ))
}
</code></pre>

<p>I get:</p>

<pre><code>barchart(a ~ b, data = x, groups = c,
    panel = function(x, y, ...) {
        panel.barchart(x, y, a ~ b, data = x, groups = c)
    })
</code></pre>

<p>I'm not sure if this is the cause of above error but this would mean
that the ellipsis in panel.barchart gets wrongly expanded with the
contents of the arguments given to f.barchart and not the panel
function.</p>

<p>Is there a way to avoid this problem? How can I make the function
work? </p>
",1
"<p>There is an option in R to get control over digit display. For example:</p>

<pre><code>options(digits=10)
</code></pre>

<p>is supposed to give the calculation results in 10 digits till the end of R session. In the help file of R, the definition for digits parameter is as follows:</p>

<blockquote>
  <p>digits: controls the number of digits
  to print when printing numeric values.
  It is a suggestion only. Valid values
  are <strong>1...22</strong> with default <strong>7</strong></p>
</blockquote>

<p>So, it says this is a suggestion only. What if I like to always display 10 digits, not more or less?</p>

<p>My second question is, what if I like to display more than 22 digits, i.e. for more precise calculations like 100 digits? Is it possible with base R, or do I need an additional package/function for that?</p>

<p><strong>Edit:</strong> Thanks to jmoy's suggestion, I tried <code>sprintf(""""%.100f"""",pi)</code> and it gave</p>

<pre><code>[1] """"3.1415926535897931159979634685441851615905761718750000000000000000000000000000000000000000000000000000""""
</code></pre>

<p>which has 48 decimals. Is this the maximum limit R can handle? Actually pi has an infinite number of decimals.</p>
",1
"<p>How do you convert a data frame column to a numeric type?</p>
",1
"<p>I have a bunch of loglinear models, which, for our purposes will just be <code>glm()</code> objects called <code>mx, my, mz</code>.  I want to get a nicely-formatted <code>xtable</code> of the analysis of deviance, so naturally I would want to perform <code>xtable(anova(mx, my, mz, test = """"Chisq""""))</code>.</p>

<p>The vanilla output of <code>xtable</code>, however, doesn't include the model specifications.  I'd like to include those for all the ANOVA tests I'm running, so if there is not a param I'm missing that does this I'll probably just have to hack up my own solution.  But looking over the help page, there doesn't seem to be an easy way to include the model specifications.  </p>

<p>Any thoughts?  Alternatives?</p>

<p>If it helps this was done in 2.9.1 with xtable 1.5-5.</p>
",1
"<p>I am creating some graphs which I want to update into a database table. The procedure I am following is:</p>

<ol>
<li>create the graphs as a png/jpeg file.</li>
<li>Read that file as a binary vector</li>
<li>sqlUpdate</li>
</ol>

<p>My code for steps 2 &amp; 3:</p>

<pre><code>  pngfile &lt;- file(&lt;filename&gt;, """"rb"""")
  N &lt;- 1e6
  repeat{
    pngfilecontents &lt;- readBin(pngfile, what=""""raw"""", n=N)
    if(length(pngfilecontents) == N) N &lt;- 5 * N else break
  }
  close(pngfile)
</code></pre>

<p>There is a table df_DemandPatternMaster in the database with primary key DemandPatternID, with appropriate record in place with NULL value in pngFile field.</p>

<pre><code>  update.query &lt;- """"update df_DemandPatternMaster set """"
  update.query &lt;- paste( update.query, """" pngFile = '"""", serialize(pngfilecontents, NULL) , """"' where DemandPatternID = """", , sep="""""""")
  d &lt;- sqlQuery(connection, update.query)
</code></pre>

<p>I end up inserting only a byte of data. The reason it seems is that paste sees the serialized vector and creates a vector with the prefix &amp; suffix text.
I have also tried passing the pngfile handle directly</p>

<pre><code>pngfile &lt;- file(&lt;filename&gt;, """"rb"""")
update.query &lt;- paste( update.query, """" pngFile = '"""", pngfile, """"' where DemandPatternID = """", , sep="""""""")
</code></pre>

<p>This also fails.</p>

<p>Please advise.</p>
",1
"<p>Let's say I have created the following matrix:</p>

<pre><code>&gt; x &lt;- matrix(1:20000,nrow=100)
&gt; x[1:10,1:10]
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    1  101  201  301  401  501  601  701  801   901
 [2,]    2  102  202  302  402  502  602  702  802   902
 [3,]    3  103  203  303  403  503  603  703  803   903
 [4,]    4  104  204  304  404  504  604  704  804   904
 [5,]    5  105  205  305  405  505  605  705  805   905
 [6,]    6  106  206  306  406  506  606  706  806   906
 [7,]    7  107  207  307  407  507  607  707  807   907
 [8,]    8  108  208  308  408  508  608  708  808   908
 [9,]    9  109  209  309  409  509  609  709  809   909
[10,]   10  110  210  310  410  510  610  710  810   910
</code></pre>

<p>What are the methods in R to change row and column names? For example, I like row names to be <code>SS1, SS2, ..., SS100</code> and column names to be <code>M1, M2, ..., M200</code>. I usually work with data with 1000s of rows and columns, and I need a good method to do that. Some people use something like <code>attributes(x)$dimnames &lt;- list(...)</code> and some use <code>rownames &lt;- paste(...)</code>. What are all possible methods?</p>

<p>My second question is, can I use the same methods after I convert the matrix to a data frame? </p>
",1
"<p>Is there Java or .NET version of R?
(like Jython / IronPython for the Python language)</p>

<p>I guess some R-packages which use C or Fortran may not run on Java/.NET version of R, but as long as pure R code can be run, it must be great.</p>
",1
"<p>I have a large data set I am plotting in R, and I'd like to have an axis on each side of the graph show the data in two different scales. So for example, on the left vertical axis I'd like to plot the data directly (e.g. plot(y ~ x) ) and on the right axis, I'd like to have a linear scaling of the left axis. (e.g. plot( y*20 ~ x). </p>

<p>So there would only be one data set displayed, but the axes would show different meanings for those data points.</p>

<p>I've tried the following:</p>

<pre><code>plot(x = dataset$x, y = dataset$y)
axis(4, pretty(dataset$y,10) )
</code></pre>

<p>This will correctly print a new right axis with the same scale as the default left axis. (essentially useless, but it works) However, if I make this tiny change:</p>

<pre><code>plot(x = dataset$x, y = dataset$y)
axis(4, pretty(10*dataset$y,10) )
</code></pre>

<p>Suddenly, it refuses to add my new right axis. I suspect this has something to do with R seeing if the axis matches the data set in some way and rejecting it if not. How can I get R to ignore the data set and just print an arbitrary axis of my choosing?</p>
",1
"<p>I'm trying to read data from csv file, but instead of e.g. 001000 I get 1000 in my data.<br>
I've tried to set <code>as.is=!stringsAsFactors</code>, but got the following error message:</p>

<pre><code> error: object stringsAsFactors not found.  
</code></pre>

<p>Anybody can help?</p>
",1
"<p>I have two vectors in R of different size, and I want to add them, but without repeating the shorter one - instead, I want the """"missing"""" numbers to be zeroes.</p>

<p>Example:</p>

<pre><code>x&lt;-c(1,2)
y&lt;-c(3,4,5)
z&lt;-x+y 
</code></pre>

<p>Now, <code>z</code> is <code>4 6 6</code>, but I want it only <code>4 6 5</code>.</p>
",1
"<p>What's the most efficient way to sort two vectors in lockstep in R?  The first vector should be sorted in ascending order and the second should be reordered in lockstep such that elements with corresponding indices before the sort still have corresponding indices after the sort.  For example:</p>

<pre><code>foo &lt;- c(1,3,2, 5,4)
bar &lt;- c(2,6,4,10,8)
sort2(foo, bar)

# foo == c(1,2,3,4, 5)
# bar == c(2,4,6,8,10)
</code></pre>

<p>Note:  Efficiency is an absolute must here as I am trying to use this as the basis for creating an O(N log N) implementation of Kendall's Tau to submit as a patch.  I'd like to avoid writing my own special function in C to do this, but would be willing to if it can't be done efficiently within R.</p>
",1
"<p>
    I'm taking my first course in multiple linear regression, so I'm still a beginner in R. We've recently learned a bit about taking slices of bivariate scatterplot data, both horizontally and vertically. What I'd like to know is how to go beyond a basic scatterplot, and take advantage of conditionally grouping data by slices to examine patterns.
    </p>

<p><p>
  As an example, I'm working with high-octane data from a bank where we're regressing employee's current salary <code>csalary</code> onto their beginning salary <code>bsalary</code>. Here's what my dataframe looks like.</p>

<pre>
  <code>
    > str(data)
    'data.frame':   474 obs. of  10 variables:
     $ id     : num  628 630 632 633 635 637 641 649 650 652 ...
     $ bsalary: num  8400 24000 10200 8700 17400 ...
     $ gender : Factor w/ 2 levels """"Male"""",""""Female"""": 1 1 1 1 1 1 1 1 1 1 ...
     $ time   : num  81 73 83 93 83 80 79 67 96 77 ...
     $ age    : num  28.5 40.3 31.1 31.2 41.9 ...
     $ csalary: num  16080 41400 21960 19200 28350 ...
     $ educlvl: num  16 16 15 16 19 18 15 15 15 12 ...
     $ work   : num  0.25 12.5 4.08 1.83 13 ...
     $ jobcat : Factor w/ 7 levels """"Clerical"""",""""Office Trainee"""",..: 4 5 5 4 5 4 1 1 1 3 ...
     $ ethnic : Factor w/ 2 levels """"White"""",""""Non-White"""": 1 1 1 1 1 1 1 1 1 1 ...
  </code>
</pre>

<p>
  To explore the relationship of <code>bsalary</code> and <code>csalary</code> I created a scatterplot using some of the functionality of <code>lattice</code> library. I arbitrarily drew vertical lines at $5000 intervals along <code>bsalary</code>.
</p>

<p>
<pre>
  <code>
    library (lattice)
    # Constructing vertical """"slices"""" of our csalary ~ bsalary data
    # First we define a vector with our slice points, in this case 
    # $5,000 bsalary increments
    bslices = seq (from = 5000, to = 30000, by = 5000)
    length (bslices)
    xyplot (csalary ~ bsalary,
        main  = """"Current Bank Employee Salary as Predicted by Beginning Salary"""",
        xlab  = """"Beginning Salary ($USD)"""",
        ylab  = """"Current Salary ($USD)"""",
        panel = function(...){
            panel.abline(v = bslices, col=""""red"""", lwd=2);
            panel.xyplot(...);
        }
    )
  </code>
</pre>
</p>

<p>
  The above code gets me this.
</p>

<a href=""""http://skitch.com/capbri/nsq1r/rplot002.pdf-1-page"""" rel=""""nofollow noreferrer"""">Rplot002.pdf (1 page) http://img.skitch.com/20100222-tkcu613r9cjqc4cs3314hc1i7h.preview.jpg</a><br />

<p>
  Which is fantastic. But I feel like there ought to be a simple way to generate, from my data, graphs that group slice data into boxplots:
</p>

<p><a href=""""http://skitch.com/capbri/nsq1y/01linreg.pdf-page-3-of-25"""" rel=""""nofollow noreferrer"""">01LinReg.pdf (page 3 of 25) http://img.skitch.com/20100222-rhjudjw4txnfu43pycuqneuqan.preview.jpg</a><br /></p>

<p><p>
   Or stacked-dot scatterplots, again grouped by slice, like this:
 </p></p>

<p><a href=""""http://skitch.com/capbri/nsq1b/01linreg.pdf-page-3-of-25"""" rel=""""nofollow noreferrer"""">01LinReg.pdf (page 3 of 25) http://img.skitch.com/20100222-cgsqwnhnd26k5qhb6gb2sjk1bs.preview.jpg</a><br /></p>

<p><p>
  Ultimately, my question is how to turn raw scatterplot data into conditionally-grouped data. I feel like there are some simple, underlying features of lattice (or even the simpler plot commands that don't require it) that would allow me to start slicing my data to explore for patterns.
 </p></p>

<p><p>
  Thanks in advance for your help!
 </p></p>
",1
"<p>My question is how to extract the name of a variable from a function that is called in another function in R?</p>

<p>To illustrate, here is an example: </p>

<pre><code>a &lt;- function(variable) {

    print(deparse(substitute(variable)))

    internala(substitute(variable))

}

internala &lt;- function(variableXX) {

    namex=deparse(substitute(variableXX))

    print(namex)
}
</code></pre>

<p>Calling the function  <code>a</code>  gives the following result:</p>

<pre><code>&gt;a(whatever)

[1] """"whatever""""

[1] """"substitute(variable)""""
</code></pre>

<p>which means that i can extract the name of the variable <code>whatever</code> from <code>a</code>, but not from <code>internala</code>.</p>

<p>Any thoughts on this?</p>

<p>Any help will be appreciated!</p>

<p>Maria</p>
",1
"<p>Is it possible to include .R files in the data directory of my package in the roxygen process?</p>

<p>I have put several .R files in the data directory. When they are sourced with data(), they read in raw data files and perform some transformations.</p>
",1
"<p>I have a dendrogram given to me as images. Since it is not very large, I can construct it """"by hand"""" into an R object.</p>

<p>So my question is how do I manually create a dendrogram (or """"hclust"""") object, when all I have is the dendrogram image ?</p>

<p>I see that there is a function called """"as.dendrogram"""" But I wasn't able to find an example on how to use it.</p>

<p>(p.s: This post is following my question from <a href=""""https://stackoverflow.com/questions/2218395/how-do-you-compare-the-similarity-between-two-dendrograms-in-r"""">here</a>)</p>

<p>Many thanks,
Tal</p>
",1
"<p>Many algorithms for clustering are available. A popular algorithm is the K-means where, based on a given number of clusters, the algorithm iterates to find best clusters for the objects. </p>

<p>What method do you use to determine the number of clusters in the data in k-means clustering?</p>

<p>Does any package available in R contain the <code>V-fold cross-validation</code> method for determining the right number of clusters?</p>

<p>Another well used approach is Expectation Maximization (EM) algorithm which assigns a probability distribution to each instance which indicates the probability of it belonging to each of the clusters.</p>

<p>Is this algorithm implemented in R?</p>

<p>If it is, does it have the option to automatically select the optimum number of clusters by cross validation?</p>

<p>Do you prefer some other clustering method instead?</p>
",1
"<p>I'm trying to understand how the <code>order()</code> function works.  I was under the impression that it returned a permutation of indices, which when sorted, would sort the original vector.</p>

<p>For instance,</p>

<pre><code>&gt; a &lt;- c(45,50,10,96)
&gt; order(a)
[1] 3 1 2 4
</code></pre>

<p>I would have expected this to return <code>c(2, 3, 1, 4)</code>, since the list sorted would be 10 45 50 96.</p>

<p>Can someone help me understand the return value of this function?</p>
",1
"<p>I've just started playing around with the <code>roxygen</code> package and I've very happy with the results so far.  However I was wondering, is there a way to specify to <code>roxygen</code> that it should ignore certain functions that are not user-accessible?</p>

<p>Specifically, I'd rather not have a <code>.Rd</code> file pop up because I'm using the <code>.onLoad()</code> hook in my package.  This function is already documented in the <code>base</code> package so there's no reason for me to re-document it.</p>
",1
"<p>I'm trying to change the name of a variable that is included inside a for loop and function call.  In the example below, I'd like column_1 to be passed to the plot function, then column_2 etc.  I've tried using do.call, but it returns """"object 'column_j' not found"""".  But object column_j is there, and the plot function works if I hard-code them in.   Help much appreciated.</p>

<pre><code>for (j in 2:12) {
    column_to_plot = paste(""""column_"""", j, sep = """""""")
    do.call(""""plot"""", list(x, as.name(column_to_plot)))
}
</code></pre>
",1
"<p>I'm using the support vector machine from the e1071 package to classify my data and want to visualize how the machine actually does the classification. However, when using the plot.svm function, I get an error that I can't resolve.</p>

<p>Script:</p>

<pre><code>library(""""e1071"""")

data &lt;-read.table(""""2010223_11042_complete"""")
names(data) &lt;- c(""""Class"""",""""V1"""", """"V2"""")

model &lt;- svm(Class~.,data, type = """"C-classification"""", kernel = """"linear"""")
plot(model,data,fill=TRUE, grid=200, svSymbol=4, dataSymbol=1, color.palette=terrain.colors)
</code></pre>

<p>Output:</p>

<pre><code>plot(model,data,fill=TRUE, grid=200, svSymbol=4, dataSymbol=1, color.palette=terrain.colors)
Error in rect(0, levels[-length(levels)], 1, levels[-1L], col = col) : 
  cannot mix zero-length and non-zero-length coordinates
</code></pre>

<p>Traceback:</p>

<pre><code>traceback()
4: rect(0, levels[-length(levels)], 1, levels[-1L], col = col)
3: filled.contour(xr, yr, matrix(as.numeric(preds), nr = length(xr), 
       byrow = TRUE), plot.axes = {
       axis(1)
       axis(2)
       colind &lt;- as.numeric(model.response(model.frame(x, data)))
       dat1 &lt;- data[-x$index, ]
       dat2 &lt;- data[x$index, ]
       coltmp1 &lt;- symbolPalette[colind[-x$index]]
       coltmp2 &lt;- symbolPalette[colind[x$index]]
       points(formula, data = dat1, pch = dataSymbol, col = coltmp1)
       points(formula, data = dat2, pch = svSymbol, col = coltmp2)
   }, levels = 1:(length(levels(preds)) + 1), key.axes = axis(4, 
       1:(length(levels(preds))) + 0.5, labels = levels(preds), 
       las = 3), plot.title = title(main = """"SVM classification plot"""", 
       xlab = names(lis)[2], ylab = names(lis)[1]), ...)
2: plot.svm(model, data, fill = TRUE, grid = 200, svSymbol = 4, 
       dataSymbol = 1, color.palette = terrain.colors)
1: plot(model, data, fill = TRUE, grid = 200, svSymbol = 4, 
       dataSymbol = 1, color.palette = terrain.colors)
</code></pre>

<p>Part of my (4488 lines long) data file:</p>

<pre><code>-1 0 23.532
+1 1 61.1157
+1 1 61.1157
+1 1 61.1157
-1 1 179.03
-1 0 17.0865
-1 0 27.6201
-1 0 17.0865
-1 0 27.6201
-1 1 89.6398
-1 0 42.7418
-1 1 89.6398
</code></pre>

<p>Since I`m just starting with R, I have no idea what this means and how I should deal with it, nor did I find anything useful in other places.</p>
",1
"<p>Can a function in R return not one, but two vectors?</p>

<p><em>(I am really beginning with R, so I might be overlooking something simple)</em></p>
",1
"<p>I'm trying to read a text file into R so I can use the sqldf functions.  I'm following this example, <a href=""""https://stat.ethz.ch/pipermail/r-help/2008-January/152040.html"""" rel=""""nofollow noreferrer"""">https://stat.ethz.ch/pipermail/r-help/2008-January/152040.html</a>, but I have a text file holding my data instead of the data being pasted as the example has it.   My text file is below:</p>

<pre><code>#""""test.table.1.0"""" file has this contents:
id  Source
1     A10
2     A32
3     A10
4     A25
</code></pre>

<p>I tried this following the example</p>

<pre><code>test_table &lt;- read.table(textConnection(""""test.table.1.0""""))
</code></pre>

<p>I can see that the problem is that textConnection is supposed to take a character vector, 
and I'm giving it a data.frame, but converting it via as.character also fails.  Ultimately, I want to run a query like this:</p>

<pre><code>sqldf(""""select test_table.source from test_table"""");
</code></pre>
",1
"<p>I have some mixed-type data that I would like to store in an R data structure of some sort.  Each data point has a set of fixed attributes which may be 1-d numeric, factors, or characters, and also a set of variable length data.  For example:</p>

<pre><code>id  phrase                    num_tokens  token_lengths
1   """"hello world""""             2           5 5
2   """"greetings""""               1           9
3   """"take me to your leader""""  4           4 2 2 4 6
</code></pre>

<p>The actual values are not all computable from one another, but that's the flavor of the data. The operations I'm going to want to do include subsetting the data based on boolean functions (e.g. something like <code>nchar(data$phrase) &gt; 10</code> or <code>lapply(data$token_lengths, length) &gt; 2)</code>.  I'd also like to index and average values in the variable length portion by index. This doesn't work, but something like: <code>mean(data$token_lengths[1], na.rm=TRUE))</code></p>

<p>I've found I can shoehorn """"token_lengths"""" into a data.frame by making it an array:</p>

<pre><code>d &lt;- data.frame(id=c(1,2,3), ..., token_lengths=as.array(list(c(5,5), 9, c(4,2,2,4,6)))
</code></pre>

<p>But is this the best way?</p>
",1
"<p>I am trying to produce plots with a loop.</p>

<pre><code>l1&lt;-factor(rep(letters,4))
n1&lt;-abs(rnorm(104))*10000
b1&lt;-rep(c(""""1"""",""""2"""",""""3"""",""""4"""",""""5"""",""""6"""",""""7"""",""""8""""),c(2,2,11,24,11,20,33,1))
k1&lt;-rep((rep(c(""""A"""",""""B"""",""""C"""",""""D""""),c(2,3,4,4))),8)
my.df&lt;-data.frame(l1,b1,k1,n1)                            #make a dataframe

names(my.df)&lt;-c(""""letter"""",""""branch"""",""""ltrtype"""",""""number"""")     #factor names
library(ggplot2)

branch.list&lt;-unique(my.df$branch)
sayi&lt;-length(branch.list)                                 # list of factor:letters

for (i in 1:sayi) {

branch.iter&lt;-branch.list[i]
my.df.plot&lt;-subset(my.df,my.df$branch==branch.iter,drop=T)

my.df.plot$branch&lt;-factor(my.df.plot$branch)               #So that unused levels don't show up
my.df.plot$letter&lt;-factor(my.df.plot$letter)               #So that unused levels don't show up
my.df.plot$ltrtype&lt;-factor(my.df.plot$ltrtype)             #So that unused levels don't show up
my.df.plot$number&lt;-as.numeric(as.character(my.df.plot$number))
my.df.plot&lt;-data.frame(my.df.plot)

myfilename&lt;-paste(branch.iter,"""".jpeg"""",sep="""""""")
jpeg(file=myfilename)

cizim&lt;-ggplot(my.df.plot,aes(letter,number,fill=ltrtype))
cizim&lt;-cizim + geom_bar(width = 1, position = """"fill"""", binwidth = 1) +     facet_grid(ltrtype~.)
cizim&lt;-cizim + opts(title=branch.iter)

print(cizim)
dev.off()

}
</code></pre>

<p>(Q1): When number of levels in x-axis change width of bars change
How can i prevent this and make bar width in every plot same?</p>

<p><a href=""""http://img411.imageshack.us/i/95325388.jpg/"""" rel=""""nofollow noreferrer"""">alt text http://img411.imageshack.us/i/95325388.jpg/</a></p>

<p><a href=""""http://img411.imageshack.us/i/91510133.jpg/"""" rel=""""nofollow noreferrer"""">alt text http://img411.imageshack.us/i/91510133.jpg/</a></p>

<p>(Q2): when <code>i=7</code> R gives following warning:</p>

<blockquote>
  <p>(data$ymin == 0)) warning(""""Filling not well defined when ymin != 0"""") :
  missing value where TRUE/FALSE needed</p>
</blockquote>

<p>what can i do about it?</p>

<p>(Q3): Is there an easier way to drop unused levels in such a case so i don't have to use</p>

<pre><code> my.df.plot$branch&lt;-factor(my.df.plot$branch)
</code></pre>

<p>everytime?</p>
",1
"<p>I have a data.frame called series_to_plot.df which I created by combining a number of other data.frames together (shown below).  I now want to pull out just the .mm column from each of these, so I can plot them.   So I want to pull out the 3rd column of each data.frame (e.g. p3c3.mm, p3c4.mm etc...), but I can't see how to do this for all data.frames in the object without looping through the name.  Is this possible?</p>

<p>I can pull out just one set: e.g. series_to_plot.df[[3]]   and another by 
series_to_plot.df[[10]] (so it is just a list of vectors..) and I can reference directly with  series_to_plot.df$p3c3.mm, but is there a command to get a vector containing all mm's from each data.frame?  I was expecting an index something like this to work: series_to_plot.df[,3[3]]  but it returns  Error in <code>[.data.frame</code>(series_to_plot.df, , 3[3]) : undefined columns selected</p>

<pre><code>series_to_plot.df
          p3c3.rd         p3c3.day    p3c3.mm      p3c3.sd                 p3c3.n p3c3.noo p3c3.no_NAs
    1     2010-01-04             0    0.1702531    0.04003364              7                1           0
    2     2010-01-06             2    0.1790594    0.04696674              7                1           0
    3     2010-01-09             5    0.1720404    0.03801756              8                0           0

          p3c4.rd         p3c4.day    p3c4.mm      p3c4.sd                 p3c4.n p3c4.noo p3c4.no_NAs
    1     2010-01-04             0    0.1076581   0.006542157              6                2           0
    2     2010-01-06             2    0.1393447   0.066758781              7                1           0
    3     2010-01-09             5    0.2056846   0.047722862              7                1           0

          p3c5.rd         p3c5.day    p3c5.mm      p3c5.sd                 p3c5.n p3c5.noo p3c5.no_NAs
    1     2010-01-04             0   0.07987147   0.006508766              7                1           0
    2     2010-01-06             2   0.11496167   0.046478767              8                0           0
    3     2010-01-09             5   0.40326471   0.210217097              7                1           0
</code></pre>
",1
"<p>In ggplot I can add a series to a plot with:</p>

<pre><code>ggplot(diamonds, aes(x = carat, y = price)) + geom_point()
</code></pre>

<p>How do I simply add another series, e.g. plotting the cost of rubies against diamonds.  Assuming rubies was also in the diamonds dataset.  I have tried to lay over the top another layer with the rubies data, but it just plots the rubies and not the diamonds/carat.</p>

<pre><code>ggplot(diamonds, aes(x = carat, y = price)) + geom_point() + aes(x = rubies, y = price)
</code></pre>

<p>I can see that this would be possible by melding all the data together first, ready to plot it, so maybe I should go down that route.   However, just adding another series to a plot like this seems like it should not be too hard, but I can't figure out how to do it.</p>
",1
"<p>I created an age-sex-pyramid using gplots. I would like to center a subtitle between the two sides of the pyramid.</p>

<p>However, I can only get the subtitle aligned with one of the two sides of the pyramid:</p>

<pre><code>library(gplots)
agetable &lt;- as.data.frame(cbind (c(2, 4, 7, 8, 10, 8, 6, 4, 2, 1), 
                                 c(1, 3, 5, 9, 11, 6, 4, 1, 0, 1)))
names(agetable) &lt;- c(""""Male"""", """"Female"""")
maxdir &lt;- max(agetable)
subtitle &lt;- """"34% of data are mising age or sex""""

agegraph.general.bysex &lt;- function(agetable, maxdir, varname, miss){
agegroups &lt;- 
if (varname=='Male') {
  datavec &lt;- agetable[,'Male']
  lim = c(maxdir,0)
  agelabels = c('0-9','10-19','20-29','30-39','40-49','50-59',
                '60-69','70-79','80-89','90+')
} else {
  datavec &lt;- agetable[,'Female']
  lim = c(0, maxdir)
     agelabels = ''
}
barplot2(
       datavec, horiz=TRUE, space=0, xlab = varname, xlim=lim, col='grey85',
       axisnames=TRUE, cex.axis = 1, cex.names = 1, names.arg=agelabels, 
       plot.grid=TRUE, cex.sub = 0.8, sub = miss)
}


layout(matrix(1:2, ncol=2, nrow=1))
par(las=1, adj=0.5, omi=c(0.1, 0.1, 0.1 ,0.1), cex=0.8 , cex.lab=0.8)
par(mar=c(7,5,0,0))
agegraph.general.bysex(agetable, maxdir, 'Male', subtitle)
par(mar=c(7,0,0,5))
agegraph.general.bysex(agetable, maxdir, 'Female', '')
</code></pre>

<p>I would be grateful for any suggestions!</p>
",1
"<p>I've written an SQL query that tells me the names of the previous week's top 10 most frequent Alarms. And I've written a query that takes those top 10 alarms and provides a YTD weekly totals for each of those alarms.</p>

<p>Now I'm looking to create a panel of sparklines showing the YTD trend for each of the week's top 10 alarms. </p>

<p>I got something resembling what I'd like, but I now need to make it """"dynamic"""". i.e. to make it work without hardcoding the names of the alarms (since these will change with the SQL query every week).</p>

<p>How can I go about changing the R code below to work without hardcoding the names of the alarms? </p>

<p>Does levels(spark$Alarm) have something to do with?</p>

<p>Thanks kindly for the advice :-)</p>

<pre><code>Week = c(rep(1:8,2))
Total = rnorm(16,1000,600)
Alarm = c(rep(""""BELTWEIGHER HIGH HIGH"""",8), rep(""""MICROWAVE LHS"""",8))
spark &lt;- data.frame(Week, Alarm, Total)

s &lt;- ggplot(spark, aes(Week, Total)) +
     facet_grid(Alarm ~ ., scales = """"free"""", as.table = FALSE) +
     opts(
  panel.background = theme_rect(size = 1, colour = """"lightgray""""),
  panel.grid.major = theme_blank(),
  panel.grid.minor = theme_blank(),
  axis.line = theme_blank(),
  axis.text.x = theme_blank(),
  axis.text.y = theme_blank(),
  axis.title.x = theme_blank(),
  axis.title.y = theme_blank(), 
  axis.ticks = theme_blank(),
  strip.background = theme_blank(),
  strip.text.y = theme_text(size = 7, colour = """"red"""", angle = 90)
 )

s1 &lt;- s  + geom_line(subset = .(Alarm == """"BELTWEIGHER HIGH HIGH""""))
s2 &lt;- s1 + geom_line(subset = .(Alarm == """"MICROWAVE LHS""""))
s2
</code></pre>
",1
"<p>I have a simple program that breaks a dataset (a CSV file) into 4 chunks, reads each chunk in, does some calculations, and then appends the output together.  Think of it as a simple map-reduce operation.  Processing a single chunk uses about 1GB of memory.  I'm running the program on a quad core PC, with 4GB of ram, running Windows XP.  I happen to have coded it up using R, but I don't think it's relevant.</p>

<p>I coded up two versions.  One version processes each chunk in sequence.  The other version processes chunks two at a time in parallel.  Both versions take nearly the same amount of time to finish.</p>

<p>Under what circumstances would you expect to see this performance result?</p>

<p>My current hypothesis is that the processes are bounded by the memory performance, but I don't know the best way to investigate this further.  Any suggestions or guesses?</p>

<p>Edit: The program is not IO-bound in terms of the disk.  The processing step reads a chunk of a CSV file into memory, churns on it for 5 minutes or so, and then writes the result back out to a file on disk.  The file input and output takes a few seconds at most.</p>
",1
"<p>I'm writing an R script to get some database data and then do stuff with it, using the RODBC package.  Currently all my sqlQuery commands are one long string;</p>

<pre><code>stsample&lt;-sqlQuery(odcon, paste""""select * from bob.DESIGNSAMPLE T1, bob.DESIGNSUBJECTGROUP T2, bob.DESIGNEVENT T3, bob.CONFIGSAMPLETYPES T4 WHERE T1.SUBJECTGROUPID = T2.SUBJECTGROUPID AND T1.TREATMENTEVENTID = T3.TREATMENTEVENTID AND T1.SAMPLETYPEKEY = T4.SAMPLETYPEKEY AND T1.STUDYID = T2.STUDYID AND T1.STUDYID = T3.STUDYID AND T1.STUDYID = """", chstudid, sep=""""""""))
head(stsample)
</code></pre>

<p>which looks ugly and is hard to read/update.  I've tried putting them multiline, but then new line characters get in the way, currently my best is this using lots of paste's;</p>

<pre><code>stsample&lt;-sqlQuery(odcon,
    paste(
        """"select """",
            """"* """", 
        """"from """", 
            """"BOB.DESIGNSAMPLE T1, """",
            """"BOB.DESIGNSUBJECTGROUP T2, """",
            """"BOB.DESIGNEVENT T3, """",
            """"BOB.CONFIGSAMPLETYPES T4 """",
        """"WHERE """",
            """"T1.SUBJECTGROUPID = T2.SUBJECTGROUPID """",
            """"AND T1.TREATMENTEVENTID = T3.TREATMENTEVENTID """",
            """"AND T1.SAMPLETYPEKEY = T4.SAMPLETYPEKEY """",
            """"AND T1.STUDYID = T2.STUDYID """",
            """"AND T1.STUDYID = T3.STUDYID """",
            """"AND T1.STUDYID = """",chstudid,
        sep="""""""")
    )
head(stsample)
</code></pre>

<p>But I don't like having to put quotes around everyline, and getting my whitespace correct.  Is there a better way ?</p>
",1
"<p>Trying the ggplot2 examples in the online reference manual, and particularly in <a href=""""http://had.co.nz/ggplot2/stat_density2d.html"""" rel=""""nofollow noreferrer"""">this page</a>, I fail to produce all but the first of the second example's plots.</p>

<pre><code>&gt; d + stat_density2d(geom=""""tile"""", aes(fill = ..density..), contour = FALSE) 
Error in `[&lt;-.data.frame`(`*tmp*`, var, value = list(`NA` = NULL)) : 
  missing values are not allowed in subscripted assignments of data frames
In addition: Warning message:
Removed 34912 rows containing missing values (stat_density2d).
</code></pre>

<p>I have R ver. 2.10.1 and ggplot2 ver. 0.8.6</p>

<p>What is wrong?</p>
",1
"<p>I have the following setup to analyse:
We have about 150 subjects, and for each subject we performed a pair of tests (under different conditions) 18 times.
The 18 different conditions of the test are complementary, in such a way so that if we where to average over the tests (for each subject), we would get no correlation between the tests (between subjects).
What we wish to know is the correlation (and P value) between the tests, in within subjects, but over all the subjects.</p>

<p>The way I did this by now was to perform the correlation for each subject, and then look at the distribution of the correlations received so to see if it's mean is different then 0.
But I suspect there might be a better way for answering the same question (someone said to me something about """"geographical correlation"""", but a shallow search didn't help).</p>

<p>p.s: I understand there might be a place here to do some sort of mixed model, but I would prefer to present a """"correlation"""", and am not sure how to extract such an output from a mixed model.</p>

<p>Also, here is a short dummy code to give an idea of what I am talking about:</p>

<pre><code>attach(longley)
N &lt;- length(Unemployed)
block &lt;- c(
        rep( """"a"""", N),
        rep( """"b"""", N),
        rep( """"c"""", N)
        )

Unemployed.3 &lt;- c(Unemployed + rnorm(1),
                    Unemployed + rnorm(1),
                    Unemployed + rnorm(1))

GNP.deflator.3 &lt;- c(GNP.deflator + rnorm(1),
                    GNP.deflator + rnorm(1),
                    GNP.deflator + rnorm(1))

cor(Unemployed, GNP.deflator)
cor(Unemployed.3, GNP.deflator.3)
cor(Unemployed.3[block == """"a""""], GNP.deflator.3[block == """"a""""])
cor(Unemployed.3[block == """"b""""], GNP.deflator.3[block == """"b""""])
cor(Unemployed.3[block == """"c""""], GNP.deflator.3[block == """"c""""])
(I would like to somehow combine the last three correlations...)
</code></pre>

<p>Any ideas will be welcomed.</p>

<p>Best,
Tal</p>
",1
"<p>I've been banging my head against <code>rpart</code> for a few days now (trying to make classification trees for this dataset that I have), and I think it's time to ask a lifeline at this point :-)  I'm sure it's something silly that I'm not seeing, but here's what I've been doing:</p>

<pre><code>EuropeWater &lt;- read.csv(file=paste(""""/Users/artessaniccola/Documents/"""",
                       """"Magic Briefcase/CityTypology/Europe_water.csv"""",sep=""""""""))
library(rpart)
attach(EuropeWater)
names(EuropeWater)
[1] """"City""""          """"waterpercapita_m3"""" """"water_class""""       """"population""""       
[5] """"GDPpercapita""""  """"area_km2""""          """"populationdensity"""" """"climate""""            
EuropeWater$water_class &lt;- factor(EuropeWater$water_class, levels=1:3, 
                                  labels=c(""""Low"""", """"Medium"""", """"High""""))
EuropeWater$climate &lt;- factor(EuropeWater$climate, levels=2:4, 
                              labels=c(""""Arid"""", """"Warm temperate"""", """"Snow""""))
EuropeWater_tree &lt;- rpart(EuropeWater$water_class ~ 
               population+GDPpercapita + area_km2 + populationdensity + 
               EuropeWater$climate, 
               data=EuropeWater, method=class)   
Error in as.character(x) : 
          cannot coerce type 'builtin' to vector of type 'character'
</code></pre>

<p>and for the life of me, I can't figure out what the Error is about.</p>
",1
"<p>I have run two multilevel logistic regressions using the same predictors, but on two different responses:</p>

<pre><code>fruitMLM &lt;- lmer(InsuffFruit ~ Income + HDI + Income:HDI + (1 + Income | Country),family=binomial(link=""""logit""""))  
fuelMLM &lt;- lmer(Pollution ~ Income + HDI + Income:HDI + (1 + Income | Country),family=binomial(link=""""logit""""))
</code></pre>

<p><code>Income</code> is discrete with values <code>c(-2,-1,0,1,2)</code>, <code>HDI</code> is continuous between 0 and 1, <code>Country</code> is categorical, and the responses are both 1/0.</p>

<p>To plot confidence bands I run a simulation using the sim() function from the arm package:</p>

<pre><code>sim(fruitMLM,100)  
sim(fuelMLM,100)
</code></pre>

<p>The first one computes fine.  The second one returns the following error:</p>

<pre><code>Error in mvnorm(n.sims, bhat[j,], V.beta) :  
  'Sigma' is not positive definite
</code></pre>

<p>I actually am doing this with 8 different responses.  Six of them worked fine and two of them returned this error.</p>

<p>Does anyone know how to rectify this?</p>
",1
"<p>In R it is easy to turn a matrix into a boxplot</p>

<pre><code>&gt; myMatrix
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   27   32   31   28   20   28   10   29   15    29
 [2,]   31   33   20   28   21    9   14   21   34    33
 [3,]   27   33   28   23   26   33   19   11   26    30
 [4,]   33   17   10   31   10   32   10   29   31    28
 [5,]   25   10   29   34   32   33   28   32   32    32
 [6,]   32   19   13   32   26   20    9   26   32    33
 [7,]   33   32   18   26   27   28   29   32   24    25
 [8,]   33   34   32   30   27   31   22   32   33    30
 [9,]   32   34   31   22   17   31   11   27   18    23
[10,]   26   10   30   30   27    4    4    4    4     4

&gt; boxplot(as.data.frame(myMatrix))
</code></pre>

<p>How do I accomplish the same thing in ggplot?</p>
",1
"<p>I have a plot (sample code pasted below) that I am trying to add by own labels for the series information.  Instead of plotting """"p1s1"""" """"p1s2"""" """"p3s4"""", I would like """"treatment 1"""" """"treatment 2"""" """"treatment 3"""".  I have used levels(series_id) to get the unique series names and used a lookup table to get the descriptions.  (I think this gets them in the same order they are plotted?) and I have these descriptions in a vector called treatment_descriptions.   </p>

<p>From the documentation I think that I should be using a scale here, but I can't figure out which one, or how to do it.  Something like:  scale_something(name=""""Treatment Descriptions"""", breaks=NULL, labels=treatment_descriptions, formatter=NULL)  ?  But where should this go?</p>

<pre><code>library(ggplot2)

# Create a long data.frame to store data...
growth_series = data.frame (""""read_day"""" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""""series_id"""" = c(""""p1s1"""", """"p1s1"""", """"p1s1"""", """"p1s2"""", """"p1s2"""", """"p1s2"""", """"p3s4"""", """"p3s4"""", """"p3s4""""),
""""mean_od"""" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""""sd_od"""" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""""n_in_stat"""" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

&gt; # Now gives us some example long form data...
&gt; &gt; growth_series 
&gt;  read_day series_id mean_od sd_od        n_in_stat   
&gt;   1       p1s1     0.6      0.10         8 2       
&gt;   3       p1s1     0.9      0.20         8 3    
&gt;   9       p1s1     1.3      0.20         8 4    
&gt;   0       p1s2     0.3      0.10         8 5    
&gt;   3       p1s2     0.6      0.10         7 6    
&gt;   9       p1s2     1.0      0.30         5 7    
&gt;   0       p3s4     0.2      0.04         8 8    
&gt;   2       p3s4     0.5      0.10         7 9    
&gt;   8       p3s4     1.2      0.30         2 2

# Plot using ggplot...
ggplot(data = growth_series, aes(x = read_day, y = mean_od, group = series_id, color = series_id)) +
geom_line(size = 1.5) +
geom_point(aes(size = n_in_stat)) +
geom_errorbar(aes(ymin = mean_od - sd_od, ymax = mean_od + sd_od), size = 1, width = 0.3) +
xlab(""""Days"""") + ylab(""""Log (O.D. 730 nm)"""") +
scale_y_log2() +
scale_colour_hue('my legend', breaks = levels(growth_series$series_id), labels=c('t1', 't2', 't3'))
</code></pre>
",1
"<p>Each time when I have to recode some set of variables, I have SPSS recode function in mind. I must admit that it's quite straightforward. There's a similar <code>recode</code> function in <code>car</code> package, and it does the trick, but let's presuppose that I want to get things done with <code>factor</code>.</p>

<p>I have <code>data.frame</code> with several variables with value range from 1 to 7. I want to """"reverse"""" variable values, hence replacing 1s with 7s, 2s with 6s, 3s with 5s etc. I can utilize <code>factor</code> function:</p>

<pre><code># create dummy factor
set.seed(100)
x &lt;- as.factor(round(runif(100,1,7)))
y &lt;- factor(x, levels = rev(levels(x)))
</code></pre>

<p>And if I run:</p>

<pre><code>&gt; levels(x)
[1] """"1"""" """"2"""" """"3"""" """"4"""" """"5"""" """"6"""" """"7""""
&gt; levels(y)
[1] """"7"""" """"6"""" """"5"""" """"4"""" """"3"""" """"2"""" """"1""""
</code></pre>

<p>Problem starts when I want to recode factors that do not have equal levels. If some factor, z, has levels <code>c(""""1"""", """"3"""", """"4"""", """"6"""", """"7"""")</code>, is there any chance that I can """"reverse"""" levels so 1=7, 2=6, 3=5 etc. by utilizing <code>factor</code> function?</p>

<p>Other efficient recode functions should suffice!</p>
",1
"<p>I have several questions:<br>
1. What's the difference between isoMDS and cmdscale?<br>
2. May I use asymmetric matrix?<br>
3. Is there any way to determine optimal number of dimensions (in result)?</p>
",1
"<p>I've been trying to get RApache set up properly on my Macbook Pro running OS X 10.5.8.  After installing RApache successfully (I think), I added the following to the httpd.conf file as suggested in the manual.</p>

<pre><code>LoadModule R_module /apache/module/path/mod_R.so 
ROutputErrors
&lt;Location /RApacheInfo&gt; 
    SetHandler r-info 
&lt;/Location&gt; 
</code></pre>

<p>With these additions, I was then able to successfully go to <a href=""""http://localhost/RApacheInfo"""" rel=""""nofollow noreferrer"""">http://localhost/RApacheInfo</a> and see the status information. If I add the following additional line, 
REvalOnStartup """"library(brew)"""" 
I can no longer load the RApacheInfo page successfully. </p>

<p>I don't know what the issue is here. Without the REvalOnStartup call, I'm seeing the following in the Apache error log. </p>

<pre><code>[Fri Feb 26 11:36:36 2010] [notice] Apache/2.2.13 (Unix) mod_ssl/2.2.13 OpenSSL/0.9.7l DAV/2 mod_R/1.1.8 R/2.10.1 configured -- resuming normal operations
The process has forked and you cannot use this CoreFoundation functionality safely. You MUST exec().
Break on __THE_PROCESS_HAS_FORKED_AND_YOU_CANNOT_USE_THIS_COREFOUNDATION_FUNCTIONALITY___YOU_MUST_EXEC__() to debug.
The process has forked and you cannot use this CoreFoundation functionality safely. You MUST exec().
Break on __THE_PROCESS_HAS_FORKED_AND_YOU_CANNOT_USE_THIS_COREFOUNDATION_FUNCTIONALITY___YOU_MUST_EXEC__() to debug.
</code></pre>

<p>Not a good sign.  Any thoughts on what might be going on?  Or things to check?  </p>

<p>Chris</p>
",1
"<p>I would like to lay out graphs (trees) with two types of nodes: boxes and circles.</p>

<p>Is this possible with igraph and how would a minimal example look like?</p>
",1
"<p>The dataset I want to read in contains numbers with and without a comma as thousand separator:</p>

<pre><code>""""Sudan"""", """"15,276,000"""", """"14,098,000"""", """"13,509,000""""
""""Chad"""", 209000, 196000, 190000
</code></pre>

<p>and I am looking for a way to read this data in.</p>

<p>Any hint appreciated!</p>
",1
"<p>I have a data file with this format:</p>

<p>Weight    Industry Type<br>
251,787   Kellogg  h<br>
253,9601  Kellogg  a<br>
256,0758  Kellogg  h<br>
....</p>

<p>I read the data and try to draw an histogram with this commands:</p>

<pre><code> ce= read.table(""""file.txt"""", header= T)

 we = ce[,1]
 in = ce[,2]
 ty = ce[,3]

hist(we)
</code></pre>

<p>But I get this error:
Error en hist.default(we) : 'x' must be numeric.<br>
What do I need to do in order to draw histograms for my three variables ?</p>
",1
"<p>Combining  2 columns into 1 column many times in a very large dataset in R</p>

<p>The clumsy solutions I am working on are not going to be very fast if I can get them to work and the true dataset is ~1500 X 45000 so they need to be fast. I definitely at a loss for 1) at this point although have some code for 2) and 3).</p>

<p>Here is a toy example of the data structure:</p>

<pre><code>pop = data.frame(status = rbinom(n, 1, .42), sex = rbinom(n, 1, .5),
age = round(rnorm(n, mean=40, 10)), disType = rbinom(n, 1, .2),
rs123=c(1,3,1,3,3,1,1,1,3,1), rs123.1=rep(1, n), rs157=c(2,4,2,2,2,4,4,4,2,2),
rs157.1=c(4,4,4,2,4,4,4,4,2,2),  rs132=c(4,4,4,4,4,4,4,4,2,2),
rs132.1=c(4,4,4,4,4,4,4,4,4,4))
</code></pre>

<p>Thus, there are a few columns of basic demographic info and then the rest of the columns are biallelic SNP info.  Ex: rs123 is allele 1 of rs123 and rs123.1 is the second allele of rs123.</p>

<p>1) I need to merge all the biallelic SNP data that is currently in 2 columns into 1 column, so, for example: rs123 and rs123.1 into one column (but within the dataset):</p>

<pre><code>11
31
11
31
31
11
11
11
31
11
</code></pre>

<p>2) I need to identify the least frequent SNP value (in the above example it is 31).</p>

<p>3) I need to replace the least frequent SNP value with 1 and the other(s) with 0.</p>
",1
"<p>Is it possible to run R in Processing through rJava/JRI? If I deployed a Processing app on the web, would the client need R on their system?</p>

<p>I'm looking to create an interactive information dashboard that I can deploy on the web. It seems that Processing is probably my best bet for the interactive/web part of things. Unfortunately, it doesn't look like there are many math/stats functions built-in. And there aren't any libraries for plotting data either. </p>

<p>I've been using R and gpplot2 for a few months and am thrilled (amazed) at how easily it manipulates and plots data. </p>

<p>So I'm wondering now if can get the best of both worlds and run R through a Processing applet.</p>

<p>From the <a href=""""http://rosuda.org/JRI/"""" rel=""""noreferrer"""">JRI</a> website:</p>

<blockquote>
  <p>JRI is a Java/R Interface, which allows to run R inside Java
  applications as a single thread.
  Basically it loads R dynamic library
  into Java and provides a Java API to R
  functionality. It supports both simple
  calls to R functions and a full
  running REPL.</p>
  
  <p>In a sense JRI is the inverse of rJava
  and both can be combined (i.e. you can
  run R code inside JRI that calls back
  to the JVM via rJava). The JGR project
  makes the full use of both JRI and
  rJava to provide a full Java GUI for
  R.</p>
  
  <p>JRI uses native code, but it supports
  all platforms where Sun's Java (or
  compatible) is available, including
  Windows, Mac OS X, Sun and Linux (both
  32-bit and 64-bit).</p>
</blockquote>

<p>Thanks for the advice :)</p>
",1
"<p>This may seem as a typical <code>plyr</code> problem, but I have something different in mind.
Here's the function that I want to optimize (skip the <code>for</code> loop).</p>

<pre><code># dummy data
set.seed(1985)
lst &lt;- list(a=1:10, b=11:15, c=16:20)
m &lt;- matrix(round(runif(200, 1, 7)), 10)
m &lt;- as.data.frame(m)


dfsub &lt;- function(dt, lst, fun) {
    # check whether dt is `data.frame`
    stopifnot (is.data.frame(dt))
    # check if vectors in lst are """"whole"""" / integer
    # vector elements should be column indexes
    is.wholenumber &lt;- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) &lt; tol
    # fall if any non-integers in list
    idx &lt;- rapply(lst, is.wholenumber)
    stopifnot(idx)
    # check for list length
    stopifnot(ncol(dt) == length(idx))
    # subset the data
    subs &lt;- list()
    for (i in 1:length(lst)) {
            # apply function on each part, by row
            subs[[i]] &lt;- apply(dt[ , lst[[i]]], 1, fun)
    }
    # preserve names
    names(subs) &lt;- names(lst)
    # convert to data.frame
    subs &lt;- as.data.frame(subs)
    # guess what =)
    return(subs)
}
</code></pre>

<p>And now a short demonstration... actually, I'm about to explain what I primarily intended to do. I wanted to subset a <code>data.frame</code> by vectors gathered in <code>list</code> object. Since this is a part of code from a function that accompanies data manipulation in psychological research, you can consider <code>m</code> as a results from personality questionnaire (10 subjects, 20 vars). Vectors in list hold column indexes that define questionnaire subscales (e.g. personality traits). Each subscale is defined by several items (columns in <code>data.frame</code>). If we presuppose that the score on each subscale is nothing more than <code>sum</code> (or some other function) of row values (results on that part of questionnaire for each subject), you could run:</p>

<pre><code>&gt; dfsub(m, lst, sum)
    a  b  c
1  46 20 24
2  41 24 21
3  41 13 12
4  37 14 18
5  57 18 25
6  27 18 18
7  28 17 20
8  31 18 23
9  38 14 15
10 41 14 22
</code></pre>

<p>I took a glance at this function and I must admit that this little loop isn't spoiling the code at all... BUT, if there's an easier/efficient way of doing this, please, let me know!</p>
",1
"<p>Here is a function I wrote to break a long string into lines not longer than a given length</p>

<pre><code>strBreakInLines &lt;- function(s, breakAt=90, prepend="""""""") {
  words &lt;- unlist(strsplit(s, """" """"))
  if (length(words)&lt;2) return(s)
  wordLen &lt;- unlist(Map(nchar, words))
  lineLen &lt;- wordLen[1]
  res &lt;- words[1]
  lineBreak &lt;- paste(""""\n"""", prepend, sep="""""""")
  for (i in 2:length(words)) {
    lineLen &lt;- lineLen+wordLen[i]
    if (lineLen &lt; breakAt) 
      res &lt;- paste(res, words[i], sep="""" """")
    else {
      res &lt;- paste(res, words[i], sep=lineBreak)
      lineLen &lt;- 0
    }
  }
  return(res)
}
</code></pre>

<p>It works for the problem I had; but I wonder if I can learn something here. Is there a shorter or more efficient solution, especially can I get rid of the for loop?</p>
",1
"<p>Under what cases do you create contrasts in your analysis? How is it done and what is it used for?</p>

<p>I checked <code>?contrasts</code> and <code>?C</code> - both lead to """"Chapter 2 of Statistical Models in S"""", which is not readily available to me.</p>
",1
"<p>I am trying to merge two <code>data.frames</code> together, based on a common column name in each of them called <code>series_id</code>.  Here is my merge statement: </p>

<pre><code>merge(test_growth_series_LUT,  test_growth_series, by = intersect(series_id, series_id))
</code></pre>

<p>The error I'm getting is </p>

<blockquote>
  <p>Error in as.vector(y) : object 'series_id' not found</p>
</blockquote>

<p>The help gives this description, but I can't see why it can't find the <code>series_id</code>.   Example data is below.  </p>

<pre><code>### S3 method for class 'data.frame':
   #merge(x, y, by = intersect(names(x), names(y)),
   #      by.x = by, by.y = by, all = FALSE, all.x = all, all.y = all,
   #      sort = TRUE, suffixes = c("""".x"""","""".y""""), ...)



# Create a long data.frame to store data...
test_growth_series = data.frame (""""read_day"""" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""""series_id"""" = c(""""p1s1"""", """"p1s1"""", """"p1s1"""", """"p1s2"""", """"p1s2"""", """"p1s2"""", """"p3s4"""", """"p3s4"""", """"p3s4""""),
""""mean_od"""" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""""sd_od"""" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""""n_in_stat"""" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

# Create a name LUT
test_growth_series_LUT = data.frame (""""series_id"""" = c(""""p1s1"""", """"p1s2"""", """"p3s4"""", """"p4s2"""", """"p5s2"""", """"p6s2"""", """"p7s4"""", """"p8s4"""", """"p9s4""""),""""description"""" = c(""""blah1"""", """"blah2"""", """"blah3"""", """"blah4"""", """"blah5"""", """"blah6"""", """"blah7"""", """"blah8"""", """"blah9"""")
)

&gt; test_growth_series
  read_day series_id mean_od sd_od n_in_stat
1        0      p1s1     0.6  0.10         8
2        3      p1s1     0.9  0.20         8
3        9      p1s1     1.3  0.20         8
4        0      p1s2     0.3  0.10         8
5        3      p1s2     0.6  0.10         7
6        9      p1s2     1.0  0.30         5
7        0      p3s4     0.2  0.04         8
8        2      p3s4     0.5  0.10         7
9        8      p3s4     1.2  0.30         2
&gt; test_growth_series_LUT
  series_id description
1      p1s1       blah1
2      p1s2       blah2
3      p3s4       blah3
4      p4s2       blah4
5      p5s2       blah5
6      p6s2       blah6
7      p7s4       blah7
8      p8s4       blah8
9      p9s4       blah9
&gt; 



this is what I'm trying to achieve:  
&gt; new_test_growth_series
  read_day series_id mean_od sd_od n_in_stat        description
1        0      p1s1     0.6  0.10         8        blah1
2        3      p1s1     0.9  0.20         8        blah1
3        9      p1s1     1.3  0.20         8        blah1
4        0      p1s2     0.3  0.10         8        blah2
5        3      p1s2     0.6  0.10         7        blah2
6        9      p1s2     1.0  0.30         5        blah2
7        0      p3s4     0.2  0.04         8        blah3
8        2      p3s4     0.5  0.10         7        blah3
9        8      p3s4     1.2  0.30         2        blah3
</code></pre>
",1
"<p>Is there an easy way to do a fixed-effects regression in R when the number of dummy variables leads to a model matrix that exceeds the R maximum vector length? E.g., </p>

<pre><code>&gt; m &lt;- lm(log(bid) ~ after + I(after*score) + id, data = data)
Error in model.matrix.default(mt, mf, contrasts) : 
cannot allocate vector of length 905986769
</code></pre>

<p>where id is a factor (and is the variable causing the problem above). </p>

<p>I know that I could go through and de-mean all the data, but this throws the standard errors off (yes, you could compute the SE's """"by hand"""" w/ a df adjustment but I'd like to minimize the probability that I'm introducing new errors). I've looked at the plm package but it seems only designed for classical panel data w/ a time component, which is not the structure of my data.  </p>
",1
"<p>I need to create an object of type ShortReadQ from Bioconductor's ShortRead library.</p>

<pre><code>ShortReadQ 'signature(sread = """"DNAStringSet"""", quality =
          """"QualityScore"""", id = """"BStringSet"""")'
</code></pre>

<p>The quality slot needs to be an object inheriting from QualityScore, of which I can easily determine from another ShortReadQ object that I wish to emulate.</p>

<pre><code>&gt; class(quality(anotherObject))
[1] """"SFastqQuality""""
attr(,""""package"""")
[1] """"ShortRead""""
</code></pre>

<p>What is the best way to use that information (""""SFastqQuality"""") in the contructor argument?</p>

<pre><code>newObject&lt;-ShortReadQ(sread=...,
             quality=SFastqQuality(...), 
             id=...)
</code></pre>
",1
"<p>At the end of a ggplot, this works fine:</p>

<pre><code>+ opts(title = expression(""""Chart chart_title...""""))
</code></pre>

<p>But this does not:</p>

<pre><code>chart_title = """"foo""""
+ opts(title = expression(chart_title))
</code></pre>

<p>nor this: </p>

<pre><code>chart_title = """"foo""""
+ opts(title = chart_title)
</code></pre>

<p>How can I add a title to a ggplot when the title is a variable name?</p>
",1
"<p>I was wondering if anyone could kindly help me on this seemingly easy task.  I'm using nlminb to conduct optimization and compute some statistics by index. Here's an example from nlminb help.</p>

<pre><code>&gt; x &lt;- rnbinom(100, mu = 10, size = 10)
&gt; hdev &lt;- function(par) {
+     -sum(dnbinom(x, mu = par[1], size = par[2], log = TRUE))
+ }
&gt; nlminb(c(9, 12), hdev)
$par
[1] 9.730000 5.954936
$objective
[1] 297.2074
$convergence
[1] 0
$message
[1] """"relative convergence (4)""""
$iterations
[1] 10
$evaluations
function gradient
      12       27
</code></pre>

<p>Suppose I generate random variables <code>x, y</code> and <code>z</code> where <code>z</code> acts as an index (from 1 to 3).</p>

<pre><code>&gt; x &lt;- rnbinom(100, mu = 10, size = 10)
&gt; y &lt;- rnbinom(100, mu = 10, size = 10)
&gt; z &lt;- rep(1:3, length=100)
&gt; A &lt;- cbind(x,y,z)
&gt; hdev &lt;- function(par) {
+     -sum(dnbinom(x+y, mu = par[1], size = par[2], log = TRUE))}
</code></pre>

<p>1) How can I apply <code>nlminb(c(9, 12), hdev)</code> to the data set by index <code>z</code>? In other words, I would like to compute <code>nlminb(c(9, 12), hdev)</code> for <code>z=1, z=2</code>, and <code>z=3</code> separately. I tried <code>by(A, z, function(A) nlminb(c(9,12), hdev))</code> and <code>sparseby(A, z, function(A) nlminb(c(9,12), hdev))</code>, but they return exactly the same values for each value of <code>z</code>.</p>

<p>2) I would like to turn each output into a new data frame so that it will become a 3X2 matrix.</p>

<pre><code>[1] Z1_ANSWER_1 Z1_ANSWER_2
[2] Z2_ANSWER_1 Z2_ANSWER_2
[3] Z3_ANSWER_1 Z3_ANSWER_2
</code></pre>

<p>Since nlminb returns the summary of statistics, I needed to use <code>CASEZ1&lt;-nlminb$par, CASEZ2&lt;-nlminb$par, CASEZ3&lt;-nlminb$par</code> and then use cbind to combine them. However, I would like to automate this process as the real data I'm working on has a lot more categories than <code>z</code> presented here.</p>

<p>If I'm not making myself clear, please let me know. I'll see if I can replicate the actual data set and functions I'm working on (I just don't have them on this computer).</p>

<p>Thank you very much in advance.</p>
",1
"<p>I am trying to add a condition to geom_point size and I've pasted my example below.  I would like geom_point size to be 2 when n_in_stat is 4 or more, and size = 5 when n_in_stat is less than 4.   I tried putting an ifelse statement inside the geom_point, but this failed.  Perhaps I can't include logical operators here and I have to create a new column in the data.frame and set the size to that?</p>

<p>geom_point(size = ifelse(n_in_stat &lt; 4, 5, 2)) +   # trying to set size with an ifelse</p>

<p>geom_point(aes(size = n_in_stat)) +  # original scaled linearly</p>

<pre><code>library(ggplot2)

# Create a long data.frame to store data...
growth_series = data.frame (""""read_day"""" = c(0, 3, 9, 0, 3, 9, 0, 2, 8), 
""""series_id"""" = c(""""p1s1"""", """"p1s1"""", """"p1s1"""", """"p1s2"""", """"p1s2"""", """"p1s2"""", """"p3s4"""", """"p3s4"""", """"p3s4""""),
""""mean_od"""" = c(0.6, 0.9, 1.3, 0.3, 0.6, 1.0, 0.2, 0.5, 1.2),
""""sd_od"""" = c(0.1, 0.2, 0.2, 0.1, 0.1, 0.3, 0.04, 0.1, 0.3),
""""n_in_stat"""" = c(8, 8, 8, 8, 7, 5, 8, 7, 2)
)

# Plot using ggplot...
ggplot(data = growth_series, aes(x = read_day, y = mean_od, group = series_id, color = series_id)) +
geom_line(size = 1.5) +
geom_point(aes(size = n_in_stat)) +
geom_errorbar(aes(ymin = mean_od - sd_od, ymax = mean_od + sd_od), size = 1, width = 0.3) +
xlab(""""Days"""") + ylab(""""Log (O.D. 730 nm)"""") +
scale_y_log2() +
scale_colour_hue('my legend', breaks = levels(growth_series$series_id), labels=c('t1', 't2', 't3'))
</code></pre>
",1
"<p>I'm trying to generate a stacked area plot, but instead, ggplot makes overlapping areas. I've tried other examples that seems analogous to me, but they work and mine doesn't.</p>

<pre><code>&gt; cx
         date type visitors
1  2009-11-23    A        2
2  2010-01-07    A        4
3  2010-01-09    A        6
4  2010-02-07    A        8
5  2009-12-02    B        2
6  2009-12-03    B        4
7  2009-12-11    B        6
8  2010-01-20    B        8
9  2010-01-26    B       10
10 2010-01-30    B       11
11 2010-02-01    B       12
12 2009-12-07   LU        2
13 2009-12-28   LU        4
14 2010-01-27   LU        7
15 2010-02-04    L        1
16 2010-02-22    L        2
17 2009-11-14    O        2
18 2009-11-27    O        4
19 2010-01-11    O        6
20 2010-01-13    O        8
21 2010-02-10    O        9
22 2009-11-24    R        2
23 2009-12-01    R        4
24 2009-12-13    R        6
25 2009-12-14    R        8
26 2010-01-03    R       10
27 2010-01-16    R       12
28 2010-02-06    R       13
29 2010-02-08    R       15
30 2009-11-15    T        2
31 2009-11-19    T        4
32 2009-11-25    T        6
33 2009-11-26    T        8
34 2009-12-09    T       10
35 2009-12-10    T       12
36 2009-12-15    T       14
37 2009-12-19    T       16
38 2009-12-22    T       18
39 2010-02-23    T       19
40 2010-02-24    T       20
41 2010-01-21   Tr        2
42 2010-01-23   Tr        4
43 2010-01-24   Tr        6
44 2010-01-06    U        2
45 2009-11-09    V        2
46 2009-11-18    V        4
47 2009-12-16    V        6
48 2009-12-23    V        8
49 2009-12-25    V       10
50 2010-01-02    V       12
51 2010-01-12    V       14
52 2010-01-14    V       16
53 2010-01-15    V       18
54 2010-01-17    V       20
55 2010-01-19    V       22
56 2010-01-25    V       25
57 2010-02-05    V       26
&gt; ggplot(cx) + geom_area(aes(x=date, y=visitors, fill=type), position=""""stack"""")
</code></pre>

<p>This gives a plot where each type is plotted as its own area, and these are overlaid instead of stacked. If I sort them right, I then get a series of smaller areas inside larger, but that's not what I'm after.</p>

<p>I've tried different arguments of position, to no avail.</p>

<p>How can I get the stacked areas?</p>
",1
"<p>For example. Assume I do:</p>

<pre><code>dev.new(width=5, height=4)
plot(1:20)
</code></pre>

<p>And now I wish to do</p>

<pre><code>plot(1:40)
</code></pre>

<p>But I want a bigger window for it.</p>

<p>I would guess that the way to do it would be (assuming I don't want to open a new window) to do</p>

<pre><code>plot(1:40, width=10, height=4)
</code></pre>

<p>Which of course doesn't work.</p>

<p>The only solution I see to it would be to turn off the window and start a new one. (Which will end my plotting history)</p>

<p>Is there a better way ?</p>

<p>Thanks.</p>
",1
"<p>I've encountered a strange behaviour in cast/melt from Hadley Wickham's reshape package. If I cast a data frame, and then try to melt it, the melt comes out wrong. Manually unsetting the """"df.melt"""" class from the cast dataframe lets it be melted properly.</p>

<p>Does anyone know if this is intended behaviour, and if so, what is the use case when you'd want it?</p>

<p>A small code example which shows the behaviour:</p>

<pre><code>&gt; df &lt;- data.frame(type=c(1, 1, 2, 2, 3, 3), variable=""""n"""", value=c(71, 72, 68, 80, 21, 20))

&gt; df
  type variable value
1    1        n    71
2    1        n    72
3    2        n    68
4    2        n    80
5    3        n    21
6    3        n    20

&gt; df.cast &lt;- cast(df, type~., sum)
&gt; names(df.cast)[2] &lt;- """"n""""

&gt; df.cast
  type   n
1    1 143
2    2 148
3    3  41

&gt; class(df.cast)
[1] """"cast_df""""    """"data.frame""""

&gt; melt(df.cast, id=""""type"""", measure=""""n"""")
         type value value
X.all.      1   143 (all)
X.all..1    2   148 (all)
X.all..2    3    41 (all)

&gt; class(df.cast) &lt;- """"data.frame""""
&gt; class(df.cast)
[1] """"data.frame""""

&gt; melt(df.cast, id=""""type"""", measure=""""n"""")
  type variable value
1    1        n   143
2    2        n   148
3    3        n    41
</code></pre>
",1
"<p>Suppose I have a list or data frame in R, and I would like to get the row index, how do I do that? That is, I would like to know how many rows a certain matrix consists of.</p>
",1
"<p>I need to modify the <code>lm</code> (or eventually <code>loess</code>) function so I can use it in ggplot2's <code>geom_smooth</code> (or <code>stat_smooth</code>).</p>

<p>For example, this is how <code>stat_smooth</code> is used normally:</p>

<pre><code>&gt; qplot(data=diamonds, carat, price, facets=~clarity) + stat_smooth(method='lm')`
</code></pre>

<p>I would like to define a custom <code>lm2</code> function to use as value for the <code>method</code> parameter in <code>stat_smooth</code>, so I can customize its behaviour.</p>

<pre><code>&gt; lm2 &lt;- function(formula, data, ...)
  {
      print(head(data))
      return(lm(formula, data, ...))
  }
&gt; qplot(data=diamonds, carat, price, facets=~clarity) + stat_smooth(method='lm2')
</code></pre>

<p>Note that I have used <code>method='lm2'</code> as parameter in <code>stat_smooth</code>.
When I execute this code a get the error:</p>

<blockquote>
  <p>Error in eval(expr, envir, enclos) : 'nthcdr' needs a list to CDR down</p>
</blockquote>

<p>Which I don't understand very well. The <code>lm2</code> method works very well when run outside of <code>stat_smooth</code>. I played with this a bit and I have got different types of error, but since I am not comfortable with R's debug tools it is difficult for me to debug them. Honestly, I  don't get what I should put inside the <code>return()</code> call.</p>
",1
"<p>It is very straight-forward to plot a tree using igraph in R</p>

<pre><code>library(igraph)
plot(graph.tree(20, 2), layout=layout.reingold.tilford)
</code></pre>

<p>Is it possible to """"turn the graph around"""", so that the root (node 0) is at the top of the plot? Or, alternatively, is it possible to put the root to middle left?</p>
",1
"<p>I'm having some trouble indexing data.frames in R. I'm an R beginner. I have a <code>data.frame</code> called <code>d</code> which has 35512 columns and 77 rows. I have a list called <code>rd</code> which contains 35512 elements. I'd like all the columns of <code>d</code> which correspond to the items in <code>rd</code> less than 100. Here's what I'm doing:</p>

<pre><code># just to prove I'm not crazy
&gt; length(colnames(d))
[1] 35512
&gt; length(rownames(d))
[1] 77
&gt; length(rd)
[1] 35512
# find all the elements of rd less than 100 (+ unnecessary faffing?)
&gt; i &lt;- unlist(rd&lt;100)
&gt; names(i) &lt;- NULL
# try to extract all the elements of d corresponding to rd &lt; 100
&gt; d &lt;- d[,i]
Error in `[.data.frame`(d, , i) : undefined columns selected
</code></pre>

<p>I don't really want to be doing the <code>unlist</code> and <code>names(i) &lt;- NULL</code> stuff but I'm getting seriously paranoid. Can anyone help with what the hell this error message means?</p>

<p>In case it helps, the <code>rd</code> variable is created using the following:</p>

<pre><code>rd = lapply(lapply(d, range), diff)
</code></pre>

<p>Which hopefully tells me the difference in the range of each column of <code>d</code>.</p>

<p>P.S. bonus awesomeness for anyone who can tell me a command to find the shape of a data.frame other than querying the length of its row and column names.</p>

<p>Edit: Here's what <code>rd</code> looks like:</p>

<pre><code>&gt; rd[1:3]
$`10338001`
[1] 7198.886

$`10338003`
[1] 4748.963

$`10338004`
[1] 3173.046
</code></pre>

<p>and when I've done my faffing, <code>i</code> looks like this:</p>

<pre><code>&gt; i[7:10]
[1] FALSE FALSE FALSE  TRUE
</code></pre>
",1
"<p>I have data frame with some numerical variables and some categorical <code>factor</code> variables. The order of levels for those factors is not the way I want them to be. </p>

<pre><code>numbers &lt;- 1:4
letters &lt;- factor(c(""""a"""", """"b"""", """"c"""", """"d""""))
df &lt;- data.frame(numbers, letters)
df
#   numbers letters
# 1       1       a
# 2       2       b
# 3       3       c
# 4       4       d
</code></pre>

<p>If I change the order of the levels, the letters no longer are with their corresponding numbers (my data is  total nonsense from this point on).</p>

<pre><code>levels(df$letters) &lt;- c(""""d"""", """"c"""", """"b"""", """"a"""")
df
#   numbers letters
# 1       1       d
# 2       2       c
# 3       3       b
# 4       4       a
</code></pre>

<p>I simply want to change the <em>level</em> order, so when plotting, the bars are shown in the desired order - which may differ from default alphabetical order.</p>
",1
"<p>I have a scatter plot in R (with ggplot2). The data has a numeric column (let's call it <code>bin</code>) which can contain various integer values or null.</p>

<p>I would like to colour the points with non-null bin values differently from the others. I do not want to one colour per value of bin, that would be too noisy. Just simply, say, red for those with a non-null bin and black for the others.</p>

<p>qplot has a <code>colour</code> attribute, but I don't know how to express a condition like <code>colour = bin != null ? """"red"""" : """"black""""</code></p>
",1
"<p>I have a large chart with many data points. When I create the qplot in R, the chart is auto-fitted to the window. Even if I maximize the window, the chart is still too small and details are lost. I would like to save it as a large PNG and then look at certain areas at 1:1 resolution with an image viewer (as I cannot zoom in easily in R). Rendering the chart for a range of the values is not really convenient, I'd like to have one PNG and scroll around and discuss it with my peers, rather than pre-generating a bunch of subgraphs.</p>

<p>Is this possible? I kind of expect to be so, but some help would be appreciated (I've recently started with R so am still finding my way around).</p>

<p>Thank you.</p>
",1
"<p>I've got some data (the output of a ddply function) that I want to present in an xtable for use somewhere else.</p>

<pre><code>calqc_table&lt;-structure(list(RUNID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ANALYTEINDEX = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ID = structure(1:11, .Label = c(""""Cal A"""", """"Cal B"""", """"Cal C"""", 
""""Cal D"""", """"Cal E"""", """"Cal F"""", """"Cal G"""", """"Cal H"""", """"Cal High"""", """"Cal Low"""", 
""""Cal Mid""""), class = """"factor""""), mean_conc = c(200.619459644855, 
158.264703128903, 102.469121407733, 50.3551544728544, 9.88296440865076, 
4.41727762501703, 2.53494715706024, 1.00602831741361, 199.065054555735, 
2.48063347296935, 50.1499780776199), sd_conc = c(2.3275711264554, 
NA, NA, NA, NA, NA, NA, 0.101636943231162, 0, 0, 0), nrow = c(3, 
1, 1, 1, 1, 1, 1, 3, 2, 2, 2)), .Names = c(""""RUNID"""", """"ANALYTEINDEX"""", 
""""ID"""", """"mean_conc"""", """"sd_conc"""", """"nrow""""), row.names = c(NA, -11L
), class = """"data.frame"""")
calqc_xtable&lt;-xtable(calqc_table)
print(calqc_xtable,type=""""html"""")
</code></pre>

<p>which gives me the table in html format.  However, I want to Merge together the content of the RUNID and ANALYTEINDEX columns vertically where the values are the same.  Anyone know how to do that via xtable (or some other way ?)</p>
",1
"<p>I would like to plot means and standard errors as a horizontal barchart, and I want the mean sorted. </p>

<p>I've found the way to plot horizontal sorted barcharts using lattice, but I do not know how to add error marks. The following are my data and the R code I came up with.</p>

<pre><code>data &lt;- structure(c(0.67, 0.67, 0.76, 0.66, 0.71, 0.6, 0.52, 0.6, 0.71, 0.76, 
0.76, 0.71, 0.6, 0.61, 0.9, 0.5, 0.58, 0.84, 0.68, 0.88,
0.89, 0.96, 1, 0.95, 1, 1, 0.98, 0.78, 0.98, 1, 
1, 0.99, 1, 1, 0.95, 0.92, 1, 0.91, 1, 0.87, 
0.91, 0.72, 0.73, 0.55, 0.82, 0.87, 0.64, 0.75, 0.75, 1, 
0.81, 0.79, 1, 0.74, 0.57, 0.84, 1, 0.95, 0.78, 0.95), .Dim = c(20L, 3L), .Dimnames = list(
    c(""""1"""", """"2"""", """"3"""", """"4"""", """"5"""", """"6"""", """"7"""", """"8"""", """"9"""", """"10"""", """"11"""", 
    """"12"""", """"13"""", """"14"""", """"15"""", """"16"""", """"17"""", """"18"""", """"19"""", """"20""""), c(""""A"""", 
    """"B"""", """"C"""")))

means &lt;- apply(data, 2, mean)

errors &lt;- apply(data, 2, sd)

plot.data &lt;- data.frame(colnames(data), means, errors)

colnames(plot.data) &lt;- c(""""var"""", """"mean"""", """"error"""")

library(""""lattice"""")
plot.new()

barchart(reorder(var, mean) ~ mean, plot.data, xlim = c(0, 1))
</code></pre>

<p>Is there any way to add error marks to this chart? If not, any suggestion on how to plot the chart I want in R?</p>

<p>Thank you in advance!</p>
",1
"<p>As part of a larger task performed in R run under windows, I would like to copy selected files between directories. Is it possible to give within R a command like <code>cp patha/filea*.csv pathb</code> (notice the wildcard, for extra spice)?</p>
",1
"<p>I'm trying to read in a (tab separted) csv file in R. When I want to read the column including a <code>/</code>, I get an error. <p></p>

<pre><code>doSomething &lt;- function(dataset) {
     a &lt;- dataset$data_transfer.Jingle/TCP.total_size_kb
     ...
     }
</code></pre>

<p>The error says, that this object cannot be found. I've tried escaping with backslash but it did not work.</p>

<p>If anybody has got some idea, I'd really appreciate it!</p>
",1
"<p>I am trying to write an R package that accesses some data via a REST API. The API, however, doesn't use http authentication, but rather relies on cookies to keep credentials with the session.</p>

<p>Essentially, I'd like to replace the following two lines from a bash script with two R functions: One to perform the login, and store the session cookie, and the second to GET the data.</p>

<pre><code>curl -X POST -c cookies.txt -d""""username=xxx&amp;password=yyy"""" http://api.my.url/login
curl         -b cookies.txt                               http://api.my.url/data
</code></pre>

<p>I'm clearly not understanding how RCurl works with curl options. My script as it stands has:</p>

<pre><code>library(RCurl)
curl &lt;- getCurlHandle()
curlSetOpt(cookiejar='cookies.txt', curl=curl)
postForm(""""http://api.my.url/login"""", username='xxx', password='yyy', curl=curl)
getURL('http://api.my.url/data"""", curl=curl)
</code></pre>

<p>The final <code>getURL()</code> fails with a """"Not logged in."""" message from the server, and after the <code>postForm()</code> no <code>cookies.txt</code> file exists.</p>
",1
"<p>The following script </p>

<pre><code>#!/usr/bin/Rscript --vanilla
x &lt;- c(4.5,6.4,7.2,6.7,8.8,7.8,9.6,7.0,5.9,6.8,5.7,5.2)
fertilizer&lt;- factor(c('A','A','A','A','B','B','B','B','C','C','C','C'))
crop &lt;- factor(c('I','II','III','IV','I','II','III','IV','I','II','III','IV'))
av &lt;- aov(x~fertilizer*crop)
summary(av)
</code></pre>

<p>yields</p>

<pre><code>                Df  Sum Sq Mean Sq
fertilizer       2 13.6800  6.8400
crop             3  2.8200  0.9400
fertilizer:crop  6  6.5800  1.0967
</code></pre>

<p>For other data, <code>aov</code> usually gives the F-statistic and associated p-value. What is wrong/special about this data that causes R to omit the juicy parts?</p>
",1
"<p>I'm trying to find a way to convert multiple lines of text into a
data frame.  I'm not sure if there's a way where you can use <code>read.delim()</code>
to read in multiple lines of text and create the following data frame
with something akin to <code>rehape()</code>?.</p>

<p>The data is structured as follows:</p>

<pre><code>A: 1
B: 2
C: 10
A: 34
B: 20
C: 6.7
A: 2
B: 78
C: 35
</code></pre>

<p>I'd like to convert this data to something that looks like the following data frame:</p>

<pre><code>A             B             C
1             2             10
34            20            6.7
2             78            35
</code></pre>

<p>Apologies if there is an obvious way to do this!</p>
",1
"<p>How can I run a OSX terminal command from within R?</p>
",1
"<p>I process a lot of text/data that I exchange between Python, R, and sometimes Matlab.</p>

<p>My go-to is the flat text file, but also use SQLite occasionally to store the data and access from each program (not Matlab yet though). I don't use GROUPBY, AVG, etc. in SQL as much as I do these operations in R, so I don't necessarily require the database operations.</p>

<p>For such applications that requires exchanging data among programs to make use of available libraries in each language, is there a good rule of thumb on which data exchange format/method to use (even XML or NetCDF or HDF5)?</p>

<p>I know between Python -> R there is rpy or rpy2 but I was wondering about this question in a more general sense - I use many computers which all don't have rpy2 and also use a few other pieces of scientific analysis software that require access to the data at various times (the stages of processing and analysis are also separated).</p>
",1
"<p>I want to convert variables into factors using <code>apply()</code>:</p>

<pre><code>a &lt;- data.frame(x1 = rnorm(100),
                x2 = sample(c(""""a"""",""""b""""), 100, replace = T),
                x3 = factor(c(rep(""""a"""",50) , rep(""""b"""",50))))

a2 &lt;- apply(a, 2,as.factor)
apply(a2, 2,class)
</code></pre>

<p>results in:</p>

<pre><code>         x1          x2          x3 
""""character"""" """"character"""" """"character"""" 
</code></pre>

<p>I don't understand why this results in character vectors instead of factor vectors.</p>
",1
"<p>As usual, I got some SPSS file that I've imported into R with <code>spss.get</code> function from <code>Hmisc</code> package. I'm bothered with <code>labelled</code> class that <code>Hmisc::spss.get</code> adds to all variables in <code>data.frame</code>, hence want to remove it.</p>

<p><code>labelled</code> class gives me headaches when I try to run <code>ggplot</code> or even when I want to do some menial analysis! One solution would be to remove <code>labelled</code> class from each variable in <code>data.frame</code>. How can I do that? Is that possible at all? If not, what are my other options?</p>

<p>I really want to bypass reediting variables """"from scratch"""" with <code>as.data.frame(lapply(x, as.numeric))</code> and <code>as.character</code> where applicable... And I certainly don't want to run SPSS and remove labels manually (don't like SPSS, nor care to install it)!</p>

<p>Thanks!</p>
",1
"<p>I have an R function which produces 95% confidence ellipses for scatterplots. The output looks like this, having a default of 50 points for each ellipse (50 rows):</p>

<pre><code>           [,1]         [,2]
 [1,]  0.097733810  0.044957994
 [2,]  0.084433494  0.050337990
 [3,]  0.069746783  0.054891438
</code></pre>

<p>I would like to superimpose a number of such ellipses for each level of a factor called 'site' on a <code>ggplot2</code> scatterplot, produced from this command:</p>

<pre><code>&gt; plat1 &lt;- ggplot(mapping=aes(shape=site, size=geom), shape=factor(site)); plat1 + geom_point(aes(x=PC1.1,y=PC2.1))
</code></pre>

<p>This is run on a dataset, called <code>dflat</code> which looks like this:</p>

<pre><code>site      geom         PC1.1        PC2.1       PC3.1        PC1.2       PC2.2
1 Buhlen 1259.5649 -0.0387975838 -0.022889782  0.01355317  0.008705276  0.02441577
2 Buhlen  653.6607 -0.0009398704 -0.013076251  0.02898955 -0.001345149  0.03133990
</code></pre>

<p>The result is fine, but when I try to add the ellipse (let's say for this one site, called """"Buhlen""""):</p>

<pre><code>&gt; plat1 + geom_point(aes(x=PC1.1,y=PC2.1)) + geom_path(data=subset(dflat, site=""""Buhlen""""),mapping=aes(x=ELLI(PC1.1,PC2.1)[,1],y=ELLI(PC1.1,PC2.1)[,2]))
</code></pre>

<p>I get an error message: <code>""""Error in data.frame(x = c(0.0977338099339815, 0.0844334944904515, 0.0697467834016782,  : 
  arguments imply differing number of rows: 50, 211</code></p>

<p>I've managed to fix this in the past, but I cannot remember how. It seems that geom_path is relying on the same points rather than plotting new ones. Any help would be appreciated.</p>
",1
"<p>When using R's <code>rpart</code> function, I can easily fit a model with it. for example:</p>

<pre><code># Classification Tree with rpart
library(rpart)

# grow tree 
fit &lt;- rpart(Kyphosis ~ Age + Number + Start,
     method=""""class"""", data=kyphosis)

printcp(fit) # display the results 
plotcp(fit) 
summary(fit) # detailed summary of splits

# plot tree 
plot(fit, uniform=TRUE, 
     main=""""Classification Tree for Kyphosis"""")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
</code></pre>

<p>My question is - 
How can I measure the """"importance"""" of each of my three explanatory variables (Age, Number, Start) to the model?</p>

<p>If this was a regression model, I could have looked at p-values from the """"anova"""" F-test (between <code>lm</code> models with and without the variable). But what is the equivalence of using """"anova"""" on <code>lm</code> to an <code>rpart</code> object?</p>

<p>(I hope I managed to make my question clear)</p>

<p>Thanks.</p>
",1
"<p>I have been struggling to load the rJava package in R. </p>

<p>I get the following messages</p>

<pre><code>&gt; library(rJava)
Error in inDL(x, as.logical(local), as.logical(now), ...) : 
  unable to load shared library \
     'C:/PROGRA~1/R/R-210~1.1/library/rJava/libs/rJava.dll':
  LoadLibrary failure:  The specified module could not be found.


Error : .onLoad failed in 'loadNamespace' for 'rJava'
Error: package/namespace load failed for 'rJava'
</code></pre>

<p>I have tried so many solutions that they are all bamboozeled in my head. 
At some point I even got </p>

<pre><code>&gt; R Console: Rgui.exe - System Error The
&gt; program can't start because
&gt; MSVCR71.dll is is missing from your
&gt; computer. Try reinstalling the program
&gt; to fix this problem.
</code></pre>

<p>I made sure everything I could think of was on the path</p>

<pre><code>&gt; C:\Program Files\R\Rtools\bin;C:\Program Files\R\Rtools\perl\bin;
  C:\Program Files\R\Rtools\MinGW\bin;%SystemRoot%\system32;
  %SystemRoot%;%SystemRoot%\System32\Wbem;
  %SYSTEMROOT%\System32\WindowsPowerShell\v1.0\;
  C:\Program Files\QuickTime\QTSystem\;
  C:\Program Files\R\R-2.10.1\library\rJava\libs\;
  C:\Program Files\R;C:\Program Files\Java\jre6\bin\client  
</code></pre>

<p>What should I try next?</p>

<p>I am running R version 2.10.1 (2009-12-14) and I have also tried R version 2.10.1 Patched (2010-03-03 r51210). It is on a Windows machine running windows 7 enterprise</p>
",1
"<p>I want an stacked barplot, or at least two barplots (histogramms) of the data below. But I cant't figure out how. plot(online) is not the solution, Im looking for. Please see below.</p>

<pre><code>          online              offline
1         sehrwichtig             wichtig
2             wichtig           unwichtig
3         sehrwichtig           unwichtig
4         sehrwichtig         sehrwichtig
5         sehrwichtig         sehrwichtig
6         sehrwichtig           unwichtig
7         sehrwichtig           unwichtig
8             wichtig             wichtig
9             wichtig           unwichtig
10        sehrwichtig         sehrwichtig
11        sehrwichtig             wichtig
12        sehrwichtig           unwichtig
13            wichtig         sehrwichtig
14        sehrwichtig             wichtig
</code></pre>

<p><strong>I know I need a step, where the data is aggregated to:</strong></p>

<pre><code>                   online        offline 
   sehrwichtig           6         7 
   unwichtig             0         1 
   wichtig               3         5 
</code></pre>

<p>But how?</p>
",1
"<p>I'm trying to override the text in some ggplot strips to incorporate Greek characters.  Here's some sample data, and the base for the plot.</p>

<pre><code>dfr &lt;- data.frame(
   x = rep(1:10, times = 6),
   y = runif(60),
   fx = rep(c(""""foo"""", """"bar""""), each = 30),
   fy = rep(c(""""alpha"""", """"beta"""", """"gamma""""), each = 10, times = 2)
)

p &lt;- ggplot(dfr, aes(x, y)) + geom_point()
</code></pre>

<p>My first attempt at a plot has no Greek in the strip labels.</p>

<pre><code> p + facet_grid(fy ~ fx)
</code></pre>

<p>I gather that I'm supposed to add a labeller argument to <code>facet_grid</code> to override the text.  I presumed that this should spit out an expression to handle the greek characters, but my code just throws an error when the graphic is printed.</p>

<pre><code>lbl &lt;- function(variable, value)
{
   if(variable == """"fy"""") parse(text=as.character(value)) else value
}
p + facet_grid(fy ~ fx, labeller = lbl)


Error in aperm(X, c(s.call, s.ans)) : 
  unimplemented type 'expression' in 'aperm'
</code></pre>

<p>How should I be creating the strip labels?</p>
",1
"<p>I have a data frame where one particular column has a set of specific values (let's say, 1, 2, ..., 23). What I would like to do is to convert from this layout to the one, where the frame would have extra 23 (in this case) columns, each one representing one of the factor values. The data in these columns would be booleans indicating whether a particular row had a given factor value... To show a specific example:</p>

<p>Source frame:</p>

<pre><code>ID       DATE         SECTOR
123      2008-01-01   1
456      2008-01-01   3
789      2008-01-02   5
... &lt;more records with SECTOR values from 1 to 5&gt;
</code></pre>

<p>Desired format:</p>

<pre><code>ID       DATE         SECTOR.1   SECTOR.2   SECTOR.3   SECTOR.4   SECTOR.5
123      2008-01-01      T          F          F          F          F
456      2008-01-01      F          F          T          F          F
789      2008-01-02      F          F          F          F          T
</code></pre>

<p>I have no problem doing it in a loop but I hoped there would be a better way. So far <code>reshape()</code> didn't yield the desired result. Help would be much appreciated.</p>
",1
"<p>I want to plot stacked histograms in R; i.e. stack individual histograms in the third dimension.</p>

<hr>

<p>thank you all for your suggestions, especially the one by Shane.</p>

<p>@hadley, I agree with your points, however, my situation is different: the main point I'm trying to convey by plotting four stacked histograms is that the tails vary significantly....the part that will get obscured is of no consequence in the data I'm presenting....also, being able to read the frequency axis is also not important since I'll be plotting the relative frequencies...</p>
",1
"<p>I am working with a data frame where one of the columns consists of <code>POSIXct</code> date-time values.  I am trying to plot a histogram of these timestamps using <code>ggplot2</code> but I'm having two issues:</p>

<ol>
<li><p>I don't know how to set the binwidth in <code>geom_histogram()</code>.  I'd like to set each bin to a day or a week.  I've tried providing a difftime object, but I get an error.  I also tried <code>binwidth=1</code> but R just hangs.</p></li>
<li><p>How do I set the limits in <code>scale_x_time()</code>?  The only way I could get it to work was by converting my <code>POSIXct</code> timestamps using <code>as.Date()</code>.</p></li>
</ol>
",1
"<p>Using <code>ggplot2</code> I normally use <code>geom_text</code> and something like <code>position=jitter</code> to annotate my plots.</p>

<p>However - for a nice plot I often finds it worthwhile to annotate manually. like below:</p>

<pre><code>data2 &lt;- structure(list(type = structure(c(5L, 1L, 2L, 4L, 3L, 5L, 1L, 
2L, 4L, 3L, 5L, 1L, 2L, 4L, 3L, 5L, 1L, 2L, 4L, 3L), .Label = c(""""EDS"""", 
""""KIU"""", """"LAK"""", """"MVH"""", """"NA*""""), class = """"factor""""), value = c(0.9, 
0.01, 0.01, 0.09, 0, 0.8, 0.05, 0, 0.15, 0, 0.41, 0.04, 0.03, 
0.52, 0, 0.23, 0.11, 0.02, 0.64, 0.01), time = c(3L, 3L, 3L, 
3L, 3L, 6L, 6L, 6L, 6L, 6L, 15L, 15L, 15L, 15L, 15L, 27L, 27L, 
27L, 27L, 27L), year = c(2008L, 2008L, 2008L, 2008L, 2008L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2006L, 2006L, 2006L, 2006L, 2006L)), .Names = c(""""type"""", """"value"""", 
""""time"""", """"year""""), row.names = c(1L, 3L, 4L, 5L, 6L, 7L, 9L, 10L, 
11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 21L, 22L, 23L, 24L), class = """"data.frame"""")
ggplot(data2, aes(x=time, y=value, group=type, col=type))+
geom_line()+
geom_point()+
theme_bw()+
annotate(""""text"""", x=6, y=0.9, label=""""this is a wrong color"""")+
annotate(""""text"""", x=15, y=0.6, label=""""this is a second annotation with a wrong color"""")
</code></pre>

<p>The problem is, that I can't get the text annotations color to match the line color. I assume I could fix this with a manual scale, but I hope there is a better way?</p>
",1
"<p>I started using Emacs (ESS) as a default R editor (yes, @Dirk, as you've said, I want ESS), and I must admit it's by far <b> the best</b> <code>R</code> editor I've been using so far. However, I cannot manage to get an output of <code>help()</code> function up to web browser. It keeps displaying help page in a separate R buffer, even if <code>options(help_type = """"html"""", browser = """"firefox"""")</code> are set.</p>

<p>How can I get help back to browser, while using Emacs/ESS?</p>
",1
"<p>I'd like to begin thinking about how I can scale up my algorithms that I write for data analysis so that they can be applied to arbitrarily large sets of data. I wonder what are the relevant concepts (threads, concurrency, immutable data structures, recursion) and tools (Hadoop/MapReduce, Terracota, and Eucalyptus) to make this happen, and how specifically these concepts and tools are related to each other. I have a rudimentary background in R, Python, and bash scripting and also C and Fortran programming, though I'm familiar with some basic functional programming concepts also. Do I need to change the way that I program, use a different language (Clojure, Haskell, etc.), or simply (or not so simply!) adapt something like R/Hadoop (HRIPE)... or write wrappers for Python to enable multi-threading or Hadoop access? I understand this would might involve requirements for additional hardware and I would like some basic idea of what the requirements/options available might be. My apologies for this rather large and yet vague question, but just trying to get started - thanks in advance!</p>
",1
"<p>JD Long helped me with this: <a href=""""https://stackoverflow.com/questions/2409357/how-to-nicely-annotate-a-ggplot2-manual"""">question about manual annotation</a>. But is it possible to do something similar on a facetted plot, such that the label style corresponds to the linestyle (aestetics) and in a way that I can annotate different facets individually?
Some data</p>

<p><code>funny &lt;- structure(list(Institution = structure(c(1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 1L, 
1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c(""""Q-branch"""", 
""""Some-Ville"""", """"Spectre""""), class = """"factor""""), Type = structure(c(5L, 
6L, 1L, 3L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 
6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 
6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L, 5L, 6L, 2L, 4L), .Label = c(""""Korte videregende uddannelser"""", 
""""Mammas beer"""", """"Mellemlange videregende uddannelser"""", """"Tastes good"""", 
""""Unknown"""", """"Your""""), class = """"factor""""), r = c(2008L, 2008L, 
2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 
2008L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 
2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2007L, 2006L, 2006L, 
2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 2006L, 
2006L), Mndr = c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 15L, 15L, 
15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 27L, 27L, 27L, 
27L, 27L, 27L, 27L, 27L, 27L, 27L, 27L, 27L), Data = c(159L, 
NA, NA, 23L, 204L, NA, NA, 12L, 256L, NA, NA, 24L, 166L, 6L, 
NA, 43L, 228L, NA, NA, 20L, 196L, 11L, NA, 37L, 99L, 14L, 9L, 
96L, 147L, 7L, 5L, 91L, 100L, 10L, 7L, 126L, 60L, 17L, 6L, 106L, 
78L, 18L, 13L, 140L, 48L, 23L, 5L, 136L)), .Names = c(""""Institution"""", 
""""Type"""", """"r"""", """"Mndr"""", """"Data""""), class = """"data.frame"""", row.names = c(NA, 
-48L))</code></p>

<p>And a facetted plot:</p>

<pre><code>ggplot(funny, aes(Mndr, y=Data, group=Type, col=Type))+geom_line()+facet_grid(.~Institution)
</code></pre>

<p>Thanks in advance for your help!</p>
",1
"<p>I'd like to write an R function that accepts a formula as its first argument, similar to lm() or glm() and friends.  In this case, it's a function that takes a data frame and writes out a file in <a href=""""http://svmlight.joachims.org/"""" rel=""""nofollow noreferrer"""">SVMLight</a> format, which has this general form:</p>

<pre><code>&lt;line&gt; .=. &lt;target&gt; &lt;feature&gt;:&lt;value&gt; &lt;feature&gt;:&lt;value&gt; ... &lt;feature&gt;:&lt;value&gt; # &lt;info&gt;
&lt;target&gt; .=. +1 | -1 | 0 | &lt;float&gt; 
&lt;feature&gt; .=. &lt;integer&gt; | """"qid""""
&lt;value&gt; .=. &lt;float&gt;
&lt;info&gt; .=. &lt;string&gt;
</code></pre>

<p>for example, the following data frame:</p>

<pre><code>  result qid     f1     f2     f3     f4   f5     f6     f7     f8
1     -1   1 0.0000 0.1253 0.0000 0.1017 0.00 0.0000 0.0000 0.9999
2     -1   1 0.0098 0.0000 0.0000 0.0000 0.00 0.0316 0.0000 0.3661
3      1   1 0.0000 0.0000 0.1941 0.0000 0.00 0.0000 0.0509 0.0000
4     -1   2 0.0000 0.2863 0.0948 0.0000 0.34 0.0000 0.7428 0.0608
5      1   2 0.0000 0.0000 0.0000 0.4347 0.00 0.0000 0.9539 0.0000
6      1   2 0.0000 0.7282 0.9087 0.0000 0.00 0.0000 0.0000 0.0355
</code></pre>

<p>would be represented as follows:</p>

<pre><code>-1 qid:1 2:0.1253 4:0.1017 8:0.9999
-1 qid:1 1:0.0098 6:0.0316 8:0.3661
1  qid:1 3:0.1941 7:0.0509
-1 qid:2 2:0.2863 3:0.0948 5:0.3400 7:0.7428 8:0.0608
1  qid:2 4:0.4347 7:0.9539
1  qid:2 2:0.7282 3:0.9087 8:0.0355
</code></pre>

<p>The function I'd like to write would be called something like this:</p>

<pre><code>write.svmlight(result ~ f1+f2+f3+f4+f5+f6+f7+f8 | qid, data=mydata, file=""""out.txt"""")
</code></pre>

<p>Or even</p>

<pre><code>write.svmlight(result ~ . | qid, data=mydata, file=""""out.txt"""")
</code></pre>

<p>But I can't figure out how to use <code>model.matrix()</code> and/or <code>model.frame()</code> to know what columns it's supposed to write.  Are these the right things to be looking at?</p>

<p>Any help much appreciated!</p>
",1
"<p>From the <a href=""""http://docs.ggplot2.org/0.9.2.1/geom_bar.html"""" rel=""""nofollow noreferrer"""">online bar chart guide</a>:</p>

<pre><code>qplot(factor(cyl), data=mtcars, geom=""""bar"""", fill=factor(gear)) 
</code></pre>

<p><a href=""""https://i.stack.imgur.com/T9H6N.png"""" rel=""""nofollow noreferrer""""><img src=""""https://i.stack.imgur.com/T9H6N.png"""" alt=""""barplot using &lt;code&gt;qplot&lt;/code&gt; feature of &lt;code&gt;ggplot2&lt;/code&gt;""""></a></p>

<p>How do I get 5 to sit on the bottom, 4 above that, and 3 on top?</p>
",1
"<p>How can I build a function </p>

<pre><code>slice(x, n) 
</code></pre>

<p>which would return a list of vectors where each vector except maybe the last has size n, i.e.</p>

<pre><code>slice(letters, 10)
</code></pre>

<p>would return</p>

<pre><code>list(c(""""a"""", """"b"""", """"c"""", """"d"""", """"e"""", """"f"""", """"g"""", """"h"""", """"i"""", """"j""""),
     c(""""k"""", """"l"""", """"m"""", """"n"""", """"o"""", """"p"""", """"q"""", """"r"""", """"s"""", """"t""""),
     c(""""u"""", """"v"""", """"w"""", """"x"""", """"y"""", """"z""""))
</code></pre>

<p>?</p>
",1
"<p>I have the following problem.  </p>

<p>First my environment, I have two 24-CPU servers to work with and one big job (resampling a large dataset) to share among them.  I've setup multicore and (a socket) Snow cluster on each. As a high-level interface I'm using foreach.</p>

<p>What is the optimal sharing of the job? Should I setup a Snow cluster using CPUs from both machines and split the job that way (i.e. use doSNOW for the foreach loop). Or should I use the two servers separately and use multicore on each server (i.e. split the job in two chunks, run them on each server and then stich it back together). </p>

<p>Basically what is an easy way to:
 1. Keep communication between servers down (since this is probably the slowest bit).
 2. Ensure that the random numbers generated in the servers are not highly correlated.</p>
",1
"<p>Is it possible, in the <code>expr</code> expression of the <code>with()</code> function, to access the <code>data</code> argument directly?  Here's what I mean conceptually:</p>

<pre><code>&gt; print(df)
  result qid     f1     f2     f3
1     -1   1 0.0000 0.1253 0.0000
2     -1   1 0.0098 0.0000 0.0000
3      1   1 0.0000 0.0000 0.1941
4     -1   2 0.0000 0.2863 0.0948
5      1   2 0.0000 0.0000 0.0000
6      1   2 0.0000 0.7282 0.9087
&gt; with(df, subset(.data, select=f1:f3))  # Doesn't work
</code></pre>

<p>Of course the above example is kind of silly, but it would be handy for things like this:</p>

<pre><code>with(subset(df, f2&gt;0), foo(qid, vars=subset(.data, select=f1:f3)))
</code></pre>

<p>I tried to poke around with <code>environment()</code> and <code>parent.frame()</code> etc., but didn't come up with anything that worked.</p>

<p>Maybe this is really a question about <code>eval()</code>, since that's how <code>with.default()</code> is implemented.</p>
",1
"<p>If I have some R list <code>mylist</code>, you can append an item <code>obj</code> to it like so:</p>

<pre><code>mylist[[length(mylist)+1]] &lt;- obj
</code></pre>

<p>But surely there is some more compact way.  When I was new at R, I  tried writing <code>lappend()</code> like so:</p>

<pre><code>lappend &lt;- function(lst, obj) {
    lst[[length(lst)+1]] &lt;- obj
    return(lst)
}
</code></pre>

<p>but of course that doesn't work due to R's call-by-name semantics (<code>lst</code> is effectively copied upon call, so changes to <code>lst</code> are not visible outside the scope of <code>lappend()</code>.  I know you can do environment hacking in an R function to reach outside the scope of your function and mutate the calling environment, but that seems like a large hammer to write a simple append function.</p>

<p>Can anyone suggest a more beautiful way of doing this? Bonus points if it works for both vectors and lists.</p>
",1
"<p>I accidentally managed to get colour names, #HEX, and a colour preview in Emacs. Don't have a bloody idea how, must've pressed some keybinding or menu item... But, now I can't seem to find where's that feature... I'm quite sure I wasn't hallucinating, so it's gotta be there, under some keystroke that I can't reproduce!!! =)</p>
",1
"<p>I'm working on visualizing a matrix in R (almost exactly like <a href=""""http://reference.wolfram.com/mathematica/ref/MatrixPlot.html"""" rel=""""nofollow noreferrer"""">http://reference.wolfram.com/mathematica/ref/MatrixPlot.html</a>), and I've been using </p>

<pre><code>image(&lt;matrix&gt;,axes=FALSE) 
</code></pre>

<p>to draw the picture. However, I noticed that with the y-axis turned off, the plot isn't centered--the space is still there for the axis ticks + label. I can finagle some centering with </p>

<pre><code>par(oma=c(0,0,0,2.5))
</code></pre>

<p>but this seems inefficient and error-prone (if my matrix were to change dimensions/become non-square). Is there a better way to force the graphic to center?
<a href=""""http://img694.imageshack.us/img694/9891/metropolis.png"""" rel=""""nofollow noreferrer"""">Reference image http://img694.imageshack.us/img694/9891/metropolis.png</a></p>

<p>The right hand margin is significantly smaller than the left.</p>
",1
"<p>I'm looking for some LaTeX template for creating quality output. On R-bloggers I've bumped on Frank Harrel's Rreport package. Due to my quite modest LaTeX abilities, only a user-friendly (and noob-friendly) interface should suffice. Here's a <a href=""""http://biostat.mc.vanderbilt.edu/wiki/Main/Rreport"""" rel=""""nofollow noreferrer"""">link</a> to an official website. I'm following the instructions, but I cannot manage to install an app. I use Ubuntu 9.10, R version is 2.10.1 (updated regularly from UCLA's CRAN server), and of course, cvs is installed on my system.</p>

<p>Now, I'd like to know if there is some user-friendly LaTeX template package (Sweave is still to advanced/spartan for me). I'm aware that my question is quite confounding, but a brief glance on examples on Rreport page should give you a hint. I'm aware that LaTeX skills are a must, but just for now I need something that will suit my needs (as a psychological researcher).</p>

<p>Is there any package similar with Rreport?</p>
",1
"<p>From a data frame with timestamped rows (strptime results), what is the best method for aggregating statistics for intervals?  </p>

<p>Intervals could be an hour, a day, etc. </p>

<p>There's the <code>aggregate</code> function, but that doesn't help with assigning each row to an interval.  I'm planning on adding a column to the data frame that denotes interval and using that with <code>aggregate</code>, but if there's a better solution it'd be great to hear it.</p>

<p>Thanks for any pointers!</p>

<hr>

<p><strong><em>Example Data</em></strong></p>

<p>Five rows with timestamps divided into 15-minute intervals starting at 03:00.</p>

<p><strong>Interval 1</strong></p>

<ul>
<li>""""2010-01-13 03:02:38 UTC"""" </li>
<li>""""2010-01-13 03:08:14 UTC"""" </li>
<li>""""2010-01-13 03:14:52 UTC""""</li>
</ul>

<p><strong>Interval 2</strong></p>

<ul>
<li>""""2010-01-13 03:20:42 UTC""""</li>
<li>""""2010-01-13 03:22:19 UTC""""</li>
</ul>

<hr>

<p><strong><em>Conclusion</em></strong></p>

<p>Using a time series package such as <code>xts</code> should be the solution; however I had no success using them and winded up using <code>cut</code>.  As I presently only need to plot histograms, with rows grouped by interval, this was enough.</p>

<p><code>cut</code> is used liked so:</p>

<pre><code>interv &lt;- function(x, start, period, num.intervals) {
  return(cut(x, as.POSIXlt(start)+0:num.intervals*period))
}
</code></pre>
",1
"<p>I am going through one of my .R files and by cleaning it up a little bit I am trying to get more familiar with writing the code the r-ight way. As a beginner, one of my favorite starting points is to get rid of the <code>for()</code> loops and try to transform the expression into a functional programming form.
So here is the scenario:</p>

<p>I am assembling a bunch of <code>data.frames</code> into a <code>list</code> for later usage. </p>

<pre><code>dataList &lt;- list (dataA,
                  dataB,
                  dataC,
                  dataD,
                  dataE
                  )
</code></pre>

<p>Now I like to take a look at each data.frame's column names and substitute certain character strings. Eg I like to substitute each """"foo"""" and """"bar"""" with """"baz"""". At the moment I am getting the job done with a <code>for()</code> loop which looks a bit awkward.</p>

<pre><code>colnames(dataList[[1]])
[1] """"foo""""        """"code"""" """"lp15""""       """"bar""""       """"lh15""""  
colnames(dataList[[2]])
[1] """"a""""        """"code"""" """"lp50""""       """"ls50""""       """"foo""""  

matchVec &lt;- c(""""foo"""", """"bar"""")
for (i in seq(dataList)) {
  for (j in seq(matchVec)) {
    colnames (dataList[[i]])[grep(pattern=matchVec[j], x=colnames (dataList[[i]]))] &lt;- c(""""baz"""")
  }
}
</code></pre>

<p>Since I am working here with a <code>list</code> I thought about the <code>lapply</code> function. My attempts handling the job with the <code>lapply</code> function all seem to look alright but only at first sight. If I write</p>

<pre><code>f &lt;- function(i, xList) {
  gsub(pattern=c(""""foo""""), replacement=c(""""baz""""), x=colnames(xList[[i]]))
}
lapply(seq(dataList), f, xList=dataList)
</code></pre>

<p>the last line prints out almost what I am looking for. However, if i take another look at the actual names of the data.frames in dataList:</p>

<pre><code>lapply (dataList, colnames)
</code></pre>

<p>I see that no changes have been made to the initial character strings.</p>

<p>So how can I rewrite the <code>for()</code> loop and transform it into a functional programming form?
And how do I substitute both strings, """"foo"""" and """"bar"""", in an efficient way? Since the <code>gsub()</code> function takes as its <code>pattern</code> argument only a character vector of length one.</p>
",1
"<p>I noticed a strange malfunction in using <code>findFn</code> function (library <code>sos</code>) and I can't find out the source. While it works fine on my Windows XP pc, it does not on my Vista one.</p>

<pre><code>library (sos)

findFn(""""randomization test"""")
# in both finds 72 results

findFn(""""{randomization test}"""")
# In XP finds 19 or about so, but in Vista whenever I use {} and more than one word inside, 
# I keep getting the following:

found 0 matches
x has zero rows;  nothing to display.
Warning message:
In findFn(""""{randomization test}"""") :
  HIT not found in HTML;  processing one page only.
</code></pre>

<p>R ver = 2.10.1 and packages updated.
Any ideas where the problem might be?</p>

<p>Bonus: As it's obvious, I was looking for functions about <code>tests for randomized experiments</code>  </p>
",1
"<p>I have a (somewhat complex) web scraping challenge that I wish to accomplish and would love for some direction (to whatever level you feel like sharing) here goes:</p>

<p>I would like to go through all the """"species pages"""" present in this link:</p>

<p><a href=""""http://gtrnadb.ucsc.edu/"""" rel=""""nofollow noreferrer"""">http://gtrnadb.ucsc.edu/</a></p>

<p>So for each of them I will go to:</p>

<ol>
<li>The species page link (for example: <a href=""""http://gtrnadb.ucsc.edu/Aero_pern/"""" rel=""""nofollow noreferrer"""">http://gtrnadb.ucsc.edu/Aero_pern/</a>)</li>
<li>And then to the """"Secondary Structures"""" page link (for example: <a href=""""http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-structs.html"""" rel=""""nofollow noreferrer"""">http://gtrnadb.ucsc.edu/Aero_pern/Aero_pern-structs.html</a>)</li>
</ol>

<p>Inside that link I wish to scrap the data in the page so that I will have a long list containing this data (for example):</p>

<pre><code>chr.trna3 (1-77)    Length: 77 bp
Type: Ala   Anticodon: CGC at 35-37 (35-37) Score: 93.45
Seq: GGGCCGGTAGCTCAGCCtGGAAGAGCGCCGCCCTCGCACGGCGGAGGcCCCGGGTTCAAATCCCGGCCGGTCCACCA
Str: &gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;.........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;....
</code></pre>

<p>Where each line will have it's own list (inside the list for each """"trna"""" inside the list for each animal)</p>

<p>I remember coming across the packages Rcurl and XML (in R) that can allow for such a task.  But I don't know how to use them.  So what I would love to have is:
1. Some suggestion on how to build such a code.
2. And recommendation for how to learn the knowledge needed for performing such a task.</p>

<p>Thanks for any help,</p>

<p>Tal</p>
",1
"<p>How do I specify random factors in R ? </p>

<p>If I have a factor <code>x1</code>  which is supposed to be random , can I try something like this ? </p>

<pre><code>lm(y ~ x1, data = p)
</code></pre>
",1
"<p>Im trying to run a model with a response variable p and  3 fixed factors to get ANOVA. this is how my code looks like : </p>

<pre><code>#run it as 3 fixed factor model 
p1=c(37,38,37,41,41,40,41,42,41)
p2=c(42,41,43,42,42,42,43,42,43)
p3=c(30,31,31,31,31,31,29,30,28)
p4=c(42,43,42,43,43,43,42,42,42)
p5=c(28,30,29,29,30,29,31,29,29)
p6=c(42,42,43,45,45,45,44,46,45)
p7=c(25,26,27,28,28,30,29,27,27)
p8=c(40,40,40,43,42,42,43,43,41)
p9=c(37,38,37,41,41,40,41,42,41)
p10=c(35,34,34,35,35,34,35,34,35)
p = cbind(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10)
partnumber=c(rep(1,9),rep(2,9),rep(3,9),rep(4,9),rep(5,9),rep(6,9),rep(7,9),rep(8,9),rep(9,9),rep(10,9))
test=c(rep(c(rep(1:3,3)),10))
inspector = rep(c(rep(1,3),rep(2,3),rep(3,3)),10)
fpartnumber = factor(partnumber)
ftest = factor(test)
finspector = factor(inspector)
model=lm(p~fpartnumber*ftest*finspector)
summary(model)
anova(model)
</code></pre>

<p>but when I run it I get this error : it says my variable length for fpartnumber is different , but when I checked the length of each variable and is 90. What is going on ?</p>

<blockquote>
  <p>model=lm(y~fpartnumber<em>ftest</em>finspector)
      Error in model.frame.default(formula = yang ~ fpartnumber * ftest * finspector,  : 
      variable lengths differ (found for 'fpartnumber')</p>
</blockquote>
",1
"<p>I have a couple of questions regarding facetting in ggplot2...</p>

<p>Let's say I have a query that returns data that looks like this:</p>

<p>(note that it's ordered by Rank asc, Alarm asc and two Alarms have a Rank of 3 because their Totals = 1798 for Week 4, and Rank is set according to Total for Week 4)</p>

<pre><code>   Rank Week                      Alarm Total
      1    1      BELTWEIGHER HIGH HIGH  1000
      1    2      BELTWEIGHER HIGH HIGH  1050
      1    3      BELTWEIGHER HIGH HIGH   900
      1    4      BELTWEIGHER HIGH HIGH  1800
      2    1              MICROWAVE LHS   200
      2    2              MICROWAVE LHS  1200
      2    3              MICROWAVE LHS   400
      2    4              MICROWAVE LHS  1799
      3    1  HI PRESS FILTER 2 CLOG SW  1250
      3    2  HI PRESS FILTER 2 CLOG SW  1640
      3    3  HI PRESS FILTER 2 CLOG SW  1000
      3    4  HI PRESS FILTER 2 CLOG SW  1798
      3    1 LOW PRESS FILTER 2 CLOG SW   800
      3    2 LOW PRESS FILTER 2 CLOG SW  1200
      3    3 LOW PRESS FILTER 2 CLOG SW   800
      3    4 LOW PRESS FILTER 2 CLOG SW  1798
</code></pre>

<p>(duplication code below)</p>

<pre><code>Rank = c(rep(1,4),rep(2,4),rep(3,8))
Week = c(rep(1:4,4))
Total = c(  1000,1050,900,1800,
        200,1200,400,1799,
        1250,1640,1000,1798,
        800,1200,800,1798) 
Alarm = c(rep(""""BELTWEIGHER HIGH HIGH"""",4),  
        rep(""""MICROWAVE LHS"""",4), 
        rep(""""HI PRESS FILTER 2 CLOG SW"""",4), 
        rep(""""LOW PRESS FILTER 2 CLOG SW"""",4)) 
spark &lt;- data.frame(Rank, Week, Alarm, Total) 
</code></pre>

<p>Now when I do this...</p>

<pre><code>s &lt;- ggplot(spark, aes(Week, Total)) +          
     opts( 
        panel.background = theme_rect(size = 1, colour = """"lightgray""""), 
        panel.grid.major = theme_blank(), 
        panel.grid.minor = theme_blank(), 
        axis.line = theme_blank(), 
        axis.text.x = theme_blank(), 
        axis.text.y = theme_blank(), 
        axis.title.x = theme_blank(), 
        axis.title.y = theme_blank(),  
        axis.ticks = theme_blank(), 
        strip.background = theme_blank(), 
        strip.text.y = theme_text(size = 7, colour = """"red"""", angle = 0) 
    ) 

s + facet_grid(Alarm ~ .) + geom_line() 
</code></pre>

<p>I get this....</p>

<p><a href=""""http://img101.imageshack.us/img101/9103/ss20100315112108.png"""" rel=""""nofollow noreferrer"""">alt text http://img101.imageshack.us/img101/9103/ss20100315112108.png</a></p>

<p>Notice that it's facetted according to Alarm and that the facets are arranged alphabetically. </p>

<p>Two Questions:</p>

<ol>
<li>How can I can I keep it facetted by alarm but displayed in the correct order? (Rank asc, Alarm asc).</li>
</ol>

<p><a href=""""http://img17.imageshack.us/img17/6986/ss20100315113243.png"""" rel=""""nofollow noreferrer"""">alt text http://img17.imageshack.us/img17/6986/ss20100315113243.png</a></p>

<ol start=""""2"""">
<li>Also, how can I keep it facetted by Alarm but show labels from Rank instead of Alarm?</li>
</ol>

<p><a href=""""http://img85.imageshack.us/img85/470/ss20100315113529.png"""" rel=""""nofollow noreferrer"""">alt text http://img85.imageshack.us/img85/470/ss20100315113529.png</a></p>

<p>Note that I can't just facet on Rank because ggplot2 would see only 3 facets to plot where there are really 4 different Alarms.</p>
",1
"<p>The following code is supposed to create a heatmap in rpy2</p>

<pre><code>import numpy as np
from rpy2.robjects import r
data = np.random.random((10,10))
r.heatmap(data)    
</code></pre>

<p>However, it results in the following error</p>

<pre><code>Traceback (most recent call last):
  File """"z.py"""", line 8, in &lt;module&gt;
    labRow=rowNames, labCol=colNames)
  File """"C:\Python25\lib\site-packages\rpy2\robjects\__init__.py"""", line 418, in __call__
    new_args = [conversion.py2ri(a) for a in args]
  File """"C:\Python25\lib\site-packages\rpy2\robjects\__init__.py"""", line 93, in default_py2ri
    raise(ValueError(""""Nothing can be done for the type %s at the moment."""" %(type(o))))
ValueError: Nothing can be done for the type &lt;type 'numpy.ndarray'&gt; at the moment.
</code></pre>

<p>From the documentation I learn that r.heatmap expects """"a numeric matrix"""". How do I convert np.array to the required data type?</p>
",1
"<p>I'm looking for a faster way to calculate GC content for DNA strings read in from a FASTA file. This boils down to taking a string and counting the number of times that the letter 'G' or 'C' appears. I also want to specify the range of characters to consider.  </p>

<p>I have a working function that is fairly slow, and it's causing a bottleneck in my code. It looks like this:</p>

<pre><code>##
## count the number of GCs in the characters between start and stop
##
gcCount &lt;-  function(line, st, sp){
  chars = strsplit(as.character(line),"""""""")[[1]]
  numGC = 0
  for(j in st:sp){
    ##nested ifs faster than an OR (|) construction
    if(chars[[j]] == """"g""""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == """"G""""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == """"c""""){
      numGC &lt;- numGC + 1
    }else if(chars[[j]] == """"C""""){
      numGC &lt;- numGC + 1
    }
  }
  return(numGC)
}
</code></pre>

<p>Running Rprof gives me the following output:</p>

<pre><code>&gt; a = """"GCCCAAAATTTTCCGGatttaagcagacataaattcgagg""""
&gt; Rprof(filename=""""Rprof.out"""")
&gt; for(i in 1:500000){gcCount(a,1,40)};
&gt; Rprof(NULL)
&gt; summaryRprof(filename=""""Rprof.out"""")

                   self.time self.pct total.time total.pct
""""gcCount""""          77.36     76.8     100.74     100.0
""""==""""               18.30     18.2      18.30      18.2
""""strsplit""""          3.58      3.6       3.64       3.6
""""+""""                 1.14      1.1       1.14       1.1
"""":""""                 0.30      0.3       0.30       0.3
""""as.logical""""        0.04      0.0       0.04       0.0
""""as.character""""      0.02      0.0       0.02       0.0

$by.total
               total.time total.pct self.time self.pct
""""gcCount""""          100.74     100.0     77.36     76.8
""""==""""                18.30      18.2     18.30     18.2
""""strsplit""""           3.64       3.6      3.58      3.6
""""+""""                  1.14       1.1      1.14      1.1
"""":""""                  0.30       0.3      0.30      0.3
""""as.logical""""         0.04       0.0      0.04      0.0
""""as.character""""       0.02       0.0      0.02      0.0

$sampling.time
[1] 100.74
</code></pre>

<p>Any advice for making this code faster?</p>
",1
"<p>Here is a simple randomized experiment. </p>

<p>In the following code I calculate the p-value under the null hypothesis that two different fertilizers applied to tomato plants have no effect in plants yields.
The first random sample (x) comes from plants where a standard fertilizer has been used, while an """"improved"""" one has been used in the plants where the second sample (y) comes from.</p>

<pre><code>x &lt;- c(11.4,25.3,29.9,16.5,21.1)
y &lt;- c(23.7,26.6,28.5,14.2,17.9,24.3)
total &lt;- c(x,y)
first &lt;- combn(total,length(x))
second &lt;- apply(first,2,function(z) total[is.na(pmatch(total,z))])
dif.treat &lt;- apply(second,2,mean) - apply(first,2,mean)
# the first element of dif.treat is the one that I'm interested in 
(p.value &lt;- length(dif.treat[dif.treat &gt;= dif.treat[1]]) / length(dif.treat))
</code></pre>

<p>Do you know of any R function that performs tests like this one?</p>

<p>EDIT</p>

<pre><code># this is the equivalent independent t.test
t.test(x,y,alternative = """"less"""",var.equal = T)
</code></pre>
",1
"<p>I'm trying to practice writing better code, so I wanted to validate my input sequence with regex to make sure that the first thing I get is a single letter A to H only, and the second is a number 1 to 12 only.  I'm new to regex and not sure what the expression should look like.  I'm also not sure what type of error R would throw if this is invalidated?</p>

<p>In Perl it would be something like this I think: =~ m/([A-M]?))/)</p>

<p>Here is what I have so far for R:</p>

<pre><code>input_string = """"A1""""
first_well_row = unlist(strsplit(input_string, """"""""))[1]  # get the letter out
first_well_col = unlist(strsplit(input_string, """"""""))[2]  # get the number out  
</code></pre>
",1
"<p>R offers max and min, but I do not see a really fast way to find the another value in the order apart from sorting the whole vector and than picking value x from this vector.</p>

<p>Is there a faster way to get the second highest value (e.g.)?</p>

<p>Thanks</p>
",1
"<p>I want to use R to do string parsing that (I think) is like a simplistic HTML parsing.</p>

<p>For example, let's say we have the following two variables:</p>

<pre><code>Seq &lt;- """"GCCTCGATAGCTCAGTTGGGAGAGCGTACGACTGAAGATCGTAAGGtCACCAGTTCGATCCTGGTTCGGGGCA""""
Str &lt;- """"&gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;.""""
</code></pre>

<p>Say that I want to parse """"Seq"""" According to """"Str"""", by using the legend here </p>

<pre><code>Seq: GCCTCGATAGCTCAGTTGGGAGAGCGTACGACTGAAGATCGTAAGGtCACCAGTTCGATCCTGGTTCGGGGCA
Str: &gt;&gt;&gt;&gt;&gt;&gt;&gt;..&gt;&gt;&gt;&gt;........&lt;&lt;&lt;&lt;.&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;.....&gt;&gt;&gt;&gt;&gt;.......&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;.
     |     |  |              | |               |     |               ||     |
     +-----+  +--------------+ +---------------+     +---------------++-----+
        |        Stem 1            Stem 2                 Stem 3         |
        |                                                                |
        +----------------------------------------------------------------+
                                Stem 0
</code></pre>

<p>Assume that we always have 4 stems (0 to 3), but that the length of letters before and after each of them can very.</p>

<p>The output should be something like the following list structure:</p>

<pre><code>list(
    """"Stem 0 opening"""" = """"GCCTCGA"""",
    """"before Stem 1"""" = """"TA"""",
    """"Stem 1"""" = list(opening = """"GCTC"""",
                inside = """"AGTTGGGA"""",
                closing = """"GAGC""""
            ),
    """"between Stem 1 and 2"""" = """"G"""",
    """"Stem 2"""" = list(opening = """"TACGA"""",
                inside = """"CTGAAGA"""",
                closing = """"TCGTA""""
            ),
    """"between Stem 2 and 3"""" = """"AGGtC"""",
    """"Stem 3"""" = list(opening = """"ACCAG"""",
                inside = """"TTCGATC"""",
                closing = """"CTGGT""""
            ),
    """"After Stem 3"""" = """""""",
    """"Stem 0 closing"""" = """"TCGGGGC""""
)
</code></pre>

<p>I don't have any experience with programming a parser, and would like advices as to what strategy to use when programming something like this (and any recommended R commands to use).</p>

<p>What I was thinking of is to first get rid of the """"Stem 0"""", then go through the inner string with a recursive function (let's call it """"seperate.stem"""") that each time will split the string into:
1. before stem
2. opening stem
3. inside stem
4. closing stem
5. after stem</p>

<p>Where the """"after stem"""" will then be recursively entered into the same function (""""seperate.stem"""")</p>

<p>The thing is that I am not sure how to try and do this coding without using a loop.</p>

<p>Any advices will be most welcomed.</p>

<p><strong>Update</strong>: someone sent me a bunch of question, here they are.</p>

<p><strong>Q: Does each sequence have the same number of """">>>>"""" for the opening sequence as it does for """"&lt;&lt;&lt;&lt;"""" on the ending sequence?</strong><br>
A: Yes</p>

<p><strong>Q: Does the parsing always start with a partial stem 0 as your example shows?</strong> 
A: No. Sometimes it will start with a few """".""""</p>

<p><strong>Q: Is there a way of making sure you have the right sequences when you start?</strong> 
A: I am not sure I understand what you mean.</p>

<p><strong>Q: Is there a chance of error in the middle of the string that you have to restart from?</strong>
A: Sadly, yes. In which case, I'll need to ignore one of the inner stems...</p>

<p><strong>Q: How long are these strings that you want to parse?</strong> 
A: Each string has between 60 to 150 characters (and I have tens of thousands of them...)</p>

<p><strong>Q: Is each one a self contained sequence like you show in your example, or do they go on for thousands of characters?</strong> 
A: each sequence is self contained.</p>

<p><strong>Q: Is there always at least one '.' between stems?</strong><br>
A: No.</p>

<p><strong>Q: A full set of rules as to how the parsing should be done would be useful.</strong>
A: I agree.  But since I don't have even a basic idea on how to start coding this, I thought first to have some help on the beginning and try to tweak with the other cases that will come up before turning back for help.</p>

<p><strong>Q: Do you have the BNF syntax for parsing?</strong>
A: No. Your e-mail is the first time I came across it (<a href=""""http://en.wikipedia.org/wiki/Backus"""" rel=""""nofollow noreferrer"""">http://en.wikipedia.org/wiki/Backus</a>Naur_Form).</p>
",1
"<p>I have a problem where I have to add thirty-three integer vectors of equal length from a dataset in R. I know the simple solution would be</p>

<pre><code>Vector1 + Vector2 + Vector3 +VectorN
</code></pre>

<p>But I am sure there is a way to code this. Also some vectors have NA in place of integers so I need a way to skip those. I know this may be very basic but I am new to this.</p>
",1
"<p>In R, how can I print a character list from A to Z?  With integers I can say:</p>

<pre><code>my_list = c(1:10)
&gt; my_list
 [1]  1  2  3  4  5  6  7  8  9 10
</code></pre>

<p>But can I do the same with characters?  e.g. </p>

<pre><code>my_char_list = c(A:Z)
my_char_list = c(""""A"""":""""Z"""")
</code></pre>

<p>These don't work, I want the output to be: <code>""""A"""" """"B"""" """"C"""" """"D""""</code>, or separated by commas.</p>
",1
"<p>Is it possible to return a HashMap to R with the rJava extension of R?
E.g. I have a method in Java, which returns a HashMap and I want this HashMap use in R. I tried:</p>

<pre><code>.jcall(javaObj, """"Ljava/util/HashMap"""", """"getDbInfoMap"""")
</code></pre>

<p>This doesn't work.<br/>
Do I have to put everything into a String[], that I want to pass to R from Java?
Or is there another possibility?</p>

<p>Any help/info on this would be greatly appreciated.</p>
",1
"<p>Why do I see a difference when I convert a unix timestamp to datetime object in R?</p>

<pre><code>&gt; as.POSIXlt(1268736919, origin=""""1970-01-01"""", tz=""""America/New_York"""")
[1] """"2010-03-16 06:55:19 EDT""""

&gt; as.POSIXct(1268736919, origin=""""1970-01-01"""", tz=""""America/New_York"""")
[1] """"2010-03-16 11:55:19 EDT""""
</code></pre>

<p>The result from POSIXlt is actually correct.</p>

<p>Also, is there a way to do this conversion without specifying the origin?</p>

<p>Thanks</p>
",1
"<p>I want to get the index of a particular letter, e.g. </p>

<pre><code>&gt;  match(LETTERS,""""G"""")
 [1] NA NA NA NA NA NA  1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
</code></pre>

<p>Gives me that the letter exists, but I want it to return 6 in this case for the 6th element of the list.</p>
",1
"<p>Let's say we have the following function:</p>

<pre><code>foo &lt;- function(x)
{
    line1 &lt;- x
    line2 &lt;- 0
    line3 &lt;- line1 + line2
    return(line3)
}
</code></pre>

<p>And that we want to change the second line to be:</p>

<pre><code>    line2 &lt;- 2
</code></pre>

<p>How would you do that?</p>

<p>One way is to use</p>

<pre><code>fix(foo)
</code></pre>

<p>And change the function.</p>

<p>Another way is to just write the function again.</p>

<p>Is there another way? (Remember, the task was to change just the second line)</p>

<p>What I would like is for some way to represent the function as a vector of strings (well, characters), then change one of it's values, and then turn it into a function again.</p>
",1
"<p>This is a naive (and likely dumb) question, but I can't seem to get the R syntax highlighting to work with my Linux setup.  </p>

<p>I've downloaded a <code>r.vim</code> file that has improved syntax highlighting, and it works on my Windows gvim setup.  Does this <code>r.vim</code> file need to be in the <code>/usr/share/vim/v70/syntax</code> directory?  Right now, I have it in my home directory and trying out <code>source ~/r.vim</code> in the <code>~/.vimrc</code> file.  However, this doesn't seem to do anything.  Perhaps I'm barking up the wrong tree?</p>
",1
"<p>What is the simplest possible C function for starting the R interpreter, passing in a small expression (eg, 2+2), and getting out the result?  I'm trying to compile with MingW on Windows.</p>
",1
"<p>I am wondering if there exists in R a package/function to perform the: """"Post Hoc Pair-Wise Comparisons for the Chi-Square Test of Homogeneity of Proportions"""" (or an equivalent of it) Which is described here: 
<a href=""""http://epm.sagepub.com/cgi/content/abstract/53/4/951"""" rel=""""nofollow noreferrer"""">http://epm.sagepub.com/cgi/content/abstract/53/4/951</a></p>

<p>My situation is of just making a chi test, on a 2 by X matrix. I found a difference, but I want to know which of the columns is """"responsible"""" for the difference.</p>

<p>Thanks, 
Tal</p>
",1
"<p>I installed/uninstalled java jre/jdk now many times and finally installed the older version 1.6.0_17 which is now located at """"C:\Program Files\Java\jre6\bin"""". Now after all if I call 'java -version' within R i can see that R is looking for Java at the old path which is now wrong. The question is: Why is R looking for Java at the wrong path even so the windows path is set correctly? There are no double entrys within the windows path as far as I can see and I restarted R as well as Windows more then once since then. Any Ideas where R takes the wrong path from?</p>

<p>On windows shell:<br><code> 
$>set <br> 
[..]<br>
OS=Windows_NT<br> 
Path=C:\Program Files\Java\jre6\bin;<br> 
[..]<br></code> </p>

<p><code> 
$> java -version<br>
java version """"1.6.0_17""""<br>
Java(TM) SE Runtime Environment (build 1.6.0_17-b04)<br>
Java HotSpot(TM) 64-Bit Server VM (build 14.3-b01, mixed mode)<br></code> </p>

<p>within R: <br><code> 
$>system(""""java -version"""")<br> 
Error: could not open `C:\Program Files (x86)\Java\jre6\lib\i386\jvm.cfg' <br></code></p>
",1
"<p>I have a time series of two indexes, with each row representing the closing price on the same day. I'd like to go to row 30 and lookback over the last 30 'days' and calculate the pearson correlation. And then store that value in a new vector. Then, repeat the calculation for the entire time series. </p>

<p>It is a trivial task in Excel, so I'm convinced it can be done in R. I don't know the method to use though.</p>
",1
"<p>I am somewhat new to R, and i have this piece of code which generates a variable that i don't know the type for. Are there any introspection facility in R which will tell me which type this variable belongs to?</p>

<p>The following illustrates the property of this variable:</p>

<p>I am working on linear model selection, and the resource I have is <code>lm</code> result from another model. Now I want to retrieve the <code>lm</code> call by the command summary(model)$call so that I don't need to hardcode the model structure. However, since I have to change the dataset, I need to do a bit of modification on the """"string"""", but apparently it is not a simple string. I wonder if there is any command similar to string.replace so that I can manipulate this variable from the variable $call.</p>

<pre><code>&gt; str&lt;-summary(rdnM)$call
&gt; str
lm(formula = y ~ x1, data = rdndat)
&gt; str[1]
lm()
&gt; str[2]
y ~ x1()
&gt; str[3]
rdndat()
&gt; str[3] &lt;- data
Warning message:
In str[3] &lt;- data :
  number of items to replace is not a multiple of replacement length
&gt; str
lm(formula = y ~ x1, data = c(10, 20, 30, 40))
&gt; str&lt;-summary(rdnM)$call
&gt; str
lm(formula = y ~ x1, data = rdndat)
&gt; str[3] &lt;- 'data'
&gt; str
lm(formula = y ~ x1, data = """"data"""")
&gt; str&lt;-summary(rdnM)$call
&gt; type str
Error: unexpected symbol in """"type str""""
&gt; 
</code></pre>
",1
"<p>In the R scripting language, how do I write lines of text, e.g. the following two lines</p>

<pre><code>Hello
World
</code></pre>

<p>to a file named """"output.txt""""?</p>
",1
"<p>Say I have an array of number </p>

<p>a &lt;- c(1,2,3,6,7,8,9,10,20)</p>

<p>if there a way to tell R to output just the range of the continuous sequence from """"a""""
e.g., the continuous sequences in """"a"""" are the following</p>

<p>1,3
6,10
20</p>

<p>Thanks a lot!
Derek</p>
",1
"<p>What happens when I call <code>rchisq(100,1:100,1:100)</code>:</p>

<ul>
<li>does R generate 100 numbers with df=1,ncp=1?</li>
<li>or does it generate 100 numbers each with df=k,ncp=k for  k=1...100?</li>
</ul>

<p>What I want to know is whether  df and ncp can be vectors or not. It is not clear in the documentation (when compared with rnorm). I suspect that they can also be vectors and recycling happens if the lengths differ(?) </p>
",1
"<p>I am trying to read a .txt file, with Hebrew column names, but without success.</p>

<p>I uploaded an example file to:
<a href=""""http://www.talgalili.com/files/aa.txt"""" rel=""""nofollow noreferrer"""">http://www.talgalili.com/files/aa.txt</a></p>

<p>And am trying the command:</p>

<pre><code>read.table(""""http://www.talgalili.com/files/aa.txt"""", header = T, sep = """"\t"""")
</code></pre>

<p>This returns me with:</p>

<pre><code>  X..... X......... X.......
1      12          97         6
2     123         354        44
3       6           1         3
</code></pre>

<p>Instead of:</p>

<pre><code>    
12  97  6
123 354 44
6   1   3
</code></pre>

<p>My output for:</p>

<pre><code>l10n_info()
</code></pre>

<p>Is:</p>

<pre><code>$MBCS
[1] FALSE

$`UTF-8`
[1] FALSE

$`Latin-1`
[1] TRUE

$codepage
[1] 1252
</code></pre>

<p>And for:</p>

<pre><code>Sys.getlocale()
</code></pre>

<p>Is:</p>

<pre><code>[1] """"LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252""""
</code></pre>

<p>Can you suggest to me what to try and change to allow me to load the file correctly ?</p>

<p><strong>Update:</strong>
Trying to use:</p>

<pre><code>read.table(""""http://www.talgalili.com/files/aa.txt"""",fileEncoding =""""iso8859-8"""")
</code></pre>

<p>Has resulted in:</p>

<pre><code> V1
1  ?
Warning messages:
1: In read.table(""""http://www.talgalili.com/files/aa.txt"""", fileEncoding = """"iso8859-8"""") :
  invalid input found on input connection 'http://www.talgalili.com/files/aa.txt'
2: In read.table(""""http://www.talgalili.com/files/aa.txt"""", fileEncoding = """"iso8859-8"""") :
  incomplete final line found by readTableHeader on 'http://www.talgalili.com/files/aa.txt'
</code></pre>

<p>While also trying this:</p>

<pre><code>Sys.setlocale(""""LC_ALL"""", """"en_US.UTF-8"""")
</code></pre>

<p>Or this:</p>

<pre><code>Sys.setlocale(""""LC_ALL"""", """"en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8"""")
</code></pre>

<p>Get's me this:</p>

<pre><code>[1] """"""""
Warning message:
In Sys.setlocale(""""LC_ALL"""", """"en_US.UTF-8"""") :
  OS reports request to set locale to """"en_US.UTF-8"""" cannot be honored
</code></pre>

<p>Finally, here is the > sessionInfo() </p>

<pre><code>R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1255  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.10.1
</code></pre>

<p>Any suggestion or clarification will be appreciated.</p>

<p>Best,
Tal</p>
",1
"<p>Suppose I have a matrix <code>foo</code> as follows:</p>

<pre><code>foo &lt;- cbind(c(1,2,3), c(15,16,17))

&gt; foo
     [,1] [,2]
[1,]    1   15
[2,]    2   16
[3,]    3   17
</code></pre>

<p>I'd like to turn it into a list that looks like</p>

<pre><code>[[1]]
[1]  1 15

[[2]]
[1]  2 16

[[3]]
[1]  3 17
</code></pre>

<p>You can do it as follows:</p>

<p><code>lapply(apply(foo, 1, function(x) list(c(x[1], x[2]))), function(y) unlist(y))</code></p>

<p>I'm interested in an alternative method that isn't as complicated.  Note, if you just do <code>apply(foo, 1, function(x) list(c(x[1], x[2])))</code>, it returns a list within a list, which I'm hoping to avoid.</p>
",1
"<p>I am new to R, can anyone help me with boxplot for a dataset like:</p>

<p>file1</p>

<pre><code>     col1 col2     col3     col4  col5
050350005  101   56.625   48.318 RED    
051010002  106   50.625   46.990 GREEN    
051190007   25   65.875   74.545 BLUE    
051191002  246   52.875   57.070 RED    
220050004   55   70       80.274 BLUE    
220150008   75   67.750   62.749 RED    
220170001   77   65.750   54.307 GREEN
</code></pre>

<p>file2</p>

<pre><code>     col1 col2     col3     col4  col5
050350005  101   56.625   57     RED
051010002  106   50.625   77     GREEN    
051190007   25   65.875   51.6   BLUE    
051191002  246   52.875   55.070 RED    
220050004   55   70       32     BLUE    
220150008   75   67.750   32.49  RED
220170001   77   65.750   84.07  GREEN
</code></pre>

<p>for each color (red,green and blue), I need to compare file1 and file2 by making box plot with MB and RMSE for (col4-col3) for file1 and file2 by dividing col2 in different group: if col2&lt;20,20&lt;=col2&lt;50, 50 &lt;= col2 &lt;70, col2 >=70. That is, for the boxplot, the x is (&lt;20, 20-50,50-70, >70), while y is MB (and RMSE) of the difference of col4 and col3</p>

<p>I hope I didn't confuse anybody. Thank you so much.</p>
",1
"<p>I have a scientific paper under review, and a referee asked for my R code to be provided as a Sweave document. I've never heard of Sweave before, do you know what's the better way to do it?</p>

<p>Thanks a lot :-)</p>
",1
"<p>I'm running R via Rpy on a redhat linux distribution. Periodically I'll encounter this error message:</p>

<pre><code>*** caught segfault ***
address (nil), cause 'unknown'
</code></pre>

<p>And the entire program dies right there. It usually occurs when I run a lot of regression <code>r.lm()</code>. But by simply running the identical code again, the problem may or may not go away (so not always reproduceable). Does anyone know what might be causing this, and/or how I can prevent it from happening?</p>
",1
"<p>I'm blanking on the best way to paste a list of strings together to go into an SQL statement...  I'm having trouble with the separator bar | printing at the beginning when I don't want it to:</p>

<pre><code>foo = """"blah""""
paste_all_together = NULL
for (n in 1:4) {
    paste_together =     paste(foo ,sep = """""""")
    paste_all_together = paste(paste_all_together, paste_together, sep = """"|"""")
    }

&gt; paste_all_together
[1] """"|blah|blah|blah|blah""""
</code></pre>

<p>I just want it to print out """"blah|blah|blah|blah"""".   Do I need a nested loop, or is there a better itterator in R for doing this?  Or perhaps a better way to input SQL statements?</p>
",1
"<p>TRUE/FALSE if clauses are easily and quickly done in R. However, if the argument gets more complex, it also gets ugly very soon.</p>

<p>For instance: 
I might want to execute different operations for a row(foo) dependent on the value in one cell (<code>foo[1]</code>).
Let the intervals be 0:39 and 40:59 and 60:100</p>

<p>Something like does not exit:</p>

<pre><code>(if foo[1] """"in"""" 40:60){...
</code></pre>

<p>In fact, I only see ways of at least two if clauses and two else statements and the action for the first interval somewhere at the bottom of the code. With more intervals(or any other condition) it is getting more complex.</p>

<p>Is there a best practice (for this purpose or others) with a simple construction and nice design to read?</p>
",1
"<p>I have a data.frame from this code:</p>

<pre><code>   my_df = data.frame(""""read_time"""" = c(""""2010-02-15"""", """"2010-02-15"""", 
                                      """"2010-02-16"""", """"2010-02-16"""", 
                                       """"2010-02-16"""", """"2010-02-17""""), 
                      """"OD"""" = c(0.1, 0.2, 0.1, 0.2, 0.4, 0.5) )
</code></pre>

<p>which produces this:</p>

<pre><code>&gt; my_df
   read_time  OD
1 2010-02-15 0.1
2 2010-02-15 0.2
3 2010-02-16 0.1
4 2010-02-16 0.2
5 2010-02-16 0.4
6 2010-02-17 0.5
</code></pre>

<p>I want to average the OD column over each distinct read_time (notice some are replicated others are not) and I also would like to calculate the standard deviation, producing a table like this:</p>

<pre><code>&gt; my_df
   read_time  OD        stdev
1 2010-02-15 0.15       0.05
5 2010-02-16 0.3         0.1
6 2010-02-17 0.5         0
</code></pre>

<p>Which are the best functions to deal with concatenating such values in a data.frame?</p>
",1
"<p>I have data that looks like this:</p>

<pre><code>#val  Freq1 Freq2
0.000 178 202
0.001 4611 5300
0.002 99 112
0.003 26 30
0.004 17 20
0.005 15 20
0.006 11 14
0.007 11 13
0.008 13 13
...many more lines..
</code></pre>

<p>Full data can be found here:
<a href=""""http://dpaste.com/173536/plain/"""" rel=""""nofollow noreferrer"""">http://dpaste.com/173536/plain/</a></p>

<p>What I intend to do is to have a cumulative graph
with """"val"""" as x-axis with """"Freq1"""" &amp; """"Freq2"""" as
y-axis, plot together in 1 graph.</p>

<p>I have this code. But it creates two plots instead of 1.</p>

<pre><code>dat &lt;- read.table(""""stat.txt"""",header=F);
val&lt;-dat$V1
freq1&lt;-dat$V2
freq2&lt;-dat$V3

valf1&lt;-rep(val,freq1)
valf2&lt;-rep(val,freq2)

valfreq1table&lt;- table(valf1)
valfreq2table&lt;- table(valf2)
cumfreq1=c(0,cumsum(valfreq1table))
cumfreq2=c(0,cumsum(valfreq2table))

plot(cumfreq1, ylab=""""CumFreq"""",xlab=""""Loglik Ratio"""")
lines(cumfreq1)
plot(cumfreq2, ylab=""""CumFreq"""",xlab=""""Loglik Ratio"""")
lines(cumfreq2)
</code></pre>

<p>What's the right way to approach this?</p>
",1
"<p>I have no problem plotting the following cumulative <strong>frequency</strong> graph plot
like this.</p>

<pre><code>     library(Hmisc)
     pre.test &lt;- rnorm(100,50,10)
     post.test &lt;- rnorm(100,55,10)
     x &lt;- c(pre.test, post.test)
     g &lt;- c(rep('Pre',length(pre.test)),rep('Post',length(post.test)))
     Ecdf(x, group=g, what=""""f"""", xlab='Test Results', label.curves=list(keys=1:2))
</code></pre>

<p>But I want to show the graph in forms of the """"reverse"""" cumulative frequency of values > x.
(i.e. something equivalent to what=""""1-f"""").</p>

<p>Is there a way to do it?</p>

<p>Other suggestions in R other than using Hmisc are also very much welcomed.</p>
",1
"<p>I'm trying to create a large XML tree in R. Here's a simplified version of the code:</p>

<pre><code>library(XML)
N = 100000#In practice is larger  10^8/ 10^9
seq = newXMLNode(""""sequence"""")
pars = as.character(1:N)
for(i in 1:N)
    newXMLNode(""""Parameter"""", parent=seq, attrs=c(id=pars[i]))
</code></pre>

<p>When N is about N^6 this takes about a minute, N^7 takes about forty minutes. Is there anyway to speed this up?</p>

<p>Using the paste command:</p>

<pre><code>par_tmp = paste('&lt;Parameter id=""""', pars, '""""/&gt;', sep="""""""")
</code></pre>

<p>takes less than a second.</p>
",1
"<p>I created my own new R library (called """"Media""""). There is no problem when I try to load it with RGui, and I can call the functions defined in the new package.  This is how I load it:</p>

<pre><code>   &gt; library(Media)
</code></pre>

<p>But, I'm also trying to call that functions from <a href=""""http://www.rforge.net/JRI/"""" rel=""""nofollow noreferrer"""">Java/JRI</a> code, and when I load the new R package, Java doesn't seem to find the pacakge, throwing the message """"Error in library(Media) : object 'Media' not found""""</p>

<p>This is my current code using JRI:</p>

<pre><code>    REXP rexpSetFolder = re.eval(""""setwd('C:/Users/Albert/Documents')"""");
    REXP rexpFolder = re.eval(""""getwd()"""");
    System.out.println(rexpFolder.asString());

    REXP rexpLoad = re.eval(""""library(Media)""""); // fails
</code></pre>

<p>It also fails without the 'setwd' command, and simple calls to existing R functions work fine.  I'm using R 2.10 and the latest JRI 0.5-0 under Windows.</p>

<p>Any help would be appreciated.
Thank you very much.</p>

<p><strong>Edit:</strong></p>

<p>The parameter <code>lib.loc</code> seems to work, at least this sentence does not return an error:</p>

<pre><code>library(""""Media"""", lib.loc = """"c:/Users/Albert/Documents"""")
</code></pre>

<p>But after that, calling a function in the package with <code>re.eval(""""myfunction()"""");</code> still fails, as the function is not properly found.</p>
",1
"<p>I am wondering if there is a way to transform a matrix of 2 columns into a multimap or list of list.</p>

<p>The first column of the matrix is an id (with possibly duplicated entries) and the 2nd column is some value.</p>

<p>For example,
if I have to following matrix</p>

<pre><code>m &lt;- matrix(c(1,2,1,3,2,4), c(3,2))
</code></pre>

<p>I would like to transform it into the following list</p>

<pre><code>[[1]]
3,4
[[2]]
2
</code></pre>
",1
"<p>The standard stats::kruskal.test module allows to calculate the kruskal-wallis test on a dataset:</p>

<pre><code>&gt;&gt;&gt; data(diamonds)
&gt;&gt;&gt; kruskal.test(price~carat, data=diamonds)

Kruskal-Wallis rank sum test

data:  price by carat by color 
Kruskal-Wallis chi-squared = 50570.15, df = 272, p-value &lt; 2.2e-16
</code></pre>

<p>This is correct, it is giving me a probability that all the groups in the data have the same mean.</p>

<p>However, I would like to have the details for each pair comparison, like if diamonds of colors D and E have the same mean price, as some other softwares do (SPSS) when you ask for a Kruskal test.</p>

<p>I have found <a href=""""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/pgirmess/man/kruskalmc.html"""" rel=""""noreferrer"""">kruskalmc</a> from the package pgirmess which allows me to do what I want to do:</p>

<pre><code>&gt; kruskalmc(diamonds$price, diamonds$color)
Multiple comparison test after Kruskal-Wallis 
p.value: 0.05 
Comparisons
      obs.dif critical.dif difference
D-E  571.7459     747.4962      FALSE
D-F 2237.4309     751.5684       TRUE
D-G 2643.1778     726.9854       TRUE
D-H 4539.4392     774.4809       TRUE
D-I 6002.6286     862.0150       TRUE
D-J 8077.2871    1061.7451       TRUE
E-F 2809.1767     680.4144       TRUE
E-G 3214.9237     653.1587       TRUE
E-H 5111.1851     705.6410       TRUE
E-I 6574.3744     800.7362       TRUE
E-J 8649.0330    1012.6260       TRUE
F-G  405.7470     657.8152      FALSE
F-H 2302.0083     709.9533       TRUE
F-I 3765.1977     804.5390       TRUE
F-J 5839.8562    1015.6357       TRUE
G-H 1896.2614     683.8760       TRUE
G-I 3359.4507     781.6237       TRUE
G-J 5434.1093     997.5813       TRUE
H-I 1463.1894     825.9834       TRUE
H-J 3537.8479    1032.7058       TRUE
I-J 2074.6585    1099.8776       TRUE
</code></pre>

<p>However, this package only allows for one categoric variable (e.g. I can't study the prices clustered by color and by carat, as I can do with kruskal.test), and I don't know anything about the pgirmess package, whether it is maintained or not, or if it is tested.</p>

<p>Can you recommend me a package to execute the Kruskal-Wallis test which returns details for every comparison? How would you handle the problem?</p>
",1
"<p>check this example:</p>

<pre><code>&gt; a = matrix(1:9, nrow = 3, ncol = 3, dimnames = list(LETTERS[1:3], LETTERS[1:3]))
&gt; a
  A B C
A 1 4 7
B 2 5 8
C 3 6 9
</code></pre>

<p>the table displays correctly. There are two different ways of writing it to file... </p>

<p><code>write.csv(a, 'a.csv')</code> which gives as expected:</p>

<pre><code>"""""""",""""A"""",""""B"""",""""C""""
""""A"""",1,4,7
""""B"""",2,5,8
""""C"""",3,6,9
</code></pre>

<p>and <code>write.table(a, 'a.txt')</code> which screws up</p>

<pre><code>""""A"""" """"B"""" """"C""""
""""A"""" 1 4 7
""""B"""" 2 5 8
""""C"""" 3 6 9
</code></pre>

<p>indeed, an empty tab is missing.... which is a pain in the butt for downstream things.
Is this a bug or a feature?
Is there a workaround? (other than <code>write.table(cbind(rownames(a), a), 'a.txt', row.names=FALSE</code>)</p>

<p>Cheers,
yannick</p>
",1
"<p>I'm creating a plot in R, and need to add an en dash to some axis labels, as opposed to your everyday hyphen.  </p>

<pre><code>axis(1, at=c(0:2), labels=c(""""0-10"""",""""11-30"""",""""31-70""""))
</code></pre>

<p>I'm running R version 2.8.1 on Linux.</p>
",1
"<p>In SPSS, it is (relatively) easy to create a cross tab with multiple variables using the factors (or values) as the table heading.  So, something like the following (made up data, etc.).  Q1, Q2, and Q3 each have either a 1, a 2, or a 3 for each person.  I just left these as numbers, but they could be factors, neither seemed to help solve the problem.</p>

<pre>
                        1 (very Often)   2 (Rarely)   3 (Never)
   Q1. Likes it           12              15             13
   Q2. Recommends it      22              11             10
   Q3. Used it            22              12             9
</pre>

<p>In SPSS, one can even request row, column, or total percentages.</p>

<p>I've tried table(), ftable(), xtab(), CrossTable() from gmodels, and CrossTable() from descr, and none of these can handle (afaik) multiple variables; they mostly seem to handle 1 variable crossed with another variable, and the 3rd creates layers.</p>

<p>Is there a package with some good cross tabbing/table examples that I could use to figure this out?   I'm sure I'm missing something simple, so I appreciate you pointing out what I missed.  Perhaps I have to generate each row as a separate list and then make a dataframe and print the dataframe?</p>

<p>UPDATE: I've now discovered ctab() in package catspec, which is also on the right track.  It's interesting that R has no consistent equivalent to Ctables in SPSS, which is basically a """"tabbing"""" tool ala the old tabulate tools used for survey research.   ctab() is trying, and is an admirable 1st step... but you still can't make this table (above) with it.</p>
",1
"<p>I have two sparse matrices, <code>m1</code> and <code>m2</code>:</p>

<pre><code>&gt; m1 &lt;- Matrix(data=0,nrow=2, ncol=1, sparse=TRUE, dimnames=list(c(""""b"""",""""d""""),NULL))
&gt; m2 &lt;- Matrix(data=0,nrow=2, ncol=1, sparse=TRUE, dimnames=list(c(""""a"""",""""b""""),NULL))
&gt; m1[""""b"""",1]&lt;- 4
&gt; m2[""""a"""",1]&lt;- 5
&gt; m1
2 x 1 sparse Matrix of class """"dgCMatrix""""

b 4
d .
&gt; m2
2 x 1 sparse Matrix of class """"dgCMatrix""""

a 5
b .
&gt;
</code></pre>

<p>and I want to <code>cbind()</code> them to make a sparse matrix like:</p>

<pre><code>  [,1] [,2] 
a    .    5
b    4    .
d    .    .
</code></pre>

<p>however <code>cbind()</code> ignores the named rows:</p>

<pre><code>&gt; cbind(m1[,1],m2[,1])
  [,1] [,2]
b    4    5
d    0    0
</code></pre>

<p>is there some way to do this without a brute force loop?</p>
",1
"<p>I have what may be a very simple question.  I want to process a column of POSIXct objects from a dataframe and generate a vector of datetime strings.  I tried to use the following sapply call</p>

<pre><code>dt &lt;- sapply(df$datetime, function(x) format(x,""""%Y-%m-%dT%H:%M:%S""""))
</code></pre>

<p>but to no avail.  I keep getting the following error:</p>

<pre><code>&gt; Error in prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3L,  :
invalid 'trim' argument
</code></pre>

<p>When I apply this function to a single POSIXct object from the column, I have no problem. So I'm stumped at the moment about what the problem is.  Do I need to do something special with POSIXct objects?</p>
",1
"<p>I am trying to remove an object from the parent environment.</p>

<pre><code>rm_obj &lt;- function(obj){
  a &lt;-deparse(substitute(obj))
  print (a)
  print(ls(envir=sys.frame(-1)))  
  rm(a,envir=sys.frame(-1))
}
&gt; x&lt;-c(1,2,3)
&gt; rm_obj(x)
[1] """"x""""

[1] """"rm_obj"""" """"x""""    
Warning message:
In rm(a, envir = sys.frame(-1)) : object 'a' not found
</code></pre>

<p>This will help clarify my misunderstanding regarding frames.</p>
",1
"<p>I'm having a bit of a problem programming R for Sweave, and the #rstats twitter group often points here, so I thought I'd put this question to the SO crowd. I'm an analyst- not a programmer- so go easy on my first post. </p>

<p>Here's the problem: I am drafting a survey report in Sweave with R and would like to report the marginal returns in line using <code>\Sexpr{}</code>. For example, rather than saying:</p>

<blockquote>
  <p>Only 14% of respondents said 'X'.</p>
</blockquote>

<p>I want to write the report like this:</p>

<blockquote>
  <p>Only \Sexpr{p.mean(variable)}$\%$ of respondents said 'X'. </p>
</blockquote>

<p>The problem is that Sweave converts the results of the expression in <code>\Sexpr{}</code> to a character string, which means that the output from the expression in R and the output that appears in my document are different. For example, above I use the function 'p.mean':</p>

<blockquote>
<pre><code>p.mean&lt;- function (x) {options(digits=1)  
mmm&lt;-weighted.mean(x, weight=weight, na.rm=T)  
print(100*mmm)  
}
</code></pre>
</blockquote>

<p>In R, the output looks like this:</p>

<blockquote>
<pre><code>p.mean(variable)
&gt;14
</code></pre>
</blockquote>

<p>but when I use <code>\Sexpr{p.mean(variable)}</code>, I get an unrounded character string (in this case: 13.5857142857143) in my document. I have tried to limit the output of my function to <code>digits=1</code> in the global environment, in the function itself, and and in various commands. It only seems to contain what R prints, not the character transformation that is the result of the expression and which eventually prints in the LaTeX file. </p>

<blockquote>
<pre><code>as.character(p.mean(variable))  
&gt;[1] 14  
&gt;[1] """"13.5857142857143""""  
</code></pre>
</blockquote>

<p>Does anyone know what I can do to limit the digits printed in the LaTeX file, either by reprogramming the R function or with a setting in Sweave or <code>\Sexpr{}</code>?</p>
",1
"<p>That's <code>x \ y</code> using mathematical notation. Suppose</p>

<pre><code>x &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,2,1,1,1,3) 
y &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1)
</code></pre>

<p>How can I get a vector with ALL the values in x that are not in y. i.e the result should be:</p>

<pre><code>2,1,1,3
</code></pre>

<p>There is a similar question <a href=""""https://stackoverflow.com/questions/1837968/r-how-to-tell-what-is-in-one-vector-and-not-another"""">here</a>. However, none of the answers returns the result that I want.</p>
",1
"<p>I have a data.frame: </p>

<pre><code>df&lt;-data.frame(a=c(""""x"""",""""x"""",""""y"""",""""y""""),b=c(1,2,3,4))

&gt; df
      a b
    1 x 1
    2 x 2
    3 y 3
    4 y 4
</code></pre>

<p>What's the easiest way to print out each pair of values as a list of strings like this:</p>

<blockquote>
  <p>""""x1"""", """"x2"""", """"y1"""", """"y2""""</p>
</blockquote>
",1
"<p>Suppose we have generated a matrix <code>A</code> where each column contains one of the combinations of <code>n</code> elements in groups of <code>k</code>. So, its dimensions will be <code>k,choose(n,k)</code>. Such a matrix is produced giving the command <code>combn(n,k)</code>. What I would like to get is another matrix <code>B</code> with dimensions <code>(n-k),choose(n,k)</code>, where each column <code>B[,j]</code> will contain the excluded <code>n-k</code> elements of <code>A[,j]</code>.  </p>

<p>Here is an example of the way I use tho get table <code>B</code>. Do you think it is a safe method to use? Is there another way?</p>

<pre><code>n &lt;- 5 ; k &lt;- 3
(A &lt;- combn(n,k))
(B &lt;- combn(n,n-k)[,choose(n,k):1])
</code></pre>

<p>Another example</p>

<pre><code>x&lt;-c(0,1,0,2,0,1) ; k&lt;- 4
(A &lt;- combn(x,k))
(B &lt;- combn(x,length(x)-k)[,choose(length(x),k):1])
</code></pre>

<p>That <a href=""""https://stackoverflow.com/questions/2487922/r-how-can-i-get-the-complement-of-vector-y-in-vector-x"""">previous question</a> of mine is part of this problem.<br>
Thank you.</p>
",1
"<p>Does anybody know of a way of generating a boxplot in R with a line (or another symbol) in the value corresponding to the mean?</p>

<p>Thank you!</p>
",1
"<p>I know I can use the RODBC library for accessing excel (.xls) docs from within Windows, but is there something similar for the Numbers program that come with iWorks?   If not, what other solutions are there for easily editing a spreadsheet (like a lookup table) and accessing it within R?  I know there the is an internal R editor, but I don't like it very much.</p>
",1
"<p>I'm trying to access $a using the following example: </p>

<pre><code>df&lt;-data.frame(a=c(""""x"""",""""x"""",""""y"""",""""y""""),b=c(1,2,3,4))

&gt; df
  a b
1 x 1
2 x 2
3 y 3
4 y 4

test_fun &lt;- function (data.frame_in) {
    print (data.frame_in[1])
    }
</code></pre>

<p>I can now access $a if I use an index for the first column:</p>

<blockquote>
  <p>apply(df, 1, test_fun)</p>
</blockquote>

<pre><code>  a 
""""x"""" 
  a 
""""x"""" 
  a 
""""y"""" 
  a 
""""y"""" 
[1] """"x"""" """"x"""" """"y"""" """"y""""
</code></pre>

<p>But I cannot access column $a with the $ notation:  error: """"$ operator is invalid for atomic vectors""""</p>

<pre><code>test_fun_2 &lt;- function (data.frame_in) {
    print (data.frame_in$a)
    }

&gt;apply(df, 1, test_fun_2)
Error in data.frame_in$a : $ operator is invalid for atomic vectors
</code></pre>

<p>Is this not possible?</p>
",1
"<p>I'm writing an <a href=""""http://en.wikipedia.org/wiki/R_%28programming_language%29"""" rel=""""nofollow noreferrer"""">R</a> package that's going to be used by others, so I'm trying to get this one right!  I want to use <a href=""""http://cran.r-project.org/web/packages/roxygen/index.html"""" rel=""""nofollow noreferrer"""">roxygen</a> for documentation and <a href=""""http://cran.r-project.org/web/packages/RUnit/index.html"""" rel=""""nofollow noreferrer"""">RUnit</a> for unit testing, but I haven't used them before.</p>

<p>What packages exist (either on CRAN or elsewhere) that use either of these tools well?</p>
",1
"<p>Is there a way to decode tinyURL links in R so that I can see which web pages they actually refer to?</p>
",1
"<p>I can't install odfWeave - it looks like the problem is with the package XML, which gets as far as """"checking for xml2-config..."""" and then cannot find it. :</p>

<pre><code>checking for xml2-config... no Cannot find xml2-config 
ERROR: configuration failed for package XML
* removing /home/andreas/R/i486-pc-linux-gnu-library/2.10/XML
* installing *source* package odfWeave ...
** R
** inst
** preparing package for lazy loading Warning in library(pkg, character.only
= TRUE, logical.return = TRUE, lib.loc = lib.loc) :   there is no package called 'XML' Error : package 'XML'
could not be loaded ERROR: lazy
loading failed for package odfWeave
* removing /home/andreas/R/i486-pc-linux-gnu-library/2.10/odfWeave
</code></pre>
",1
"<p>I would like to suppress output in R when I run my R script from the command prompt. </p>

<p>I tried numerous options including <code>--slave</code> and <code>--vanilla</code>. Those options lessens the amount of text outputted.</p>

<p>I also tried to pipe the output to <code>NUL</code> but that didn't help.</p>
",1
"<p>I am starting to use ggplot2. I have some small n (about 30 or so) granular data with lots of overlap. Neither jitter nor alpha (transparency) are suitable. Instead a stripchart with stack and offset do it best but I do not know how to do it in ggplot2. Do you know?</p>

<p>To see what the end result should be click on this <a href=""""http://www.biomedcentral.com/1471-2180/7/56/figure/F1"""" rel=""""noreferrer"""">graphic</a>.</p>

<p>Here is the script I used a few years ago.</p>

<pre><code>stripchart(SystData$DayTo1Syst~SystData$strain,vertical=TRUE,method=""""stack"""",pch=19,offset=.3,xlab=""""Strain"""",main=""""Rapidity of Systemic Disease Onset"""",ylab=""""Days post inoculation"""")
</code></pre>
",1
"<p>I'm getting some really bizarre stuff while trying to merge multiple data frames. Help!</p>

<p>I need to merge a bunch of data frames by the columns 'RID' and 'VISCODE'. Here is an example of what it looks like:</p>

<pre><code>d1 = data.frame(ID = sample(9, 1:100), RID = c(2, 5, 7, 9, 12),
            VISCODE = rep('bl', 5),
            value1 = rep(16, 5))

d2 = data.frame(ID = sample(9, 1:100), RID = c(2, 2, 2, 5, 5, 5, 7, 7, 7),
            VISCODE = rep(c('bl', 'm06', 'm12'), 3),
            value2 = rep(100, 9))

d3 = data.frame(ID = sample(9, 1:100), RID = c(2, 2, 2, 5, 5, 5, 9,9,9),
            VISCODE = rep(c('bl', 'm06', 'm12'), 3),
            value3 = rep(""""a"""", 9),
            values3.5 = rep(""""c"""", 9))

d4 = data.frame(ID =sample(8, 1:100), RID = c(2, 2, 5, 5, 5, 7, 7, 7, 9),
            VISCODE = c(c('bl', 'm12'), rep(c('bl', 'm06', 'm12'), 2), 'bl'),
            value4 = rep(""""b"""", 9))

dataList = list(d1, d2, d3, d4)
</code></pre>

<p>I looked at the answers to the question titled """"Merge several data.frames into one data.frame with a loop."""" I used the reduce method suggested there as well as a loop I wrote:</p>

<pre><code>try1 = mymerge(dataList)

try2 &lt;- Reduce(function(x, y) merge(x, y, all= TRUE,
by=c(""""RID"""", """"VISCODE"""")), dataList, accumulate=F)
</code></pre>

<p>where dataList is a list of data frames and mymerge is:</p>

<pre><code>mymerge = function(dataList){

L = length(dataList)

mdat = dataList[[1]]

  for(i in 2:L){

    mdat = merge(mdat, dataList[[i]], by.x = c(""""RID"""", """"VISCODE""""),
                                  by.y = c(""""RID"""", """"VISCODE""""), all = TRUE)
  }

mdat
}
</code></pre>

<p>For my test data and subsets of my real data, both of these work fine and produce exactly the same results. However, when I use larger subsets of my data, they both break down and give me the following error: Error in match.names(clabs, names(xi)) : names do not match previous names.</p>

<p>The really weird thing is that using this works:</p>

<pre><code>  dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:47, ])
</code></pre>

<p>And using this fails:</p>

<pre><code>  dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:48, ])
</code></pre>

<p>As far as I can tell, there is nothing special about row 48 of faq. Likewise, using this works:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            pdx[1:47, ])
</code></pre>

<p>And using this fails:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            pdx[1:48, ])
</code></pre>

<p>Row 48 in faq and row 48 in pdx have the same values for RID and VISCODE, the same value for EXAMDATE (something I'm not matching on) and different values for ID (another thing I'm not matching on). Besides the matching RID and VISCODE, I see anything special about them. They don't share any other variable names. This same scenario occurs elsewhere in the data without problems. </p>

<p>To add icing on the complication cake, this doesn't even work:</p>

<pre><code>dataList = list(demog[1:50,],
            neurobat[1:50,],
            apoe[1:50,],
            mmse[1:50,],
            faq[1:48, 2:3])
</code></pre>

<p>where columns 2 and 3 are """"RID"""" and """"VISCODE"""". </p>

<p>48 isn't even the magic number because this works:</p>

<pre><code> dataList = list(demog[1:500,],
            neurobat[1:500,],
            apoe[1:500,],
            mmse[1:457,])
</code></pre>

<p>while using mmse[1:458, ] fails. </p>

<p>I can't seem to come up with test data that causes the problem. Has anyone had this problem before? Any better ideas on how to merge?</p>

<p>Thanks for your help!
Jasmine</p>
",1
"<p>I have a vector X that contains positive numbers that I want to bin/discretize.  For this vector, I want the numbers [0, 10) to show up just as they exist in the vector, but numbers [10,&infin;)  to be 10+.  </p>

<p>I'm using:</p>

<pre><code>x &lt;- c(0,1,3,4,2,4,2,5,43,432,34,2,34,2,342,3,4,2)
binned.x &lt;- as.factor(ifelse(x &gt; 10,""""10+"""",x))
</code></pre>

<p>but this feels klugey to me.  Does anyone know a better solution or a different approach?</p>
",1
"<p>I'm running an logit model using the Zelig package. I get the following error...what could be wrong?</p>

<pre><code>anes96two &lt;- zelig(trade962a ~ age962 + education962 + personal962 + economy962 + partisan962 + employment962 + union962 + home962 + market962 + race962 + income962, model=""""mlogit"""", data=data96)

 #Error in attr(tt, """"depFactors"""")$depFactorVar : 
#  $ operator is invalid for atomic vectors
</code></pre>
",1
"<p>Suppose you have the following function <code>foo</code>.  When I'm running a <code>for</code> loop, I'd like it to skip the remainder of <code>foo</code> when <code>foo</code> initially returns the value of <code>0</code>.  However, <code>break</code> doesn't work when it's inside a function.  </p>

<p>As it's currently written, I get an error message, <code>no loop to break from, jumping to top level</code>.  </p>

<p>Any suggestions?</p>

<pre><code>foo &lt;- function(x) {
    y &lt;- x-2
    if (y==0) {break} # how do I tell the for loop to skip this
    z &lt;- y + 100
    z
}


for (i in 1:3) {
    print(foo(i))
}
</code></pre>
",1
"<p>I am looking for the way to annotate axis in ggplot2. The example of the problem can be found here: <a href=""""http://learnr.wordpress.com/2009/09/24/ggplot2-back-to-back-bar-charts"""" rel=""""nofollow noreferrer"""">http://learnr.wordpress.com/2009/09/24/ggplot2-back-to-back-bar-charts</a>. </p>

<p>The y axis of the chart (example graph in the link) has an annotation: (million euro). Is there a way to create such types of annotations in ggplot2? Looking at the documentation there is no obvious way, since the ggplot does not explicitly let you put objects outside plotting area. But maybe there is some workaround?</p>

<p>One of the possible workarounds I thought about is using scales:</p>

<pre><code>data=data.frame(x=1:10,y=1:10)
qplot(x=x,y=y,data=data)+scale_y_continuous(breaks=10.1,label=""""Millions"""")
</code></pre>

<p>But then how do I remove the tick? And it seems that since ggplot does not support multiple scales, I will need to grab the output of the scale_y_continuous, when it calculates the scales automaticaly and then add my custom break and label by hand. Maybe there is a better way?</p>
",1
"<p>I want to write some temporary data to disk in an R package, and I want to be sure that it can run on every OS without assuming the user has admin rights.  Is there an existing R function that can provide a path to a temporary directory on all major OS's?  Or a way to reference a user's home directory?  </p>

<p>Otherwise, I was thinking of trying this: </p>

<pre><code>Sys.getenv(""""temp"""")
</code></pre>

<p>I presume that I can't expect people to have write access to their R locations, otherwise I could reference a path within the package directory: <code>.find.package(""""package.name"""")</code>.</p>
",1
"<p>I'm trying to do a simple genomic track intersection in R, and running into major performance problems, probably related to my use of for loops.  </p>

<p>In this situation, I have pre-defined windows at intervals of 100bp and I'm trying to calculate how much of each window is covered by the annotations in mylist.  Graphically, it looks something like this:</p>

<pre><code>          0    100   200    300    400   500   600  
windows: |-----|-----|-----|-----|-----|-----|

mylist:    |-|   |-----------|
</code></pre>

<p>So I wrote some code to do just that, but it's fairly slow and has become a bottleneck in my code:</p>

<pre><code>##window for each 100-bp segment    
windows &lt;- numeric(6)

##second track
mylist = vector(""""list"""")
mylist[[1]] = c(1,20)
mylist[[2]] = c(120,320)


##do the intersection
for(i in 1:length(mylist)){
  st &lt;- floor(mylist[[i]][1]/100)+1
  sp &lt;- floor(mylist[[i]][2]/100)+1
  for(j in st:sp){       
    b &lt;- max((j-1)*100, mylist[[i]][1])
    e &lt;- min(j*100, mylist[[i]][2])
    windows[j] &lt;- windows[j] + e - b + 1
  }
}

print(windows)
[1]  20  81 101  21   0   0
</code></pre>

<p>Naturally, this is being used on data sets that are much larger than the example I provide here. Through some profiling, I can see that the bottleneck is in the for loops, but my clumsy attempt to vectorize it using *apply functions resulted in code that runs an order of magnitude more slowly.</p>

<p>I suppose I could write something in C, but I'd like to avoid that if possible. Can anyone suggest another approach that will speed this calculation up? </p>
",1
"<p>Imagine you have an object <code>foo</code> that you saved as <code>saved.file.rda</code> as follows:</p>

<pre><code>foo &lt;- 'a'
save(foo, file='saved.file.rda')
</code></pre>

<p>Suppose you load <code>saved.file.rda</code> into an environment with multiple objects but forgot the name of the object that is in <code>saved.file.rda</code>.  Is there a way in R to determine that name?  </p>

<p>You can do it the following way, which seems a little clunky:</p>

<pre><code>bar &lt;- load('saved.file.rda')
eval(parse(text=bar)) # this will pull up the object that was in saved.file.rda
</code></pre>

<p>However, is there a better way of doing this?</p>
",1
"<p>I need to show the values on the horizontal axis (aka abscissa, aka x-axis) converted into other units. Hence the need for a second axis.</p>
",1
"<p>Most functions for generating lognormally distributed random numbers take the mean and standard deviation of the associated normal distribution as parameters.</p>

<p>My problem is that I only know the mean and the coefficient of variation of the lognormal distribution.  It is reasonably straight forward to derive the parameters I need for the standard functions from what I have:</p>

<p>If <code>mu</code> and <code>sigma</code> are the mean and standard deviation of the associated normal distribution, we know that</p>

<pre><code>coeffOfVar^2 = variance / mean^2
             = (exp(sigma^2) - 1) * exp(2*mu + sigma^2) / exp(mu + sigma^2/2)^2
             = exp(sigma^2) - 1
</code></pre>

<p>We can rearrange this to </p>

<pre><code>sigma = sqrt(log(coeffOfVar^2 + 1))
</code></pre>

<p>We also know that</p>

<pre><code>mean = exp(mu + sigma^2/2)
</code></pre>

<p>This rearranges to </p>

<pre><code>mu = log(mean) - sigma^2/2
</code></pre>

<p>Here's my R implementation</p>

<pre><code>rlnorm0 &lt;- function(mean, coeffOfVar, n = 1e6)
{
   sigma &lt;- sqrt(log(coeffOfVar^2 + 1))
   mu &lt;- log(mean) - sigma^2 / 2
   rlnorm(n, mu, sigma)
}
</code></pre>

<p>It works okay for small coefficients of variation</p>

<pre><code>r1 &lt;- rlnorm0(2, 0.5)
mean(r1)                 # 2.000095
sd(r1) / mean(r1)        # 0.4998437
</code></pre>

<p>But not for larger values</p>

<pre><code>r2 &lt;- rlnorm0(2, 50)
mean(r2)                 # 2.048509
sd(r2) / mean(r2)        # 68.55871
</code></pre>

<p>To check that it wasn't an R-specific issue, I reimplemented it in MATLAB. (Uses stats toolbox.)</p>

<pre><code>function y = lognrnd0(mean, coeffOfVar, sizeOut)
if nargin &lt; 3 || isempty(sizeOut)
   sizeOut = [1e6 1];
end
sigma = sqrt(log(coeffOfVar.^2 + 1));
mu = log(mean) - sigma.^2 ./ 2;
y = lognrnd(mu, sigma, sizeOut);
end

r1 = lognrnd0(2, 0.5);
mean(r1)                  % 2.0013
std(r1) ./ mean(r1)       % 0.5008

r2 = lognrnd0(2, 50);
mean(r2)                  % 1.9611
std(r2) ./ mean(r2)       % 22.61
</code></pre>

<p>Same problem.  The question is, why is this happening?  Is it just that the standard deviation is not robust when the variation is that wide?  Or have I screwed up somewhere?</p>
",1
"<p>I have a system set up that's been happily running R from a java servlet, spawning processed &amp; hooking into the process's stdin, stdout, and stderr streams, as in the second andwer to <a href=""""https://stackoverflow.com/questions/2180235/r-from-within-java"""">this question</a>.  </p>

<p>After a system upgrade (that included glibc), the input is no longer reaching the R process.*  </p>

<p>Until now, 'R --vanilla --slave -f [file] ...' was working fine for me.  I also have no swing dependencies right now, so I'm somewhat reluctant to add them. (I may actually not be <em>able</em> to add swing dependencies; am I right that using REngine automatically brings swing in?  The examples import all of swing.)</p>

<p>Are there advantages to switching to JRI?  What changes would I need to make to my R script?  (It currently reads from stdin and writes to stdout).  I'm not finding the provided examples terribly helpful for how to use JRI in this situation. </p>

<p>Thanks for your help &amp; comments.</p>

<p>*I can't even tell if the problem is data being written too soon or too late, but that's a separate issue/question; if I move to JRI I'm hoping it all becomes moot.</p>
",1
"<p>A recurring analysis paradigm I encounter in my research is the need to subset based on all different group id values, performing statistical analysis on each group in turn, and putting the results in an output matrix for further processing/summarizing.</p>

<p>How I typically do this in R is something like the following:</p>

<blockquote>
  <p>data.mat &lt;- read.csv(""""..."""")<br>
     groupids &lt;- unique(data.mat$ID)  #Assume there are then 100 unique groups</p>
  
  <p>results &lt;- matrix(rep(""""NA"""",300),ncol=3,nrow=100)  </p>
  
  <p>for(i in 1:100) {<br>
     <code></code>tempmat &lt;- subset(data.mat,ID==groupids[i])  </p>
  
  <p><code>#</code>Run various stats on tempmat (correlations, regressions, etc), checking to<br>
     <code>#</code>make sure this specific group doesn't have NAs in the variables I'm using<br>
     <code>#</code>and assign results to x, y, and z, for example.  </p>
  
  <p><code></code>results[i,1] &lt;- x<br>
     <code></code>results[i,2] &lt;- y<br>
     <code></code>results[i,3] &lt;- z<br>
     }  </p>
</blockquote>

<p>This ends up working for me, but depending on the size of the data and the number of groups I'm working with, this can take up to three days. </p>

<p>Besides branching out into parallel processing, is there any """"trick"""" for making something like this run faster? For instance, converting the loops into something else (something like an apply with a function containing the stats I want to run inside the loop), or eliminating the need to actually assign the subset of data to a variable?</p>

<p>EDIT:</p>

<p>Maybe this is just common knowledge (or sampling error), but I tried subsetting with brackets in some of my code rather than using the subset command, and it seemed to provide a slight performance gain which surprised me. I have some code I used and output below using the same object names as above:</p>

<blockquote>
  <p><code>&gt;</code>system.time(for(i in 1:1000){data.mat[data.mat$ID==groupids[i],]})<br>
        user  system elapsed<br>
      361.41   92.62  458.32 </p>
  
  <p><code>&gt;</code> system.time(for(i in 1:1000){subset(data.mat,ID==groupids[i])})<br>
        user  system elapsed<br>
      378.44  102.03  485.94   </p>
</blockquote>

<p>UPDATE:<br>
In one of the answers, jorgusch suggested that I use the data.table package to speed up my subsetting. So, I applied it to a problem I ran earlier this week. In a dataset with a little over 1,500,000 rows, and 4 columns (ID,Var1,Var2,Var3), I wanted to calculate two correlations in each group (indexed by the """"ID"""" variable). There are slightly more than 50,000 groups. Below is my initial code (which is very similar to the above):  </p>

<blockquote>
  <p>data.mat &lt;- read.csv(""""//home...."""")<br>
     groupids &lt;- unique(data.mat$ID)</p>
  
  <p>results &lt;- matrix(rep(""""NA"""",(length(groupids) * 3)),ncol=3,nrow=length(groupids))  </p>
  
  <p>for(i in 1:length(groupids)) {<br>
     <code></code>tempmat &lt;- data.mat[data.mat$ID==groupids[i],] </p>
  
  <p><code></code>results[i,1] &lt;- groupids[i]<br>
     <code></code>results[i,2] &lt;- cor(tempmat$Var1,tempmat$Var2,use=""""pairwise.complete.obs"""")<br>
     <code></code>results[i,3] &lt;- cor(tempmat$Var1,tempmat$Var3,use=""""pairwise.complete.obs"""")    </p>
  
  <p>}  </p>
</blockquote>

<p>I'm re-running that right now for an exact measure of how long that took, but from what I remember, I started it running when I got into the office in the morning and it finished sometime in mid-afternoon. Figure 5-7 hours.  </p>

<p>Restructuring my code to use data.table....</p>

<blockquote>
  <p>data.mat &lt;- read.csv(""""//home...."""")<br>
     data.mat &lt;- data.table(data.mat)  </p>
  
  <p>testfunc &lt;- function(x,y,z) {<br>
     <code></code>temp1 &lt;- cor(x,y,use=""""pairwise.complete.obs"""")<br>
     <code></code>temp2 &lt;- cor(x,z,use=""""pairwise.complete.obs"""")<br>
     <code></code>res &lt;- list(temp1,temp2)<br>
     <code></code>res<br>
     }  </p>
  
  <p>system.time(test &lt;- data.mat[,testfunc(Var1,Var2,Var3),by=""""ID""""])  </p>
  
  <p>user  system  elapsed<br>
    16.41   0.05    17.44  </p>
</blockquote>

<p>Comparing the results using data.table to the ones I got from using a for loop to subset all IDs and record results manually, they seem to have given me the same answers(though I'll have to check that a bit more thoroughly). That looks to be a pretty big speed increase.</p>

<p>UPDATE 2: Running the code using subsets finally finished up again:</p>

<blockquote>
<pre><code>   user     system   elapsed  
17575.79  4247.41   23477.00
</code></pre>
</blockquote>

<p>UPDATE 3:<br>
I wanted to see if anything worked out differently using the plyr package that was also recommended. This is my first time using it, so I may have done things somewhat inefficiently, but it still helped substantially compared to the for loop with subsetting.  </p>

<p>Using the same variables and setup as before...  </p>

<blockquote>
  <p><code>&gt;</code>data.mat &lt;- read.csv(""""//home...."""")<br>
     <code>&gt;</code>system.time(hmm &lt;- ddply(data.mat,""""ID"""",function(df)c(cor(df$Var1,df$Var2,  use=""""pairwise.complete.obs""""),cor(df$Var1,df$Var3,use=""""pairwise.complete.obs""""))))  </p>

<pre><code>  user  system elapsed  
250.25    7.35  272.09  
</code></pre>
</blockquote>
",1
"<p><code>ess-mode</code> is """"Emacs speaks statistics."""" This mode is useful for editing programs for R or Splus (two separate statistics packages).</p>

<p>In my buffer, when ever I type <code>_</code> the character is replaced with <code>&lt;-</code>, which is very frustrating.  Is there an emacs lisp statement to turn off this behavior?</p>

<p>emacs: 22.1.1
ess-mode release (unknown)</p>
",1
"<h3>Background</h3>

<p>Right now, I'm creating a multiple-predictor linear model and generating diagnostic plots to assess regression assumptions. (It's for a multiple regression analysis stats class that I'm loving at the moment :-)</p>

<p>My textbook (Cohen, Cohen, West, and Aiken 2003) recommends plotting each predictor against the residuals to make sure that:</p>

<ol>
<li>The residuals don't systematically covary with the predictor</li>
<li>The residuals are homoscedastic with respect to each predictor in the model</li>
</ol>

<p>On point (2), my textbook has this to say:</p>

<blockquote>
  <p>Some statistical packages allow the analyst to plot lowess fit lines at the mean of the residuals (0-line), 1 standard deviation above the mean, and 1 standard deviation below the mean of the residuals....In the present case {their example}, the two lines {mean + 1sd and mean - 1sd} remain roughly parallel to the lowess {0} line, consistent with the interpretation that the variance of the residuals does not change as a function of X. (p. 131)</p>
</blockquote>

<h3>How can I modify loess lines?</h3>

<p>I know how to generate a scatterplot with a """"0-line,"""":</p>

<pre><code>    # First, I'll make a simple linear model and get its diagnostic stats
    library(ggplot2)
    data(cars)
    mod &lt;- fortify(lm(speed ~ dist, data = cars))
    attach(mod)
    str(mod)

    # Now I want to make sure the residuals are homoscedastic
    qplot (x = dist, y = .resid, data = mod) + 
    geom_smooth(se = FALSE) # """"se = FALSE"""" Removes the standard error bands
</code></pre>

<p>But does anyone know how I can use <code>ggplot2</code> and <code>qplot</code> to generate plots where the 0-line, """"mean + 1sd"""" AND """"mean - 1sd"""" lines would be superimposed? Is that a weird/complex question to be asking?</p>
",1
"<p>Can you tell me what is returned by <strong>glm$residuals</strong> and <strong>resid(glm)</strong> where glm is a quasipoisson object.  e.g. How would I create them using glm$y and glm$linear.predictors. </p>

<p><strong>glm$residuals</strong></p>

<pre><code> n missing  unique    Mean     .05     .10   .25  .50     .75     .90     .95
</code></pre>

<p>37715   10042    2174 -0.2574 -2.7538 -2.2661 -1.4480 -0.4381  0.7542  1.9845  2.7749</p>

<p>lowest : -4.243 -3.552 -3.509 -3.481 -3.464
highest:  8.195  8.319  8.592  9.089  9.416</p>

<p><strong>resid(glm)</strong></p>

<pre><code>    n    missing     unique       Mean        .05        .10        .25
37715          0       2048 -2.727e-10    -1.0000    -1.0000    -0.6276
  .50        .75        .90        .95
</code></pre>

<p>-0.2080     0.4106     1.1766     1.7333</p>

<p>lowest : -1.0000 -0.8415 -0.8350 -0.8333 -0.8288
highest:  7.2491  7.6110  7.6486  7.9574 10.1932</p>
",1
"<p>I'm wondering if there is a built in function in R that can find the cosine similarity (or cosine distance) between two arrays?</p>

<p>Currently, I implemented my own function, but I can't help but think that R should already come with one.</p>
",1
"<p>I have high frequency commodity price data that I need to analyze. My objective is to not assume any seasonal component and just identify a trend. Here is where I run into problems with R. There are two main functions that I know of to analyze this time series: decompose() and stl(). The problem is that they both take a ts object type with a frequency parameter greater than or equal to 2. Is there some way I can assume a frequency of 1 per unit time and still analyze this time series using R? I'm afraid that if I assume frequency greater than 1 per unit time, and seasonality is calculated using the frequency parameter, then my forecasts are going to depend on that assumption. </p>

<pre><code>names(crude.data)=c('Date','Time','Price')
names(crude.data)
freq = 2
win.graph()
plot(crude.data$Time,crude.data$Price, type=""""l"""")
crude.data$Price = ts(crude.data$Price,frequency=freq) 
</code></pre>

<p>I want frequency to be 1 per unit time but then decompose() and stl() don't work!</p>

<pre><code>dim(crude.data$Price)
decom = decompose(crude.data$Price)
win.graph()
plot(decom$random[2:200],type=""""line"""")
acf(decom$random[freq:length(decom$random-freq)])
</code></pre>

<p>Thank you.</p>
",1
"<p>I'm trying to put multiple lattice plots in one window using <code>levelplot</code> by setting <code>par(mfrow=c(2,1))</code> but it seems to be ignoring this.</p>

<p>Is there a particular function for setting multiple plots in <code>lattice</code>?</p>
",1
"<p>For example, if I need that the user specifies the number of rows and columns of a matrix:</p>

<p>PROMPT: Number of rows?: </p>

<p>USER INPUT: [a number]</p>

<p>I need that R 'waits' for the input. Then save [a number] into a variable v1. Next, </p>

<p>PROMPT: Number of columns?: </p>

<p>USER INPUT: [another number]</p>

<p>Also save [another number] into a variable v2. At the end, I will have two variables (v1, v2) that will be used in the rest of the code.</p>

<p>""""readline"""" only works for one input at a time. I can't run the two lines together</p>

<pre><code>v1 &lt;- readline(""""Number of rows?: """")
v2 &lt;- readline(""""Number of columns?: """")
</code></pre>

<p>Any ideas or suggestions?</p>

<p>Thank you in advance</p>
",1
"<p>I have a dataframe with numeric entries like this one</p>

<pre><code>test &lt;- data.frame(x=c(26,21,20),y=c(34,29,28))
</code></pre>

<p>How can I get the following vector?</p>

<pre><code>&gt; 26,34,21,29,20,28
</code></pre>

<p>I was able to get it using the following, but I guess there should be a much more elegant way</p>

<pre><code>X &lt;- test[1,]
for (i in 2:dim(test)[1]){
X &lt;- cbind(X,test[i,])
} 
</code></pre>
",1
"<p>I am trying to convert a 120mb XML database of terrorist incidents (the first file for download available here <a href=""""http://wits.nctc.gov/Export.do"""" rel=""""nofollow noreferrer"""">http://wits.nctc.gov/Export.do</a>) to spreadsheet form so I can merge it with other data and do statistical analysis.</p>

<p>So far I have worked with Stata, which is useless now because it wont read XML. the site offers smaller files by month which can be opened via excel, but excel does not display them in the form I want and there ought to be a better way to transform the complete file rather than opening over a hundred single files, manually saving them as tab separated and then merging them.</p>

<p>I am looking for a way to convert the complete WITS.xml file to a spreadsheet where one row represents a single terrorist incident, and no info from the xml should be missing. even a differently structured XML is probably fine. I have tried converters but they are either not free, do not perform in the way I want them to or the file size is too large, and I have no idea how to use xslt. I am studying economics, and my programming knowledge is virtually nonexistent, which is increasingly becoming a drawback. I have seen that there is a package for R that I could use, maybe now is the right moment to start learning R or some other language. However, if there is a quick and easy way to do it, I'd sure prefer it.</p>
",1
"<p>What if one wants to <code>apply</code> a functon i.e. to each row of a matrix, but also wants to use as an argument for this function the number of that row. As an example, suppose you wanted to get the n-th root of the numbers in each row of a matrix, where n is the row number. Is there another way (using <code>apply</code> only) than column-binding the row numbers to the initial matrix, like this?</p>

<pre><code>test &lt;- data.frame(x=c(26,21,20),y=c(34,29,28))

t(apply(cbind(as.numeric(rownames(test)),test),1,function(x) x[2:3]^(1/x[1])))
</code></pre>

<p>P.S. Actually if <em>test</em> was really a matrix :  <code>test &lt;- matrix(c(26,21,20,34,29,28),nrow=3)</code>  , rownames(test) doesn't help :(
Thank you.</p>
",1
"<p>I have the following simple data</p>

<pre><code>data &lt;- structure(list(status = c(9, 5, 9, 10, 11, 10, 8, 6, 6, 7, 10, 
10, 7, 11, 11, 7, NA, 9, 11, 9, 10, 8, 9, 10, 7, 11, 9, 10, 9, 
9, 8, 9, 11, 9, 11, 7, 8, 6, 11, 10, 9, 11, 11, 10, 11, 10, 9, 
11, 7, 8, 8, 9, 4, 11, 11, 8, 7, 7, 11, 11, 11, 6, 7, 11, 6, 
10, 10, 9, 10, 10, 8, 8, 10, 4, 8, 5, 8, 7), statusgruppe = c(0, 
0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, NA, 0, 1, 0, 1, 
0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 
1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 
1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0)), .Names = c(""""status"""", 
""""statusgruppe""""), class = """"data.frame"""", row.names = c(NA, -78L
))
</code></pre>

<p>from that I'd like to make a histogram:</p>

<pre><code>ggplot(data, aes(status))+
geom_histogram(aes(y=..density..),
     binwidth=1, colour = """"black"""",
     fill=""""white"""")+
theme_bw()+
scale_x_continuous(""""Staus"""", breaks=c(min(data$status,na.rm=T), median(data$status, na.rm=T), max(data$status, na.rm=T)),labels=c(""""Low"""", """"Middle"""", """"High""""))+
scale_y_continuous(""""Percent"""", formatter=""""percent"""")
</code></pre>

<p>Now - i'd like for the bins to take colou according to value - e.g. bins with value > 9 gets  dark grey - everything else should be light grey.</p>

<p>I have tried with <code>fill=statusgruppe</code>, <code>scale_fill_grey(breaks=9)</code> etc. - but I can't get it to work. Any ideas?</p>
",1
"<p>I'd like to spawn several graphics windows from within a function in R using ggplot graphics...</p>

<pre><code>testf &lt;- function(a, b) {
  devAskNewPage(TRUE)
  qplot(a, b);
  # grid.newpage(recording = TRUE)
  dev.new()
  qplot(a, a+a);
  # grid.newpage(recording = TRUE)
  dev.new()
  qplot(b, b+b);
}

library(ggplot2)

x &lt;- rnorm(50)
y &lt;- rnorm(50)
testf(x, y)
</code></pre>

<p>However, neither dev.new() nor grid.newpage() seems to flush the preceding plot.</p>

<p>I know that, in R, functions normally only produce the last thing they evaluate, but I'd like to understand the process better and to learn of any possible workarounds. </p>

<p>Thoughts?</p>
",1
"<p>In R, <code>mean()</code> and <code>median()</code> are standard functions which do what you'd expect.  <code>mode()</code> tells you the internal storage mode of the object, not the value that occurs the most in its argument. But is there is a standard library function that implements the statistical mode for a vector (or list)?</p>
",1
"<p><a href=""""http://en.wikipedia.org/wiki/R_%28programming_language%29"""" rel=""""noreferrer"""">R</a> is a statistics programming language.  Part of R is the use of Packages, which themselves are written in the R language.  Programming best practice includes the use of unit-testing to test the functions within these packages while they are being written and when they are used.</p>

<p>I am aware of a few packages for unit testing within R, these being</p>

<ul>
<li><a href=""""http://cran.r-project.org/web/packages/RUnit/index.html"""" rel=""""noreferrer"""">RUnit</a></li>
<li><a href=""""http://cran.r-project.org/web/packages/svUnit/index.html"""" rel=""""noreferrer"""">Svunit</a></li>
<li><a href=""""http://cran.r-project.org/web/packages/testthat/index.html"""" rel=""""noreferrer"""">Testthat</a></li>
</ul>

<p>I'm interested to know;</p>

<p>Are there any other packages out there ?
Given peoples experience, do these packages excel at different things ?
What's the current state of the art in unit testing for R ?</p>
",1
"<p>Is there a way to extract the file name from the file full path (part of a file path) without the hassle of manipulating string?</p>

<p>The equivalent in Java would be:</p>

<pre><code>File f = new File (""""C:/some_dir/a"""")
f.getName() //output a
f.getFullAbsolutePath() //output c:/some_dir/a
</code></pre>
",1
"<p>I'm trying to display frequencies within barplot ... well, I want them <strong>somewhere</strong> in the graph: under the bars, within bars, above bars or in the legend area. And I recall (I may be wrong) that it can be done in <code>ggplot2</code>. This is probably an easy one... at least it seems easy. Here's the code:</p>

<pre><code>p &lt;- ggplot(mtcars)
p + aes(factor(cyl)) + geom_bar()
</code></pre>

<p>Is there any chance that I can get frequencies embedded in the graph?</p>
",1
"<p>I have a dataframe which contains (among other things) a numeric column with a concentration, and a factor column with a status flag.  This status flag contains NA's.</p>

<p>Here's an example</p>

<pre><code>df&lt;-structure(list(conc = c(101.769, 1.734, 62.944, 92.697, 25.091, 27.377, 24.343, 55.084, 0.335, 23.280), status = structure(c(NA, NA, NA, NA, NA, NA, 2L, NA, 1L, NA), .Label = c(""""&lt;LLOQ"""", """"NR""""), class = """"factor"""")), .Names = c(""""conc"""", """"status""""), row.names = c(NA, -10L), class = """"data.frame"""")
</code></pre>

<p>I want to replace the concentration column with a string for some values of the flag column, or with the concentration value formatted to a certain number of significant digits.</p>

<p>When I try this</p>

<pre><code>ifelse(df$status==""""NR"""",""""NR"""",df$conc)
</code></pre>

<p>The NA's in the status flag don't trigger either the true or false condition (and return NA) - as the documentation suggests it will.  I could loop over the rows and use IF then else on each one but this seems inefficient.</p>

<p>Am I missing something ?  I've tried as.character(df$status) as well which doesn't work.  My mojo must be getting low....</p>
",1
"<p>Are there any R packages for the calculation of Kendall's tau-b and tau-c, and their associated standard errors?  My searches on Google and Rseek have turned up nothing, but surely someone has implemented these in R.</p>
",1
"<p>I need to summarize a data frame by some variables, ignoring the others. This is sometimes referred to as collapsing. E.g. if I have a dataframe like this:  </p>

<pre><code>Widget Type Energy  
egg 1 20  
egg 2 30  
jap 3 50  
jap 1 60
</code></pre>

<p>Then collapsing by Widget, with Energy the dependent variable,   Energy~Widget, would yield  </p>

<pre><code>Widget Energy  
egg  25  
jap  55  
</code></pre>

<p>In Excel the closest functionality might be """"Pivot tables"""" and I've worked out how to do it in python ( <a href=""""http://alexholcombe.wordpress.com/2009/01/26/summarizing-data-by-combinations-of-variables-with-python/"""" rel=""""noreferrer"""">http://alexholcombe.wordpress.com/2009/01/26/summarizing-data-by-combinations-of-variables-with-python/</a>), and here's an example with R using doBy library to do something very related ( <a href=""""http://www.mail-archive.com/r-help@r-project.org/msg02643.html"""" rel=""""noreferrer"""">http://www.mail-archive.com/r-help@r-project.org/msg02643.html</a>), but is there an easy way to do the above?  And even better is there anything built into the ggplot2 library to create plots that collapse across some variables?</p>
",1
"<p>I would like to create, in a function, a boucle to create a data.frame with a variable number of columns.</p>

<p>WIth something like :</p>

<pre><code>a = c(""""a"""",""""b"""")
b = c(list(1,2,3), list(4,5,6))
data.frame(a,b)
</code></pre>

<p>I would like to get a data-frame like :</p>

<pre><code>a 1 2 3
b 4 5 6
</code></pre>

<p>Instead of I obtain :</p>

<pre><code>a  1  2  3  4  5  6
b  1  2  3  4  5  6
</code></pre>

<p>Thank you !</p>

<p>PS : I also try with rbind, but it's doesn't work...</p>
",1
"<p>I am looking for a function that will tell me, for a list of packages, which of them is up to date and which is not (I need it so to trace back an R crash).</p>

<p>Thanks,</p>

<p>Tal</p>
",1
"<p>I'm trying to write from a loop to a data frame in R, for example a loop like this></p>

<pre><code>for (i in 1:20) {
print(c(i+i,i*i,i/1))}
</code></pre>

<p>and to write each line of 3 values to a data frame with three columns, so that each iteration takes on a new row. I've tried using matrix, with ncol=3 and filled by rows, but only get the last item from the loop.</p>

<p>Thanks.</p>
",1
"<p>I am installing Matrix on a Linux x86_64 multicore system. I receive a message:</p>

<pre><code>Warning message:
In install.packages(""""Matrix"""", dependencies = TRUE) :
  package 'Matrix' is not available
</code></pre>

<p>Sure enough, there are not many details on package troubleshooting. It appears that Matrix is available for x86_64, but it's not available in any repository. How come?</p>
",1
"<p>I would like to plot y1 and y2 in the same plot.</p>

<pre><code>x  &lt;- seq(-2, 2, 0.05)
y1 &lt;- pnorm(x)
y2 &lt;- pnorm(x,1,1)
plot(x,y1,type=""""l"""",col=""""red"""")
plot(x,y2,type=""""l"""",col=""""green"""")
</code></pre>

<p>But when I do it like this, they are not plotted in the same plot together.</p>

<p>In Matlab one can do <code>hold on</code>, but does anyone know how to do this in R?</p>
",1
"<p>This is strange - I think?</p>

<pre><code>library(ggplot2)
tf &lt;- which(sapply(diamonds, is.factor))
diamonds.tf &lt;- diamonds[,tf]
</code></pre>

<p>So far so good. But next comes the trouble:</p>

<pre><code>pl.f &lt;- ggplot(diamonds.tf, aes(x=diamonds.tf[,i]))+
geom_bar()+
xlab(names(diamonds.tf[i]))

for (i in 1:ncol(diamonds.tf)) {
ggsave(paste(""""plot.f"""",i,"""".png"""",sep=""""""""), plot=pl.f, height=3.5, width=5.5)
}
</code></pre>

<p>This saves the plots in my working directory - but with the wrong x-label. I think this is strange since calling ggplot directly produces the right plot:</p>

<pre><code>i &lt;- 2
ggplot(diamonds, aes(x=diamonds[,i]))+geom_bar()+xlab(names(diamonds)[i])
</code></pre>

<p>I don't really know how to describe this as a fitting title - suggestions as to a more descriptive question-title is most welcome.</p>

<p>Thanks in advance</p>
",1
"<p>I'm using by() to evaluate a function by factors in my dataframe, but I need to use the results in a table form.</p>

<p>I've seen a use of as.data.frame.table to get a """"By"""" class object into a data frame, but I'm not sure if this only works when the number of factors employed in the by() function is the same as the length of the """"by"""" output. Using as.data.frame.table I get the following error</p>

<p>""""...arguments imply differing number of rows: 10, 33""""</p>

<p>Is there another way of doing this? 
Can tapply be used instead of by() to get a different output class?</p>

<p>btw, I'm using by() to convert my data into a frequency table and then regroup by standard bins</p>

<pre><code>BT_by &lt;- by(BT_H, BT_H$Tax_pp, function(BT_H) hist(rep.int(BT_H$Altitude, BT_H$Count), breaks = seq(0,6600,200), plot = FALSE)$counts)
</code></pre>

<p>Any help would be appreciated. </p>
",1
"<p>The default value of a parameter of my function contains a """"%"""". This seems to be a problem for roxygen, it produces a lot of warnings and R CMD check fails when trying to build latex documentation.</p>

<p>How can I make this function (and its documentation) work? Using %% or \% instead of % does not help.</p>

<pre><code>#' Test escape \% from in-source documentation (roxygen).
#'
#' What happens when parameters contain special latex characters? 
#'
#' @param x unsuspicious parameter 
#' @param format sprintf format string (default """"\%5.0f"""")
#'
#' @return formatted string
#' @export
#' @author Karsten Weinert
testroxy &lt;- function(x, format = """"%5.0f"""") {
  sprintf(format,x)
}
</code></pre>
",1
"<p>If you have 2 cross classifying variables you can use <code>rowSums</code> and <code>colSums</code> to produce margin totals on an <code>xtabs</code> output. But how can it be done if you have 3 classifying variables (ie margin totals in each sub table)?</p>
",1
"<p>In R, given a vector</p>

<pre><code>casp6 &lt;- c(0.9478638, 0.7477657, 0.9742675, 0.9008372, 0.4873001, 0.5097587, 0.6476510, 0.4552577, 0.5578296, 0.5728478, 0.1927945, 0.2624068, 0.2732615)
</code></pre>

<p>and a factor:</p>

<pre><code>trans.factor &lt;- factor (rep (c(""""t0"""", """"t12"""", """"t24"""", """"t72""""), c(4,3,3,3)))
</code></pre>

<p>I want to create a plot where the data points are grouped as defined by the factor. So the categories should be on the x-axis, values in the same category should have the same x coordinate.</p>

<p>Simply doing <code>plot(trans.factor, casp6)</code> does almost what I want, it produces a boxplot, but I want to see the individual data points.</p>
",1
"<p>Suppose I have a dataframe like this one:</p>

<pre><code>df &lt;- data.frame (id = c(""""a"""", """"b"""", """"a"""", """"c"""", """"e"""", """"d"""", """"e""""), n=1:7)
</code></pre>

<p>and a vector with ids like this one:</p>

<pre><code>v &lt;- c(""""a"""", """"b"""")
</code></pre>

<p>How can I select the rows of the dataframe that match the ids in v? I can't use the id column for rownames because they are not unique. When I try that, I get:</p>

<pre><code> rownames(df) &lt;- df[[""""id""""]]
Error in `row.names&lt;-.data.frame`(`*tmp*`, value = c(1L, 2L, 1L, 3L, 5L,  : 
  duplicate 'row.names' are not allowed
In addition: Warning message:
non-unique values when setting 'row.names': a, e 
</code></pre>
",1
"<p>Okay, I'm fairly new to R and I've tried to search the documentation for what I need to do but here is the problem.</p>

<p>I have a data.frame called heeds.data in the following form (some columns omitted for simplicity)
eval.num, eval.count, ... fitness, fitness.mean, green.h.0, green.v.0, offset.0, green.h.1, green.v.1,...green.h.7, green.v.7, offset.7...</p>

<p>And I have selected a row meeting the following criteria:</p>

<pre><code>best.fitness &lt;- min(heeds.data$fitness.mean[heeds.data$eval.count &gt;= 10])
best.row &lt;- heeds.data[heeds.data$fitness.mean == best.fitness]
</code></pre>

<p>Now, what I want are all of the other rows with that have columns green.h.0 to offset.7 (a contiguous section of columns) equal to the best.row</p>

<p>I was thinking this might work</p>

<pre><code>heeds.best &lt;- heeds.data$fitness[
  heeds.data$green.h.0 == best.row$green.h.0 &amp; ...
]
</code></pre>

<p>But with 24 columns it seems like a stupid method.  Looking for something a bit simpler with less manual typing.</p>

<p>Here is a short data sample to show what I want</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0
1         1           1500     1500          100        120        40
2         2           1000     1250          100        120        40
3         3           1250     1250          100        120        40
4         4           1000     1187.5        100        120        40
5         1           2000     2000          200        100        40
6         1           3000     3000          150        90         10
7         1           2000     2000          90         90         100
8         2           1800     1900          90         90         100
</code></pre>

<p>Should select the """"best"""" as row 4
Then I want to grab the results as follows</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0
1         1           1500     1500          100        120        40
2         2           1000     1250          100        120        40
3         3           1250     1250          100        120        40
4         4           1000     1187.5        100        120        40
</code></pre>

<p>Data isn't actually sorted and there are many more columns but that is the concept</p>

<p>Thanks!</p>
",1
"<p>I'm not sure how to do this without getting an error.  Here is a simplified example of my problem.</p>

<p>Say I have this data frame DF</p>

<pre><code>a   b  c  d
1   2  3  4
2   3  4  5
3   4  5  6
</code></pre>

<p>Then I have a variable</p>

<pre><code>x &lt;- min(c(1,2,3))
</code></pre>

<p>Now I want do do the following</p>

<pre><code>y &lt;- DF[a == x]
</code></pre>

<p>But when I try to refer to some variable like """"x"""" I get an error because R is looking for a column """"x"""" in my data frame. I get the """"undefined columns selected"""" error</p>

<p>How can I do what I am trying to do in R?</p>
",1
"<p>I have data in the following format called DF (this is just a made up simplified sample):</p>

<pre><code>eval.num, eval.count, fitness, fitness.mean, green.h.0, green.v.0, offset.0 random
1         1           1500     1500          100        120        40       232342
2         2           1000     1250          100        120        40       11843
3         3           1250     1250          100        120        40       981340234
4         4           1000     1187.5        100        120        40       4363453
5         1           2000     2000          200        100        40       345902
6         1           3000     3000          150        90         10       943
7         1           2000     2000          90         90         100      9304358
8         2           1800     1900          90         90         100      284333
</code></pre>

<p>However, the eval.count column is incorrect and I need to fix it.  It should report the number of rows with the same values for (green.h.0, green.v.0, and offset.0) by only looking at the previous rows.</p>

<p>The example above uses the expected values, but assume they are incorrect.</p>

<p>How can I add a new column (say """"count"""") which will count all previous rows which have the same values of the specified variables?</p>

<p>I have gotten help on a similar problem of just selecting all rows with the same values for specified columns, so I supposed I <em>could</em> just write a loop around that, but it seems inefficient to me.</p>
",1
"<p>I am using Python 3.1.1 on Mac OS X 10.6.2 and need an interface to R. When browsing the internet I found out about RPy. Is this the right choice? </p>

<p>Currently, a program in Python computes a distance matrix and, stores it in a file. I invoke R separately in an interactive way and read in the matrix for cluster analysis. In order to
simplify computation one could prepare a script file for R then call it from Python and read back the results. Since I am new to Python, I would not like to go back to 2.6. </p>
",1
"<p>I need to use a function on a vector that does not take a ts object. I'm trying to convert it to a plain old vector but I just can't seem to figure it out. I googled around but mostly people are trying to convert data types into ts object. I want to go the other way. Any help would be appreciated. </p>
",1
"<p>I've been using R v2.8.1 for a long time. Normally I would upgrade it to the latest version but something keeps me away from the builds later than 2.8.1:</p>

<p>I use </p>

<p><code>read.table(file=file.choose(),header=TRUE)</code></p>

<p>frequently in my libraries. After upgrading to 2.9.0, R started not to remember the latest directory used while selecting file. I downgraded to 2.8.1 and now R can remember again the last directory used. I don't know why they changed that behavior in this direction but this is absolutely crucial for me. It wastes my time in v2.9.0 every time I try to find a specific directory when R cannot remember it. </p>

<p>Now R 2.10.1 is released. I don't know if they have corrected this issue. Should I upgrade or is it just enough to continue using v2.8.1? Will I miss something if I stick at 2.8.1?</p>
",1
"<p>I often have to make stacked barplots to compare variables, and because I do all my stats in R, I prefer to do all my graphics in R with ggplot2. I would like to learn how to do two things:</p>

<p>First, I would like to be able to add proper percentage tick marks for each variable rather than tick marks by count. Counts would be confusing, which is why I take out the axis labels completely.</p>

<p>Second, there must be a simpler way to reorganize my data to make this happen. It seems like the sort of thing I should be able to do natively in ggplot2 with plyR, but the documentation for plyR is not very clear (and I have read both the ggplot2 book and the online plyR documentation. </p>

<p>My best graph looks like this, the code to create it follows:</p>

<p><img src=""""https://farm5.static.flickr.com/4016/4493625638_bb46924571_d.jpg"""" alt=""""example graph""""></p>

<p>The R code I use to get it is the following:</p>

<pre><code>library(epicalc)  

### recode the variables to factors ###
recode(c(int_newcoun, int_newneigh, int_neweur, int_newusa, int_neweco, int_newit, int_newen, int_newsp, int_newhr, int_newlit, int_newent, int_newrel, int_newhth, int_bapo, int_wopo, int_eupo, int_educ), c(1,2,3,4,5,6,7,8,9, NA), 
c('Very Interested','Somewhat Interested','Not Very Interested','Not At All interested',NA,NA,NA,NA,NA,NA))

### Combine recoded variables to a common vector
Interest1&lt;-c(int_newcoun, int_newneigh, int_neweur, int_newusa, int_neweco, int_newit, int_newen, int_newsp, int_newhr, int_newlit, int_newent, int_newrel, int_newhth, int_bapo, int_wopo, int_eupo, int_educ)


### Create a second vector to label the first vector by original variable ###  
a1&lt;-rep(""""News about Bangladesh"""", length(int_newcoun))
a2&lt;-rep(""""Neighboring Countries"""", length(int_newneigh))
[...]
a17&lt;-rep(""""Education"""", length(int_educ))


Interest2&lt;-c(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15, a16, a17)

### Create a Weighting vector of the proper length ###
Interest.weight&lt;-rep(weight, 17)

### Make and save a new data frame from the three vectors ###
Interest.df&lt;-cbind(Interest1, Interest2, Interest.weight)
Interest.df&lt;-as.data.frame(Interest.df)

write.csv(Interest.df, 'C:\\Documents and Settings\\[name]\\Desktop\\Sweave\\InterestBangladesh.csv')

### Sort the factor levels to display properly ###

Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Not Very Interested')
Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Somewhat Interested')
Interest.df$Interest1&lt;-relevel(Interest$Interest1, ref='Very Interested')

Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='News about Bangladesh')
Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='Education')
[...]
Interest.df$Interest2&lt;-relevel(Interest$Interest2, ref='European Politics')

detach(Interest)
attach(Interest)

### Finally create the graph in ggplot2 ###

library(ggplot2)
p&lt;-ggplot(Interest, aes(Interest2, ..count..))
p&lt;-p+geom_bar((aes(weight=Interest.weight, fill=Interest1)))
p&lt;-p+coord_flip()
p&lt;-p+scale_y_continuous("""""""", breaks=NA)
p&lt;-p+scale_fill_manual(value = rev(brewer.pal(5, """"Purples"""")))
p
update_labels(p, list(fill='', x='', y=''))
</code></pre>

<p>I'd very much appreciate any tips, tricks or hints. </p>
",1
"<p>In R, the <code>plot()</code> function takes a <code>pch</code> argument that controls the appearance of the points in the plot.  I'm making scatterplots with tens of thousands of points and prefer a small, but not too small dot.  Basically, I find <code>pch='.'</code> to be too small, but <code>pch=19</code> to be too fat.  Is there something in the middle or some way to scale the dots down somehow?</p>
",1
"<p>I have this data frame:</p>

<pre><code>structure(list(month_num = 1:24, founded_month = c(4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 1L, 2L, 3L), founded_year = c(2008L, 2008L, 2008L, 
2008L, 2008L, 2008L, 2008L, 2008L, 2008L, 2009L, 2009L, 2009L, 
2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 2009L, 
2010L, 2010L, 2010L), count = c(270L, 222L, 256L, 250L, 277L, 
268L, 246L, 214L, 167L, 408L, 201L, 225L, 203L, 220L, 230L, 225L, 
177L, 207L, 166L, 135L, 116L, 122L, 69L, 42L), month_abb = c(""""Apr"""", 
""""May"""", """"Jun"""", """"Jul"""", """"Aug"""", """"Sep"""", """"Oct"""", """"Nov"""", """"Dec"""", """"Jan"""", 
""""Feb"""", """"Mar"""", """"Apr"""", """"May"""", """"Jun"""", """"Jul"""", """"Aug"""", """"Sep"""", """"Oct"""", 
""""Nov"""", """"Dec"""", """"Jan"""", """"Feb"""", """"Mar""""), short_year = c(""""08"""", """"08"""", 
""""08"""", """"08"""", """"08"""", """"08"""", """"08"""", """"08"""", """"08"""", """"09"""", """"09"""", """"09"""", """"09"""", 
""""09"""", """"09"""", """"09"""", """"09"""", """"09"""", """"09"""", """"09"""", """"09"""", """"10"""", """"10"""", """"10""""
), proj = c(282, 246, 292, 298, 337, 340, 330, 310, 275, 528, 
333, 369, 359, 388, 410, 417, 381, 423, 394, 375, 368, 386, 345, 
330), label = c(""""Apr"""", """"May"""", """"Jun"""", """"Jul"""", """"Aug"""", """"Sep"""", """"Oct"""", 
""""Nov"""", """"Dec"""", """"Jan\n09"""", """"Feb"""", """"Mar"""", """"Apr"""", """"May"""", """"Jun"""", """"Jul"""", 
""""Aug"""", """"Sep"""", """"Oct"""", """"Nov"""", """"Dec"""", """"Jan\n10"""", """"Feb"""", """"Mar"""")), .Names = c(""""month_num"""", 
""""founded_month"""", """"founded_year"""", """"count"""", """"month_abb"""", """"short_year"""", 
""""proj"""", """"label""""), row.names = c(NA, -24L), class = """"data.frame"""")
</code></pre>

<p>and i've got all of this done (I know the code's a bit ugly looking, pointers appreciated):</p>

<pre><code>p &lt;- ggplot(m_summary2, aes(x = month_num, y = count))
p + 
geom_line(colour = rgb(0/255, 172/255, 0/255)) + geom_point(colour = rgb(0/255, 172/255,          
    0/255)) + 
geom_line(aes(x = m_summary2$month_num, y = m_summary2$proj), 
    colour = rgb(18/255, 111/255, 150/255)) + 
geom_point(aes(x = m_summary2$month_num, y = m_summary2$proj), colour = rgb(18/255,   
    111/255, 150/255)) +     
scale_x_continuous(""""Month"""", breaks = m_summary2$month_num, labels = m_summary2$label) + 
scale_y_continuous(""""# Startups Founded"""") + 
opts(title = paste(""""# Startups Founded:"""", m_summary2$month_abb[1], 
    m_summary2$short_year[1], """"-"""", m_summary2$month_abb[nrow(m_summary2)],  
    m_summary2$short_year[nrow(m_summary2)]))
</code></pre>

<p>Now I would like to add a legend to clarify that the blue line is a projection and the green line is the current data. I would like to make the changes without altering the dataframe if possible.</p>

<p>Thanks in advance!</p>
",1
"<p>In batch script, I can run an R script with the following syntax:</p>

<pre><code>Rterm.exe --quiet --slave --vanilla &lt; """"C:\some_script.R""""
</code></pre>

<p>However, Powershell seems to have reserved """"&lt;"""" for future expansion. I am wondering if there is a direct way to run R script within another Powershell script. </p>
",1
"<p>I have a data frame in R that has come about from running some stats on the result of a melt/cast operation.  I want to add a row into this dataframe containing a Nominal value.  That Nominal Value is present in the names for each column</p>

<pre><code>df&lt;-as.data.frame(cbind(x=c(1,2,3,4,5),`Var A_100`=c(5,4,3,2,1),`Var B_5`=c(9,8,7,6,5)))
&gt; df
  x Var A_100 Var B_5
1 1         5       9
2 2         4       8
3 3         3       7
4 4         2       6
5 5         1       5
</code></pre>

<p>So, I want to create a new row, that contains '100' in the column Var A_100 and '5' in Var B_5.  Currently this is what I'm doing but I'm sure there must be a better, vectorised way to do this.</p>

<pre><code>temp_nom&lt;-NULL
for (l in 1:length(names(df))){
 temp_nom[l]&lt;-strsplit(names(df),""""_"""")[[l]][2]
 }
temp_nom
[1] NA    """"100"""" """"5""""  
df[6,]&lt;-temp_nom
&gt; df
     x Var A_100 Var B_5
1    1         5       9
2    2         4       8
3    3         3       7
4    4         2       6
5    5         1       5
6 &lt;NA&gt;       100       5
rm(temp_nom)
</code></pre>

<p>Typically I'd have 16-24 columns. Any ideas?</p>
",1
"<p>(second question today - must be a bad day)</p>

<p>I have a dataframe with various columns, inculding a concentration column (numeric), a flag highlighting invalid results (boolean) and a description of the problem (character)</p>

<pre><code>df &lt;- structure(list(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), rawconc = c(77.4, 
52.6, 86.5, 44.5, 167, 16.2, 59.3, 123, 1.95, 181), reason = structure(c(NA, 
NA, 2L, NA, NA, NA, 2L, 1L, NA, NA), .Label = c(""""Fails Acceptance Criteria"""", 
""""Poor Injection""""), class = """"factor""""), flag = c(""""False"""", """"False"""", 
""""True"""", """"False"""", """"False"""", """"False"""", """"True"""", """"True"""", """"False"""", """"False""""
)), .Names = c(""""x"""", """"rawconc"""", """"reason"""", """"flag""""), row.names = c(NA, 
-10L), class = """"data.frame"""")
</code></pre>

<p>I can create a column with the numeric level of the reason column</p>

<pre><code>df$level&lt;-as.numeric(df$reason)
df
    x rawconc                    reason  flag level
1   1   77.40                      &lt;NA&gt; False    NA
2   2   52.60                      &lt;NA&gt; False    NA
3   3   86.50            Poor Injection  True     2
4   4   44.50                      &lt;NA&gt; False    NA
5   5  167.00                      &lt;NA&gt; False    NA
6   6   16.20                      &lt;NA&gt; False    NA
7   7   59.30            Poor Injection  True     2
8   8  123.00 Fails Acceptance Criteria  True     1
9   9    1.95                      &lt;NA&gt; False    NA
10 10  181.00                      &lt;NA&gt; False    NA
</code></pre>

<p>and here's what I want to do to create a column with 'level' many stars, but it fails</p>

<pre><code>df$stars&lt;-paste(rep(""""*"""",df$level)sep="""""""",collapse="""""""")
Error: unexpected symbol in """"df$stars&lt;-paste(rep(""""*"""",df$level)sep""""

df$stars&lt;-paste(rep(""""*"""",df$level),sep="""""""",collapse="""""""")
Error in rep(""""*"""", df$level) : invalid 'times' argument

rep(""""*"""",df$level)
Error in rep(""""*"""", df$level) : invalid 'times' argument

df$stars&lt;-paste(rep(""""*"""",pmax(df$level,0,na.rm=TRUE)),sep="""""""",collapse="""""""")
Error in rep(""""*"""", pmax(df$level, 0, na.rm = TRUE)) : 
  invalid 'times' argument
</code></pre>

<p>It seems that rep needs to be fed one value at a time.  I feel that this should be possible (and my gut says 'use lapply' but my apply fu is v. poor)</p>

<p>Any one want to try ?</p>
",1
"<p>Is there any way, given a function passed as a parameter, to alter its input parameter string before evaluating it?  </p>

<p>Here's pseudo-code for what I'm hoping to achieve:</p>

<pre><code>test.func &lt;- function(a, b) {
    # here I want to alter the b expression before evaluating it:
    b(..., val1=a)
}
</code></pre>

<p>Given the function call passed to <code>b</code>, I want to add in <code>a</code> as another parameter without needing to always specify <code>...</code> in the <code>b</code> call.  So the output from this <code>test.func</code> call should be:</p>

<pre><code>test.func(a=""""a"""", b=paste(1, 2))
""""1""""  """"2""""  """"a""""
</code></pre>

<p><em>Edit</em>: </p>

<p>Another way I could see doing something like this would be if I could assign the additional parameter within the scope of the parent function (again, as pseudo-code); in this case <code>a</code> would be within the scope of t1 and hence t2, but not globally assigned:</p>

<pre><code>t2 &lt;- function(...) {
  paste(a=a, ...)
}

t1 &lt;- function(a, b) {
  local( { a &lt;&lt;- a; b } )
}

t1(a=""""a"""", b=t2(1, 2))
</code></pre>

<p>This is somewhat akin to currying in that I'm nesting the parameter within the function itself.</p>

<p><em>Edit 2</em>:</p>

<p>Just to add one more comment to this: I realize that one related approach could be to use """"<a href=""""http://en.wikipedia.org/wiki/Prototype-based_programming"""" rel=""""nofollow noreferrer"""">prototype-based programming</a>"""" such that things would be inherited (which could be achieved with <a href=""""http://cran.r-project.org/web/packages/proto/index.html"""" rel=""""nofollow noreferrer"""">the proto package</a>).  But I was hoping for a easier way to simply alter the input parameters before evaluating in R.</p>
",1
"<p>I have an example function below that reads in a date as a string and returns it as a date object.  If it reads a string that it cannot convert to a date, it returns an error.</p>

<pre><code>testFunction &lt;- function (date_in) {
    return(as.Date(date_in))
    }

testFunction(""""2010-04-06"""")  # this works fine
testFunction(""""foo"""")  # this returns an error
</code></pre>

<p>Now, I want to use lapply and apply this function over a list of dates:</p>

<pre><code>dates1 = c(""""2010-04-06"""", """"2010-04-07"""", """"2010-04-08"""")
lapply(dates1, testFunction)  # this works fine
</code></pre>

<p>But if I want to apply the function over a list when one string in the middle of two good dates returns an error, what is the best way to deal with this?   </p>

<pre><code>dates2 = c(""""2010-04-06"""", """"foo"""", """"2010-04-08"""")
lapply(dates2, testFunction)
</code></pre>

<p>I presume that I want a try catch in there, but is there a way to catch the error for the """"foo"""" string whilst asking lapply to continue and read the third date?</p>
",1
"<p>I have a simple two vector dataframe (length=30) that looks something like this:  </p>

<pre><code>&gt; mDF
    Param1 w.IL.L
1   AuZgFw    0.5
2   AuZfFw      2
3   AuZgVw   74.3
4   AuZfVw  20.52
5   AuTgIL   80.9
6   AuTfIL  193.3
7   AuCgFL    0.2
8   ...
</code></pre>

<p>I'd like to use each of the rows to form 30 single value numeric vectors with the name of the vector taken from <code>mDF$Param1</code>, so that:  </p>

<pre><code>&gt; AuZgFw       
[1] 0.5     
</code></pre>

<p>etc  </p>

<p>I've tried melting and casting, but I suspect there may be an easier way? </p>
",1
"<p>I am trying:</p>

<pre><code>install.packages(""""RGoogleDocs"""", repos = """"http://www.omegahat.org/R"""")
</code></pre>

<p>As suggested <a href=""""https://stackoverflow.com/questions/1794318/rgoogledocs-and-now-rgoogledata"""">here</a>, but it doesn't work.</p>

<p>I ended up manually downloading the file from <a href=""""http://www.omegahat.org/R/bin/windows/contrib/R-2.9/"""" rel=""""nofollow noreferrer"""">here</a>.</p>

<p>What other ways are there for me to get to the file directly?</p>

<p>Thanks,
Tal</p>
",1
"<p>I have several .csv files with similar filenames except a numeric month (i.e. 03_data.csv, 04_data.csv, 05_data.csv, etc.) that I'd like to read into R.</p>

<p>I have two questions:</p>

<ul>
<li>Is there a function in R similar to
MATLAB's varname and assignin that
will let me create/declare a variable name
within a function or loop that will allow me to 
read the respective .csv file - i.e.
03_data.csv into 03_data data.frame,
etc.? I want to write a quick loop to
do this because the filenames are
similar.</li>
<li>As an alternative, is it better to
create one dataframe with the first
file and then append the rest using a
for loop? How would I do that?</li>
</ul>
",1
"<p>I just came a cross <a href=""""http://addictedtor.free.fr/graphiques/graphcode.php?graph=137"""" rel=""""nofollow noreferrer"""">this nice code</a> that makes this scatter matrix plot:</p>

<p><a href=""""http://addictedtor.free.fr/graphiques/graphiques/graph_137.png"""" rel=""""nofollow noreferrer"""">alt text http://addictedtor.free.fr/graphiques/graphiques/graph_137.png</a></p>

<p>And wanted to implement it to a likret scale variables (integers of 1 to 5) by making the dot's sizes/colors (in the lower triangle) differ according to how many options of that type occurs (like the effect the jitter might have given me).</p>

<p>Any idea on how to do this on the base plotting mechanism ?</p>

<p>Update:</p>

<p>I made the following function, but don't know how to have the scale of the dots always be """"good"""", what do you think ?</p>

<pre><code>panel.smooth2 &lt;- function (x, y, col = par(""""col""""), bg = NA, pch = par(""""pch""""), 
                    cex = 1, col.smooth = """"red"""", span = 2/3, iter = 3, ...) 
{
    require(reshape)
    z &lt;- merge(data.frame(x,y), melt(table(x ,y)),sort =F)$value
    z &lt;- z/ (4*max(z)) 

    symbols( x, y,  circles = z,#rep(0.1, length(x)), #sample(1:2, length(x), replace = T) ,
            inches=F, bg=""""blue"""", fg = bg, add = T)

    # points(x, y, pch = pch, col = col, bg = bg, cex = cex)
    ok &lt;- is.finite(x) &amp; is.finite(y)
    if (any(ok)) 
        lines(stats::lowess(x[ok], y[ok], f = span, iter = iter), 
            col = col.smooth, ...)
}



a1 &lt;- sample(1:5, 100, replace = T)
a2 &lt;- sample(1:5, 100, replace = T)
a3 &lt;- sample(1:5, 100, replace = T)
aa &lt;- data.frame(a1,a2,a3)


pairs(aa , lower.panel=panel.smooth2)
</code></pre>
",1
"<p>I have three vectors in an xts R object. Call them V1, V2, V3. After merging, the order of them left to right is V2, V3, V1. How do I re-arrange them so they read (from left to right) as V1, V2, V3?</p>
",1
"<p>If the factor variable is Climate, with 4 possible values: Tropical, Arid, Temperate, Snow, and a node in my <code>rpart</code> tree is labeled as """"Climate:ab"""", what is the split?</p>
",1
"<p>I've a question about using sqlSave. How does R map RODBC data in the data frame to the database table columns?</p>

<p>If I've a table with columns X and Y and a data frame with columns X and Y, RODBC puts X into X and Y into Y (I found out by trail-and-error). But can I explicitly tell R how to map data.frame columns to database table columns, like put A in X and B in Y.</p>

<p>I'm rather new to R and think the RODBC manual is a bit cryptic. Nor can I find an example on the internet.</p>
",1
"<p>i tried to find a built-in for geometric mean but couldn't.</p>

<p>(Obviously a built-in isn't going to save me any time while working in the shell, nor do i suspect there's any difference in accuracy; for scripts i try to use built-ins as often as possible, where the (cumulative) performance gain is often noticeable.</p>

<p>In case there isn't one (which i doubt is the case) here's mine. </p>

<pre><code>gm_mean = function(a){prod(a)^(1/length(a))}
</code></pre>
",1
"<p>Can you pass by reference with """"R"""" ?
for example, in the following code:</p>

<pre><code>setClass(""""MyClass"""",
    representation(
    name=""""character""""
    ))


instance1 &lt;-new(""""MyClass"""",name=""""Hello1"""")
instance2 &lt;-new(""""MyClass"""",name=""""Hello2"""")

array = c(instance1,instance2)

instance1
array

instance1@name=""""World!""""

instance1
array
</code></pre>

<p>the output is</p>

<pre><code>&gt; instance1
An object of class MyClass
Slot """"name"""":
[1] """"World!""""

&gt; array
[[1]]
An object of class MyClass
Slot """"name"""":
[1] """"Hello1""""


[[2]]
An object of class MyClass
Slot """"name"""":
[1] """"Hello2""""
</code></pre>

<p>but I wish it was</p>

<pre><code>&gt; instance1
An object of class MyClass
Slot """"name"""":
[1] """"World!""""

&gt; array
[[1]]
An object of class MyClass
Slot """"name"""":
[1] """"World!""""


[[2]]
An object of class MyClass
Slot """"name"""":
[1] """"Hello2""""
</code></pre>

<p>is it possible ?</p>

<p>Thanks</p>

<p>Pierre</p>
",1
"<p>I am using ESS in Windows XP. I have noticed that <code>shell.exec</code> is much slower with ESS than with RGui (the problem occurs when I try <code>help(ls)</code> for example, the help is displayed much faster in RGui, I tracked it down and it is due to <code>shell.exec</code>). Is there any reason for this? How can I fix it? My default browser is Firefox.</p>
",1
"<p>Here is some example data:</p>

<pre><code>data = data.frame(series = c(""""1a"""", """"1b"""", """"1e""""), reading = c(0.1, 0.4, 0.6))

&gt; data
  series reading
1     1a     0.1
2     1b     0.4
3     1e     0.6
</code></pre>

<p>Which I can pull out selective single rows using subset:</p>

<pre><code>&gt; subset (data, series == """"1a"""")
  series reading
1     1a     0.1
</code></pre>

<p>And pull out multiple rows using a logical OR</p>

<pre><code>&gt; subset (data, series == """"1a"""" | series  == """"1e"""")
  series reading
1     1a     0.1
3     1e     0.6
</code></pre>

<p>But if I have a long list of series expressions, this gets really annoying to input, so I'd prefer to define them in a better way, something like this: </p>

<pre><code>series_you_want = c(""""1a"""", """"1e"""")  (although even this sucks a little)
</code></pre>

<p>and be able to do something like this,  </p>

<pre><code>subset (data, series == series_you_want)
</code></pre>

<p>The above obviously fails, I'm just not sure what the best way to do this is? </p>
",1
"<p>I have a timeseries of samples in R:</p>

<pre><code>&gt; str(d)
 'data.frame': 5 obs. of  3 variables:
 $ date: POSIXct, format: """"2010-03-04 20:47:00"""" """"2010-03-04 21:47:00"""" ...
 $ x   : num  0 10 11 15.2 20
 $ y   : num  0 5 7.5 8.4 12.5
&gt; d
                 date    x    y
1 2010-03-04 20:47:00  0.0  0.0
2 2010-03-04 21:47:00 10.0  5.0
3 2010-03-04 22:47:00 11.0  7.5
4 2010-03-04 23:47:00 15.2  8.4
5 2010-03-05 00:47:00 20.0 12.5
</code></pre>

<p>In this example samples for x and y are taken every hour (but the time delta is not fix). 
The x and y values are always growing (like a milage counter in a car). I need the deltas,
how much was the growth in between, something like this:</p>

<pre><code>1 2010-03-04 20:47:00  0.0  0.0
2 2010-03-04 21:47:00 10.0  5.0
3 2010-03-04 22:47:00 1.0   2.5
4 2010-03-04 23:47:00 4.2   0.9
5 2010-03-05 00:47:00 4.8   4.1
</code></pre>

<p>And I also need the deltas per time (x and y delta, divided by the time - delta per hour)</p>

<p>How would I do this in R?</p>
",1
"<p>I have the following data set that I am trying to plot with ggplot2, it is a time series of three experiments A1, B1 and C1 and each experiment had three replicates.  </p>

<p>I am trying to add a stat which detects and removes outliers before returning a smoother (mean and variance?).  I have written my own outlier function (not shown) but I expect there is already a function to do this, I just have not found it.  </p>

<p>I've looked at stat_sum_df(""""median_hilow"""", geom = """"smooth"""") from some examples in the ggplot2 book, but I didn't understand the help doc from Hmisc to see if it removes outliers or not.  </p>

<p>Is there a function to remove outliers like this in ggplot, or where would I amend my code below to add my own function?</p>

<p>EDIT: I just saw this (<a href=""""https://stackoverflow.com/questions/1444306/how-to-use-outlier-tests-in-r-code"""">How to use Outlier Tests in R Code</a>) and notice that Hadley recommends using a robust method such as rlm.   I am plotting bacterial growth curves, so I don't think a linear model is best, but any advice on  other models or using or using robust models in this situation would be appreciated.</p>

<pre><code>library (ggplot2)  

data = data.frame (day = c(1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7,1,3,5,7), od = 
c(
0.1,1.0,0.5,0.7
,0.13,0.33,0.54,0.76
,0.1,0.35,0.54,0.73
,1.3,1.5,1.75,1.7
,1.3,1.3,1.0,1.6
,1.7,1.6,1.75,1.7
,2.1,2.3,2.5,2.7
,2.5,2.6,2.6,2.8
,2.3,2.5,2.8,3.8), 
series_id = c(
""""A1"""", """"A1"""", """"A1"""",""""A1"""",
""""A1"""", """"A1"""", """"A1"""",""""A1"""",
""""A1"""", """"A1"""", """"A1"""",""""A1"""",
""""B1"""", """"B1"""",""""B1"""", """"B1"""",
""""B1"""", """"B1"""",""""B1"""", """"B1"""",
""""B1"""", """"B1"""",""""B1"""", """"B1"""",
""""C1"""",""""C1"""", """"C1"""", """"C1"""",
""""C1"""",""""C1"""", """"C1"""", """"C1"""",
""""C1"""",""""C1"""", """"C1"""", """"C1""""),
replicate = c(
""""A1.1"""",""""A1.1"""",""""A1.1"""",""""A1.1"""",
""""A1.2"""",""""A1.2"""",""""A1.2"""",""""A1.2"""",
""""A1.3"""",""""A1.3"""",""""A1.3"""",""""A1.3"""",
""""B1.1"""",""""B1.1"""",""""B1.1"""",""""B1.1"""",
""""B1.2"""",""""B1.2"""",""""B1.2"""",""""B1.2"""",
""""B1.3"""",""""B1.3"""",""""B1.3"""",""""B1.3"""",
""""C1.1"""",""""C1.1"""",""""C1.1"""",""""C1.1"""",
""""C1.2"""",""""C1.2"""",""""C1.2"""",""""C1.2"""",
""""C1.3"""",""""C1.3"""",""""C1.3"""",""""C1.3""""))

&gt; data
   day   od series_id replicate
1    1 0.10        A1      A1.1
2    3 1.00        A1      A1.1
3    5 0.50        A1      A1.1
4    7 0.70        A1      A1.1
5    1 0.13        A1      A1.2
6    3 0.33        A1      A1.2
7    5 0.54        A1      A1.2
8    7 0.76        A1      A1.2
9    1 0.10        A1      A1.3
10   3 0.35        A1      A1.3
11   5 0.54        A1      A1.3
12   7 0.73        A1      A1.3
13   1 1.30        B1      B1.1
... etc...
</code></pre>

<p>This is what I have so far and is working nicely, but outliers are not removed:</p>

<pre><code>r &lt;- ggplot(data = data, aes(x = day, y = od))
r + geom_point(aes(group = replicate, color = series_id)) + # add points
   geom_line(aes(group = replicate, color = series_id)) + # add lines
   geom_smooth(aes(group = series_id))  # add smoother, average of each replicate
</code></pre>

<p>EDIT: I just added two charts below showing examples of the outlier problems that I'm having from the real data rather than the example data above.</p>

<p>The first plots shows series p26s4 and around day 32 something really weird went on in two of the replicates, showing 2 outliers.</p>

<p>The second plots shows series p22s5 and on day 18, something weird went on with the reading that day, likely machine error I think.</p>

<p>At the moment I am eye-balling the data, to check that the growth curves look OK.  After taking Hadley's advice and setting family = """"symmetric"""", I am confident that the loess smoother does a decent job of ignoring the outliers.</p>

<p><a href=""""http://img696.imageshack.us/img696/8743/p26s4loess.png"""" rel=""""nofollow noreferrer"""">p26s4 shows around day 32 something really weird went on in two of the replicates, showing 2 outliers http://img696.imageshack.us/img696/8743/p26s4loess.png</a>
<a href=""""http://img521.imageshack.us/img521/8083/p22s5loess.png"""" rel=""""nofollow noreferrer"""">p22s5 shows that on day 18, something weird went on with the reading that day, likely machine error I think http://img521.imageshack.us/img521/8083/p22s5loess.png</a></p>

<p>@Peter/@hadley, the next thing I'd like to do is to try and fit a logistic, gompertz or richard's growth curve to this data instead of a loess and calculate the growth rate in the exponential stage.  Eventually I plan to use the grofit package in R (<a href=""""http://cran.r-project.org/web/packages/grofit/index.html"""" rel=""""nofollow noreferrer"""">http://cran.r-project.org/web/packages/grofit/index.html</a>), but for now I'd like to plot these manually using ggplot2 if possible.  If you have any pointers then it would be much appreciated.</p>
",1
"<p>As you would expect from a DSL aimed at data analysis, R handles missing/incomplete data very well, for instance:</p>

<p>Many R functions have an <strong><em>na.rm</em></strong> flag that when set to <em>TRUE</em>, remove the NAs:</p>

<pre><code>&gt;&gt;&gt; v = mean( c(5, NA, 6, 12, NA, 87, 9, NA, 43, 67), na.rm=T)
&gt;&gt;&gt; v
      (5, 6, 12, 87, 9, 43, 67)
</code></pre>

<p>But if you want to deal with NAs <em>before</em> the function call, you need to do something like this:</p>

<p>to remove each 'NA' from a vector:</p>

<pre><code>vx = vx[!is.na(a)]
</code></pre>

<p>to remove each 'NA' from a vector and replace it w/ a '0':</p>

<pre><code>ifelse(is.na(vx), 0, vx)
</code></pre>

<p>to remove entire each row that contains 'NA' from a data frame:</p>

<pre><code>dfx = dfx[complete.cases(dfx),]
</code></pre>

<p>All of these functions permanently <em>remove</em> 'NA' or rows with an 'NA' in them.</p>

<p>Sometimes this isn't quite what you want though--making an 'NA'-excised copy of the data frame might be necessary for the next step in the workflow but in subsequent steps you often want those rows back (e.g., to calculate a column-wise statistic for a column that has missing rows caused by a prior call to 'complete cases' yet that column has no 'NA' values in it).</p>

<p>to be as clear as possible about what i'm looking for: python/numpy has a class, <em>masked array</em>, with a <em>mask</em> method, which lets you <strong>conceal</strong>--but not remove--NAs during a function call. Is there an analogous function in R?</p>
",1
"<p>Suppose that I have a data frame with a column whose name is stored in a variable. Accessing this column using the variable is easy using bracket notation:</p>

<pre><code>df &lt;- data.frame(A = rep(1, 10), B = rep(2, 10))
column.name &lt;- 'B'

df[,column.name]
</code></pre>

<p>But it is not obvious how to access an arbitrary column using a call to <code>with()</code>. The naive approach</p>

<pre><code>with(df, column.name)
</code></pre>

<p>effectively evaluates <code>column.name</code> in the caller's environment. How can I delay evaluation sufficiently that <code>with()</code> will provide the same results that brackets give?</p>
",1
"<p>I am interested in analyzing balance sheets and income statements using R. I have seen that there are R packages that pull information from Yahoo and Google Finance, but all the examples I have seen concern historical stock price information. Is there a way I can pull historical information from balance sheets and income statements using R?</p>
",1
"<p>This is a """"big"""" question, that I don't know how to start, so I hope some of you can give me a direction.  And if this is not a """"good"""" question, I will close the thread with an apology.</p>

<p>I wish to go through the database of Wikipedia (let's say the English one), and do statistics.  For example, I am interested in how many active editors (which should be defined) Wikipedia had at each point of time (let's say in the last 2 years).</p>

<p>I don't know how to build such a database, how to access it, how to know which types of data it has and so on.  So my questions are:</p>

<ol>
<li>What tools do I need for this (besides basic R) ? MySQL on my computer? RODBC database connection?</li>
<li>How do you start planning for such a project?</li>
</ol>
",1
"<p>The <code>install.packages()</code> function in R is the automatic unzipping utility that gets and install packages in R.</p>

<ol>
<li><p>How do I find out what directory R has chosen to store packages?</p></li>
<li><p>How can I change the directory in which R stores and accesses packages?</p></li>
</ol>
",1
"<p>I've got a data frame in R, and I'd like to perform a calculation on all pairs of rows. Is there a simpler way to do this than using a nested for loop?</p>

<p>To make this concrete, consider a data frame with ten rows, and I want to calculate the difference of scores between all (45) possible pairs. </p>

<pre><code>&gt; data.frame(ID=1:10,Score=4*10:1)
   ID Score
1   1    40
2   2    36
3   3    32
4   4    28
5   5    24
6   6    20
7   7    16
8   8    12
9   9     8
10 10     4
</code></pre>

<p>I know I could do this calculation with a nested for loop, but is there a better (more R-ish) way to do it? </p>
",1
"<p>Is there a way to import data from a JSON file into R? More specifically, the file is an array of JSON objects with string fields, objects, and arrays. The RJSON Package isn't very clear on how to deal with this <a href=""""http://cran.r-project.org/web/packages/rjson/rjson.pdf"""" rel=""""noreferrer"""">http://cran.r-project.org/web/packages/rjson/rjson.pdf</a>.</p>
",1
"<p>I am trying to make a faceted plot in ggplot2 of the coefficients on the regressors from 
two linear models with the same predictors. The data frame I constructed is this:  </p>

<pre><code>r.together&gt;
          reg         coef        se      y
1  (Intercept)  5.068608671 0.6990873 Labels
2     goodTRUE  0.310575129 0.5228815 Labels
3    indiaTRUE -1.196868662 0.5192330 Labels
4    moneyTRUE -0.586451273 0.6011257 Labels
5     maleTRUE -0.157618168 0.5332040 Labels
6  (Intercept)  4.225580743 0.6010509  Bonus
7     goodTRUE  1.272760149 0.4524954  Bonus
8    indiaTRUE -0.829588862 0.4492838  Bonus
9    moneyTRUE -0.003571476 0.5175601  Bonus
10    maleTRUE  0.977011737 0.4602726  Bonus
</code></pre>

<p>The """"y"""" column is a label for the model, reg are the regressors and coef and se are what you would think. </p>

<p>I want to plot:</p>

<pre><code>g &lt;- qplot(reg, coef, facets=.~y, data = r.together) + coord_flip() 
</code></pre>

<p>But when I try to display the plot, I get: </p>

<pre><code>&gt; print(g)
Error in names(df) &lt;- output : 
'names' attribute [2] must be the same length as the vector [1]
</code></pre>

<p>What's strange is that </p>

<pre><code>qplot(reg, coef, colour=y, data = r.together) + coord_flip()
</code></pre>

<p>plots as you would expect. </p>
",1
"<p>I have a data.frame in R that looks like this:</p>

<pre><code>      score    rms  template   aln_id       description
1  -261.410  4.951 2f22A.pdb  2F22A_1 S_00001_0000002_0
2  -231.987 21.813 1wb9A.pdb  1WB9A_4 S_00002_0000002_0
3  -263.722  4.903 2f22A.pdb  2F22A_3 S_00003_0000002_0
4  -269.681 17.732 1wbbA.pdb  1WBBA_6 S_00004_0000002_0
5  -258.621 19.098 1rxqA.pdb  1RXQA_3 S_00005_0000002_0
6  -246.805  6.889 1rxqA.pdb 1RXQA_15 S_00006_0000002_0
7  -281.300 16.262 1wbdA.pdb 1WBDA_11 S_00007_0000002_0
8  -271.666  4.193 2f22A.pdb  2F22A_2 S_00008_0000002_0
9  -277.964 13.066 1wb9A.pdb  1WB9A_5 S_00009_0000002_0
10 -261.024 17.153 1yy9A.pdb  1YY9A_2 S_00001_0000003_0
</code></pre>

<p>I can calculate summary statistics on the data.frame like this:</p>

<pre><code>&gt; tapply( d$score, d$template, mean )
1rxqA.pdb 1wb9A.pdb 1wbbA.pdb 1wbdA.pdb 1yy9A.pdb 2f22A.pdb 
-252.7130 -254.9755 -269.6810 -281.3000 -261.0240 -265.5993 
</code></pre>

<p>Is there an easy way that I coerce this output back into a data.frame? I'd like for it to have these two columns:</p>

<pre><code>d$template
mean
</code></pre>

<p>I love tapply, but right now I'm cutting and pasting the results from tapply into a text file and hacking it up a bit to get the summary statistics that I want with appropriate names. This feels very wrong, and I'd like to do something better!</p>
",1
"<p>I'm trying to create a stacked bar graph with variable coloring in each stacked bar; that is, one bar has say blue on top of red, the next one red on top of purple, etc. I also wanted to preserve the ability to stack graphs. Thank you so much guys.</p>

<p>Adam</p>
",1
"<p>Why is my legend faded in these examples below?  Notice how the colours in the legend are not as vivid as the colours in the plot:  </p>

<pre><code>library(ggplot2)
r &lt;- ggplot(data = diamonds, aes(x = carat, y = price, color = cut, group = cut))
r + geom_smooth() #(left)
r + geom_smooth(size = 2)  #(right)
</code></pre>

<p><a href=""""http://img64.imageshack.us/img64/1340/screenshot20100411at549.png"""" rel=""""nofollow noreferrer"""">alt text http://img64.imageshack.us/img64/1340/screenshot20100411at549.png</a></p>

<p>EDIT: added a close-up
<a href=""""http://img163.imageshack.us/img163/4715/screenshot20100411at725.png"""" rel=""""nofollow noreferrer"""">alt text http://img163.imageshack.us/img163/4715/screenshot20100411at725.png</a></p>
",1
"<pre><code>library(ggplot2)
</code></pre>

<p>This code produces a nice looking plot:</p>

<pre><code>qplot(cty, hwy, data = mpg, colour = displ) +
scale_y_log2() + 
labs(x=""""x axis"""") + 
labs(y=""""y axis"""") +
opts(title = """"my title"""")
</code></pre>

<p>But I want to setup variables to try and to reduce code repetition:</p>

<pre><code>log_scale &lt;- scale_y_log2()
xscale &lt;-   labs(x=""""x axis"""")
yscale &lt;-   labs(y=""""y axis"""") 
title &lt;- opts(title = """"my title"""")
my_scales &lt;- c(log_scale, xscale, yscale, title) 
# make a variable to hold the scale info changes above
</code></pre>

<p>So that I can do this and add a bunch of things at the same time: </p>

<pre><code>qplot(cty, hwy, data = mpg, colour = displ) + my_scales  
# add these to your plot.   
</code></pre>

<p>but I get this error: </p>

<pre><code>Error in object$class : $ operator is invalid for atomic vectors
</code></pre>

<p>I realize that the things going into my_scales need to be layers / different types of objects, but I don't see what they should be.</p>
",1
"<p>Is there a constant that stores the machine epsilon in R?</p>
",1
"<p>I'm using the """"by"""" function in R to chop up a data frame and apply a function to different parts, like this:</p>

<pre><code>pairwise.compare &lt;- function(x) {
Nright &lt;- ...
Nwrong &lt;- ...
Ntied &lt;- ...
return(c(Nright=Nright, Nwrong=Nwrong, Ntied=Ntied))
}
Z.by &lt;- by(rankings, INDICES=list(rankings$Rater, rankings$Class), FUN=pairwise.compare)
</code></pre>

<p>The result (Z.by) looks something like this:</p>

<pre><code>: 4 
: 357 
Nright Nwrong Ntied
     3      0     0
------------------------------------------------------------
: 8 
: 357 
NULL
------------------------------------------------------------
: 10 
: 470 
Nright Nwrong Ntied
     3      4     1 
------------------------------------------------------------ 
: 11 
: 470 
Nright Nwrong Ntied
    12      4     1
</code></pre>

<p>What I would like is to have this result converted into a data frame (with the NULL entries not present) so it looks like this:</p>

<pre><code>  Rater Class Nright Nwrong Ntied
1     4   357      3      0     0
2    10   470      3      4     1
3    11   470     12      4     1
</code></pre>

<p>How do I do that? </p>
",1
"<p>I have a nested loop that I'm using foreach, DoSNOW, and a SNOW socket cluster to solve for. How should I go about profiling the code to make sure I'm not doing something grossly inefficient.</p>

<p>Also is there anyway to measure the data flows going between the master and nodes in a Snow cluster?</p>

<p>Thanks,</p>

<p>James</p>
",1
"<p>Is <code>aov</code> appropriate for unbalanced datasets. According to help <code>...provides a wrapper to lm for fitting linear models to balanced or unbalanced experimental designs</code>. But later on it says <code>aov is designed for balanced designs, and the results can be hard to interpret without balance</code>.</p>

<p>How should I perform a 2-way anova on an unbalanced dataset in R? </p>

<p>I would like to reproduce the different results for type I and type III sum of squares of <code>SAS</code> output (when using <code>proc glm</code>). I remember we were using <code>type III sum of squares</code> for unbalanced datasets.</p>

<p>Thank you in advance.</p>
",1
"<p>I have a list (tmpList), which looks like this:</p>

<pre><code>$op
[1] """"empty""""

$termset
$termset$field
[1] """"entry""""

$termset[[2]]
$termset[[2]]$explode
[1] """"Y""""
</code></pre>

<p>This is a list with a list inside.
If I add this list to a vector</p>

<pre><code>theOneVector = c(theOneVector, tmpList)
</code></pre>

<p>Now the resulting vector is of the length 2, because the first entry (""""op"""") of the list is separated from the tmpList.
Is it possible to append the complete tmpList into this vector?
<br>
I already tried it with</p>

<pre><code>theOneVector = c(theOneVector, list(tmpList))
</code></pre>

<p>which gives a vector with the length of 1, but it is very cumbersome to access the elements of the list with this extra list around the list. (Too much list in one sentence I think.)<br></p>

<p></p>

<p>Any help would be appreciated,<br>
Martin</p>
",1
"<pre><code>df &lt;- data.frame(age=c(10,10,20,20,25,25,25),veg=c(0,1,0,1,1,0,1))
g=ggplot(data=df,aes(x=age,y=veg))
g=g+stat_summary(fun.y=mean,geom=""""point"""")
</code></pre>

<p>Points reflect mean of veg at each age, which is what I expected and want to preserve after changing axis limits with the command below.</p>

<pre><code>g=g+ylim(0.2,1)
</code></pre>

<p>Changing axis limits with the above command unfortunately causes veg==0 subset to be dropped from the data, yielding </p>

<blockquote>
  <p>""""Warning message: Removed 4 rows containing missing values (stat_summary)""""</p>
</blockquote>

<p>This is bad because now the data plot (stat_summary mean) omits the veg==0 points. How can this be prevented? I simply want to avoid showing the empty part of the plot- the ordinate from 0 to .2, but not drop the associated data from the stat_summary calculation.</p>
",1
"<p>I'm trying to collapse a data frame by removing all but one row from each group of rows with identical values in a particular column. In other words, the first row from each group.</p>

<p>For example, I'd like to convert this</p>

<pre><code>&gt; d = data.frame(x=c(1,1,2,4),y=c(10,11,12,13),z=c(20,19,18,17))
&gt; d
  x  y  z
1 1 10 20
2 1 11 19
3 2 12 18
4 4 13 17
</code></pre>

<p>Into this:</p>

<pre><code>    x  y  z
1   1 11 19
2   2 12 18
3   4 13 17
</code></pre>

<p>I'm using aggregate to do this currently, but the performance is unacceptable with more data:</p>

<pre><code>&gt; d.ordered = d[order(-d$y),]
&gt; aggregate(d.ordered,by=list(key=d.ordered$x),FUN=function(x){x[1]})
</code></pre>

<p>I've tried split/unsplit with the same function argument as here, but unsplit complains about duplicate row numbers.</p>

<p>Is rle a possibility? Is there an R idiom to convert rle's length vector into the indices of the rows that start each run, which I can then use to pluck those rows out of the data frame?</p>
",1
"<pre><code>&gt; D &lt;- read.csv(""""sample1.csv"""", header = FALSE, sep = """","""")

&gt; D
        V1     V2     V3     V4
1 20100316 109825 352120 239065
2 20100317 108625 352020 239000
3 20100318 109125 352324 241065

&gt; D[,1]
[1] 20100316 20100317 20100318
</code></pre>

<p>In the above example how do I get the data in <code>D[,1]</code> to be read, and stored as date values: 2010-03-16, 2010-03-17, 2010-03-18? I have lots of data files in this format.</p>

<p>TIA,</p>
",1
"<p>I just finished reading about <a href=""""http://cran.r-project.org/doc/manuals/R-intro.html#Scope"""" rel=""""noreferrer"""">scoping in the R intro</a>, and am very curious about the <code>&lt;&lt;-</code> assignment.</p>

<p>The manual showed one (very interesting) example for <code>&lt;&lt;-</code>, which I feel I understood. What I am still missing is the context of when this can be useful.</p>

<p>So what I would love to read from you are examples (or links to examples) on when the use of <code>&lt;&lt;-</code> can be interesting/useful.  What might be the dangers of using it (it looks easy to loose track of), and any tips you might feel like sharing.</p>
",1
"<p>I want to import the contents of a csv file into R, the csv file contains multiple sections of data vertically, seperated by blank lines and asterisks.  For example</p>

<pre><code>********************************************************
* SAMPLE DATA ******************************************
********************************************************
Name, DOB, Sex
Rod, 1/1/1970, M
Jane, 5/7/1980, F
Freddy, 9.12,1965, M

*******************************************************
*  Income Data ****************************************
*******************************************************
Name, Income
Rod, 10000
Jane, 15000
Freddy, 7500
</code></pre>

<p>I would like to import this into R as two seperate dataframes.  Currently I'm manually cutting the csv file up into smaller files, but I think I could do it using read.csv and the skip and nrows settings of read.csv, If I could work out where the secion breaks are.</p>

<p>This gives me a logical TRUE for every blank line</p>

<pre><code>ifelse(readLines(""""DATA.csv"""")=="""""""",TRUE,FALSE)
</code></pre>

<p>I'm hoping someone has already solved this problem.</p>
",1
"<p>EDIT: I have realized the source of my problem. I only have count information for the counties which I have data for, which is less than the number of counties in the area I'm plotting against.</p>

<p>It stands to reason that the problem lines of code are here:</p>

<pre><code>mapnames &lt;- map(""""county"""",plot=FALSE)[4]$names
colorsmatched &lt;- d$colorBuckets [na.omit(match(mapnames ,d$stcon))]
</code></pre>

<p>Does anyone have advice on how to generate a vector of the appropriate length that would match the # of counties in NY, NJ, CT, and PA from the maps library? I want to merge the count data I have and include zeros for the counties I don't have information on.</p>

<p>I am trying to follow the tutorial described here: <a href=""""http://www.thisisthegreenroom.com/2009/choropleths-in-r/"""" rel=""""nofollow noreferrer"""">http://www.thisisthegreenroom.com/2009/choropleths-in-r/</a></p>

<p>The below code executes, but it is either not matching my dataset with the maps_counties data properly, or it isn't plotting it in the order I would expect. For example, the resulting areas for the greater NYC area show no density while random counties in PA show the highest density.</p>

<p>The general format of my data table is:</p>

<pre><code>county state count
fairfield connecticut 17
hartford connecticut 6
litchfield connecticut 3
new haven connecticut 12
...
...
westchester new york 70
yates new york 1
luzerne pennsylvania 1
</code></pre>

<p>Note this data is in order by state and then county and includes data for CT, NJ, NY, &amp; PA. </p>

<p>First, I read in my data set:</p>

<pre><code>library(maps)
library(RColorBrewer)
d &lt;- read.table(""""gissum.txt"""", sep=""""\t"""", header=TRUE)

#Concatenate state and county info to match maps library
d$stcon &lt;- paste(d$state, d$county, sep="""","""")

#Color bins
colors = brewer.pal(5, """"PuBu"""")
d$colorBuckets &lt;- as.factor(as.numeric(cut(d$count,c(0,10,20,30,40,50,300))))
</code></pre>

<p>Here is my matching</p>

<pre><code>mapnames &lt;- map(""""county"""",plot=FALSE)[4]$names
colorsmatched &lt;- d$colorBuckets [na.omit(match(mapnames ,d$stcon))]
</code></pre>

<p>Plotting:</p>

<pre><code>map(""""county""""
  ,c(""""new york"""",""""new jersey"""", """"connecticut"""", """"pennsylvania"""")
  ,col = colors[d$colorBuckets[na.omit(match(mapnames ,d$stcon))]]
  ,fill = TRUE
  ,resolution = 0
  ,lty = 0
  ,lwd= 0.5
)
map(""""state""""
  ,c(""""new york"""",""""new jersey"""", """"connecticut"""", """"pennsylvania"""")
  ,col = """"black""""
  ,fill=FALSE
  ,add=TRUE
  ,lty=1
  ,lwd=2
)

map(""""county""""
   ,c(""""new york"""",""""new jersey"""", """"connecticut"""", """"pennsylvania"""")
   ,col = """"black""""
   ,fill=FALSE
   ,add=TRUE
  , lty=1
  , lwd=.5
)
title(main=""""Respondent Home ZIP Codes by County"""")
</code></pre>

<p>I am sure I am missing something basic re: the order in which the maps function plots items - but I can't seem to figure it out. Thanks for the help. Please let me know if you need any more information.</p>
",1
"<p>Given an <code>environment</code> object <code>e</code>:</p>

<pre><code>&gt; e
&lt;environment: 0x10f0a6e98&gt;
&gt; class(e)
[1] """"environment""""
</code></pre>

<p>How do you access the variables inside the environment?</p>

<p>Just in case you're curious, I have found myself with this <code>environment</code> object. I didn't make it, a package in Bioconductor made it. You can make it, too, using these commands:</p>

<pre><code>library('GEOquery')
eset &lt;- getGEO(""""GSE4142"""")[[1]]
e &lt;- assayData(eset)
</code></pre>
",1
"<p>Say I have a vector which has thousands of elements. What is the R code necessary if I want to make the elements at indices between 100-200 become 0?</p>

<p>Additionally how would I count the length between two different values, for example if I want  to know the length of time when the 'share price' is between 30-40?</p>
",1
"<p>I am trying to manipulate a conditional string outputted from SAS into the right format for a conditional statement in R.  Here is an example of the conditional outputted from SAS:</p>

<pre><code>. &lt; var1_a&lt;=80 and var2_a&gt;50.8
</code></pre>

<p>I've written a function that handles some of the transformation necessary:</p>

<pre><code>conditonalsub &lt;- function(x) {
subnew &lt;- gsub(""""&lt;="""", """" &lt;= """", x)
subnew &lt;- gsub(""""&gt;="""", """" &gt;= """", subnew)
subnew &lt;- gsub(""""&gt;"""", """" &gt; """", subnew)
subnew &lt;- gsub(""""and"""", """"&amp;"""", subnew)
subnew &lt;- gsub(""""\\.\\s"""", """"NA """", subnew)
return(subnew)
</code></pre>

<p>which produces the following string:</p>

<pre><code>NA &lt; var1_a &lt;= 80 &amp; var2_a &gt; 50.8
</code></pre>

<p>I am using these conditional statements to subset the observations of a data frame.  So in this example I want R to select all observations with var1_a values that are either missing or less than or equal to 80 AND have var2_a greater than 50.8.  How can I modify the above function so that I get a conditional statement that is able to take missing values like the var1_a portion of the conditional statement above?  My guess is the format of the new conditional statement would look something like this?</p>

<pre><code>(var1_a == NA | var1_a &lt;= 80) &amp; (var2_a &gt; 50.8) 
</code></pre>
",1
"<pre><code>library(ggplot2)

my_title = """"This is a really long title of a plot that I want to nicely wrap \n and fit onto the plot without having to manually add the backslash n, but at the moment it does not""""

r &lt;- ggplot(data = cars, aes(x = speed, y = dist))
r + geom_smooth() + #(left) 
opts(title = my_title)
</code></pre>

<p>can I set the plot title to wrap around and shrink the text to fit the plot?</p>
",1
"<p>I am reading, on my own (not for HW) about programming, and one exercise involved programming Pascal's triangle in R.  My first idea was to make a list and then append things to it, but that didn't work too well.  Then I thought of starting with a vector, and making a list out of that, at the end.  Then I thought of making a matrix, and making a list out of that at the end.</p>

<p>Not sure which way to even approach this.</p>

<p>Any hints?</p>

<p>thanks</p>
",1
"<p>I have a large data.frame displaying some weird properties when plotted.  I'd like to ask a question about it on Stackoverflow, to do that I'd like to write the data.frame out in a form that I can paste it into SO and somebody else can easily run it and have it back into a data.frame object again.  Is there an easy way to accomplish this?  Also, if it is really long, should I use paste bin instead of directly paste it here?</p>
",1
"<p>From hard experience I've found it useful to occasionally save the state of my long computations to disk to start them up later if something fails.  Can I do this in a distributed computation package in R (like SNOW or multicore)?<br>
It does not seem clear how this could be done since the master is collecting things from the slaves in a non-transparent way.</p>
",1
"<p>My question is about avoiding namespace pollution when writing modules in R.</p>

<p>Right now, in my R project, I have <code>functions1.R</code> with <code>doFoo()</code> and <code>doBar()</code>, <code>functions2.R</code> with other functions, and <code>main.R</code> with the main program in it, which first does <code>source('functions1.R'); source('functions2.R')</code>, and then calls the other functions.</p>

<p>I've been starting the program from the R GUI in Mac OS X, with <code>source('main.R')</code>.  This is fine the first time, but after that, the variables that were defined the first time through the program are defined for the second time <code>functions*.R</code> are sourced, and so the functions get a whole bunch of extra variables defined.</p>

<p>I don't want that!  I want an """"undefined variable"""" error when my function uses a variable it shouldn't!  Twice this has given me very late nights of debugging!</p>

<p>So how do other people deal with this sort of problem?  Is there something like <code>source()</code>, but that makes an independent namespace that doesn't fall through to the main one?  Making a package seems like one solution, but it seems like a big pain in the butt compared to e.g. Python, where a source file is automatically a separate namespace.</p>

<p>Any tips?  Thank you!</p>
",1
"<p>I am using ggplot2 to plot a figure that contains nine facets. Each facet represents the relationship between two variables and I would like to annotate the facets that display statistically significant results with a star '<em>'. This would result in only two of the nine facets with a '</em>'. However, I end up with all nine facets displaying the annotation.</p>

<p>How can I fix this?</p>

<pre><code>library(ggplot2)

Sig&lt;-c("""""""",""""*"""","""""""","""""""","""""""","""""""","""""""",""""*"""","""""""") # Only the second and the second to last facets should receive significance stars.
Data.annot&lt;-data.frame(unique(Aspects),Sig)

qplot(Labels,Es,data=Data1) + geom_pointrange(aes(x=Labels,y=Es,ymin=Low,ymax=Up)) + geom_hline(yintercept=0, linetype=""""dashed"""") + coord_flip() + facet_wrap(~Aspects, scales=""""free"""") + geom_text(data=Data.annot, aes(x= 0.5, y= 1, label = Sig)) + scale_y_continuous(""""Correlation coefficient\n(effect size)"""",limits=c(-0.5,1),breaks=c(-0.5,0,0.5,1.0)) + scale_x_discrete("""""""")
</code></pre>
",1
"<p>I am using R. I want to run <code>prcomp</code> on a matrix. The code works fine with one installation of R on a Linux box but breaks on another identical (or so I thought) installation of R on a different Linux box. The codes are</p>

<pre><code>dataf = read.table(""""~/data/testdata.txt"""")
pca = prcomp(dataf)
</code></pre>

<p>The error msg on the bad instance is</p>

<pre><code>&gt; dataf = read.table(""""~/data/testdata.txt"""")
&gt; pca = prcomp(dataf)
Error in La.svd(x, nu, nv) :
  BLAS/LAPACK routine 'DGESDD' gave error code -12
</code></pre>

<p>Both instances of R has <code>R version 2.9.2 (2009-08-24)</code> and, as far as I can tell, all the R libraries and environmental variables are configured in identical ways as well. </p>

<p>So does anyone have suggestions on what might be wrong? What does that error code mean? (I searched internet and found nothing helpful...) Thanks a lot in advance!</p>
",1
"<p>I'm interested in making a plot with a least squares regression line and line segments connecting the datapoints to the regression line as illustrated here in the graphic called perpendicular offsets:
<a href=""""http://mathworld.wolfram.com/LeastSquaresFitting.html"""" rel=""""noreferrer"""">http://mathworld.wolfram.com/LeastSquaresFitting.html</a>
<a href=""""http://mathworld.wolfram.com/images/eps-gif/LeastSquaresOffsets_1000.gif"""" rel=""""noreferrer"""">alt text http://mathworld.wolfram.com/images/eps-gif/LeastSquaresOffsets_1000.gif</a></p>

<p>I have the plot and regression line done here:</p>

<pre><code>## Dataset from http://www.apsnet.org/education/advancedplantpath/topics/RModules/doc1/04_Linear_regression.html

## Disease severity as a function of temperature

# Response variable, disease severity
diseasesev&lt;-c(1.9,3.1,3.3,4.8,5.3,6.1,6.4,7.6,9.8,12.4)

# Predictor variable, (Centigrade)
temperature&lt;-c(2,1,5,5,20,20,23,10,30,25)

## For convenience, the data may be formatted into a dataframe
severity &lt;- as.data.frame(cbind(diseasesev,temperature))

## Fit a linear model for the data and summarize the output from function lm()
severity.lm &lt;- lm(diseasesev~temperature,data=severity)

# Take a look at the data
plot(
 diseasesev~temperature,
        data=severity,
        xlab=""""Temperature"""",
        ylab=""""% Disease Severity"""",
        pch=16,
        pty=""""s"""",
        xlim=c(0,30),
        ylim=c(0,30)
)
abline(severity.lm,lty=1)
title(main=""""Graph of % Disease Severity vs Temperature"""")
</code></pre>

<p>Should I use some kind of for loop and segments <a href=""""http://www.iiap.res.in/astrostat/School07/R/html/graphics/html/segments.html"""" rel=""""noreferrer"""">http://www.iiap.res.in/astrostat/School07/R/html/graphics/html/segments.html</a> to do the perpendicular offsets?  Is there a more efficient way?  Please provide an example if possible.</p>
",1
"<p>I have switched to using emacs-ess for my R code development and it is working great. I would like to be able to write some small R code I am using for debugging my R script into the scratch buffer, and be able to execute the scratch buffer code in the R process buffer. I've found how I could change the scratch buffer's mode to text by putting the following in the .emacs file:</p>

<pre><code>(setq initial-major-mode 'text-mode)
</code></pre>

<p>Is there a similar statement I can put in my .emacs file that would make the scratch buffer have the ess-mode?  I tried the following which results in an error about wrong type argument:</p>

<pre><code>(setq initial-major-mode 'ess-mode)
</code></pre>
",1
"<p>I'm trying to write a function to accept a data.frame (<code>x</code>) and a <code>column</code> from it. The function performs some calculations on x and later returns another data.frame. I'm stuck on the best-practices method to pass the column name to the function.</p>

<p>The two minimal examples <code>fun1</code> and <code>fun2</code> below produce the desired result, being able to perform operations on <code>x$column</code>, using <code>max()</code> as an example. However, both rely on the seemingly (at least to me) inelegant </p>

<ol>
<li>call to <code>substitute()</code> and possibly <code>eval()</code> </li>
<li>the need to pass the column name as a character vector. </li>
</ol>

<p></p>

<pre><code>fun1 &lt;- function(x, column){
  do.call(""""max"""", list(substitute(x[a], list(a = column))))
}

fun2 &lt;- function(x, column){
  max(eval((substitute(x[a], list(a = column)))))
}

df &lt;- data.frame(B = rnorm(10))
fun1(df, """"B"""")
fun2(df, """"B"""")
</code></pre>

<p>I would like to be able to call the function as <code>fun(df, B)</code>, for example. Other options I have considered but have not tried:</p>

<ul>
<li>Pass <code>column</code> as an integer of the column number. I think this would avoid <code>substitute()</code>. Ideally, the function could accept either.</li>
<li><code>with(x, get(column))</code>, but, even if it works, I think this would still require <code>substitute</code> </li>
<li>Make use of <code>formula()</code> and <code>match.call()</code>, neither of which I have much experience with.</li>
</ul>

<p><em>Subquestion</em>: Is <code>do.call()</code> preferred over <code>eval()</code>?</p>
",1
"<p>I have a data frame in R that looks like this:</p>

<pre><code>&gt; TimeOffset, Source, Length 
&gt; 0         1           1500
&gt; 0.1       1           1000    
&gt; 0.2       1           50
&gt; 0.4       2           25
&gt; 0.6       2           3
&gt; 1.1       1           1500
&gt; 1.4       1           18
&gt; 1.6       2           2500
&gt; 1.9       2           18
&gt; 2.1       1           37
&gt; ...
</code></pre>

<p>and I want to convert it to</p>

<pre><code>&gt; TimeOffset, Source, Length
&gt; 0.2         1       2550
&gt; 0.6         2       28
&gt; 1.4         1       1518
&gt; 1.9         2       2518
&gt; ...
</code></pre>

<p>Trying to put this into English, I want to group consecutive records with the same 'Source' together, then printing out a single record per group showing the highest time offset in that group, the source, and the sum of the lengths in that group.</p>

<p>The TimeOffset values will always increase.</p>

<p>I suspect this is possible in R, but I really don't know where to start.  In a pinch I could export the data frame out and do it in e.g. Python, but I'd prefer to stay within R if possible.</p>

<p>Thanks in advance for any assistance you can provide</p>
",1
"<p>I have a numeric vector, it contains patches of elements that are repeating, something like:</p>

<pre><code>R&gt; data &lt;- c(1,1,1,2,2,2,3,3,2,2,2,2,2,3,3,1,1,1,1,1)
R&gt; data
 [1] 1 1 1 2 2 2 3 3 2 2 2 2 2 3 3 1 1 1 1 1
R&gt; 
</code></pre>

<p>I need to extract contiguous patches of elements equals to a specific value...  but I'm only interested in the patch around a specific position.  so, my input is: (1) the numeric vector, (2) the desired value, (3) the position.  I want to return a logic vector indicating which positions satisfy the request.</p>

<p>if at that position the data does not equal the value, I return all <code>FALSE</code>.</p>

<p>possible outcomes that are not all <code>F</code> would be:</p>

<pre><code> [1] 1 1 1 2 2 2 3 3 2 2 2 2 2 3 3 1 1 1 1 1

 [1] T T T F F F F F F F F F F F F F F F F F
 [2] F F F T T T F F F F F F F F F F F F F F
 [3] F F F F F F T T F F F F F F F F F F F F
 [4] F F F F F F F F T T T T T F F F F F F F
 [5] F F F F F F F F F F F F F T T F F F F F
 [6] F F F F F F F F F F F F F F F T T T T T
</code></pre>
",1
"<p>I'm having trouble with a data frame and couldn't really resolve that issue myself:<br>
The <b>dataframe</b> has arbitrary <b>properties as columns</b> and <b>each row</b> represents one <b>data set</b>.<p>
The question is:<br>
How to <b>get rid of columns where for <i>ALL</i> rows the value is NA</b>?</p>
",1
"<p>(I tried to ask this question earlier today, but later realised I over-simplified the question; the answers I received were correct, but I couldn't use them because of my over-simplification of the problem in the original question.  Here's my 2nd attempt...)</p>

<p>I have a data frame in R that looks like:</p>

<pre><code>""""Timestamp"""", """"Source"""", """"Target"""", """"Length"""", """"Content""""
0.1        , P1      , P2      , 5       , """"ABCDE""""
0.2        , P1      , P2      , 3       , """"HIJ""""
0.4        , P1      , P2      , 4       , """"PQRS""""
0.5        , P2      , P1      , 2       , """"ZY""""
0.9        , P2      , P1      , 4       , """"SRQP""""
1.1        , P1      , P2      , 1       , """"B""""
1.6        , P1      , P2      , 3       , """"DEF""""
2.0        , P2      , P1      , 3       , """"IJK""""
...
</code></pre>

<p>and I want to convert this to:</p>

<pre><code>""""StartTime"""", """"EndTime"""", """"Duration"""", """"Source"""", """"Target"""", """"Length"""", """"Content""""
0.1        , 0.4      , 0.3       , P1      , P2      , 12      , """"ABCDEHIJPQRS""""
0.5        , 0.9      , 0.4       , P2      , P1      , 6       , """"ZYSRQP""""
1.1        , 1.6      , 0.5       , P1      , P2      , 4       , """"BDEF""""
...
</code></pre>

<p>Trying to put this into English, I want to group consecutive records with the same 'Source' and 'Target' together, then print out a single record per group showing the StartTime, EndTime &amp; Duration (=EndTime-StartTime) for that group, along with the sum of the Lengths for that group, and a concatenation of the Content (which will all be strings) in that group.</p>

<p>The TimeOffset values will always increase throughout the data frame.</p>

<p>I had a look at melt/recast and have a feeling that it could be used to solve the problem, but couldn't get my head around the documentation.  I suspect it's possible to do this within R, but I really don't know where to start. In a pinch I could export the data frame out and do it in e.g. Python, but I'd prefer to stay within R if possible.</p>

<p>Thanks in advance for any assistance you can provide</p>
",1
"<p>Following the recent discussions here (e.g. <a href=""""https://stackoverflow.com/questions/2628621/how-do-you-use-scoping-assignment-in-r"""">1</a>, <a href=""""https://stackoverflow.com/questions/2630541/r-getting-inside-environments"""">2</a> ) I am now using environments in some of my code. My question is, how do I create functions that modify environments according to its arguments? For example:</p>

<pre><code>y &lt;- new.env()
with(y, x &lt;- 1)
f &lt;- function(env,z) {
    with(env, x+z)
}
f(y,z=1)
</code></pre>

<p>throws</p>

<pre><code>Error in eval(expr, envir, enclos) : object 'z' not found
</code></pre>

<p>I am using environments to keep concurrently two sets of simulations apart (without refactoring my code, which I wrote for a single set of experiments). </p>
",1
"<p>I have a dataframe with a column of integers that I would like to use as a reference to make a new categorical variable.  I want to divide the variable into three groups and set the ranges myself (ie 0-5, 6-10, etc).  I tried <code>cut</code> but that divides the variable into groups based on a normal distribution and my data is right skewed.  I have also tried to use if/then statements but this outputs a true/false value and I would like to keep my original variable.  I am sure that there is a simple way to do this but I cannot seem to figure it out.  Any advice on a simple way to do this quickly?</p>

<p>I had something in mind like this:</p>

<pre><code>x   x.range
3   0-5
4   0-5
6   6-10
12  11-15
</code></pre>
",1
"<p>I am trying to transform my data.frame by calculating the <code>log-differences</code> of each column
and controlling for the rows <code>id</code>. So <strong>basically I like to calculate the growth rates for each id's variable</strong>.
So here is a random df with an id column, a time period colum p and three variable columns:</p>

<pre><code>df &lt;- data.frame (id = c(""""a"""",""""a"""",""""a"""",""""c"""",""""c"""",""""d"""",""""d"""",""""d"""",""""d"""",""""d""""),
                  p = c(1,2,3,1,2,1,2,3,4,5),
                  var1 = rnorm(10, 5),
                  var2 = rnorm(10, 5),
                  var3 = rnorm(10, 5)
                  )
df
     id p     var1     var2     var3
1     a 1 5.375797 4.110324 5.773473
2     a 2 4.574700 6.541862 6.116153
3     a 3 3.029428 4.931924 5.631847
4     c 1 5.375855 4.181034 5.756510
5     c 2 5.067131 6.053009 6.746442
6     d 1 3.846438 4.515268 6.920389
7     d 2 4.910792 5.525340 4.625942
8     d 3 6.410238 5.138040 7.404533
9     d 4 4.637469 3.522542 3.661668
10    d 5 5.519138 4.599829 5.566892
</code></pre>

<p>Now I have written a function which does exactly what I want BUT I had to take a detour which is possibly unnecessary and can be removed. However, somehow I am not able to locate
the shortcut.
Here is the function and the output for the posted data frame:</p>

<pre><code>fct.logDiff &lt;- function (df) {
df.log &lt;- dlply (df, """"code"""", function(x) data.frame (p = x$p, log(x[, -c(1,2)])))
list.nalog &lt;- llply (df.log, function(x) data.frame (p = x$p, rbind(NA, sapply(x[,-1], diff))))
ldply (list.nalog, data.frame)
}

 fct.logDiff(df)
     id p        var1        var2        var3
1     a 1          NA          NA          NA
2     a 2 -0.16136569  0.46472004  0.05765945
3     a 3 -0.41216720 -0.28249264 -0.08249587
4     c 1          NA          NA          NA
5     c 2 -0.05914281  0.36999681  0.15868378
6     d 1          NA          NA          NA
7     d 2  0.24428771  0.20188025 -0.40279188
8     d 3  0.26646102 -0.07267311  0.47041227
9     d 4 -0.32372771 -0.37748866 -0.70417351
10    d 5  0.17405309  0.26683625  0.41891802
</code></pre>

<p>The trouble is due to the added <code>NA</code>-rows. I don't want to collapse the frame and reduce it, which would be automatically done by the <code>diff()</code> function. So I had 10 rows in my original frame and am keeping the same amount of rows after the transformation. In order to keep the same length I had to add some <code>NAs</code>. I have taken a detour by transforming the data.frame into a list, add the <code>NAs</code> to each id's first line, and afterwards transform the list back into a data.frame. That looks tedious. </p>

<p>Any ideas to avoid the data.frame-list-data.frame class transformation and optimize the function?</p>
",1
"<p>Does anyone know of a way to control the font size/color/weight of the row and column names when plotting a correspondence plot with the ca package?</p>

<p>The following code will produce a very nice looking chart, though if there were more attributes (very heavy, super heavy, something more than super heavy) or more classes of workers (peons, underlings, etc) then the graph will get a little cluttered and hard to tell what was what.</p>

<p>It would be nice if you could list all the attributes in a separate color than the categories of workers.</p>

<pre><code>library(ca)
data(""""smoke"""")

plot(ca(smoke)
  , map = """"symmetric""""
  , what =c(""""active"""",""""active"""")
  , mass = c(T,T)
  , contrib = """"absolute""""
  , col = c(""""red"""",""""blue"""")
  , pch = c(15,17,15,17)
  , labels = c(2,2)
  , arrows = c(T,F)
)
</code></pre>

<p>Alternatively, does anyone know if there is a way to reproduce something along these lines with ggplot2? I didn't find anything on the website that seemed comparable, but I don't know much about the package.</p>

<p>Thanks,
-Chase</p>
",1
"<p>I am impressed by what I have seen of <a href=""""http://yeroon.net/ggplot2/"""" rel=""""noreferrer"""">yeroon.net/ggplot2</a> which is a web interface for Hadley Wickham's R package ggplot2. I want to try it out on my own data. The part that has me very excited is that one can use data stored in one's own Google spreadsheet as the data. One just signs into their Google Account so that yeroon.net/ggplot2 can access the spreadsheet list. I have been hesitant to do it. If I sign in whilst on yeroon.net am I handing over my username and password to a third party? It would not be wise of me to divulge my google password to third parties since Google is fast becoming my repository of everything. </p>

<p>How do I know if Jeroon's application is using <a href=""""http://code.google.com/apis/accounts/docs/AuthForInstalledApps.html"""" rel=""""noreferrer"""">ClientLogin</a> or <a href=""""http://code.google.com/apis/accounts/docs/OAuthForInstalledApps.html#"""" rel=""""noreferrer"""">OAuth</a>? My understanding is very basic and may be wrong but nevertheless here it is. OAuth would be better since it does not actually pass the password onto the third party application. </p>
",1
"<p>I want to upgrade the package ggplot2:</p>

<pre><code>library(ggplot2)
packageDescription(""""ggplot2"""")[""""Version""""]
&gt; 0.8.3
</code></pre>

<p>But the current version is 0.8.7.</p>

<p>I tried update.packages(), which seemed to work OK.  But it still returned older version 0.8.3.</p>

<p>So I downloaded and installed the package source from Cran, which says 0.8.7 in the download page.
I then install it via the GUI menu in R.  It returns </p>

<pre><code>** building package indices ...
* DONE (ggplot2)
</code></pre>

<p>I then run:</p>

<pre><code>packageDescription(""""ggplot2"""")[""""Version""""]
&gt; 0.8.3
</code></pre>

<p>And still I have the older version!</p>

<p>I don't know why this is not working, what's more I had already come across this problem before and solved it (I can't remember exactly what) but now it has gone back to the older version!  What's the easiest way to keep packages like this updated automatically and not have them refer back to older packages?</p>
",1
"<p>Assume that I have sources of data X and Y that are indexable, say matrices. And I want to run a set of independent regressions and store the result. My initial approach would be</p>

<pre><code>results = matrix(nrow=nrow(X), ncol=(2))
for(i in 1:ncol(X)) {
        matrix[i,] = coefficients(lm(Y[i,] ~ X[i,])

}
</code></pre>

<p>But, loops are bad, so I could do it with lapply as</p>

<pre><code>out &lt;- lapply(1:nrow(X), function(i) { coefficients(lm(Y[i,] ~ X[i,])) } )
</code></pre>

<p>Is there a better way to do this?</p>
",1
"<p>I often want to do essentially the following:</p>

<pre><code>mat &lt;- matrix(0,nrow=10,ncol=1)
lapply(1:10, function(i) { mat[i,] &lt;- rnorm(1,mean=i)})
</code></pre>

<p>But, I would expect that mat would have 10 random numbers in it, but rather it has 0. (I am not worried about the rnorm part. Clearly there is a right way to do that. I am worry about affecting mat from within an anonymous function of lapply) Can I not affect matrix mat from inside lapply? Why not? Is there a scoping rule of R that is blocking this?</p>
",1
"<p>In R, what is the most efficient way to count the length between 2 values. for example, i have vector x , which are all randomly choose from 1 to 100, how can i find out the length between the first""""2"""" and first""""40"""", 
x=(1,2,<strong>3,4,5,6,7</strong>,40,1,2,<strong>3,21,4,1,23,4</strong>,43,23,4,12,3,43,5,36,3,45,12,31,3,4,23,41,23,5,53,45,3,7,6,36)
for this vector, the answer should be 5 and 6</p>
",1
"<p>I am trying to build a data processing program. Currently I use a double matrix to represent the data table, each row is an instance, each column represents a feature. I also have an extra vector as the target value for each instance, it is of double type for regression, it is of integer for classification. </p>

<p>I want to make it more general. I am wondering what kind of structure R uses to store a dataset, i.e. the internal implementation in R. </p>
",1
"<p>I wanted to do matrix multiplication in Java, and the speed needs to be very good.</p>

<p>I was thinking of calling R through java to achieve this.</p>

<p>I had a couple of Qs though:</p>

<ol>
<li><p>Is calling R using Java a good idea? If yes, are there any code samples that can be shared?</p></li>
<li><p>What are the other ways that can be considered to do matrix multiplication in Java?</p></li>
</ol>

<h3>Update:</h3>

<p>My colleague who quit the firm was a C# programmer, who was forced to write Java code that involved matrix multiplication.</p>

<p>-- He has written his own DataTable class in Java, in order to be able to </p>

<p>a) create indexes to sort and join with other DataTables</p>

<p>b) matrix multiplication.</p>

<p>So, I want to essentially clean up the code, and thought using something like R within Java will help me focus on business logic rather than sorting, joining, matrix multiplication, etc.</p>
",1
"<p>When editing .Rnw files with emacs, sometimes it gets confused as to if I am in math mode or not. Then, the syntax highlighting gets messed up, and C-f-i inserts \textit{} and \mathit{} opposite to how it normally should. Is seems like there is some bool storing the state of math mode or not, and it gets inadvertently flipped. Is there a way I can manually flip it back?</p>
",1
"<p>I have a few hundred thousand measurements where the dependent
variable is a probability, and would like to use logistic regression.
However, the covariates I have are all categorical, and worse, are all
nested. By this I mean that if a certain measurement has """"city -
Phoenix"""" then obviously it is certain to have """"state - Arizona"""" and
""""country - U.S."""" I have four such factors - the most granular has
some 20k levels, but if need be I could do without that one, I think.
I also have a few non-nested categorical covariates (only four or so,
with maybe three different levels each).
What I am most interested in
is prediction - given a new observation in some city, I would like to
know the relevant probability/dependent variable. I am not interested
as much in the related inferential machinery - standard deviations,
etc - at least as of now. I am hoping I can afford to be sloppy.
However, I would love to have that information unless it requires
methods that are more computationally expensive.
Does anyone have any advice on how to attack this? I have looked into
mixed effects, but am not sure it is what I am looking for.</p>
",1
"<p>I am sure this is easy - but I can't figure it out right now.</p>

<p>Basically: I have a long vector of variables:</p>

<pre><code>names &lt;- c(""""first"""",""""second"""", """"third"""")
</code></pre>

<p>I have some data, and I now need to add the variables. I could do:</p>

<pre><code>data$first &lt;- NA
</code></pre>

<p>But since I have a long list, and I would like an automated solution. <strong>This doesn't work</strong>.</p>

<pre><code>for (i in 1:length(names)) (paste(""""data$"""", names[i],sep="""""""") &lt;- NA)
</code></pre>

<p>The reason I want this, is that I need to vertically merge to dataframes, where one doesn't have all the variables it should have.</p>

<p>Thanks in advance</p>
",1
"<p>Given a set of real numbers drawn from a unknown continuous univariate distribution (let's say is is one of beta, Cauchy, chi-square, exponential, F, gamma, Laplace, log-normal, normal, Pareto, Student's t, uniform and Weibull) ..</p>

<pre><code>x &lt;- c(7.7495976,12.1007857,5.8663491,9.9137894,11.3822335,7.4406175,8.6997212,9.4456074,11.8370711,6.4251469,9.3597039,8.7625700,10.3171063,8.0983110,11.7564283,11.7583461,7.3760516,14.5713098,14.3289690,12.8436795,7.1834376,12.2530520,8.9362235,11.8964391,5.4378782,7.8083060,0.1356370,14.9341847,6.8625143,9.0285873,10.2251998,10.3348486,7.7518365,2.8757024,9.2676577,10.6879259,11.7623207,14.0745924,9.3478318,7.6788852,9.7491924,14.9409955,11.0297640,8.5541261,8.6129808,9.2192320,12.3507414,8.9156903,11.6892831,10.2571897,11.1673235,10.5883741,8.2396129,7.3505839,3.4437525,8.3660082,10.5779227,8.5382177,13.6647484,9.0712034,4.1090454,13.4238382,16.1965937,14.2539891,14.6498816,6.9662381,12.3282141,10.9628268,10.8859495,11.6742822,12.0469869,9.1764119,4.2324549,12.6665295,10.7467579,6.4153703,10.3090806,12.0267082,9.2375369,13.8011813,13.0457227,14.0147179,6.9224316,7.1164269,10.7577799,8.0965571,13.3371566,14.6997535,8.8248384,8.0634834,10.2226001,8.5112199,8.1701147,8.1970784,10.5432878,5.9603389,6.6287037,13.3417943,3.1122822,10.4241008,11.4281520,9.4647825,10.5480176,14.2357819,9.4220778,9.7012755,10.9251006,5.3073151,10.8228672,12.0936384,8.5146227,8.4115865,7.7244591,7.2801474,7.3412563,4.5385940,7.8822841,12.7327836,11.5509252,13.0300876,10.0458138,11.3862972,11.3644867,12.6585391,5.8567192,9.8764841,7.6447620,8.7806429,9.2089114,9.1961781,7.2400724,14.7575303,8.6874476,4.6276043,14.0592724,10.3519708,8.2222625,8.7710501,8.5724602,11.4279232,9.6734741,12.1972490,10.1250074,4.8571327,8.0019245,9.8036286,17.7386541,10.8935339,4.7258581,14.2681556,7.4236474,9.4520797,9.2066764,7.7805317,0.4938756,13.0306624,8.0225287,11.1801478,8.7481126,16.5873192,6.0404763,9.5674318,10.8915023,13.2473727,5.5877557,1.4474869,10.9504070,10.8879749,10.7765684,9.1501230,11.0798794,10.0961631,9.5913525,14.0855129,7.3918195,16.6303158,9.1436327,11.9848346,11.4691572,16.0934172,13.1431040,8.2455786,10.7388841,13.7107201,9.6223990,7.6363513,9.5731838,7.0150930,14.1341888,7.5834625,13.8362695,12.9790060,10.4156690,6.4108920,6.3731019,6.3302824,8.4924571,11.2175143,11.6346609,6.0958761,12.8728176,10.2689647,9.7923411,11.3962741,7.3723701,8.1169299,9.7926014,8.7266379,10.7350973,12.7639103,7.4425159,15.9422109,9.9073852,6.2421614,5.2925668,9.9822059,13.9768971,9.3481404,6.8102106,12.6482884,9.8595946,12.8946675,6.3519119,9.2698768,4.9538608,13.8062408,14.7438135,8.5583994,12.4232260,9.4205371,13.6507205,11.7807767,10.9747222,15.9299602,10.0202244,11.9209419,12.8159324,7.0107459,7.8076222,8.0086965,14.7694984,6.4810687,6.6833260,3.9660939,16.2414479,9.3474497,10.2626126,11.7672786,10.1245905,2.3416774,9.2548226,12.3498943,9.1731074,8.6703280,3.8079927,12.0858349,11.1027140,11.9034505,11.1981903,9.5554276,11.5333311,4.1374535,7.9397446,10.6732513,5.4928081,5.9026714,7.1902350,7.3516027,9.5251792,12.8827838,8.6051567,9.9074448,4.7244414,9.4681156,17.4316786,15.0770196,7.4215510,7.2839984,8.2040354,11.2938556,12.2308244,17.2933409,5.7154747,9.9383524,7.9912142,10.2087560,13.0489301,10.2092634,11.4029668,10.3103281,10.2810316,8.9487624,14.2699307,12.8538251,10.7545354,18.0638133,7.2115769,7.4020585,7.9737234,13.1687588,13.7186238,9.6881618,4.2991770,11.4829896,8.0113006,10.0285544,8.3325591,8.8476239,9.3618137,11.0913308,10.2702207,12.0215701,11.8083744,8.1575837,10.0413629,11.7291752,13.8315537,12.4823312,13.3289096,8.5874403,9.8624401,7.0444818,13.9701389,10.0250634,14.3841966,17.4074390,13.1290358,8.3764673,7.8796107,6.4597773,12.4989708,11.3617236,5.0730931,13.5990536,9.4800716,11.1247161,12.6283343,12.5711367,10.8075848,13.2183856,12.4566869,17.0046899,9.9132293,13.8912393,10.4806343,6.7550983,18.4982020,4.6835563,4.6068688,8.4304188,7.8747286,9.4440702,12.1033704,10.7397568,12.4483258,12.0952273,9.4609549,16.1755646,13.2110564,12.5244792,14.5511670,14.9365263,6.6852081,14.6988321,9.8833093,11.1549852,14.4090081,6.2565184,8.3488705,10.8509966,7.6795679,13.5814813,10.1733942,12.1773482,4.7032686,9.9248308,17.7067155,8.2378404,12.8208154,12.7675305,9.0907063,9.5720411,4.5536981,5.2252539,10.7393508,8.1761239,7.8011878,10.8517959,12.8793471,10.1738281,9.0522516,9.7020267,8.5743543,7.1063673,9.4366173,7.5154902,9.2420952,13.7275687,8.2097051,12.4686117,8.6426135,10.6854081,14.8617929,14.2631291,11.1449327,8.4807248,5.9399190,6.7772300,7.2566033,10.3215210,9.2483564,10.8592844,13.8227188,5.8955118,6.8936159,11.4641992,8.6535466,14.1301887,10.2194653,9.3929177,11.8592296,9.3153675,10.8574024,9.5293558,14.1394531,7.1224090,5.6785198,13.1351723,7.1031658,7.6344684,8.6918016,6.8426780,8.6902514,9.9025967,6.1603559,6.3995948,6.7157089,14.9359341,13.1275476,11.2493476,10.7684760,8.5263731,5.1711855,10.2432689,6.7908688,9.2634794,5.6242460,7.7319788,13.7579540,10.5344149,11.2123002,9.5503450,11.3042249,6.6581916,13.0363709,9.0141363,6.8815546,8.6309000,9.4825677,6.9816465,9.4836443,8.5629547,12.5643187,13.2918150,4.9542483,3.8941388,12.0723769,14.6818075,6.2067566,8.6538934,11.4860264,9.6481396,12.7096758,7.8361298,12.0167492,9.2011051,6.7472607,13.5725275,15.0862343,12.5248807,10.8804527,12.7291198,7.7527975,7.8537703,10.5257599,11.2615216,5.2586963,9.3935784,4.8959811,14.9649019,9.7550081,9.0961317,3.0822901,10.4690830,11.4116176,11.8268286,9.6303294,12.6595176,10.3003485,10.6738841,7.1545388,13.1700952,8.8394611,11.7666496,5.3739818,12.5156287,10.5998309,7.9280247,11.3985509,9.3435626,9.1445783,7.5190392,10.5207065,5.5194295,14.4021779,7.9815022,7.3148241,5.0131517,12.1867856,3.4892615,14.7278153,10.0177503,9.0080577,6.2549383,11.5792232,10.0743671,4.6603495,9.1943305,10.0549778,13.3946923,11.0435648,11.9903902,7.5212459,6.9752799,9.7793759,3.0074422,9.9630136,8.2949444,14.4448033,8.8767257,10.4919437,12.8309614,11.9987884,9.4450733,7.1909711,7.7836130,12.0111407,7.8110426,8.8857522,7.2070115,6.1091037,15.5397454,12.4138856,11.0948175,10.3384724,4.0731303,11.9523302,11.7543732,8.6845056,11.3963952,9.1248950,9.8663549,14.4536098,10.5610537,9.6523570,9.9533877,10.1019772,12.0909679,12.1466894,9.8986813,14.2406526,10.1251599,13.5607593,8.3409267,7.3538062,9.2187909,8.3878572,9.6934979,6.8270478,6.9754722,14.7438670,6.2118150,4.3408116,11.4874280,12.9580969,9.5487183,10.2743684,11.2433385,14.4445854,10.3395096,5.7534609,10.5550234,10.9322053,10.2105928,11.3020951,12.9484069,6.5904212,8.4368601,11.3280691,8.6031823,7.6938566,11.3733151,12.3900593,11.7711757,11.2307516,13.4915701,10.7228153,7.3886924,8.4401787,10.2753493,8.4389663,12.1972728,10.4918743,10.6289742,10.5594228,6.7236908,11.2358099,8.5938861,12.3906280,14.4511787,7.4746119,15.8803774,2.5522927,9.6801286,8.5697501,10.8271935,13.5280438,10.6818935,13.5646711,3.5187030,10.4440143,9.8327296,9.7382627,14.1669606,6.9083257,3.8266181,13.6244062,11.0284378,9.5523319,8.9891586,9.9055215,8.3856238,8.7478998,6.6987620,14.7248918,9.2529918,10.2082195,4.9534370,9.2030317,5.2269606,8.0661516,13.1779369,5.2971835,15.0037013,7.2702621,6.9997505,9.6490126,13.9149660,10.7425870,9.7558964,12.5752855,10.5098261,20.2689637,9.8681830,7.8259004,9.4911900,9.6024895,7.6085691,12.0086596,6.6780724,8.2764670,8.9880572,15.9231426,5.9905542,13.5816388,8.9839322,9.5235545,10.1314783,13.1174616,8.1648447,12.5653484,12.4941364,10.5916275,12.7761500,9.8608664,8.1374522,10.6055768,6.5465219,11.7945966,7.0397647,4.4046833,12.4284773,0.4180241,12.0268339,10.0441325,5.3276329,8.4208769,8.5484829,9.8222639,9.4951750,9.3263556,13.7433301,10.1112279,12.3558939,10.8694158,9.7864777,5.5161601,7.0906274,14.5786803,12.9236138,8.9206195,7.0104273,5.8283839,7.6944516,6.2924265,10.0766522,10.3576597,8.5793193,11.2022858,4.9360148,6.5907700,13.0853471,9.5498965,10.8132248,7.3545704,9.3583861,10.5726301,6.8032692,9.5914570,6.1383186,7.0176580,16.8026498,6.7959168,9.2745414,7.7390857,12.5977623,8.6116698,13.6735060,10.8476068,9.6710713,10.1086791,9.6101003,11.2849373,14.3841286,10.0175111,5.9766042,9.2654916,12.3336237,11.0695365,9.4801954,6.6405542,11.7110714,9.2962742,4.5557592,7.9725970,10.3105591,9.1068024,8.1585631,14.9021906,9.2015137,15.0472571,9.1225965,13.9551835,15.1033478,10.6360240,12.0867865,15.6969704,9.5818060,8.1641150,8.2950194,8.6544478,7.9130456,8.8904450,13.9381998,8.9913977,14.0155779,6.2856039,10.7923301,8.8070441,11.2657258,10.7901363,9.1724396,6.6433443,9.5172255,12.3402514,2.7254577,12.4006210,13.2697124,10.0670987,15.3858112,8.2044828,10.7534955,7.9282064,10.9170642,12.8222748,18.2680638,9.0601854,13.2616197,7.0193571,12.2447467,5.3729936,14.8064727,10.5359554,10.4851627,11.8312380,13.3435483,10.5894537,5.0047413,7.5532502,11.9171854,12.1777692,7.6730359,5.5515027,12.3027227,10.1575062,14.8505769,9.6526219,11.2016182,10.7898901,13.6303578,12.8561220,13.3002161,9.0945849,4.9117132,8.0514791,8.3684288,4.7461608,6.3118847,14.3888758,15.8801467,11.6563489,7.9043481,6.1992280,10.4055679,6.4948166,11.8656277,3.8399970,9.5901581,8.6379262,7.4541442,7.1135626,7.9164363,9.6439593,15.6259631,7.3244170,8.4635798,12.0317526,17.1847365,12.5357554,6.0369018,12.9830581,11.2712555,12.3488084,9.3935706,8.1248854,11.4523131,9.6710694,9.5978474,15.1563587,7.5582530,10.8587757,13.5890062,10.1390991,8.1443215,16.1032757,6.5988579,9.6915113,7.6946942,10.5688193,7.9222074,6.0964578,7.0383112,11.5956154,6.6059072,13.5679685,15.1021379,10.2625096,10.2202339,15.7814051,16.3342713,6.1339245,0.9275113,15.8169582,11.0888355,7.8822788,15.2039942,9.6944328,11.7292036,11.6230714,8.4657438,7.6462181,7.1888162,8.1788400,13.7221572,12.4793501,10.4488461,8.9233659,8.9305724,7.4913262,12.5882791,10.6825315,10.8527571,12.1660301,12.4390247,13.8529219,8.5372836,11.2575812,6.4922496,9.5404721,10.7082122,11.2365487,10.2713802,14.8685632,10.7735798,10.6526134,4.8455022,8.3135583,10.8120056,7.2903999,7.0497880,4.9958942,5.9730174,9.8642732,11.5609671,10.1178216,6.6279774,9.2441754,9.9419299,13.4710469,6.0601435,8.2095239,7.9456672,12.7039825,7.4197810,9.5928275,8.2267352,2.8314614,11.5653497,6.0828073,11.3926117,10.5403929,14.9751607,11.7647580,8.2867261,10.0291522,7.7132033,6.3337642,14.6066222,11.3436587,11.2717791,10.8818323,8.0320657,6.7354041,9.1871676,13.4381778,7.4353197,8.9210043,10.2010750,11.9442048,11.0081195,4.3369520,13.2562675,15.9945674,8.7528248,14.4948086,14.3577443,6.7438382,9.1434984,15.4599419,13.1424011,7.0481925,7.4823108,10.5743730,6.4166006,11.8225244,8.9388744,10.3698150,10.3965596,13.5226492,16.0069239,6.1139247,11.0838351,9.1659242,7.9896031,10.7282936,14.2666492,13.6478802,10.6248561,15.3834373,11.5096033,14.5806570,10.7648690,5.3407430,7.7535042,7.1942866,9.8867927,12.7413156,10.8127809,8.1726772,8.3965665)
</code></pre>

<p>.. is there some easy way in R to <b>programmatically and automatically</b> find the most likely distribution and the estimated distribution parameters?</p>

<p>Please note that the distribution identification code will be part of an automated process, so manual intervention in the identification won't be possible.</p>
",1
"<p>Could anyone please tell me what is wrong with the R code below:</p>

<pre><code>i = 1.001
#make SAV and STO become vector
SAV = c()
STO = c()
#set the initial values for the vector
SAV[1] = 0
STO[1] = 100


for (t in 2:1000) {
if ((price[t]&gt;9.9)&amp;price[t]&lt;10.1&amp;(SAV[t-1]!=0))
      SAV[t]=SAV[t-1]*i 
      STO[t]=0 
}

for (t in 2:1000) {
if ((price[t]&gt;9.9)&amp;price[t]&lt;10.1&amp;(SAV[t-1]=0))
      STO[t] = STO [t-1]
      SAV[t] = 0
}

SAV
STO
</code></pre>

<p>What I am trying to do is to find vector for both SAV and STO.</p>
",1
"<p>I like the idea of making research available at multiple levels of detail i.e., abstract for the casually curious, full text for the more interested, and finally the data and code for those working in the same area/trying to reproduce your results. In between the actual text and the data/code level, I'd like to insert another layer. Namely, I'd like to create a kind of automatically generated appendix that contains the full regression output, diagnostic plots, exploratory graphs data profiles etc. from the analysis, regardless of 
whether those plots/regressions etc. made it into the final paper.  </p>

<p>One idea I had was to write a script that would examine the .Rnw file and automatically: </p>

<ul>
<li>Profile all data sets that are loaded (sort of like the Hmisc(?) package)  </li>
<li>Summarize all regressions - i.e., run summary(model) for all models </li>
<li>Present all plots (regardless of whether they made it in the final version) </li>
</ul>

<p>The idea is to make this kind of a low-effort, push-button sort of thing as opposed to a formal appendix written like the rest of a paper. What I'm looking for is some ideas on how to do this in R in a relatively simple way. My hunch is that there is some way of going through the namespace, figuring out what something is and then dumping into a PDF. </p>

<p>Thoughts? Does something like this already exist? </p>
",1
"<pre><code>library(ca)
# Loading required package: rgl
library(Rcmdr)
# R Commander starts

# When trying to close R Commander window
Error in unloadNamespace(""""rgl"""") : name space 'rgl' is still used by: 'ca'
</code></pre>

<p>What is the suggested way to close R Commander in such a situation?</p>
",1
"<p>I'm using R for data analysis, and I'm sharing some data with collaborators via Google docs. Is there a simple interface that I can use to access a R data.frame object to and from a Google Docs spreadsheet? If not, is there a similar API in other languages? </p>
",1
"<p>How can I extract what the parameters that the loess function fitted for the polynomial function it uses, for a particular x of my data?</p>

<p>For example, in:</p>

<pre><code> cars.lo &lt;- loess(dist ~ speed, cars)
 cars.lo
</code></pre>

<p>What did it fit for when cars.lo$x == 5 ?</p>

<p><strong>Update</strong>: I want the parameters of the polynomial function, not the prediction (predict) of the loess.</p>

<p>I am asking for it to get an estimate of the slope in that point.</p>

<p>Thanks,
Tal</p>
",1
"<p>Using stat_smooth, I can fit models to data. E.g.</p>

<pre><code>g=ggplot(tips,aes(x=tip,y=as.numeric(unclass(factor(tips$sex))-1))) +facet_grid(time~.) 
g=g+ stat_summary(fun.y=mean,geom=""""point"""") 
g=g+ stat_smooth(method=""""glm"""", family=""""binomial"""")
</code></pre>

<p>I would like to know the coefficients of the glm binomial fits. I could re-do the fit with dlply and get the coefficients with ldply, but I'd like to avoid such duplication.</p>

<p>Calling str(g) reveals the hierarchy of objects that ggplot creates, perhaps there's some way to get to the coefficients through that?</p>
",1
"<p>In R , when I use """"print"""", I can see all the values, but how can I save this as a vector?
   For example, in a 'for' loop: 
   <code>for(i in 1:10)</code>, I would like the value of A , when i= 1,2,3,4..... but if I use <code>x=A</code>, it only saves the final value of A which is the value when i = 10. So, how can I save the values in print(A)?
    Additionally, I use more than one 'for' loop e.g.:</p>

<pre><code>for (i in 1:9) {
  for (k in 1:4) {
  }
}
</code></pre>

<p>Consequently, x[i]=A..does not work very well here.</p>
",1
"<p>How can I select the first 4 rows of a <code>data.frame</code>:</p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
</code></pre>
",1
"<p>I am using the twitteR package in R to update my twitter status with results from analysis. The static tweet function works:</p>

<pre><code>library(twitteR)

sess = initSession('username','password')

tweet = tweet('I am a tweet', sess)
</code></pre>

<p>However, when I add a variable to display some specific results I get an error. </p>

<pre><code>library(twitteR)

sess = initSession('username','password')

res = c(3,5,8)
msg = cat('Results are: ', res, ', that is nice right?')

tweet = tweet(msg, sess)
</code></pre>

<p>Results in:</p>

<pre><code>Error in twFromJSON(rawToChar(out)) : 
  Error: Client must provide a 'status' parameter with a value.
</code></pre>

<p>Any suggestions are appreciated. </p>
",1
"<p>say i have 5 summary for 5 sets of data. how can i get those number out or combine the summary in to 1 rather than 5</p>

<pre><code>       V1               V2               V3               V4        
 Min.   : 670.2   Min.   : 682.3   Min.   : 690.7   Min.   : 637.6  
 1st Qu.: 739.9   1st Qu.: 737.2   1st Qu.: 707.7   1st Qu.: 690.7  
 Median : 838.6   Median : 798.6   Median : 748.3   Median : 748.3  
 Mean   : 886.7   Mean   : 871.0   Mean   : 869.6   Mean   : 865.4  
 3rd Qu.:1076.8   3rd Qu.:1027.6   3rd Qu.:1070.0   3rd Qu.: 960.8  
 Max.   :1107.8   Max.   :1109.3   Max.   :1131.3   Max.   :1289.6  
       V5        
 Min.   : 637.6  
 1st Qu.: 690.7  
 Median : 748.3  
 Mean   : 924.3  
 3rd Qu.: 960.8  
 Max.   :1584.3  
</code></pre>

<p>how can i have 1 table looks like</p>

<pre><code>        v1  v2 v3 v4 v5
  Min.   :   
 1st Qu.:   
 Median : 
 Mean   :   
 3rd Qu.:   
 Max.   :  
</code></pre>

<p>or how to save those number as vector so i can use matrix to generate a table</p>
",1
"<p>I have a data.frame in R. It contains a lot of data : gene expression levels from many (125) arrays. I'd like the data in Python, due mostly to my incompetence in R and the fact that this was supposed to be a 30 minute job.</p>

<p>I would like the following code to work. To understand this code, know that the variable <code>path</code> contains the full path to my data set which, when loaded, gives me a variable called <code>immgen</code>. Know that <code>immgen</code> is an object (a Bioconductor <code>ExpressionSet</code> object) and that <code>exprs(immgen)</code> returns a data frame with 125 columns (experiments) and tens of thousands of rows (named genes). (Just in case it's not clear, this is Python code, using robjects.r to call R code)</p>

<pre><code>import numpy as np
import rpy2.robjects as robjects
# ... some code to build path
robjects.r(""""load('%s')""""%path) # loads immgen
e = robjects.r['data.frame'](""""exprs(immgen)"""")
expression_data = np.array(e)
</code></pre>

<p>This code runs, but <code>expression_data</code> is simply <code>array([[1]])</code>. </p>

<p>I'm pretty sure that <code>e</code> doesn't represent the data frame generated by <code>exprs()</code> due to things like:</p>

<pre><code>In [40]: e._get_ncol()
Out[40]: 1

In [41]: e._get_nrow()
Out[41]: 1
</code></pre>

<p>But then again who knows? Even if <code>e</code> did represent my data.frame, that it doesn't convert straight to an array would be fair enough - a data frame has more in it than an array (rownames and colnames) and so maybe life shouldn't be this easy. However I still can't work out how to perform the conversion. The documentation is a bit too terse for me, though my limited understanding of the headings in the docs implies that this should be possible.</p>

<p>Anyone any thoughts?</p>
",1
"<p>Is there a way to call an R-Script within C-Code? </p>

<p>I did find the R Api for C (chaper 6. of the 'Writing R Extensions' manual), but as far as I understood this does """"only"""" allow to call the C-Implementation of R. Of cause I could call the R-Script via shell, but that's no solution for me, since this does not allow proper passing of data (at least no if I don't what to write the data into a Csv-File or something like this). </p>

<p>Is there a easy way of using the R to C parser beforehand?</p>
",1
"<p>I am looking for a solution that allows me to keep a track of a multitude of R scripts that I create for various projects and purposes. Some scripts are easily tracked to specific projects, whereas others are """"convenience"""" functions created to serve a set of tasks.</p>

<p>Is there a way I can create a central DB and query it to find which scripts match most appropriately?
I could create a system using a DBMS manually, but are users aware of anything in general or specific to R, that comes in the form of a software tool (maybe FOSS) ?</p>

<p>EDIT: Thank you for the responses. My current system is just a set of scripts with comments that allow me to identify their intended task. Though I use StatET with SVN, I would like a search utility along the lines of the """"sos"""" package. </p>
",1
"<p>I came across this in the following context from B. Pfaff's """"Analysis of Integrated and Cointegrated Time Series in R""""</p>

<pre><code>## Impulse response analysis of SVAR Atype model 1
args (vars ::: irf.svarest) 2
irf.svara &lt; irf (svar.A, impulse = y1  , 3
response = y2  , boot = FALSE) 4
args (vars ::: plot.varirf) 5
plot (irf.svara)
</code></pre>
",1
"<p>I'm trying to add a Row to my data.frame to spit out the average of the column.</p>

<p><strong>This is my data frame:</strong></p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
</code></pre>

<p><strong>I'd like it to become:</strong></p>

<pre><code>              Weight Response
1   Control     59      0.0
2 Treatment     90      0.8
3 Treatment     47      0.1
4 Treamment    106      0.1
5   Control     85      0.7
6 Treatment     73      0.6
7   Control     61      0.2
8 AVERAGES      74      0.3
</code></pre>

<p>Thanks!</p>
",1
"<p>Is there any command to find the standard error of the mean in R?</p>
",1
"<pre><code>a = matrix(1:25,5,5)
B = capture.output(for (X in 1:5){
    A = c(min(a[,X]),quantile(a[,X],0.25),median(a[,X]),quantile(a[,X],0.75),max(a[,X]),mean(a[,X]),sd(a[,X])/m^(1/2),var(a[,X]))
    cat(A,""""\n"""")
})

matrix(B,8,5)
</code></pre>

<p>What I was trying to do is to generate a table which each column has those element in A and in that order. I try to use the matrix, but seems like it doesn't really work here. Can anyone help?</p>

<pre><code>               |  1  |  2  |  3  |  4  |  5  |
|---------------------------------------------
| min          |     |     |     |     |     |
|---------------------------------------------
| 1st quartile |     |     |     |     |     |
|---------------------------------------------
| median       |     |     |     |     |     |
|---------------------------------------------
| SEM          |     |     |     |     |     |
|---------------------------------------------
| VAR          |     |     |     |     |     |
</code></pre>

<p>The above is what I want the table to look like.</p>
",1
"<p>I am building a bar chart for which bars suffice as indications of horizontal (x) placement, so I'd like to avoid drawing the superfluous vertical gridlines.</p>

<p>I understand how to style the minor and major gridlines in opts(), but I can't for the life of me figure out how to suppress just the vertical gridlines.</p>

<pre><code>library(ggplot2)

data &lt;- data.frame(x = 1:10, y = c(3,5,2,5,6,2,7,6,5,4))

ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  opts(
    panel.grid.major = theme_line(size = 0.5, colour = '#1391FF'),
    panel.grid.minor = theme_line(colour = NA),
    panel.background = theme_rect(colour = NA),
    axis.ticks = theme_segment(colour = NA)
  )
</code></pre>

<p>At this point, it's looking like I'm going to have to suppress all of the gridlines and then draw them back in with geom_hline(), which seems like kind of a pain (also, it's not entirely clear how I can find the tick/major gridline positions to feed to geom_hline().)</p>

<p>Any thoughts would be appreciated!</p>
",1
"<p>Is it possible to create new variable names on the fly?</p>

<p>I'd like to read data frames from a list into new variables with numbers at the end. Something like orca1, orca2, orca3...</p>

<p>If I try something like</p>

<pre><code>paste(""""orca"""",i,sep="""""""")=list_name[[i]]
</code></pre>

<p>I get this error</p>

<pre><code>target of assignment expands to non-language object
</code></pre>

<p>Is there another way around this?</p>
",1
"<p>Has anyone connected the R package to QuickBooks?  I know there is an ODBC driver than can be bought.  Just wondering if anyone has already gone down this road.</p>

<p>Any insight will be much appreciated!</p>

<p>~ Brock</p>
",1
"<p>R has a useful function <code>pairs</code> that provides nice matrix of plots of pairwise connections between variables in a data set. The resulting plot looks similar to the following figure, copied from <a href=""""http://statisticsr.blogspot.com/2009/12/r-pairs-plot.html"""" rel=""""noreferrer"""">this blog post</a>:</p>

<p><img src=""""https://2.bp.blogspot.com/_xLDEmoNB_RM/SzRINMDPNbI/AAAAAAAAFDc/N5gUwj7JHWA/s640/screenshot_001.png"""" alt=""""pairs""""></p>

<p>Is there any ready to use function based on python's matplolib? I have searched its <a href=""""http://matplotlib.sourceforge.net/gallery.html"""" rel=""""noreferrer"""">gallery</a>, but couldn't find anything that resembles what I need.  Technically, this should be a simple task, but proper handling of all the possible cases, labels, titles, etc is very tedious.</p>

<p><strong>UPDATE</strong> see below my answer with a quick and dirty approximation.</p>
",1
"<p>I heard R is the """"de facto"""" language amongst statistical software developers, and I'm giving it a try. I already know the basics, but it still looks """"weird"""" to me (a C developer). I think it would be very useful to see a working example to see how a real R program is built.
I thought that an R solution for any of the mlbench problems would be optimal, because I'm already familiar with it and it would allow me to compare it to other languages, but any other """"toy problem"""" example is welcome.</p>

<p>The <code>mlbench</code> package is pointed out in the answers below, but it seems that it provides only sample data and functions to generate sample data, with the exception of a generic bayes classifier. I'm searching for solutions of any of the mlbench data problems (DNA, Glass, Ionosphere, etc.). Maybe I'm missing something?</p>
",1
"<p>I'm creating a GUI in R using <code>gWidgets</code> (more specifically <code>gWidgetstcltk</code>).  I'd like to know how to update the contents of selection-type widgets, such as <code>gdroplist</code> and <code>gtable</code>.  I currently have a rather hackish method of deleting the widget and re-creating it.  I'm sure there's a better way.</p>

<p>This simple example displays all the variables in the global environment.</p>

<pre><code>library(gWidgets)
library(gWidgetstcltk)

create.widgets &lt;- function()
{
  grp &lt;- ggroup(container = win)
  ddl &lt;- gdroplist(ls(envir = globalenv()), 
    container = grp)
  refresh &lt;- gimage(""""refresh"""", 
    dirname   = """"stock"""",
    container = grp,
    handler   = function(h, ...)
    {
      if(exists(""""grp"""") &amp;&amp; !is.null(grp)) 
      {
        delete(win, grp)
      }
      create.widgets()   
    }
  )
}

win &lt;- gwindow()
create.widgets()
</code></pre>
",1
"<p>I'm writing a Sweave document, and I want to include a small section that details the R and package versions, platofrms and how long ti took to evalute the doucment, however, I want to put this in the middle of the document !</p>

<p>I was using a \Sexpr{elapsed} to do this (which didn't work), but thought if I put the code printing elapsed in a chunk that evaluates at the end, I could then include the chunk half way through, which also fails.</p>

<p>My document looks something like this </p>

<pre><code>% 
\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{Sweave}
\geometry{left=1.25in, right=1.25in, top=1in, bottom=1in}
\begin{document}

&lt;&lt;label=start, echo=FALSE, include=FALSE&gt;&gt;=
startt&lt;-proc.time()[3]
@ 
Text and Sweave Code in here
% 
This document was created on \today, with \Sexpr{print(version$version.string)} running
 on a \Sexpr{print(version$platform)} platform. It took approx sec to process.
&lt;&lt;&gt;&gt;=
    &lt;&lt;elapsed&gt;&gt;
@ 
More text and Sweave code in here
&lt;&lt;label=bye, include=FALSE, echo=FALSE&gt;&gt;= 
odbcCloseAll()
endt&lt;-proc.time()[3]
elapsedtime&lt;-as.numeric(endt-startt)
@ 
&lt;&lt;label=elapsed, include=FALSE, echo=FALSE&gt;&gt;=
print(elapsedtime)
@ 
\end{document}
</code></pre>

<p>But this doesn't seem to work (amazingly !)</p>

<p>Does anyone know how I could do this ?</p>

<p>Thanks</p>

<p>Paul.</p>
",1
"<p>I am trying to explain to myself the forecasting result from applying an ARIMA model to a time-series dataset. The data is from the M1-Competition, the series is MNB65. I am trying to fit the data to an ARIMA(1,0,0) model and get the forecasts. I am using R. Here are some output snippets:</p>

<pre><code>&gt; arima(x, order = c(1,0,0))
Series: x 
ARIMA(1,0,0) with non-zero mean 
Call: arima(x = x, order = c(1, 0, 0)) 
Coefficients:
         ar1  intercept
      0.9421  12260.298
s.e.  0.0474    202.717

&gt; predict(arima(x, order = c(1,0,0)), n.ahead=12)
$pred
Time Series:
Start = 53 
End = 64 
Frequency = 1 
[1] 11757.39 11786.50 11813.92 11839.75 11864.09 11887.02 11908.62 11928.97 11948.15 11966.21 11983.23 11999.27
</code></pre>

<p>I have a few questions:</p>

<p>(1) How do I explain that although the dataset shows a clear downward trend, the forecast from this model trends upward. This also happens for ARIMA(2,0,0), which is the best ARIMA fit for the data using auto.arima (forecast package) and for an ARIMA(1,0,1) model.</p>

<p>(2) The intercept value for the ARIMA(1,0,0) model is 12260.298. Shouldn't the intercept satisfy the equation: C = mean * (1 - sum(AR coeffs)), in which case, the value should be 715.52. I must be missing something basic here.</p>

<p>(3) This is clearly a series with non-stationary mean. Why is an AR(2) model still selected as the best model by auto.arima? Could there be an intuitive explanation?</p>

<p>Thanks.</p>
",1
"<p>I have a data.frame in R; it's called <code>p</code>. Each element in the data.frame is either True or False. My variable <code>p</code> has, say, <em>m</em> rows and <em>n</em> columns. For every row there is strictly only one <code>TRUE</code> element.</p>

<p>It also has column names, which are strings. What I would like to do is the following:</p>

<ol>
<li>For every row in <code>p</code> I see a <code>TRUE</code> I would like to replace with the name of the corresponding column</li>
<li>I would then like to collapse the data.frame, which now contains <code>FALSE</code>s and column names, to a single vector, which will have <em>m</em> elements.</li>
<li>I would like to do this in an R-thonic manner, so as to continue my enlightenment in R and contribute to a world without for-loops.</li>
</ol>

<p>I can do step 1 using the following for loop:</p>

<pre><code>for (i in seq(length(colnames(p)))) {
    p[p[,i]==TRUE,i]=colnames(p)[i]
}
</code></pre>

<p>but theres's no beauty here and I have totally subscribed to this for-loops-in-R-are-probably-wrong mentality. Maybe wrong is too strong but they're certainly not great.</p>

<p>I don't really know how to do step 2. I kind of hoped that the sum of a string and <code>FALSE</code> would return the string but it doesn't. I kind of hoped I could use an OR operator of some kind but can't quite figure that out (Python responds to <code>False or 'bob'</code> with <code>'bob'</code>). Hence, yet again, I appeal to you beautiful Rstats people for help!</p>
",1
"<p>This is a follow-on from <a href=""""https://stackoverflow.com/questions/2678141/how-can-i-suppress-the-vertical-gridlines-in-a-ggplot2-plot"""">this question, in which I was trying to suppress the vertical gridlines</a>.</p>

<p>The solution, as provided by learnr, was to add scale_x_continuous(breaks = NA), but this had the side effect of also suppressing the x-axis labels, as well.  I am totally happy to write the labels back in by hand, but it's not clear to me how to figure out where the labels should go.</p>

<p>The other option is to suppress all gridlines (using opts( panel.grid.major = theme_blank()) or some such) and then drawing back in just the major horizontal gridlines.  Again, the problem here is how to figure out what the breaks are in the plot to supply to geom_hline().</p>

<p>So, essentially, my options are:</p>

<ol>
<li>Suppress vertical gridlines and x-axis labels (using scale_x_continuous(breaks = NA) ) and add the x-axis labels back in.</li>
<li>Suppress all gridlines (using opts( panel.grid.major = theme_blank()) ) and add the major horizontal gridlines back in using geom_hline().</li>
</ol>

<p>Here are the two options:</p>

<pre><code>library(ggplot2)

data &lt;- data.frame(x = 1:10, y = c(3,5,2,5,6,2,7,6,5,4))

# suppressing vertical gridlines and x-axis labels
# need to re-draw x-axis labels
ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  scale_x_continuous(breaks = NA) +
  opts(
    panel.grid.major = theme_line(size = 0.5, colour = '#1391FF'),
    panel.grid.minor = theme_blank(),
    panel.background = theme_blank(),
    axis.ticks = theme_blank()
  )

# suppressing all gridlines
# need to re-draw horizontal gridlines, probably with geom_hbar() 
ggplot(data, aes(x, y)) +
  geom_bar(stat = 'identity') +
  scale_x_continuous(breaks = NA) +
  opts(
    panel.grid.major = theme_blank(),
    panel.grid.minor = theme_blank(),
    panel.background = theme_blank(),
    axis.ticks = theme_blank()
  )
</code></pre>
",1
"<p>I'm a student working on an epidemiology model in R, using maximum likelihood methods. I created my negative log likelihood function. It's sort of gross looking, but here it is:</p>

<pre><code>NLLdiff = function(v1, CV1, v2, CV2, st1 = (czI01 - czV01), st2 = (czI02 - czV02), st01 = czI01, st02 = czI02, tt1 = czT01, tt2 = czT02) { 
    prob1 = (1 + v1 * CV1 * tt1)^(-1/CV1)
    prob2 = ( 1 + v2 * CV2 * tt2)^(-1/CV2) 
    -(sum(dbinom(st1, st01, prob1, log = T)) + sum(dbinom(st2, st02, prob2, log = T)))
 }
</code></pre>

<p>The reason the first line looks so awful is because most of the data it takes is input there. <code>czI01</code>, for example, is already declared. I did this simply so that my later calls to the function don't all have to have awful vectors in them.</p>

<p>I then optimized for CV1, CV2, v1 and v2 using mle2 (library bbmle). That's also a bit gross looking, and looks like:</p>

<pre><code>ml.cz.diff = mle2 (NLLdiff, start=list(v1 = vguess, CV1 = cguess, v2 = vguess, CV2 = cguess), method=""""L-BFGS-B"""", lower = 0.0001)
</code></pre>

<p>Now, everything works fine up until here. ml.cz.diff gives me values that I can turn into a plot that reasonably fits my data. I also have several different models, and can get AICc values to compare them. However, when I try to get confidence intervals around v1, CV1, v2 and CV2 I have problems. Basically, I get a negative bound on CV1, which is impossible as it actually represents a square number in the biological model as well as some warnings.</p>

<p>Is there a better way to get confidence intervals? Or, really, a way to get confidence intervals that make sense here? </p>

<p>What I see happening is that, by coincidence, my hessian matrix is singular for some values in the optimization space. But, since I'm optimizing over 4 variables and don't have overly extensive programming knowledge, I can't come up with a good method of optimization that doesn't rely on the hessian. I have googled the problem - it suggested that my model's bad, but I'm reconstructing some work done before which suggests that my model's really not awful (the plots I make using the ml.cz.diff look like the plots of the original work). I have also read the relevant parts of the manual as well as Bolker's book <em>Ecological Models in R</em>. I have also tried different optimization methods, which resulted in a longer run time but the same errors. The """"SANN"""" method didn't finish running within an hour, so I didn't wait around to see the result.</p>

<p>In a nutshell: my confidence intervals are bad.  Is there a relatively straightforward way to fix them in R?</p>

<p>My vectors are: </p>

<pre><code>czT01 = c(5, 5, 5, 5, 5, 5, 5, 25, 25, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 50, 50)
czT02 = c(5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 50, 50, 50, 50, 50, 75, 75, 75, 75, 75)
czI01 = c(25, 24, 22, 22, 26, 23, 25, 25, 25, 23, 25, 18, 21, 24, 22, 23, 25, 23, 25, 25, 25)
czI02 = c(13, 16, 5, 18, 16, 13, 17, 22, 13, 15, 15, 22, 12, 12, 13, 13, 11, 19, 21, 13, 21, 18, 16, 15, 11)
czV01 = c(1, 4, 5, 5, 2, 3, 4, 11, 8, 1, 11, 12, 10, 16, 5, 15, 18, 12, 23, 13, 22)
czV02 = c(0, 3, 1, 5, 1, 6, 3, 4, 7, 12, 2, 8, 8, 5, 3, 6, 4, 6, 11, 5, 11, 1, 13, 9, 7)
</code></pre>

<p>and I get my guesses by:</p>

<pre><code>v = -log((c(czI01, czI02) - c(czV01, czV02))/c(czI01, czI02))/c(czT01, czT02)
vguess = mean(v)
cguess = var(v)/vguess^2
</code></pre>

<p>It's also possible that I'm doing something else completely wrong, but my results seem reasonable so I haven't caught it.</p>
",1
"<p>Not sure what I'm doing wrong here. I have this plot: </p>

<pre><code>ggplot(data.PE5, aes(ybands,fill=factor(decide))) + geom_bar(position=""""dodge"""") 
</code></pre>

<p>which produces: 
<img src=""""https://dl.dropbox.com/u/420874/colored.png""""></p>

<p>Then I want to facet by a factor, creating two stacked plots w/ dodged, colored bars</p>

<pre><code>ggplot(data.PE5, aes(ybands,fill=factor(decide))) + geom_bar(position=""""dodge"""") + 
facet_grid(~group_label) 
</code></pre>

<p>However, I lose the factor-based coloring, which I want to keep: </p>

<p><img src=""""https://dl.dropbox.com/u/420874/non_colored.png""""></p>
",1
"<p>I have a dataframe that I am putting into a <a href=""""http://www.stat.uni-muenchen.de/~leisch/Sweave/"""" rel=""""noreferrer"""">sweave</a> document using xtable, however one of my column names is quite long, and I would like to break it over two lines to save space</p>

<pre><code>calqc_table&lt;-structure(list(RUNID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ANALYTEINDEX = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), ID = structure(1:11, .Label = c(""""Cal A"""", """"Cal B"""", """"Cal C"""", 
""""Cal D"""", """"Cal E"""", """"Cal F"""", """"Cal G"""", """"Cal H"""", """"Cal High"""", """"Cal Low"""", 
""""Cal Mid""""), class = """"factor""""), mean_conc = c(200.619459644855, 
158.264703128903, 102.469121407733, 50.3551544728544, 9.88296440865076, 
4.41727762501703, 2.53494715706024, 1.00602831741361, 199.065054555735, 
2.48063347296935, 50.1499780776199), sd_conc = c(2.3275711264554, 
NA, NA, NA, NA, NA, NA, 0.101636943231162, 0, 0, 0), nrow = c(3, 
1, 1, 1, 1, 1, 1, 3, 2, 2, 2)), .Names = c(""""Identifier of the Run within the Study"""", """"ANALYTEINDEX"""", 
""""ID"""", """"mean_conc"""", """"sd_conc"""", """"nrow""""), row.names = c(NA, -11L
), class = """"data.frame"""")
calqc_xtable&lt;-xtable(calqc_table)
</code></pre>

<p>I have tried putting a newline into the name, but this didn't seem to work</p>

<pre><code>names(calqc_table)[1]&lt;-""""Identifier of the \nRun within the Study""""
</code></pre>

<p>Is there a way to do this ?  I have seen someone suggest using the latex function from the <a href=""""http://cran.r-project.org/web/packages/Hmisc/index.html"""" rel=""""noreferrer"""">hmisc</a> package to manually iterate over the table and write it out in latex manually, including the newline, but this seems like a bit of a faf !</p>
",1
"<p>I have attempted to email the author of this package without success,
just wondering if anybody else has experienced this.</p>

<p>I am having an using <code>rpart</code> on 4000 rows of data with 13 attributes.
I can run the same test on 300 rows of the same data with no issue.
When I run on 4000 rows, Rgui.exe runs consistently at 50% CPU and the
UI hangs; it will stay like this for at least 4-5hours if I let it
run, and never exit or become responsive.</p>

<p>here is the code I am using both on the 300 and 4000 size subset:</p>

<pre><code>train &lt;- read.csv(""""input.csv"""", header=T)
y &lt;- train[, 18]
x &lt;- train[, 3:17]
library(rpart)
fit &lt;- rpart(y ~ ., x)
</code></pre>

<p>Is this a known limitation of <code>rpart</code>, am I doing something wrong?
potential workarounds?</p>
",1
"<p>I have a big Sweave file with a variable called """"specialty"""" near the top. The rest of this file is Latex and R, and uses this variable.</p>

<p>How can I loop over various values for """"specialty""""?</p>

<p>Two possibilities are:</p>

<ol>
<li>Make the file be one big loop (and convert the Latex parts to R).</li>
<li>Write a script that copies the Sweave file, replace the value of """"specialty"""", and run Sweave on each copy.</li>
</ol>

<p>Can you comment on these ideas, or suggest better ones?</p>
",1
"<p>I need to colour datapoints that are outside of the the confidence bands on the plot below differently from those within the bands.  Should I add a separate column to my dataset to record whether the data points are within the confidence bands?  Can you provide an example please?</p>

<p><img src=""""https://lh3.ggpht.com/_NlGxmxSBXvU/S8-GODJ7j8I/AAAAAAAAAe0/2NME354m3lE/confidenceBands.jpg"""" alt=""""Plot with confidence bands""""></p>

<h1>Example dataset:</h1>

<pre><code>## Dataset from http://www.apsnet.org/education/advancedplantpath/topics/RModules/doc1/04_Linear_regression.html

## Disease severity as a function of temperature

# Response variable, disease severity
diseasesev&lt;-c(1.9,3.1,3.3,4.8,5.3,6.1,6.4,7.6,9.8,12.4)

# Predictor variable, (Centigrade)
temperature&lt;-c(2,1,5,5,20,20,23,10,30,25)

## For convenience, the data may be formatted into a dataframe
severity &lt;- as.data.frame(cbind(diseasesev,temperature))

## Fit a linear model for the data and summarize the output from function lm()
severity.lm &lt;- lm(diseasesev~temperature,data=severity)

# Take a look at the data
plot(
  diseasesev~temperature,
  data=severity,
  xlab=""""Temperature"""",
  ylab=""""% Disease Severity"""",
  pch=16,
  pty=""""s"""",
  xlim=c(0,30),
  ylim=c(0,30)
)
title(main=""""Graph of % Disease Severity vs Temperature"""")
par(new=TRUE) # don't start a new plot

## Get datapoints predicted by best fit line and confidence bands
## at every 0.01 interval
xRange=data.frame(temperature=seq(min(temperature),max(temperature),0.01))
pred4plot &lt;- predict(
                        lm(diseasesev~temperature),
                        xRange,
                        level=0.95,
                        interval=""""confidence""""
                    )

## Plot lines derrived from best fit line and confidence band datapoints
matplot(
  xRange,
  pred4plot,
  lty=c(1,2,2),   #vector of line types and widths
  type=""""l"""",       #type of plot for each column of y
  xlim=c(0,30),
  ylim=c(0,30),
  xlab="""""""",
  ylab=""""""""
)
</code></pre>
",1
"<p>I have two small data frames, <code>this_tx</code> and <code>last_tx</code>.  They are, in every way that I can tell, completely identical.  <code>this_tx</code> == <code>last_tx</code> results in a frame of identical dimensions, all <code>TRUE</code>.  <code>this_tx %in% last_tx</code>, two <code>TRUEs</code>.  Inspected visually, clearly identical.  But when I call</p>

<p><code>identical(this_tx, last_tx)</code></p>

<p>I get a <code>FALSE</code>.  Hilariously, even</p>

<p><code>identical(str(this_tx), str(last_tx))</code></p>

<p>will return a <code>TRUE</code>.  If I set <code>this_tx &lt;- last_tx</code>, I'll get a <code>TRUE</code>.</p>

<p>What is going on?  I don't have the deepest understanding of R's internal mechanics, but I can't find a single difference between the two data frames.  If it's relevant, the two variables in the frames are both factors - same levels, same numeric coding for the levels, both just subsets of the same original data frame.  Converting them to character vectors doesn't help.</p>

<p>Background (because I wouldn't mind help on this, either): I have records of drug treatments given to patients.  Each treatment record essentially specifies a person and a date.  A second table has a record for each drug and dose given during a particular treatment (usually, a few drugs are given each treatment).  I'm trying to identify contiguous periods during which the person was taking the same combinations of drugs at the same doses.</p>

<p>The best plan I've come up with is to check the treatments chronologically.  If the combination of drugs and doses for treatment[i] is identical to the combination at treatment[i-1], then treatment[i] is a part of the same phase as treatment[i-1].  Of course, if I can't compare drug/dose combinations, that's right out.</p>
",1
"<p>Is there a way to pass commands (from a shell) to an already running R-runtime/R-GUI, without copy and past.</p>

<p>So far I only know how to call R via shell with the <code>-f</code> or <code>-e</code> options, but in both cases a new R-Runtime will process the R-Script or R-Command I passed to it.</p>

<p>I rather would like to have an open R-Runtime waiting for commands passed to it via whatever connection is possible. </p>
",1
"<p>I'm posting this question to ask for advice on how to optimize the use of multiple processors from R on a Windows XP machine.</p>

<p>At the moment I'm creating 4 scripts (each script with e.g. for (i in 1:100) and (i in 101:200), etc) which I run in 4 different R sessions at the same time. This seems to use all the available cpu.</p>

<p>I however would like to do this a bit more efficient. One solution could be to use the """"doMC"""" and the """"foreach"""" package but this is not possible in R on a Windows machine.</p>

<p>e.g.</p>

<pre><code>library(""""foreach"""")
library(""""strucchange"""")
library(""""doMC"""") # would this be possible on a windows machine?
registerDoMC(2)  # for a computer with two cores (processors)
## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data(""""Nile"""")
plot(Nile)

## F statistics indicate one breakpoint
fs.nile &lt;- Fstats(Nile ~ 1)
plot(fs.nile)
breakpoints(fs.nile)     # , hpc = """"foreach"""" --&gt; It would be great to test this.
lines(breakpoints(fs.nile))
</code></pre>

<p>Any solutions or advice?</p>
",1
"<p>My program takes a data.frame and crunches the numbers. At one point, values from j-th column are multiplied by a predefined values that depends on the column name (species name, actually - it's en ecological index). So far, I've been providing these values via a second data.frame by matching column names. What would be an efficient way of integrating fixed variable values within a function? I would like my program to be as portable as possible, without the need for a second data.frame file.</p>

<p><em>EDIT</em></p>

<p>This is the function. I'm trying to improve the second line (index &lt;- read.table...) so that it would not depend on the outside source.</p>

<pre><code>macroIndex &lt;- function(obj, index) {
    index &lt;- read.table(""""conv.csv"""", header=T, dec="""","""")
    a &lt;- c()
    b &lt;- names(obj)
    for (i in 2:length(obj)) {
        obj[i] &lt;- obj[i] * index[which(index==b[i]), 2]
    }
    obj
}
</code></pre>

<p>Another solution I tried, while it may not seem pretty, it gets the job done. I use dput(index) and create a permanent object which I then insert into my function.</p>
",1
"<p>I am sorry for the non-informative title. </p>

<pre><code>&gt; y=read.csv(textConnection(scan("""""""",sep=""""\n"""",what=""""raw"""")))
"""""""",""""org"""",""""art"""",""""type"""",""""length""""
""""191"""",""""gk"""",""""Finish"""",""""short"""",4
""""147"""",""""ik"""",""""Attending"""",""""short"""",7
""""175"""",""""gl"""",""""Finish"""",""""long"""",11
""""192"""",""""il"""",""""Attending"""",""""long"""",95
""""144"""",""""gm"""",""""Finish"""",""""between"""",5
""""161"""",""""im"""",""""Attending"""",""""between"""",15
""""164"""",""""tu"""",""""Something"""",""""young"""",8
""""190"""",""""tv"""",""""Something"""",""""old"""",4

&gt; decompress=function(x)x[rep(1:nrow(x),x$length),-ncol(x)]
&gt; exstatus=decompress(y)
</code></pre>

<p>and then the plot</p>

<pre><code>ggplot(exstatus, aes(x=type, fill=art))+
geom_bar(aes(y=..count../sum(..count..)),position=""""dodge"""")
</code></pre>

<p>The problem is that the two rightmost bars (""""young"""", """"old"""") are too thick - """"something"""" takes up the whole width - which is not what I intended. </p>

<p><a href=""""http://www.imagechicken.com/uploads/1272295176088679800.png"""" rel=""""nofollow noreferrer"""">alt text http://www.imagechicken.com/uploads/1272295176088679800.png</a></p>

<p>I am sorry that I can not explain it better. </p>
",1
"<p>In ESS when I am evaluating chunks of code in a .R file using C-c C-j or C-c C-r (to send the line or region to a running R process), how can I get the R buffer to scroll down automatically, such that after evaluating a region the cursor is at the bottom, at the prompt?</p>

<p>Thanks.</p>
",1
"<p>Having installed canvas from here <a href=""""http://www.rforge.net/canvas/files/"""" rel=""""nofollow noreferrer"""">http://www.rforge.net/canvas/files/</a></p>

<p>I try to plot:</p>

<pre><code>&gt; canvas('test.js')
&gt; qplot(rnorm(100), geom='histogram')
stat_bin: binwidth defaulted to range/30. Use 'binwidth = x' to adjust this.
Error in grid.Call.graphics(""""L_setviewport"""", pvp, TRUE) : 
  Non-finite location and/or size for viewport
&gt; 
</code></pre>
",1
"<p>Many data analysts that I respect use version control.
For example: </p>

<ul>
<li><a href=""""http://github.com/hadley/"""" rel=""""noreferrer"""">http://github.com/hadley/</a></li>
<li>See comments on <a href=""""http://permut.wordpress.com/2010/04/21/revision-control-statistics-bleg/"""" rel=""""noreferrer"""">http://permut.wordpress.com/2010/04/21/revision-control-statistics-bleg/</a></li>
</ul>

<p>However, I'm evaluating whether adopting a version control system such as git would be worthwhile.</p>

<p><b>A brief overview:</b>
I'm a social scientist who uses R to analyse data for research publications.
I don't currently produce R packages.
My R code for a project typically includes a few thousand lines of code for data input, cleaning, manipulation, analyses, and output generation.
Publications are typically written using LaTeX.</p>

<p>With regards to version control there are many benefits which I have read about, yet they seem to be less relevant to the solo data analyst.</p>

<ul>
<li><b>Backup:</b> I have a backup system already in place. </li>
<li><b>Forking and rewinding:</b> I've never felt the need to do this, 
   but I can see how it could be useful (e.g., you are preparing multiple 
  journal articles based on the same dataset; you are preparing a report 
  that is updated monthly, etc)</li>
<li><b>Collaboration:</b> Most of the time I am
analysing data myself, thus, I
wouldn't get the collaboration
benefits of version control.</li>
</ul>

<p>There are also several potential costs involved with adopting version control:</p>

<ul>
<li>Time to evaluate and learn a version control system</li>
<li>A possible increase in complexity over my current file management system</li>
</ul>

<p>However, I still have the feeling that I'm missing something.
General guides on version control seem to be addressed more towards computer scientists than data analysts.</p>

<p>Thus, specifically <b>in relation to data analysts</b> in circumstances similar to those listed above:</p>

<ol>
<li>Is version control worth the effort?</li>
<li>What are the main pros and cons of adopting version control? </li>
<li>What is a good strategy for getting started with version control
 for data analysis with R (e.g., examples, workflow ideas, software, links to guides)?</li>
</ol>
",1
"<p>In <strong>R</strong>, I'm looking for a memory-efficient way to create a summary of tabular data as follows.</p>

<p>Take for example the <code>data.frame</code> <code>foo</code> which I've used <code>table()</code> to summarize, followed by <code>as.data.frame()</code> to obtain the frequency counts.</p>

<pre><code>foo &lt;- data.frame(x= c('a', 'a', 'a', 'b', 'b', 'b'), y=c('ab', 'ac', 'ad', 'ae', 'fx', 'fy'))
bar &lt;- as.data.frame(table(foo), stringsAsFactors=F)
</code></pre>

<p>This results in the following frequency count for <code>bar</code></p>

<pre><code>   x  y Freq
1  a ab    1
2  b ab    0
3  a ac    1
4  b ac    0
5  a ad    1
6  b ad    0
7  a ae    0
8  b ae    1
9  a fx    0
10 b fx    1
11 a fy    0
12 b fy    1
</code></pre>

<p>The problem I'm running into is when there are many levels of <code>x</code> and <code>y</code>, it starts using up significant amounts of memory >64 GB.  I was wondering if there was an alternative way of doing this kind of frequency count.  As a first step, I set <code>stringsAsFactors=F</code>, however this doesn't completely solve the problem.</p>
",1
"<p>I'm using the quantmod package to import financial series data from Yahoo.</p>

<pre><code>library(quantmod)
getSymbols(""""^GSPC"""")
[1] """"GSPC""""
</code></pre>

<p>I'd like to change the name of object """"GSPC"""" to """"SPX"""". I've tried the rename function in the reshape package, but it only changes the variable names. The """"GSPC"""" object has vectors GSPC.Open, GSPC.High, etc. I'd like my renaming of """"GSPC"""" to """"SPX"""" to also change GSPC.Open to SPX.Open and so on.</p>
",1
"<p>I am trying to get around the strange overlap of <code>stats::reorder</code> vs <code>Hmisc::reorder</code>.</p>

<p>Without <code>Hmisc</code> loaded I get the result I want, i.e. an unordered factor:</p>

<pre><code>&gt; with(InsectSprays, reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
attr(,""""scores"""")
   A    B    C    D    E    F 
14.0 16.5  1.5  5.0  3.0 15.0 
Levels: C E D A F B
</code></pre>

<p>Now after loading <code>Hmisc</code> the result is an ordered factor:</p>

<pre><code>&gt; library(Hmisc)
Loading required package: survival
Loading required package: splines

Attaching package: 'Hmisc'

The following object(s) are masked from 'package:survival':

    untangle.specials

The following object(s) are masked from 'package:base':

    format.pval, round.POSIXt, trunc.POSIXt, units

&gt; with(InsectSprays, reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
Levels: C &lt; E &lt; D &lt; A &lt; F &lt; B
</code></pre>

<p>In calling <code>stats::reorder</code> directly, I now for some reason get an ordered factor.</p>

<pre><code>&gt; with(InsectSprays, stats::reorder(spray, count, median))
 [1] A A A A A A A A A A A A B B B B B B B B B B B B C C C C C C C C C C C C D D
[39] D D D D D D D D D D E E E E E E E E E E E E F F F F F F F F F F F F
Levels: C &lt; E &lt; D &lt; A &lt; F &lt; B
</code></pre>

<p>Specifying, that I would need an unordered factor results in an error suggesting that <code>stats::reorder</code> is not used?</p>

<pre><code>&gt; with(InsectSprays, stats::reorder(spray, count, median, order = FALSE))
Error in FUN(X[[1L]], ...) : unused argument(s) (order = FALSE)
</code></pre>

<p>So the question really is <strong>how do I get an unordered factor with Hmisc loaded?</strong></p>
",1
"<p>I'm looking to suppress the output of <strong>one</strong> command (in this case, the <code>apply</code> function).</p>

<p>Is it possible to do this without using <code>sink()</code>?  I've found the described solution below, but would like to do this in one line if possible.</p>

<p><a href=""""https://stackoverflow.com/questions/2501895/how-to-suppress-output-in-r"""">How to suppress output</a></p>
",1
"<p>I just installed R 2.11.0-x64 onto my Windows 7 Professional machine.</p>

<p>With my previous installations of R (2.10.1 32 bit was the most recent) the little icon that appeared in the title bar and in the taskbar at the bottom of windows was the R """"R.""""  Now however, the icon almost looks like a small windows Task Manager.</p>

<p>I know this isn't a code issue, but it affects me as I flip between windows.</p>

<p>Is there a way to put the """"R"""" icon back in there?  Would it be an R setting or a Windows setting?</p>
",1
"<p>I'm going to use the sample code from <a href=""""http://gettinggeneticsdone.blogspot.com/2009/11/split-apply-and-combine-in-r-using-plyr.html"""" rel=""""nofollow noreferrer"""">http://gettinggeneticsdone.blogspot.com/2009/11/split-apply-and-combine-in-r-using-plyr.html</a> for this example.  So, first, let's copy their example data:</p>

<pre><code>mydata=data.frame(X1=rnorm(30), X2=rnorm(30,5,2),
SNP1=c(rep(""""AA"""",10), rep(""""Aa"""",10), rep(""""aa"""",10)),
SNP2=c(rep(""""BB"""",10), rep(""""Bb"""",10), rep(""""bb"""",10)))
</code></pre>

<p>I am going to ignore SNP2 in this example and just pretend the values in SNP1 denote group membership.  So then, I may want some summary statistics about each group in SNP1: """"AA"""", """"Aa"""", """"aa"""".</p>

<p>Then if I want to calculate the means for each variable, it makes sense (modifying their code slightly) to use:</p>

<pre><code>&gt; ddply(mydata, c(""""SNP1""""), function(df)
data.frame(meanX1=mean(df$X1), meanX2=mean(df$X2)))
  SNP1      meanX1   meanX2
1   aa  0.05178028 4.812302
2   Aa  0.30586206 4.820739
3   AA -0.26862500 4.856006
</code></pre>

<p>But what if I want the sample covariance matrix for each group? Ideally, I would like a 3D array, where the I have the covariance matrix for each group, and the third dimension denotes the corresponding group. I tried a modified version of the previous code and got the following results that have convinced me that I'm doing something wrong.</p>

<pre><code>&gt; daply(mydata, c(""""SNP1""""), function(df) cov(cbind(df$X1, df$X2)))
, ,  = 1


SNP1         1          2
  aa 1.4961210 -0.9496134
  Aa 0.8833190 -0.1640711
  AA 0.9942357 -0.9955837

, ,  = 2


SNP1          1        2
  aa -0.9496134 2.881515
  Aa -0.1640711 2.466105
  AA -0.9955837 4.938320
</code></pre>

<p>I was thinking that the dim() of the 3rd dimension would be 3, but instead, it is 2. Really this is a sliced up version of the covariance matrix for each group.  If we manually compute the sample covariance matrix for aa, we get:</p>

<pre><code>           [,1]       [,2]
[1,]  1.4961210 -0.9496134
[2,] -0.9496134  2.8815146
</code></pre>

<p>Using plyr, the following gives me what I want in list() form:</p>

<pre><code>&gt; dlply(mydata, c(""""SNP1""""), function(df) cov(cbind(df$X1, df$X2)))
$aa
           [,1]       [,2]
[1,]  1.4961210 -0.9496134
[2,] -0.9496134  2.8815146

$Aa
           [,1]       [,2]
[1,]  0.8833190 -0.1640711
[2,] -0.1640711  2.4661046

$AA
           [,1]       [,2]
[1,]  0.9942357 -0.9955837
[2,] -0.9955837  4.9383196

attr(,""""split_type"""")
[1] """"data.frame""""
attr(,""""split_labels"""")
  SNP1
1   aa
2   Aa
3   AA
</code></pre>

<p>But like I said earlier, I would really like this in a 3D array. Any thoughts on where I went wrong with daply() or suggestions? Of course, I could typecast the list from dlply() to a 3D array, but I'd rather not do this because I will be repeating this process many times in a simulation.</p>

<p>As a side note, I found one method (<a href=""""http://www.mail-archive.com/r-help@r-project.org/msg86328.html"""" rel=""""nofollow noreferrer"""">http://www.mail-archive.com/r-help@r-project.org/msg86328.html</a>) that provides the sample covariance matrix for each group, but the outputted object is bloated. </p>

<p>Thanks in advance.</p>
",1
"<p>I want to have a sweave document that will include a variable number of tables in.  I thought the example below would work, but it doesn't.  I want to loop over the list foo and print each element as it's own table.</p>

<pre><code>% 
\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{longtable}
\usepackage{geometry}
\usepackage{Sweave}
\geometry{left=1.25in, right=1.25in, top=1in, bottom=1in}
\listfiles
\begin{document}

&lt;&lt;label=start, echo=FALSE, include=FALSE&gt;&gt;=
startt&lt;-proc.time()[3]
library(RODBC)
library(psych)
library(xtable)
library(plyr)
library(ggplot2)
options(width=80)

#Produce some example data, here I'm creating some dummy dataframes and putting them in a list
foo&lt;-list()
foo[[1]]&lt;-data.frame(GRP=c(rep(""""AA"""",10), rep(""""Aa"""",10), rep(""""aa"""",10)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[2]]&lt;-data.frame(GRP=c(rep(""""BB"""",10), rep(""""bB"""",10), rep(""""BB"""",10)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[3]]&lt;-data.frame(GRP=c(rep(""""CC"""",12), rep(""""cc"""",18)), X1=rnorm(30), X2=rnorm(30,5,2))
foo[[4]]&lt;-data.frame(GRP=c(rep(""""DD"""",10), rep(""""Dd"""",10), rep(""""dd"""",10)), X1=rnorm(30), X2=rnorm(30,5,2))
@ 

\title{Docuemnt to test putting a variable number of tables into a sweave Document}
\author{""""Paul Hurley""""}
\maketitle

\section{Text}

This document was created on \today, with \Sexpr{print(version$version.string)} running
 on a \Sexpr{print(version$platform)} platform. It took approx \input{time} sec to process.

&lt;&lt;label=test, echo=FALSE, results=tex&gt;&gt;= 
cat(""""Foo"""")
@ 
that was a test, so is this
&lt;&lt;label=table1test, echo=FALSE, results=tex&gt;&gt;=
print(xtable(foo[[1]]))
@ 
\newpage

\subsection{Tables}

&lt;&lt;label=Tables, echo=FALSE, results=tex&gt;&gt;=
for(i in seq(foo)){
    cat(""""\n"""")
    cat(paste(""""Table_"""",i,sep=""""""""))
    cat(""""\n"""")
    print(xtable(foo[[i]]))
    cat(""""\n"""")
    }
#cat(""""&lt;&lt;label=endofTables&gt;&gt;= """")
@ 


&lt;&lt;label=bye, include=FALSE, echo=FALSE&gt;&gt;= 
endt&lt;-proc.time()[3]
elapsedtime&lt;-as.numeric(endt-startt)
@ 
&lt;&lt;label=elapsed, include=FALSE, echo=FALSE&gt;&gt;=
fileConn&lt;-file(""""time.tex"""", """"wt"""") 
writeLines(as.character(elapsedtime), fileConn) 
close(fileConn) 
@ 

\end{document}
</code></pre>

<p>Here, the table1test chunk works as expected, and produced a table based on the dataframe in foo[[1]], however the loop only produces Table(underscore)1....</p>
",1
"<p>I have a list called <code>cols</code> with column names in it:</p>

<p><code>cols &lt;- c('Column1','Column2','Column3')</code></p>

<p>I'd like to reproduce this command, but with a call to the list:</p>

<p><code>data.frame(Column1=rnorm(10))</code></p>

<p>Here's what happens when I try it:</p>

<p><code>&gt; data.frame(cols[1]=rnorm(10))</code></p>

<p><code>Error: unexpected '=' in """"data.frame(I(cols[1])=""""</code></p>

<p>The same thing happens if I wrap <code>cols[1]</code> in <code>I()</code> or <code>eval()</code>.</p>

<p>How can I feed that item from the vector into the <code>data.frame()</code> command?</p>

<p><strong>Update:</strong></p>

<p>For some background, I have defined a function <code>calc.means()</code> that takes a data frame and a list of variables and performs a large and complicated ddply operation, summarizing at the level specified by the variables. </p>

<p>What I'm trying to do with the <code>data.frame()</code> command is walk back up the aggregation levels to the very top, re-running <code>calc.means()</code> at each step and using <code>rbind()</code> to glue the results onto one another. I need to add dummy columns with 'All' values in order to get the rbind to work properly. </p>

<p>I'm rolling <code>cast</code>-like margin functionality into ddply, basically, and I'd like to not retype the column names for each run. Here's the full code:</p>

<pre><code>cols &lt;- c('Col1','Col2','Col3')
rbind ( calc.means(dat,cols),
    data.frame(cols[1]='All', calc.means(dat, cols[2:3])),
    data.frame(cols[1]='All', cols[2]='All', calc.means(dat, cols[3]))
)
</code></pre>
",1
"<p>Why do these two cases behave differently?</p>

<pre><code>&gt;substitute(c1&lt;-100,list(c1=100))
100 &lt;- 100
</code></pre>

<p>vs</p>

<pre><code>&gt; substitute(c1=100,list(c1=100))
[1] 100
</code></pre>
",1
"<pre><code>data &lt;- read.delim(""""C:\\test.txt"""", header = FALSE, sep = """"$$$$$"""")
Error in scan(file, what = """""""", sep = sep, quote = quote, nlines = 1, quiet = TRUE,  : 
  invalid 'sep' value: must be one byte
</code></pre>

<p>Why there is a restriction like this? Can I overcome it?</p>
",1
"<p>A tab-delimited text file, which is actually an export (using bcp) of a database table, is of that form (first 5 columns):</p>

<pre><code>102 1   01  e113c   3224.96     12  
102 1   01  e185    101127.25   12
102 2   01  e185    176417.90   12
102A   3    01  e185    26261.03    12
</code></pre>

<p>I tried to import it in R with a command like </p>

<pre><code>data &lt;- read.delim(""""C:\\test.txt"""", header = FALSE, sep = """"\t"""")
</code></pre>

<p>The problem is that the 3rd column which is actually a varchar field (alphanumeric) is mistakenly read as integer (as there are no letters in the entire column) and the leading zeros disappeared. The same thing happened when I imported the data directly from the database, using odbcConnect. Again that column was read as integer.</p>

<pre><code>str(data)
$ code: int  1 1 1 1 1 1 6 1 1 8 ...
</code></pre>

<p>How can I import such a dataset in R correctly, so as to be able to safely populate that db table again, after doing some data manipulations?</p>

<p><strong>EDIT</strong></p>

<p>I did it adding the following parameter in read.delim</p>

<pre><code> colClasses = c(""""factor"""",""""integer"""",""""factor"""",""""factor"""",""""numeric"""",""""character"""",""""factor"""",""""factor"""",""""factor"""",""""factor"""",""""integer"""",""""character"""",""""factor"""")
</code></pre>

<ul>
<li><p>Would you suggest """"character"""" or """"factor"""" for varchar fields?</p></li>
<li><p>Is it ok to use """"character"""" for datetime ones?</p></li>
<li><p>What should I do in order to be able to read a numeric field like this 540912.68999999994 exactly as is and not as 540912.69?</p></li>
</ul>

<p>I would like an -as automatic as possible- creation of that <code>colClasses</code> vector, depending on the datatypes defined in the relevant table's schema. </p>
",1
"<p>Suppose I have a named vector, <code>bar</code>:</p>

<pre><code>bar=c()
bar[""""1997-10-14""""]=1
bar[""""2001-10-14""""]=2
bar[""""2007-10-14""""]=1
</code></pre>

<p>How can I select from <code>bar</code> all values for which the index is within a specific date range? So, if I look for all values between <code>""""1995-01-01""""</code> and <code>""""2000-06-01""""</code>, I should get <code>1</code>. And similarly for the period between <code>""""2001-09-01""""</code> and <code>""""2007-11-04""""</code>, I should get <code>2</code> and <code>1</code>.</p>
",1
"<p>I'm writing a R package (<a href=""""https://r-forge.r-project.org/projects/delftfews/"""" rel=""""nofollow noreferrer""""><code>delftfews</code></a>) here at office.  we are using <a href=""""https://r-forge.r-project.org/projects/sciviews"""" rel=""""nofollow noreferrer""""><code>svUnit</code></a> for unit testing. </p>

<p>our process for describing new functionality: we define new unit tests, initially marked as <code>DEACTIVATED</code>; one block of tests at a time we activate them and implement the function described by the tests.  almost all the time we have a small amount of DEACTIVATED tests, relative to functions that might be dropped or will be implemented.</p>

<p>my problem/question is: can I alter the <a href=""""http://rwiki.sciviews.org/doku.php?id=developers:runit#another_approach_using_svunit"""" rel=""""nofollow noreferrer"""">doSvUnit.R</a> so that <code>R CMD check pkg</code> emits a NOTE (i.e. a custom message """"NOTE"""" instead of """"OK"""") in case there are DEACTIVATED tests?  </p>

<p>as of now, we see only that the active tests don't give error:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running doSvUnit.R
 OK
* checking PDF version of manual ... OK
</code></pre>

<p>which is all right if all tests succeed, but less all right if there are skipped tests and definitely wrong if there are failing tests.  In this case, I'd actually like to see a NOTE or a WARNING like the following:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running doSvUnit.R
 NOTE
6 test(s) were skipped.
 WARNING
1 test(s) are failing.
* checking PDF version of manual ... OK
</code></pre>

<p>As of now, we have to open the <code>doSvUnit.Rout</code> to check the real test results.</p>

<hr>

<p>I contacted two of the maintainers at r-forge and CRAN and they pointed me to the <a href=""""https://svn.r-project.org/R/trunk/"""" rel=""""nofollow noreferrer"""">sources of R</a>, in particular the <a href=""""https://svn.r-project.org/R/trunk/src/library/tools/R/testing.R"""" rel=""""nofollow noreferrer""""><code>testing.R</code></a> script.</p>

<p>if I understand it correctly, to answer this question we need patching the <code>tools</code> package: </p>

<ul>
<li>scripts in the tests directory are called using a <code>system</code> call,</li>
<li>output (stdout and stderr) go to one single file,</li>
<li>there are two possible outcomes: <strong>ok</strong> or <strong>not ok</strong>,</li>
</ul>

<p>so I opened a <a href=""""https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14702"""" rel=""""nofollow noreferrer"""">change request</a> on R, proposing something like bit-coding the return status, bit-0 for ERROR (as it is now), bit-1 for WARNING, bit-2 for NOTE.  </p>

<p>with my modification, it would be easy producing this output:</p>

<pre><code>.
.
* checking for unstated dependencies in tests ... OK
* checking tests ...
  Running doSvUnit.R
 NOTE - please check doSvUnit.Rout.
 WARNING - please check doSvUnit.Rout.
* checking PDF version of manual ... OK
</code></pre>

<hr>

<p>Brian Ripley replied """"There are however several packages with properly written unit tests
that do signal as required. Please do take this discussion elsewhere: R-bugs is not the place to ask
questions."""" and closed the change request.</p>

<hr>

<p>anybody has hints?</p>
",1
"<p>In Emacs, I'm working with a file that is a hybrid of two languages.</p>

<p><strong>Question 1: Is there a simple way to write a major mode file that combines two major modes?</strong></p>

<p>Details:</p>

<ul>
<li><p>The language is called """"brew"""" (not the """"BREW"""" of """"Binary Runtime Environment for Wireless"""").</p></li>
<li><p>brew is made up of the languages R and Latex, whose modes are R-mode and latex-mode.</p></li>
<li><p>The R code appears between the tags &lt;% and %>. Everything else is Latex.</p></li>
<li><p>How can I write a brew-mode.el file? (Or is one already available?)</p></li>
</ul>

<p>One idea, which I got from this <a href=""""http://mail-archives.apache.org/mod_mbox/perl-modperl/200002.mbox/%3CNDBBIDIMBKMLMLLCGCNAEEFPCBAA.jreid@ocireland.com%3E"""" rel=""""nofollow noreferrer"""">posting</a>, is to use Latex mode, and treat the code of the form  &lt;% ... %> as a comment.</p>
",1
"<p>checkException will validate if meeting a stop() call, but not a warning() call. 
Is there a workaround or hack to check for warnings? (and make them silent during testing)</p>

<p>thanks </p>
",1
"<p>Dear StackOverFlowers (flowers in short),</p>

<p>I have a list of data.frames (walk.sample) that I would like to collapse into a single (giant) data.frame. While collapsing, I would like to mark (adding another column) which rows have came from which element of the list. This is what I've got so far.</p>

<p>This is the data.frame that needs to be collapsed/stacked.</p>

<pre><code>&gt; walk.sample
[[1]]
     walker        x         y
1073      3 228.8756 -726.9198
1086      3 226.7393 -722.5561
1081      3 219.8005 -728.3990
1089      3 225.2239 -727.7422
1032      3 233.1753 -731.5526

[[2]]
     walker        x         y
1008      3 205.9104 -775.7488
1022      3 208.3638 -723.8616
1072      3 233.8807 -718.0974
1064      3 217.0028 -689.7917
1026      3 234.1824 -723.7423

[[3]]
[1] 3

[[4]]
     walker        x         y
546       2 629.9041  831.0852
524       2 627.8698  873.3774
578       2 572.3312  838.7587
513       2 633.0598  871.7559
538       2 636.3088  836.6325
1079      3 206.3683 -729.6257
1095      3 239.9884 -748.2637
1005      3 197.2960 -780.4704
1045      3 245.1900 -694.3566
1026      3 234.1824 -723.7423
</code></pre>

<p>I have written a function to add a column that denote from which element the rows came followed by appending it to an existing data.frame.</p>

<pre><code>collapseToDataFrame &lt;- function(x) { # collapse list to a dataframe with a twist
    walk.df &lt;- data.frame()
    for (i in 1:length(x)) {
        n.rows &lt;- nrow(x[[i]])
        if (length(x[[i]])&gt;1) {
            temp.df &lt;- cbind(x[[i]], rep(i, n.rows))
            names(temp.df) &lt;- c(""""walker"""", """"x"""", """"y"""", """"session"""")
            walk.df &lt;- rbind(walk.df, temp.df)
        } else {
            cat(""""Empty list"""", """"\n"""")
        }
    }
    return(walk.df)
}


&gt; collapseToDataFrame(walk.sample)
Empty list 
Empty list 
     walker         x          y session
3         1 -604.5055 -123.18759       1
60        1 -562.0078  -61.24912       1
84        1 -594.4661  -57.20730       1
9         1 -604.2893 -110.09168       1
43        1 -632.2491  -54.52548       1
1028      3  240.3905 -724.67284       1
1040      3  232.5545 -681.61225       1
1073      3  228.8756 -726.91980       1
1091      3  209.0373 -740.96173       1
1036      3  248.7123 -694.47380       1
</code></pre>

<p>I'm curious whether this can be done more elegantly, with perhaps do.call() or some other more generic function?</p>
",1
"<p>Is there a way to determine if a function generates a figure in <strong>R</strong>?</p>

<p>For example, if we have functions <em>f</em> and <em>g</em></p>

<pre><code>f = function(x,y){plot(x,y)}
g = function(x,y){mean(x*y)}
</code></pre>

<p>I would like able to run </p>

<pre><code>createFigure(f(x,y))#Returns TRUE
createFigure(g(x,y))#Returns FALSE
</code></pre>

<p>Thanks</p>
",1
"<p>I have a data.frame with 3 time series in it, shown below.   When I plot them with a smoother time series, I want to be able to get the parameters of the linear model that I plot, but I can't see how to do that?  </p>

<pre><code>   &gt; data
   day   od series_id
    1    1 0.10        A1
    2    3 1.00        A1
    3    5 0.50        A1
    4    7 0.70        A1
    5    1 1.70        B1
    6    3 1.60        B1
    7    5 1.75        B1
    8    7 1.70        B1
    9    1 2.10        C1
    10   3 2.30        C1
    11   5 2.50        C1
    12   7 2.70        C1

    data = data.frame (day = c(1,3,5,7,1,3,5,7,1,3,5,7), 
    od = c(0.1,1.0,0.5,0.7 ,1.7,1.6,1.75,1.7 ,2.1,2.3,2.5,2.7), 
    series_id = c(""""A1"""", """"A1"""", """"A1"""",""""A1"""", """"B1"""", """"B1"""",""""B1"""", """"B1"""", """"C1"""",""""C1"""", """"C1"""", """"C1""""))

    r &lt;- ggplot(data = data, aes(x = day, y = od))
    r + stat_smooth(aes(group = series_id, color = series_id),method=""""lm"""")   
</code></pre>
",1
"<p>I'm looking for something similar in form to weighted.mean().  Sorry for posting such a banal question...  new to R.  I've found some solutions via search that write out the entire function but would appreciate something a bit more user friendly.</p>
",1
"<p>Is there any IDE -from the ones supporting R-, that gives access to the command history (at least to the current session's commands)? Or is there a way to get a (character or expression) vector with those commands in R?  </p>

<p>For those of you that have been using MATLAB, I mean something like the <a href=""""http://www.mathworks.com/access/helpdesk/help/techdoc/matlab_env/command_history_overview.gif"""" rel=""""noreferrer"""">Command History</a> window there..</p>

<p>Thank you </p>
",1
"<p>I am trying to create a huge matrix in ff, and I know that ff is good for this sort of thing. </p>

<p>But, there is a major problem. The dimensions of the matrix exceed .Machine$max_integer! I am running on a 64 bit machine, using 64bit R and 64bit ff. </p>

<p>Is there any way to get around this problem? </p>

<p>It's been suggested that R is using the MAXINT value from stdint.h. Is there any way to fix this without changing that file and possibly breaking build?</p>

<pre><code>&gt; ffMatrix &lt;- ff(vmode=""""boolean"""", dim=c(300000,300000))
Error in if (length &lt; 0 || length &gt; .Machine$integer.max) stop(""""length must be between 1 and .Machine$integer.max"""") : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In ff(vmode = """"boolean"""", dim = c(300000, 300000)) :
  NAs introduced by coercion

&gt; 300000**2 &gt; .Machine$integer.max
[1] TRUE
</code></pre>
",1
"<p>I'm wondering how I can manipulate the size of strip text in facetted plots. My question
is similar to <a href=""""https://stackoverflow.com/questions/2631780/r-ggplot2-can-i-set-the-plot-title-to-wrap-around-and-shrink-the-text-to-fit-th"""">a question on plot titles</a>, but I'm specifically concerned with
manipulating not the plot title but the text that appears in facet titles (strip_h).</p>

<p>As an example, consider the mpg dataset.</p>

<pre><code>    library(ggplot2) 
    qplot(hwy, cty, data = mpg) + facet_grid( . ~ manufacturer)
</code></pre>

<p>The resulting <a href=""""http://skitch.com/capbri/dbx1n/quartz-2"""" rel=""""nofollow noreferrer"""">output</a> produces some facet titles that don't fit in the strip.</p>

<p>I'm thinking there must be a way to use <code>grid</code> to deal with the strip text. But I'm
still a novice and wasn't sure from the <code>grid</code> appendix in <a href=""""http://rads.stackoverflow.com/amzn/click/0387981403"""" rel=""""nofollow noreferrer"""">Hadley's book</a> how,
precisely, to do it. Also, I was afraid if I did it wrong it would break my washing
machine, since I believe all technology is connected through The Force :-(</p>

<p>Many thanks in advance.</p>
",1
"<p>I am looking for something like the 'msm' package, but for discrete Markov chains. For example, if I had a transition matrix defined as such</p>

<pre><code>Pi &lt;- matrix(c(1/3,1/3,1/3,
0,2/3,1/6,
2/3,0,1/2))
</code></pre>

<p>for states A,B,C. How can I simulate a Markov chain according to that transition matrix?</p>

<p>Thanks,</p>
",1
"<p>The x-axis is time broken up into time intervals.  There is an <em>interval</em> column in the data frame that specifies the time for each row.  The column is a factor, where each interval is a different factor level.</p>

<p>Plotting a histogram or line using geom_histogram and geom_freqpoly works great, but I'd like to have a line, like that provided by geom_freqpoly, with the area filled.</p>

<p>Currently I'm using geom_freqpoly like this:</p>

<pre><code>ggplot(quake.data, aes(interval, fill=tweet.type)) + geom_freqpoly(aes(group = tweet.type, colour = tweet.type)) + opts(axis.text.x=theme_text(angle=-60, hjust=0, size = 6))
</code></pre>

<p><img src=""""https://i.stack.imgur.com/ZFSUV.png"""" alt=""""plots""""></p>

<p>I would prefer to have a filled area, such as provided by <code>geom_density</code>, but without smoothing the line:</p>

<p><img src=""""https://i.stack.imgur.com/JKCj5.png"""" alt=""""smoooth""""></p>

<p>The <code>geom_area</code> has been suggested, is there any way to use a ggplot2-generated statistic, such as ..count.., for the geom_area's y-values?  Or, does the count aggregation need to occur prior to using ggplot2?</p>

<hr>

<p>As stated in the answer, geom_area(..., stat = """"bin"""") is the solution: </p>

<pre><code>ggplot(quake.data, aes(interval)) + geom_area(aes(y = ..count.., fill = tweet.type, group = tweet.type), stat = """"bin"""") + opts(axis.text.x=theme_text(angle=-60, hjust=0, size = 6))
</code></pre>

<p>produces:</p>

<p><img src=""""https://i.stack.imgur.com/leK6T.png"""" alt=""""desired""""> </p>
",1
"<p>My apologies if this is more of a statistics question than an R question. I am trying to estimate the following model in R.</p>

<p>y_t = mu0 (1 - S_t) + mu1 S_t + e_t    e_t ~ N(0, sigma_t^2)
sigma_t^2 = sigma_0^2 (1 - S_t) + sigma_1^2 S_t</p>

<p>where mu_t = mu0 if S_t = 0, mu_t = mu1 if S_t = 1, and S_t is a Markov process, either 0 or 1, with transition probabilities P(S_t = 1 | S_t-1 = 1 ) = p and P(S_t = 0 | S_t-1 = 0 ) = q.</p>

<p>Would 'flexmix' be a good library to use for this? I am new to this kind of statistics so any pointer to the right library would be appreciated.</p>

<p>Thanks,</p>
",1
"<p>Say I make a scatterplot with thousands of points:</p>

<pre><code>ggplot(head(data, n=2000), aes(length, coverage))+ 
    geom_point(alpha = 0.5, color = 'navyblue')  + coord_trans(x='log', y='log')
</code></pre>

<p><a href=""""http://fourmidable.unil.ch/temp/scatterplot.png"""" rel=""""nofollow noreferrer"""">alt text http://fourmidable.unil.ch/temp/scatterplot.png</a></p>

<p>I want to add the labels of """"the 20 or so most extreme points"""" (in the upper right and bottom right corners). They are easy to identify visually. But getting at them programatically seems a bit of a burden. (requiring many if statements).</p>

<p>Is there any way I can click on R's graphic output to obtain their precise coordinates?</p>

<p>Thanks,
yannick</p>
",1
"<p>Can someone explain why levels() shows three factor levels, while you can see that the vector has only two?</p>

<pre><code>&gt; str(walk.df)
'data.frame':   10 obs. of  4 variables:
 $ walker : Factor w/ 3 levels """"1"""",""""2"""",""""3"""": 1 1 1 1 1 2 2 2 2 2

&gt; walk.df$walker
 [1] 1 1 1 1 1 2 2 2 2 2
Levels: 1 2 3
</code></pre>

<p>I would like to extract a vector of levels, and I thought this was the proper way, but as you can see, a three sneaks in there which is messing up my function.</p>

<pre><code>&gt; as.numeric(levels(walk.df$walker))
[1] 1 2 3
</code></pre>
",1
"<p>Is it possible to use the R package 'RGL' in x64 Windows?</p>

<p><a href=""""http://r-forge.r-project.org/R/?group_id=234"""" rel=""""nofollow noreferrer"""">RGL Website</a></p>
",1
"<p>I'd like to export plotting symbols form R as a png graphic. But I haven't found a perfect way yet.</p>

<p>Using </p>

<pre><code>png(""""symbol.png"""",width=20, height=20, bg=""""transparent"""")
par(mar=c(0,0,0,0))
plot.new()
symbols(1, 1, circles=0.3, bg=2, inches=FALSE, lwd=2, bty=""""n"""")
dev.off()
</code></pre>

<p>creates a little border around the symbol (I'd like it to be transparent) and the symbol isn't filling the whole space.</p>

<p><a href=""""http://i42.tinypic.com/2s1tytk.png"""" rel=""""nofollow noreferrer"""">symbol http://i42.tinypic.com/2s1tytk.png</a></p>

<p>Is there a more specific way of doing this ?</p>
",1
"<p>I have a big dataframe with columns such as:</p>

<pre><code>ID, time, OS, IP
</code></pre>

<p>Each row of that dataframe corresponds to one entry. Within that dataframe for some <b>IDs</b> several entries (rows) exist. I would like to get rid of those multiple rows (obviously the other attributes will differ for the same ID). Or put different: I only want one single entry (row) for each ID.</p>

<p>When I use <code>unique</code> on the ID column, I only receive the levels (or each unique ID), but I want to keep the other attributes as well.
I have tried to use <code>apply(x,2,unique(data$ID))</code>, but this does not work either.</p>
",1
"<p>I am working with a large list of points (each point has three dimensions x,y,z).</p>

<p>I am pretty new with R, so I would like to know what is the best way to represent that kind of information.  As far as I know, an array allows me to represent any multidimensional data, so currently I am using:</p>

<pre><code>&gt; points&lt;-array( c(1,2,0,1,3,0,2,4,0,2,5,0,2,7,0,3,8,0), dim=c(3,6) )
&gt; points
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    1    2    2    2    3  -- x dim
[2,]    2    3    4    5    7    8  -- y dim
[3,]    0    0    0    0    0    0  -- z dim
</code></pre>

<p>The aim is to perform some computations to calculate the euclidean distance between two sets of points such as:</p>

<pre><code>points1&lt;-array( c(1,2,0,1,3,0,2,4,0,2,5,0,2,7,0,3,8,0), dim=c(3,6) )
points2&lt;-array( c(2,2,0,1,4,0,2,3,0,2,4,0,2,6,0,2,8,0), dim=c(3,6) )
</code></pre>

<p>(any hint in this sense would also be highly appreciated)</p>
",1
"<p>I have 40 subjects, of two groups, over 15 weeks, with some measured variable (Y).</p>

<p>I wish to have a plot where: x = time, y = T, lines are by subjects and colours by groups.</p>

<p>I found it can be done like this:</p>

<pre><code>TIME &lt;- paste(""""week"""",5:20)
ID &lt;- 1:40
GROUP &lt;- sample(c(""""a"""",""""b""""),length(ID), replace = T)
group.id &lt;- data.frame(GROUP, ID)
a &lt;- expand.grid(TIME, ID)
colnames(a) &lt;-c(""""TIME"""", """"ID"""")
group.id.time &lt;- merge(a, group.id)
Y &lt;- rnorm(dim(group.id.time)[1], mean = ifelse(group.id.time$GROUP ==""""a"""",1,3) )
DATA &lt;- cbind(group.id.time, Y)
qplot(data = DATA,
        x=TIME, y=Y, 
        group=ID,       
        geom = c(""""line""""),colour = GROUP) 
</code></pre>

<p>But now I wish to add to the plot something to show the difference between the two groups (for example, a trend line for each group, with some CI shadelines) - how can it be done?</p>

<p>I remember once seeing the ggplot2 can (easily) do this with geom_smooth, but I am missing something about how to make it work.</p>

<p>Also, I wondered at maybe having the lines be like a boxplot for each group (with a line for the different quantiles and fences and so on).  But I imagine answering the first question would help me resolve the second.</p>

<p>Thanks.</p>
",1
"<p>I've been using <code>ggplot2</code> for a while now, and I can't find a way to get formula from <code>ggplot</code> object. Though I can get basic info with <code>summary(&lt;ggplot_object&gt;)</code>, in order to get complete formula, usually I was combing up and down through <code>.Rhistory</code> file. And this becomes frustrating when you experiment with new graphs, especially when code gets a bit lengthy... so searching through history file isn't quite convenient way of doing this... Is there a more efficient way of doing this? Just an illustration:</p>

<pre><code>p &lt;- qplot(data = mtcars, x = factor(cyl), geom = """"bar"""", fill = factor(cyl)) + 
     scale_fill_manual(name = """"Cylinders"""", value = c(""""firebrick3"""", """"gold2"""", """"chartreuse3"""")) + 
     stat_bin(aes(label = ..count..), vjust = -0.2, geom = """"text"""", position = """"identity"""") + 
     xlab(""""# of cylinders"""") + ylab(""""Frequency"""") + 
     opts(title = """"Barplot: # of cylinders"""")
</code></pre>

<p>I can get some basic info with <code>summary</code>:</p>

<pre><code>&gt; summary(p)
data: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb [32x11]
mapping:  fill = factor(cyl), x = factor(cyl)
scales:   fill 
faceting: facet_grid(. ~ ., FALSE)
-----------------------------------
geom_bar:  
stat_bin:  
position_stack: (width = NULL, height = NULL)

mapping: label = ..count.. 
geom_text: vjust = -0.2 
stat_bin: width = 0.9, drop = TRUE, right = TRUE 
position_identity: (width = NULL, height = NULL)
</code></pre>

<p>But I want to get code I typed in to get the graph. I reckon that I'm missing something essential here... it's seems impossible that there's no way to get call from <code>ggplot</code> object!</p>
",1
"<p>I recently posted this question on the r-help mailing list but got no answers, so I thought I would post it here as well and see if there were any suggestions.</p>

<p>I am trying to calculate the cumulative standard deviation of a matrix. I want a function that accepts a matrix and returns a matrix of the same size where output cell (i,j) is set to the standard deviation of input column j between rows 1 and i. NAs should be ignored, unless cell (i,j) of the input matrix itself is NA, in which case cell (i,j) of the output matrix should also be NA.</p>

<p>I could not find a built-in function, so I implemented the following code. Unfortunately, this uses a loop that ends up being somewhat slow for large matrices. Is there a faster built-in function or can someone suggest a better approach?</p>

<pre><code>cumsd &lt;- function(mat)
{
    retval &lt;- mat*NA
    for (i in 2:nrow(mat)) retval[i,] &lt;- sd(mat[1:i,], na.rm=T)
    retval[is.na(mat)] &lt;- NA
    retval
}
</code></pre>

<p>Thanks.</p>
",1
"<p>I'm trying to replace elements of a data.frame containing """"#N/A"""" with """"NULL"""", and I'm running into problems: </p>

<pre><code>foo &lt;- data.frame(""""day""""= c(1, 3, 5, 7), """"od"""" = c(0.1, """"#N/A"""", 0.4, 0.8))

indices_of_NAs &lt;- which(foo == """"#N/A"""") 

replace(foo, indices_of_NAs, """"NULL"""")
</code></pre>

<p>Error in <code>[&lt;-.data.frame</code>(<code>*tmp*</code>, list, value = """"NULL"""") : 
  new columns would leave holes after existing columns</p>

<p>I think that the problem is that my index is treating the data.frame as a vector, but that the replace function is treating it differently somehow, but I'm not sure what the issue is?</p>
",1
"<p>I am playing with the """"stars"""" ({graphics}) function to create a segment of flowers.</p>

<p>I wish to plot a flower of segments, for example in way the following command will produce:</p>

<pre><code>stars1(mtcars[, 1:7],
  draw.segments = T,
        main = """"Motor Trend Cars : stars(*, full = F)"""", full = T, col.radius = 1:8)
</code></pre>

<p>But, I want the segments to not have equal angles, but smaller angles (and between the flowers there could be space).</p>

<p>The goal I am striving for is to be able to give each flower """"weight"""" so that some aspects are more important (larger weight) and some are less (and thus, will have a smaller angle).</p>

<p>I understand this can be changes in the following part of the stars command:</p>

<pre><code>   if (draw.segments) {
        aangl &lt;- c(angles, if (full) 2 * pi else pi)
        for (i in 1L:n.loc) {
            px &lt;- py &lt;- numeric()
            for (j in 1L:n.seg) {
                k &lt;- seq.int(from = aangl[j], to = aangl[j + 
                  1], by = 1 * deg)
                px &lt;- c(px, xloc[i], s.x[i, j], x[i, j] * cos(k) + 
                  xloc[i], NA)
                py &lt;- c(py, yloc[i], s.y[i, j], x[i, j] * sin(k) + 
                  yloc[i], NA)
            }
            polygon(px, py, col = col.segments, lwd = lwd, lty = lty)
        }
</code></pre>

<p>But I am unsure as to how to manipulate it in order to achieve my task (of weighted flowers, by different angles)</p>
",1
"<p>I'm trying to compare two numbers in R as a part of a if-statement condition:</p>

<p><code>(a-b) &gt;= 0.5</code></p>

<p>In this particular instance, a = 0.58 and b = 0.08... and yet <code>(a-b) &gt;= 0.5</code> is false.  I'm aware of the dangers of using <code>==</code> for exact number comparisons, and this seems related:</p>

<p><code>(a - b) == 0.5)</code> is false, while </p>

<p><code>all.equal((a - b), 0.5)</code> is true.</p>

<p>The only solution I can think of is to have two conditions: <code>(a-b) &gt; 0.5 | all.equal((a-b), 0.5)</code>.  This works, but is that really the only solution?  Should I just swear off of the <code>=</code> family of comparison operators forever?</p>

<p><strong>Edit for clarity:</strong> I know that this is a floating point problem.  More fundamentally, what I'm asking is: what should I do about it?  What's a sensible way to deal with greater-than-or-equal-to comparisons in R, since the <code>&gt;=</code> can't really be trusted?</p>
",1
"Protecting 'Causes of the 1948 Palestinian exodus' 

Hi,

Can you explain on its talk page why you protected this article?

There is some edit warring going on, but not very heavy (for the standards of this article). Also I am a participant in a mediation case, but that concerns actually only the use of one source on this page, and is irrelevant to the present edit warring.

Therefore I was wondering about your motivation.

Regards,",0
"Hello, I check this personal page very often. Please leave messages here on on the discussion page. Tks. 

Marvio",0
"""""
 My thanks to you for this. I note that I am being dressed down for everything from being nice to editors I like to work with, all the way to deleting messy posts from my own talk page. Well, a mess is a mess. Again, thanks Stephen. Please don't take that as gratuitous or ingratiating
-).... imacowboy """"",0
I don't care what you say here. I don't believe one sentence anymore.,0
"Anytime you want a nightcap, tell me.",0
"2010 Meet a Local - Vietnam TV Series, Factual / Documentary, 60mins

2010 Meet a Local - Spain TV Series, Factual / Documentary, 60mins

2009 Meet a Local - Tasmania TV Series, Factual / Documentary, 60mins

2009 Meet a Local - Ireland TV Series, Factual / Documentary, 60mins

2008 The Way - Camino de Santiago Feature, Factual / Documentary, 75mins

2008 African Stories Online, Factual / Documentary, 20mins, Overlander Multimedia for the ABC

2006 The Outback Boxing Troupe Online, Factual / Documentary, 30mins, Overlander Multimedia for the ABC, Australia, Production Company

2004 Returning Home - A Story of Ararat Online, Factual / Documentary, 20mins, Overlander Multimedia for the ABC

2001 Meet a Local - East Coast Australia TV Series, Factual / Documentary, 60mins

2001 Meet a Local - Outback Australia TV Series, Factual / Documentary, 60mins",0
"Globalization and 'Ivytrash' 

I am not Ivy anything.  That was my home.  I was born and raised 6 blocks from Harvard Square, and it was (once) the greatest place in this country.  I am not interested in 'globalization'.  I look at the square and see the smoking ruin of my home.  When this happens to you, I hope globalization is comfort enough for you.",0
"He is, self-confessed , and approved by my observations (see, e.g., history of Soviet partisan). BTW, you're the first to object ).",0
"And btw, speaking of the Armenian genocide, if we are to follow wikipedia conventions of most common name (and I don't agree Assyrian is the most common name as we also have proven many times before) we should change the name of the current article Assyrian genocide to Seyfo.",0
"""""
To quote 

- If a Wikipedia article links to this page, it is because someone is concerned that the article contains inaccurate statement(s). Such statements are followed by the following warnings: """"""""(dubious - discuss)"""""""".

The accuracy of a statement may be a cause for concern if:

    * It contains unlikely information, without providing references.
    * It contains information which is particularly difficult to verify.

Please DO NOT remove my dubious reference edits as that would be against the guidelines there, wouldn't it?""""",0
"Belarus a developed country
Hahaha, nothing more to say  82.209.225.33",0
"Censorship on Islamist Terrorism

Try not being a censor monger. Properly cited information should not be deleted.",0
"If you would like to write an article of Bill's father, including his rise to CEO of Commonwealth Edison, feel free. This article is about Bill. We're not writing a chatty, book-lenth biography about him, but stating facts - same as other biographical articles in Wikipedia. The details of his father's career are irrelevant, although his (eventual) stature as CEO is not. This is yet another issue that has already been resolved.",0
"""""
Thanks!  Really cool tool for purposes like what I have on my userpage.  Best, Tally-ho! """"",0
"It is funny because i would say exactly the same thing for you Astarti34  , the anonymous user with an ip from greece and the user WilliamThweatt . Accusing people , without a reason is not allowed in wikipedia . As per wikipedia rules you are free to ask for an investigation ! In fact i do kindly ask you to do so . If this vandalism persists i will seek an arbitration . I do kindly ask from any moderator , to see all the reverts , and i am confident that they will conclude that they have been mal intentioned , with a clear nationalistic agenda ... you all 3 guys have something in common , you are all greek * all 3 of you * !  (    )",0
"""""

 =^_^= 

I just watched the entire series, and I agree, this entire article and several other in the suzumiya haruhi articles are all from a """"""""somebody who knows haruhi personally"""""""" sort of view.

So Im going to fix it.

 """"",0
"""""
Agreed, will take a stab at it. It also needs major formatting cleanup and Wikifying, it sounds too much like a fan conversation - the references are all either YouTube links or """"""""personal communications"""""""". I'm trying to at least pare down the """"""""BEST MUSICIAN EVER!"""""""" statements, could use some help with the discography section too.   """"",0
"""""
Vandalism is for e.g. this type of edit, somebody said that The Stig was leaving so I reverted it, basically I reverted it because there was no source to suggest that he was leaving, so I do know what vandalism is I just want to carry on editing Wiki, I love this place it's amazing please don't """"""""make me leave"""""""", now that I've explained myself please please unblock me (  Thanks 123 """"",0
"""""

Baer didnt invent video games. This is jewish propaganda supported by a wiki troll named, """"""""Goldberg"""""""" Go figure. 

Hey, """"""""goldberg"""""""", try educating yourself. 

https://www.youtube.com/watch?v=EfBwz_SiK8s""""",0
"I can tell you what the argument is about here newseventsguy. It's about YOUR retroactive reversion of a simple edit trying to include secondary independent verification of sedimentary nanodiamonds in Younger Dryas sediments by Bement and Madden et al., WITHOUT DISCUSSION a reference that I notice has NOT YET been included in the reference list still, after all this time. This is after you ADMIT that you are ignorant of the peer review literature and the controversy. Any attempt to do simple reference list edits on this page have been stomped by no less that five admittedly biased and ignorant editors. The honorable thing to do here would be to recuse yourself from editing the page, as I have. But I haven't seen that happening until now. Good luck with it, you've already made complete fools of yourselves.",0
HELLO HOW DO I GET SOMEBODY TO FIX SHIT AROUND HERE?,0
"Dictionaries

How dare you call my contribution spam!!! I am a Kurd and I made a lsit of kurdish dictionaries. you bloody turkish nationalist and atoricity commiting bone breaking Nazi. watch out folk this slimy Turk is trying to censor the internet this is not undemocratic Turkey here, no prison cells in wikipedia you stupid Turk! And you buggers want membership to the EEC",0
"""""

Apparently, other editors agree that the edits I made were justified.  A group of meat-puppets working as a team to revert an article to their own POV is what has caused this block.  At issue was the """"""""advert"""""""" tag which is justified, was placed on the article by one editor, replaced by me, replaced again by another editor, and replaced again by me.  Three editors, so far, have indicated the tag belongs there.  I'm sure a forth editor is going to weigh in on this side too.  The article is riddled with brochure language.  Please note that I was removing brochure language right up to the lock-up of the article.  There's still lots more in there that needs to come out before the advert tag should be removed.  Additionally, I don't believe I broke the 3RR rule which requires a fourth reversion.   

""""",0
"While I agree that Indus valley civilisation is the correct name for the civilisation, the passage quoted above is not neccecarily factual in terms of saying Second there is no proof at all that the mighty Sarasvati of the Rigveda was in fact this (now dry) river- the identification is itself open to doubt.. Apart from there being facts/proof to indicate that Saraswati did exist as this dry river ( including geological facts as to why it dried up) The evidence also points to the fact that it was NOT a tributary of the Indus, ( refuting point 3 of the passage quoted above ) and in fact drew the waters of the Sutlej and the Yamuna to be a river system of it's own. And though a large number of sites have been found along this river system, none of them are of the scale of Harrapa / Mohenjodaro, leaving the Indus Valley tag as the correct one. Saraswati did exist,today the timing is disputed and not the existence, Wheter it is vedic and indic vs Harrapan and non vedic is more disputed today than it's existence.",0
""""" December 2015 (UTC)

Thanks. I have started working on Pranagnihotra Upanishad but I am unable to get the full text from the Deussen's Sixty Upanishads (pages 646-648 do not appear in the book under Google url}. Can you suggest a url which gives the full text? In the meanwhile I have completed this short article Sharabha Upanishad which you may like to see and add/edit. Nvvchar. 01:52, 3""""",0
I insulted people on en.wiki with criteria to provoke my filter set. You are simply abusing the power people handed over.,0
"""""
Excellent! That would be great. The comments found at its peer review should also be very helpful, but I haven't had any time to actually act upon those suggestions. Cheers. Hello! """"",0
"How do you know he is dead.  Its just his plane that crashed.  Jeezz, quit busting his nuts, folks.",0
"""""

Afican Union site vandalism

Dear BracketBot, I wrote this note to inform you that an editor is performing acts of vandalism in the website of the """"""""African Union"""""""" https://en.wikipedia.org/wiki/African_Union. Please I would appreciate if you could tell me who I should report this action?, the Board Index name is https://en.wikipedia.org/wiki/User:Knisfo

   """"",0
"You are a know it all.....Jimbo! 

Why don't you get a life instead of sitting in front of your computer all day. The high priestess of knowledge, indeed!",0
"""""
All of those statements need to be referenced.  Leaving an article unreferenced in every section opens the door for original research and the introduction for factually inaccurate information.  To point out one thing, I'll bring up Consolidated Appropriations Act, 2012.  First, it has a number of tags on it, the creation of articles that need to be tagged should be reason number 1 to remove the flag.  Second, the only reference/link provided on the article is this one while the information is from various subpages of that.  It appears that the entirety of the article is found at this deeper link.  It's possible that some came from this as well, I can't tell.  I'll also note that the style of the summary it was taken from was never meant to be encyclopedic, so the article is riddled with grammatical errors, mostly incomplete sentences.  On creation, the opening read """"""""Consolidated Appropriations Act, 2012 (H.R. 2055) is a bill passed to the 112th United States Congress""""""""  I've never heard this usage (to rather than by) and assume it is incorrect, another editor changed it, the lead is also missing an important determiner.  In any case, you can take a look at Vesey """"",0
"Ok, I just ask. For your experience, what you think about the portal?",0
"Sitush, how can anyone assume good faith when you have been writing so much against Yadavs on that page.It is evident from the discussions, how conveniently you have been selecting sources for negatives and then conveniently rejecting the same sources for the positives. You are the only person spamming on that article and vandalizing it. Yes, I will contribute to other articles on Wiki too, but let me first correct things on Yadav as so much wrong has been going on there.You got Ikonoblast banned and now you have got me banned and you will get anyone banned you differs from your biased stand on Yadavs but I am not going to give up.I will follow all WP policies and will ensure that I get things corrected on Yadav and dont let your and fowlers personal views dominate that page.Peace !!",0
""""", 30 December 2009 (UTC)
Don't worry, I told you I had your back, and I'll continue to defend ya. ;) Yup, we got our proof of work. When I first saw it, I was like 'That's no reliable source', cause I remember you reverted that source one time. But, when I looked over the article and saw Ref. 63 I was like 'Oh shit', so I reverted it. I'm glad you went """"""""going back"""""""". ;) I'm glad my """"""""two words"""""""" have gone on to """"""""save"""""""" me. Question: Would you like for me to expand leads on all SS members?  (Hit  21:31""""",0
"November 2014 (UTC)

  I agree with .   Clearly Santilak is using up his usual bag of tricks. SantiLak, please discuss the article courteously and professionally. 2.177.207.221  08:38, 28",0
"""""
Ok, I like the pyx lax track very much indeed. If you could point me towards other greek trad music, that would be great, and greawt for me. Here are some Irish - , .  Non visto ... Provvedi """"",0
"where's with pitchforks already?   17:09, 16 Jun 2005 (UTC)",0
"Again reinstated sentence about 7 Nobels in the first paragraph, for the reason stated above.  If others disagree that this is a defining characteristic of Bx Science that should be indicated right up front in the summary paragraphs, then can we discuss it here rather than playing edit games by removing text without either edit summaries or discussion on the talk page?",0
"I'm disappointed it wasn't a successful run, but it",0
"""""

Elvis... Crying in the Chapel  Feudalist  """"",0
"Please refrain from adding nonsense to Wikipedia, as you did to Fisting. It is considered vandalism. If you would like to experiment, use the sandbox.   tlka",0
"Elizabeth 

Hi lil romeo I am one of your biggest fans I really like you I always dream of you at night I would like you to come to Dallas Tx. to Ignacio Zaragoza and give a concert at this Elementary school I am in the 6th grade and I am 15 years old I want you to come and help me with my homework See you later I will write to you soon By",0
"Hi Fracophonie,

Thanks for taking the time to write such a long message - I appreciate this.

In terms of what I said about the age - I didn't mean to cause offense. I thought I read somewhere that you had to be over 18 to make these decisions but I think I was getting confused with the check user privileges. 

I have already read some of those policies but will read the rest later today. I am not a troll - I just need time to get used to all these acronyms, policies etc.

From what started out with me writing an article about my favourite website has turned into a massive thing which was not what I was expecting.

I really don't have any more time to argue and debate with the usrs since its clear they just want it deleted despite what I have said. For example one user just wrote there is another site called Amirite.net. This is Amirite.com!! This is precisely why I had to keep responding on the AFC delete page. 

In terms of the rest I agree to do them (of course I can only apologise once I am unblocked) - can you apologise for me?

On a side note I am actually French and Jewish (shame about the gay part though:)",0
"Welcome!

Hello, Soundchu, and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful:
The five pillars of Wikipedia
Tutorial
How to edit a page and How to develop articles
How to create your first article (using the Article Wizard if you wish)
Manual of Style
I hope you enjoy editing here and being a Wikipedian! Please sign your messages on discussion pages using four tildes (~~~~); this will automatically insert your username and the date. If you need help, check out Wikipedia:Questions, ask me on my talk page, or ask your question on this page and then place {{help me}} before the question. Again, welcome!   WikHead",0
"I removed the content, after it was tagged as uncited by Mattisse. If every commonly known fact need a cite because some editor-en passent wants to nominate for FARC, then it appears we have a problem. I very much suspect Mattisse's motives here, but frankly, I am too tired of her to be bothered to explore them. Perhaps one of her probabtionary mentors, more interested in her than I, would care to deal with this.",0
Is Jeff Garcia gay or not?,0
"That wouldn't be sufficient; you need explicit permission to use text copyrighted by someone else under a licence suitable for Wikipedia.  Please read the guide to requesting and formalizing permission to use copyrighted works on Wikipedia.  Note that, in addition to copyright requirements, the article must still comply with notability guidelines, advertising prohibition and avoid conflicts of interest. (talk)",0
The section is useful info and should stay - you are clearly wrong.,0
"Comment So now we are stuck with a week of 200+ broken links. Since you acknowledge that the move was a mistake and not uncontroversial, will you please revert it? If anyone wants to dispute that the opera is the primary topic, they can do so under a proper requested move discussion, as they should have done in the first place. If you are not willing or able to do this today, I'll ask a another administrator to do it.",0
"""""
It needs to be included, in the context of 1993 as well.  I'll try and dig up some sources.  User Talk  Review me! """"",0
""""":::::::::: Tim, firstly I appreciate you taking the time to discuss this issue offline, and for your willingness to debate it at length here despite the majority view here being in your favour. Yes I certainly agree with your friend that it is very important to describe the jurisidictions that a firm is present in, there is clearly a massive diffence between, say having offices in the French or Japanese jurisdictions, or between the Chinese and U.S. jurisdictions, since the legal and regulatory systems are very different, as well as the commercial characteristics of the markets.

 Beyond that however it remains my firm view that there is a big difference between a law firm having an office in, say, Paris or Toulouse, even though they are both in the same jurisdiction. I appreciate that the situation in the U.S. is slightly more complex since you have both federal and state jurisdictions. Even within each state there will be big differences between the legal markets in different cities though. To give an example, the San Jose market will be not just a lot smaller overall than the Los Angeles market, but it will also have a quite different profile - on the whole a lot more specialist, niche and focused on high tech. 

 To give another example, in the UK a law firm could never be regarded as being truly top tier if it didn't have an office in London, even if it had offices in every other big city. In fact all of the very top tier UK firms (DLA Piper is not yet regarded as one of them, despite its size) have just one UK office, in London, although they have other offices overseas. 

 Saying that DLA has """""""" has 69 offices across the United States, Egypt, South Africa, Kenya, Thailand, China, ..."""""""" would in my view still mean a loss of valuable information to the reader. We could fall back on using descriptions like """"""""in major financial centres"""""""" or """"""""in major commercial centres"""""""" or """"""""in a combination of major financial centres and major commercial centres"""""""" but then we are introducing what is in my view an unnecesssary element of vagueness, imprecision and even original research.

 I do accept that DLA, with 69 offices, is right on the borderline of having too many offices to make it practical to list all of them in the article. However I do also feel that there is an important general point of principal that information about the office locations of a law firm is very valuable information to aid the reader of an article in understanding the subject of it, and should be included as much as possible.  

""""",0
"No problem with that at all!  If you don't think that there is a problem with someone siting that I have a mistress then it just proves my point as to how far this site is to being an actual encyclopedia.  It's a forum, not an encyclopedia.  Big difference.  And that's not even what pisses me off the most about my page.  Thank god I'm single with no chick bitching me out or that would be another attorney fee I'd be handing out to sue whoever owns this site.  I'm done bitching about the mistress thing.  My whole page has errors from the very first line down to the very last line, and that is no joke!!  First line and the last line are wrong.",0
"Sprecher Brewery 

I took the tour this christmas when visiting my sister. We were charged an extra $1 for the glass. Their website may not be updated but that IS the current pricing.",0
"iPad talk page 

Why did you remove that IP's edit to the talk page? It wasn't spam...",0
"""""

Speedy deletion of Andrew takao
 A tag has been placed on Andrew takao requesting that it be speedily deleted from Wikipedia. This has been done under section A7 of the criteria for speedy deletion, because the article appears to be about a person or group of people, but it does not indicate how or why the subject is notable: that is, why an article about that subject should be included in an encyclopedia. Under the criteria for speedy deletion, articles that do not indicate the subject's importance or significance may be deleted at any time. Please see the guidelines for what is generally accepted as notable, as well as our subject-specific notability guideline for biographies. 

If you think that this notice was placed here in error, you may contest the deletion by adding  to the top of the page (just below the existing speedy deletion or """"""""db"""""""" tag), coupled with adding a note on the talk page explaining your position, but be aware that once tagged for speedy deletion, if the article meets the criterion it may be deleted without delay. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would would render it more in conformance with Wikipedia's policies and guidelines.     """"",0
"""""

 Image 

 Image deletion warning Image:Metroid Prime Hunter title screen, top display.jpg has been listed at Wikipedia:Images and media for deletion. If you feel that this image should not be deleted, please go there to voice your opinion.
 16:31, August 31, 2005 (UTC)""""",0
The real personal attacks are the repeated undoing of my edits by everyone else.,0
"""""

Nope, I didn't read the guide to appealing, didn't have time. The user in question IS engaged in harassment, I've been doing this long enough to know and I can prove it. He/she immediately placed a threatening notice of blocking me permanently on my user page, reverted the article while I was in the midst of editing it (my second pass, couldn't even preview changes), then changed his/her mind as to my real wiki-sin, since the onus for proving the Doris Day available as PD on archive.org was on him/her not me and the usual span for pre-Bern had expired long ago, ... decided my REAL sin was Original Research (oh noes), and continued to revert based on that. Does OR add clutter? Sure it can, but if the user in question was REALLY concerned about that, about the quality of the article and about extraneous details, WHY DIDN'T HE/SHE EVEN NOTICE two paragraphs already there, comprising about 1/3 of the entire article, dealt with Norman Schwarzkopf, an unrelated book and an unrelated ice cream store name? I'll tell you why: the user wasn't engaged in good-faith/goodwill editing and the normal back-and-forth that leads to better articles. He/she was involved in blocking input to the article. Why? Was it personal against me, or was it to preserve the existing content of the article, including the false claims and extraneous material not even concerned with ther subject at hand? I can only speculate, but I'd guess it's some sort of power trip and wiki-bullying. I don't really have time for this. I have made a fair number of very good edits over the years and have usually refrained from saying anything that isn't directly related to content and improving articles. I could pretend this user didn't do what he/she did, but I'm wasting my own time here and I don't really have a stake in any such pretense. I don't have any stake in improving this article either, no dog in the race, I just see how it can be improved and made more informative. As a long-term wikipedia user and editor, I don't see any problem in jumping in and fixing something. I almost expect some sort of pushback now, but not over completely minor edits which are very good and on-target in very minor stub-like articles. The problem isn't me here, it's that if people such as the user in question can get away with this sort of behavior, and they are getting away with it, wikipedia becomes a much poorer place, a playground filled with bullies rather than a library where we can all learn and share. Also, I don't recal ever having called him/her a bot, I think you put those words in my mouth, perhaps inadvertently. His/her behavior is malicious, but probably not malware, just the normal human collection of problems. I think this user should be warned against trying to be a gatekeeper, he/she isn't quite qualified for that at this point anyway, and it's having a very chilling effect across wikipedia. I won't egnage in a battle of the wikipedia rule acronyms, I will continue to write in English, and to read articles on wikipedia in English, and to think of ways to improve them in English. I am fully aware of how the terms """"""""vandlism"""""""" are used and misused here, and most of the rest of the wikijargon. Nothing new under the sun here. If you read the edits I made carefully, and note the times of the reverts and the history of actions by that other user, you will see I'm not off the mark here at all. I know what's going on. I don't know why, but I don't have to, and I expect the motivations aren't interesting. Respond if you have anything to say.   """"",0
"the communist states ==

all three call themselves as the socialist states. communist is the word that westerner use. so should that name be changed?

==",0
"Boze Hadleigh, a journalist, interviewer and writer primarily of gossip about homosexuals of Hollywood.",0
"""""
""""""""IMDb content is user-submitted and often subject to incorrect speculation and rumor. The use of the IMDb on Wikipedia for referencing is considered unacceptable and strongly discouraged.""""""""Wikipedia:WikiProject Film/Resources
""""""""...self-published media...are largely not acceptable. This includes any website whose content is largely user-generated, including the Internet Movie Database (IMDB)...""""""""WP:USERG
As I've said, this is a long-standing consensus. If you disagree, I encourage you to take it up at Wikipedia:Reliable_sources/Noticeboard. -   """"",0
"I'm new to this means of communicating ... and I am not sure that I expressing this in the right form.  However, I am reviewing all of the recent (2000-2008) MA nominations (expected to go on the web in the next couple of months). In the process I have developed a database of corrected lat/long (decimal degrees), based on Google Earth and photos and assessors maps in the nomination files. I would like to share this, if there is a way of doing it.  Alternatively, to find a way to EASILY check and correct existing coordinates on the Mass Wiki Lists. Would this be useful for anyone?",0
"Y2kgtp actually reverted the vandalism, I did not.",0
"Yes, I have read them both, and I will now ask you to provide back-up for your story. Not that it matters in the least, the one religion is as bad as the other. But you better have some proof for your claims. ChatNoir",0
"I think the error is that it is grams not kilograms. So 1.5 kg. I'm editing the article til we have a better result. If I'm wrong please change it back.  23:10, 31 Dec 2004 (UTC)",0
"Vince - FYI 'Yellowfrogs' is (Longdendale) Councillor Sean Parker Perry, a frequent purveyor of 'Greenwash' and four square behind the destruction of Swallows Wood via his support for the bypass. He is vigourously re-editing the wikpedia pages on the Longdendale Bypass, his own and Roy Oldham's page in order to boost his fake 'green' credentials and obfuscate the neutrality of these articles. He gets nasty if he gets pissed off (threatens spurious legal action), but fortunately, he's legally illiterate, so don't be put off.",0
"Summary of situation  User:ShimShem has taken a dislike to this article, and has tried numerous methods to either get it deleted or its name changed. 
 1) Completely invalid speedy deletion request
 2) Invalid DRV request
 3) Nominated for deletion via AfD, despite the fact that it had passed an AfD this year - in fact the AfD was withdrawn at 6-0 for Keep
 The current AFD here stands at 9-0 for Keep, but despite that, ShimShem has wikilawyered all the way through it - once it became clear that it was going to be kept, they decided a name change would be better...
 4) Changed the name of the band in the article, and was told to take it to talk
 After a brief non-discussion on talk, moved the article anyway, and was reverted

I was originally unsure of the motives of this editor - why they were completely desperate to delete or move this article - until I noted they were interested in Tamil subjects, one of which is M.I.A. (artist), and guessed that they believed that the two could be confused.  Their subsequent creation of the article M I A as a redirect to M.I.A. (artist) proved this, as far as I am concerned.  

As to whether the band is actually called MIA or M.I.A., it differs.  The band itself uses M.I.A. as the heading on their own website, but then uses a combination of both elsewhere.  Since in the case of most sources, this is only likely to be laziness (much as R.E.M. are regularly referred to as REM), and since the article has existed here for a while, and that all the backlinks go to this version, and most of all because we shouldn't let disruptive users get their way, the article should stay here.",0
"""""
 It is unnecessairy source, because it does not matter how many soldiers were killed. What matters is that the Safavids were deposed. Besides that, mentioning that information WITHOUT making any remarks about the brutality of the Afghan forces - for example the complete massacre of the Safavid family (including women and children), as well as the massacres on the civilian population in Isfahan, Bam, and villages of Khorasan - is considered POV. 
 Besides that, you have not shown any sources for your claim that """"""""30000-100000 soldiers were killed"""""""". 
 And as for the edits: it does not matter what YOU believe, it only matters what the Wikipedia rules are. You posted a message without editting ANYTHING ... that's the same as abusing the article's history as a message-board. Use the REAL message-board instead.  """"",0
"Whoever wrote the Plot
I feel terrible for whoever had to watch the movie in detail and then write the plot line. Who ever took their time to write the plot section must be traumatized for life. However, its missing the part where Milo's son is laying on his belly unconscious on a bed, Milo anally rapes him while several masked men watch. Also, there's some use of a knife/sword in this scene. This is truly one sick film. No, there is no artistic message. This film is basicly a middle finger by the sick-minded film makers. The cast must have been tricked into participating in this disgusting film. There's artistic gore such as the classic film Begotten and then there's this . . .
Listen to me, DON'T WATCH THIS FILM NO MATTER HOW MUCH YOU ARE TEMPTED!",0
"""""
As he has asked admins not to comment, I will refrain from doing so. I did however remove a personal attack against him; if anyone wishes to discuss this action, please email me. &Windows; """"",0
"""""
Can we compromise here? I don't think we have the budget for salmon, but (at least in the Netherlands) there is an """"""""in-between"""""""" fish, more affordable, that in Dutch was called """"""""salmon trout."""""""" So far, so good, S Marshall. Fortunately no one has yet discovered that you used to run drugs for a cartel or that you danced in a nightclub a la...Henry LaFarge, was it? in A Shot in the Dark? Ssshh, I'm not telling. Oh, I should ask you at your RfA about the proper use of  citation templates. Later!   """"",0
"Sorry, I am not sure how to take care of him.

He has quite the history, and actually has legal cases involving the Dayton Daily News.  Wikipedia is at risk if he edits any of those pages or any affiliated company.

The actual sockpuppet is 65.31.33.93, which is a puppet of hdayejr.",0
"We can agree to disagree on the relative merits of the fish and the character, but the red seabream is part of family Sparidae anyway. So that's usage outside North America right there.",0
"Large ships are typically launched into the water when the hulls are completed, but that doesn't mean all of the construction work is finished. Usually, there is still a significant amount of work to be done, including finishing the interior of the ship, building the superstructure, etc. Take a look at Image:SMS Seydliz under construction.jpg, for example; you can see the ship is already in the water, but a significant amount of work is being done to the superstructure. You can also read Ship naming and launching for more information about launching. Hope that helps.",0
"(...at which point I am predictably ignored and stonewalled, which seems to be the Wikipedia staff's official response to any direct questioning on the Justin Berry issue.  One might think they've hired Scott McClellan to handle their PR.  Clearly they are aware of the untenability of their position, and they're really hoping it will just go away.  Sorry guys, it won't.)",0
"You need to prove notability using reliable sources. Just because it has some festivities (how large are they? who organized them?) in part of a country doesn't make it notable. Also, you need to change your username; this one will probably be blocked soon for violating the username policy (no names of web sites/businesses).  (talk to me)",0
"4meter4's sigh and my concerns 
Only because Mr 4meter4 had reverted any of contributions of mine given to this article so far I did not have a single chance to develop it. His article called falsetto is not about falsetto. It may be about his arrogance, who knows. There are a huge contraries regarding only the definition of falsetto. There are many signs of entirely different falsetto compare those info which Mr 4meter4 such anxiously protects. In England, Italy or Spain 16th century were described entirely different types of falsettos. On the top of it, Mr 4meter4 perhaps never heard Pavarotti singing falsetto, or the falsetto of Ian Gillan. Singing of King Diamond is based on falsetto. What about Michael Kiske? Is it not falsetto? Mariah Carey or Whitney Houston do (did) not sing falsetto? Does any of these falsettos sound breathy? Not to me. Isn't out there published a note about those? Maybe only because 4meter4 does not look for it. Why? It would not fit to his article. He would have to admit that his ONLY source Vennard was probably having in the chair something else than falsetto or he was drunk. 4meter4 quickly opened two or three books and things he had swallowed the World. The whole physiology of his only falsetto is based on encyclopedia? Well, perhaps it is enough for Wikipedia or himself. But not for me. No. There is much more out there only regarding physiology. Much much more. And just because you allow idiots like 4meter4 to develop Wikipedia, the people, the readers of Wikipedia will read shit. Where are any proves of the research regarding female falsetto at 60ies, Mr Know Everything? Feel free to block me again. I have no desire to write here any more.",0
You've also forgotten these Premier Leagues.... But still written in English.,0
"""""

Please do not replace Wikipedia pages with blank content. Blank pages are harmful to Wikipedia because they have a tendency to confuse readers. If it is a duplicate article, please redirect it to an appropriate existing page. If the page has been vandalised, please revert it to the last legitimate version. If you feel that the content of a page is inappropriate, please edit the page and replace it with appropriate content. If you believe there is no hope for the page, please see the deletion policy for how to proceed. Thanks for contributing to Wikipedia!   talk """"",0
What a motherfucking piece of crap those fuckheads for blocking us!,0
""""" 2010 (UTC)
That's because when I made those tables, I classed everyone as """"""""independent"""""""" unless I could confirm their party identification.
According to this, the DLP intended to run in all 17 constituencies.  According to this they had at least 5 candidates.  I've only been able to identify two so far, so we do need to identify more.   03:19, 1 December""""",0
"""""

 Removed POV 

I removed undo criticism of Secretary Boutwell and POV. Wikipedia is not meant to bash persons reputations whether alive or dead. The following has been removed from the article.

""""""""Boutwell did little to withdraw paper currency from circulation, shaping his financial policy to forestall either inflation or deflation.  Intellectual critics saw in these actions a want of guiding principle and a lack of solid theoretical knowledge. """"""""He believed in knowledge just so far as it was convenient for him to justify his own theory that knowledge was a deception,"""""""" Henry Adams wrote in a much-quoted analysis in 1870. """"""""He believed in common schools, and not in political science; in ledgers and cash-books, but not in Adam Smith or Mill; as one might believe in the multiplication-table, but not in Laplace or Newton. By a natural logic he made of his disbelief in the higher branches of political science a basis for his political practice, and thus grounding action on ignorance he carried out his principle to its remotest conclusions.""""""""Henry Adams, """"""""The Session,"""""""" North American Review, July, 1870, p. 36.  But in a very corrupt time, it spoke well of Boutwell that nobody thought that he made money out of his Cabinet post, either for himself or his friends. Living within his salary, he lodged in a boarding-house throughout his tenure. His only pleasures lay in writing lectures and playing billiards or poker   though never for money. Chicago Times, March 6, 1875.  """"""""He is an inaccessible man, uninfluenced by fear, favor, affection or hope of reward, and does not burst out into brillian exhibitions of love or hatred,"""""""" a New England politician wrote his brother. Henry F. French to Benjamin B. French, March 16, 1869, Benjamin B. French Papers, Library of Congress.

""""""""Boutwell's financial policy was less dogmatic than pragmatic.""""""""Liberal reformers had hoped that he would embrace civil service reform and rush the country towards the resumption of specie payments; but while Boutwell appointed subordinates on the basis of merit for the most part, , he did little to rein in the spoils system outside of Washington, remaining on friendly terms with the party bosses.''""""""""

""""",0
"You sir are an imbecile, and a pervert.",0
"recaptcha 

1 it isn't defamatory
2 it relates to a computer system not a living person

ReCAPTCHA forces users to solve the Captcha to access whatever the service in question is. Forced labor is the definition slave labor, i am going to revert your reversion, please do not do it again or i will report you for vandalism also please don't send me threatening messages tia 94.168.204.89",0
"""""

 Question on Possible Citation 

I'm sorry if I missed your question - I don't pay much attention to that page. In response to your question, let me start by repeating my boilerplate formulation: The job of Wikipedia editors is to verifiably summarize reliable sources using the neutral point of view. (I haven't yet worked in """"""""no original research"""""""".) WP:NOR says that we mustn't integrate otherwise reliable information to arrive at novel conclusions. Comparing two lists and drawing conclusions from their differences and similarities is most likely original research. We can integrate information, so long as we don't arrive at new theories. Another principle to remember is that vagueness improves accuracy. The more precise we are the harder it is to be accurate. 

Getting down to details, the Predators and Editors website appears to be a reliable source so we can use it as a source. The Bauer site, even if somewhat unreliable, may be used in a limited fashion as a primary source about Bauer. I'm not familiar enough with this topic to make pronouncements on what would be correct. However I would say that your proposed text appears reasonable. The sources are sufficient, and no original conclusions are made. The website takedown issue is confusing to me, but you should be able to summarize what you find in reliable sources. 

Overall, my opinion is that the less we say about the subject the better. Attack articles are not encouraged. While we must show our subjects """"""""warts and all"""""""" we shouldn't enlarge the warts, nor ignore their better features. Balance is a part of NPOV. - 

""""""""but you should be able to summarize what you find in reliable sources."""""""" There no reliable sources only a he said she said blog flame war. It is alleged the website takdown was instigated by Bauer. It isn't clear if she did, and other factors between the forum and the IP are not known. It was the root cause of this article and all the players here were involved via these blogs. I don't see how that can be objective. 

 Bauer 
I'm sorry I did not get back to you about the Usenet stuff et al., but I've been somewhat overloaded at work. Personally, I think the article is better now than when I first saw it, thanks to a lot of effort on the part of the primary editors of the article to bring the best sources and present them in a way that doesn't seem like a lynch mob. Y'all are doing a good job, and there should be enough editors on either side to ensure that something resembling nuetral gets posted . I'm glad to help and try and make the article neater, and I don't mean to sound brusque in the summary field, but there was a lot to cram in there. Thanks for the note, I appreciate it!   
 I would say Karen saying I've called her names is an out and out fabrication. I've never done any such thing. 

""""""""or whether it's because he's been able to insult me and call me names on Wikipedia, repeatedly and without consequences""""""""

I've accused her and Jule of carrying the water for TNH and Absolutewrite and they have. That isn't namecalling by a long stretch. I'm really weary of these attacks over this. This is mob rule. While avi seems genuine, she's hanging with a tough insulting tribe. The threats against me are real and escalating by the hour. Blaming me won't make my points any less valid. Nobody likes to be piled on by a crowd. It's the Internet equivalent of stoning. 

This is not a fabrication. I get awfully tired of being called a troll, or part of a mob or cult or """"""""group troll,"""""""" or a """"""""self-interested partisan,"""""""" or a """"""""blog comment commando,"""""""" or other things I could point at if I wanted to depress myself. You also made a """"""""theoretical"""""""" comment about me being """"""""nosy, fat and ugly."""""""" Putting the word """"""""if"""""""" in front of it doesn't make it any less of an insult. I've tried to be polite to you, and will continue to do so, but this is the response. And, please notice, like abi (Avi is Avraham the admin, abi the ML commenter who believes in kindness) I counseled against piling on.  | Talk | contribs 

Those are not ad hominem names Karen. Yet you've linked to a thread where you and Teresa caled me a psycho. You should hear what she said in private when I asked NOT to be spoken of negatively in threads on Making Light. It's obvious you two are pro-TNH and absolutewrite. That's self-interest and backed up by the fact that you run to her for counseling. Well, avi can make her own decisons about it then can't sh",0
"Infobox hurricane season 

It's pretty much complete. I need to make some documentation, and possibly tweak things that may pop up. You might want to test it out, so if there are questions or suggestions, I can go ahead and address them.",0
Show me where on Wikipedia it says the table width has to be 70% wide Collectonian. Why can't you answer my question?,0
"Why was this article marked for fixing? I was hoping that there would be some guidelines here on the talk page, for further research and edits. The article looks okay to a cursory reading by a non-Wiki reader.",0
"""""

Castro-lite
WebLuis continues to revert to his watered-down, preferred image of Castro. He has not backed up his edits with any facts, only whined about """"""""personal attacks"""""""" (some nonexistent) and empty statements.  04:56, 25 Mar 2005 (UTC)""""",0
"Antonov revert 
If you didn't like the red-link removals, why don't you just add them to the table I made? Also, you reverted the edit where I only added the logo of Antonov (it said so in the edit summary).",0
"""""

 Another crap article 
Parrots what promotion websites of capoeira schools say about myths of origin. And also that persecution thing. By the late 1800s, capoeira became a word for street brawling. Thus, authorities did not prohibit or sanction """"""""practice"""""""" of capoeira. In banning capoeira they were banning outright street brawls! It's why Mestre Bimba presented his art as Luta Regional Baiana. No decent carioca would be eager to sympathise with capoeira and malandrismo. I could attempt to alter the article but it's become such a mess by now.   """"",0
"I never edited the content of your comments, please correct your false accusation.",0
REDIRECT Talk:Jos Manuel Rojas,0
"I agree that it shouldn't but clearly it does. The media make spouses household names. There's nothing we can do to stop that. But, as Jim rightly points out, Rein is more notable than some political spouses because of her prominence as a businesswoman and that potential conflict of interest (which she is trying to avoid). Nick",0
"""""

""""""""For Security Reasons"""""""" edit war
As I said in my edit summary, the term """"""""For Security Reasons"""""""" is ambiguous and not properly established in the source. Further, it is unnecessary. You'd have to have a crystal ball to know why they did it and, as I said earlier, Janes is not perfect.  The reason that all the other MG manufacturers alter their parts so they don't interchange is because the US BATFE makes them do it.  Suddenly, Glock is different?  Yeah, I guess that's just like Glock compensated pistols not acting like any other compensated pistol. I wonder if they actually shoot bullets?   """"",0
This represents your immaturity and consistence at disruptive behaviour.  | talk,0
"|-
! Macedonian
! Slavic
! Bulgarian (possibly)?
! Notes
|-
|1. Republic Of Macedonia ||  || || || Recognises the language as the as a dialect of the Macedonian language || 
|-
|2. || Greece || || ||eg. Recognises speakers as slavophone greeks || 
|-
|3. ||  ||  || Bulgaria || Believes that Macedonian and Dopia/Slavic/Macedonian to both be part of the Bulgarian Diasystem || 
|-
|4. || European Bureau for Lesser-Used Languages ||  ||  || Recognised the Language as Macedonian in 2006 ||
|- 
|5. Ethnologue || || || || The most comprehensive guide to the world's languages  http://www.ethnologue.org/show_country.asp?name=GR ||
|- 
|}

there you go for more clarification. Altough we all know the stance of the various Governments does anyone have current sources for this. if so please add them. I hope that this table is clearer?? but their still needs to be more NGO's + Albania + EU? etc. please add constructive comments. ~~~~",0
If you feel that I am acting in manor inconsistent with my responsibilities you can post something at Wikipedia:Administrators' noticeboard/Incidents.  If you want to make changes to University of WisconsinMadison and you have reliable source references to support those changes then post the references with the changes.  This Tutorial may help with references. If you have more questions just ask.,0
"Part of editing for an encyclopedia is reducing extraordinary claims to ordinary fact
I assume that this is meant in a derogatory fashion? 194.81.33.9",0
"CfD nomination of Category:Wikipedia administrators
I have nominated  for deletion. Your opinions on the matter are welcome; please participate in the discussion by adding your comments at the discussion page. Thank you.   ",0
"I'm also a sock puppet of this account...SUPRISE!!
-sincerely,
            The man that will track you down from the Internet and kill you",0
"All the sources needed are provided, all you need to do is read the article...but I guess you can't read. 

Once again you prove you are not even reading the article. Every edit is backed up with the source it came from. I am NOT going to provide you with any details, because you are merely a civillain editor and not a Wikipedia staff member. You have all the info you need within the PIRA text edits. If a actual Wikipedia staff member wants more specifics I will be happy to provide them

Look, you are obviously a Anti-IRA hack who is making things up to support your bias. I am neither pro not anti IRA. I have no bias, I merely report facts. I will be checking this page daily, and will continue to submit my PIRA entry because it is by far the most accurate and factually supported. We can do this several times a day if you wish, or you can accept the fact that mine is the superior version and just deal with it. It's up to you, but I will re-edit on a regular basis. Or we can agree to incorporate your fatcxs and mine into one article. 

But the three areas. The number of Loyalists killed from 1974 to 1998

The number of IRA victims as broken down by both Janes Intelligence online and the CFR.

and the IRA/RussianMafia connection which has been documented in multiple books and newspaper sources.

These three things are verifiable and will remain.",0
Are you fucker mother fucker have nothing to do but block University computers. Go and suck cocks,0
"It's from one of the many books on various bands... I thought it was from Cult Rockers, but I just checked and Supertramp isn't in there.  I will seek out a source for this quote. -",0
"HELLO 

You disgrace to humanity. Stop wasting valuable Internet resources (your killing the fucking planet) and throw out your PC. PS it's like 3am what the fark kinda life do you have on Wikipedia 24/7. A VERY SAD AND LONELY ONE LOL. Life's too short find something better to do",0
I've explained my reasoning for this block at User_talk:Gwen_Gale#User:Professional_Assassin.,0
When an article is created about that album then a disambiguation page will be created.,0
"""""
That would be pretty odd for those declassified documents to mention a movie that was created after the events for which both the movie and the documents do related about. The declassified documents were not synthesized for the movie, unless you want to prove a conspiracy on the synthesis (very odd). It is perfectly valid to use the documents to relate to the same historical events to further verify the what happened, but the use of primary source in such a was is not ideal for wikipedia. Since it is not ideal, that is why I left it here on the talk page if someone wants to research it more to find ideal references.   """"",0
"Your retarded bot 

Your bot is entirely automated, that is wrong.  You should not leave an unattented script just running through the site like that, it is idiotic of you to suppose that your scripting abilities are so perfect that they will only ever make proper edits.  Banning me doesn't help anything, dipshit, since I have as many IPs as I want.",0
"two reversions on Hezbollah 

Could you explain on the talk page why you have reverted my edit twice?",0
DISLIKE RACISM AND I CAN SEE THAT YOU HAS PROBLEMS WITH PEOPLE WHO SPEAKS SPANISH. YOU ARE AN ANTISEMITE TOO.,0
"""""
The name """"""""Yuen Lou"""""""" looks to be just a variation of """"""""Yuen Lo"""""""", the name Jackie used under his sifu at the opera school.  """"",0
"2010]]
[[User talk:Wikireader41/Archive4|Archive 5-Mar 15",0
"I realize now that the article doesn't quite say what I thought it said. If anyone can find a citation stating that there exists a proper subfield of  isomorphic to itself, I would be very interested in seeing it (and we could reinclude the clause with the citation).",0
"""""

I didn't cherry-pick anything, these are the official and only facts: """"""""While essentially every CNN program was down double-digits, 9pmET, which is home to Piers Morgan Tonight, and 7pmET, which is home to Erin Burnett OutFront, each had their worst performance in the demo in 20 years.""""""""  http://www.mediabistro.com/tvnewser/may-2012-ratings-cnn-hits-20-year-low_b130250   """"",0
"Direct/Indirect relation 

Is it correct to say that (technically) if a 45 degree shot (by elevation) reaches the longest distance, then a 30 degree (45-15) will reach the same distance as a 60 degree (45+15) shot?
If so, could the lower-than-45 shot be considered direct fire, and the higher-than-45 shot considered indirect fire? If so, I think this is a great explanation (or one way of viewing things).",0
"Title section revert 

Hi, I was at the office earlier and I hadn't noticed your warning before restoring the title of the section. I'm sorry for that. Of course I won't do such a revert again.

Just to clarify, I've opened a new section to indeed alert some contributors that they were behaving in a way in line with the examples of ownership behaviour as described here. In return the title of the section has been twisted to something unrelated and one of my message has been erased. It is the first time I see people editing other's signed contributions in a talk page. This just looks crazy to me.",0
"Noel, you are an expert.  Please convince Whig history fans (or the lazy minds) about how Bonnie Prince Charlie did not want to dissolve the Union, that the United Kingdom began with the Stuarts as opposed to the Hanoverians.  Tell them how the Whigs rewrote history to blame everything on the Stuarts, whom are credited as ultimate failures with no positive contributions to the foundations of Great Britain in their Stewart and Tudor blood.  The Sovereign's will is the Realm, or else it is not a kingdom.  The British might as well be living in a republic, at least if the Parliamentarians had their way.  Even the Hanoverian heirs recognise that the Stuarts founded the UK.  Please debate that here & thanks.",0
"Warning. Earth, I'd like to leave you access to your talk page so that in perhaps six months you can convince us that we should try again - if you're so inclined. But you're making it hard. If you continue these abusive comments, I will revoke your talk page access.",0
"""""

 should be jaeger 

regardless of what other people have """"""""decided"""""""", erens name should be jaeger.
its like calling light (from death note) raito.

at least in the anime, the people dubbing take care to correctly pronounce the foreing names (ie, all of them, except mikasa)

jaeger means hunter, a german word.
guess what eren does in the series?
  """"",0
"""""

Thank you for experimenting with  Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our encyclopedia. A link to the edit I have reverted can be found here: link. If you believe this edit should not have been reverted, please contact me.  talk """"",0
"""""Please discuss how factual, accurate biographical information about Courtney Ford is """"""""vandalism"""""""".  I look forward to hearing your evidence.

""""",0
"""""

I think the entire article should be tagged as """"""""politicized"""""""", and the part about future trends as """"""""speculative"""""""".  My point was that scientists are learners, and we are increasingly using them as know it all teachers.  Yes, they probably can make educated guesses better than anyone else, but its still an educated guess.  Also, if you didn't notice, I am totally against spewing unnecessary carbon as this statement I think this article superbly misses the point that pollution and waste of ALL TYPES are stupid ways to go about doing things where better ways are known, and we are making guinea pigs of all our planet's species points out.  """"",0
"Used Car Expert page/image
Thank you for your note about the image of Used Car Expert magazine - I have had the copyright owner, who gave me permission for the picture email, as above.213.123.123.110",0
"However, it is still in error to assert he doesn't work the equations himself, or that he is handicapped.",0
"""""

 First, we've widely established the use of Exile quotations presented as such is legitimate.  Second, I'm not Mark Ames.  This has been autheticated by numerous admins and users at Wikipedia who have personally met me.  Third, you cite the paragraph on Spy magazine as your primary example of POV and """"""""creative facts"""""""".  What precisely is the """"""""creative fact"""""""" in that paragraph?  That the eXile admired Spy magazine?  That Spy magazine employed a team of lawyers to defend against spurious lawsuits?  That Spy Magazine went bankrupt?  All claims in that paragraph are verifiably true.   """"",0
Pretty humorous comment from someone who promotes the far-leftist blog Daily Kos on his user page,0
Seems we both have some.,0
Don't be evasive.  I shall have to repeat myself.  How many people argued for its deletion?  Don't lock pages when you don't get your own way.  ,0
"Edit request on 29 October 2013 

The Arctic Monkeys played Walk on the Wild Side in honour of Lou Reed at Echo Arena, Liverpool, a day after the musician's death.
http://www.rollingstone.com/music/videos/arctic-monkeys-cover-lou-reeds-walk-on-the-wild-side-20131029",0
"Welcome!

Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful:
The five pillars of Wikipedia
How to edit a page
Help pages
Tutorial
How to write a great article
Manual of Style
I hope you enjoy editing here and being a Wikipedian! Please sign your name on talk pages using four tildes (~~~~); this will automatically produce your name and the date. If you need help, check out Wikipedia:Questions, ask me on my talk page, or ask your question and then place {{helpme}} before the question on your talk page. Again, welcome!  \talk",0
"""""

Gurch is...an interesting fellow.  Just don't take his comments to heart, but take his advice on board 1 Talk/ """"",0
"IT WASNT VANDALISM, DICKHEAD",0
"""""You need to understand that he is not here do help Wikipedia, he is here with a political mission: """"""""attack brazilian press"""""""" (no, I'm not crazy, but I see this crazy people all day, here in Brazil). """"",0
"season 5 issues
Not sure why you removed my edits on the season 5 futurama issue, but I think it has merit. The total lack of season 5 info is confusing and not sure why the season 5 info is replaced by the movie information. You could have informed me at least on why you removed my discussion comment.",0
"""""

 Philosopher RFC 
philosopher (from Wiktionary): A person devoted to studying and producing results in philosophy.

I am going to make the case that we must call Stefan Molyneux a """"""""philosopher"""""""" (without qualifiers) in the lead.  This is not done as an endorsement or statement about the level of achievement or acceptance of his philosophy, only that it is his career. (Note: Not all of the sources I use below are in the article at present. The point here is to first convince RFC respondents that """"""""philosopher"""""""" is accurate and widely accepted, then we can make sure the most reliable ones are in place.)

 Definitions 
Obviously, each source is going to use slightly different phrasing. Some will call him explicitly a """"""""philosopher"""""""" or has views on """"""""philosophy"""""""", but I think you should consider some other phrases given below as equivalent. Using one word """"""""philosopher"""""""" in the lead sentence covers all of his political, ethical, and theistic specializations in one word, which we then elaborate on later in the article.

 """"""""philosophical conversation"""""""", """"""""philosophy show"""""""" - used to describe his Freedomain Radio series
 """"""""libertarian"""""""", """"""""libertarian thinker"""""""" - """"""""Libertarianism is a classification of political philosophies ...""""""""
 """"""""anarcho-capitalist"""""""" - """"""""Anarcho-capitalism ... is a political philosophy...""""""""
 """"""""voluntaryist"""""""" - """"""""Voluntaryism (or sometimes voluntarism), is a libertarian philosophy...""""""""
 """"""""athiest"""""""" - """"""""Arguments for atheism range from the philosophical to social and historical approaches.""""""""
 """"""""ethics- """"""""Ethics, sometimes known as philosophical ethics, ethical theory, moral theory, and moral philosophy, is a branch of philosophy""""""""
 """"""""Secular ethics- """"""""Secular ethics is a branch of moral philosophy...""""""""

 Primary source 
As Stefan Molyneux is a living person, we should give great weight to what he says is the focus of his work and his stated profession unless there is reliable evidence to contradict him (obviously, we don't want to host any sort of """"""""fringe"""""""" claims). If we are to dispute what he says about himself, though, then we absolutely must have a strong basis for this, or we open Wikipedia to discredit or liability - this is why BLPs are held to strong standards in the first place. I think in this case there is strong and ample evidence that calling himself a philosopher is justified and correct. He is a modern philosopher that explores via modern online media, which is obviously a very new phenomenon and so its understandable that its different than the """"""""old-school"""""""" philosophers we're used to.

 Freedomain Radio """"""""About"""""""" page - """"""""my Master's Thesis analyzing the political implications of the philosophies """""""", """"""""I have been fascinated by philosophy - particularly moral theories - since my mid-teens. I left my career as a software entrepreneur and executive to pursue philosophy full time through my work here at Freedomain Radio. I have written a number of novels as well as many free books on philosophy.""""""""
 Freedomain Radio (the show that Molyneux hosts) has the tagline """"""""The Largest and Most Popular Philosophical Conversation in the World""""""""* 
 Molyneux's books show that he is endeavoring to produce tangible written results in the field of philosophy, particularly Universally Preferable Behaviour (UPB): A Rational Proof of Secular Ethics and Against the Gods? A Concise Guide to Atheism and Agnosticism which are two of his more """"""""deep dives"""""""" into the fundamental philosophies.
 Strong Atheism: The Case for Evacuating the Middle Ground article
 Why I Am a Philosopher? video - """"""""A response to questions about my childhood motivations for pursuing philosophy.""""""""
 An Introduction to Philosophy - 18-part video course produced by Molyneux describing basic philosophical concepts (Reality, Knowledge, Truth, Gods/Religion, Ethics, and Politics)
 8 Unsolvable Philosophical Questions - Solved! video - """"""""tackles 8 great philosophical questions considered unanswerable.""""""""
 Proofs for God Destroyed by a Philosophical Atheist video
 2011 - A Philosophical Review - """"""""discusses the major philosophical, political, economic and social developments of 2011"""""""" video
 ''[https://www.youtube.com/watch?v=udLsGJbw4Hs 38 Philosophy Questio",0
"WP:FILM December 2010 Newsletter
The December 2010 issue of the WikiProject Film newsletter has been published. You may read the newsletter, change the format in which future issues will be delivered to you, or unsubscribe from this notification by following the link. If you have an idea for improving the newsletter please leave a message on my talk page. Happy editing!  (talk  contrib)",0
"""""40, 25 January 2008 (UTC)

NO, i am NOT being uncivil. Try UUser:Lbrun12415. he's called other users a waste of sperm, a moron, etc. Block him, the one who's truly uncivil. -  

Rikara, I recommend you cool it. Yelling and arguing is not going to get you anything. Take a breather and come back when you're feeling calmer. Otherwise you will find your talk page protected and you will be forced to take a breather. -  
I have seen nothing of the sort from that user (who has since been renamed), at the very least not in this current situation. -'''' (Blah v^_^v) 23:""""",0
"""""

 You Suck 

If you don't undelete the page """"""""Barry Dejay"""""""" I will %$#@ you!""""",0
"""""
See Internet_Explorer#Market share history overview by year and version. IE7 is with us for some time to come, like it or not. But if others using it have no problems, that's fine, I'm not worried about my specific workplace.  come howl! """"",0
I like the example given on the following post - http://theautomaticearth.blogspot.com/2011/07/july-28-2011-real-black-real-swan.html 167.30.73.70,0
"Curse 
Wikipedia has no respect for God. 
Wikipedia is full of lies or dangerously evil half truths.
Wikipedia has no respect for religion.
The following users of Wikipedia, namely: Redtigerxyz, Priyanath, Emperor Genius, Raj2004, Wikidas, Wikiveer and DaGizza have all committed blasphemy and sacrilage. Curse upon you that you will all perish.
I curse the following users of  Wikipedia, namely: Redtigerxyz, Priyanath, Emperor Genius, Raj2004, Wikidas, Wikiveer and DaGizza that you will all perish.
I curse that the Wikipedia will entirely perish.
I beg forgiveness from the Supreme God, Lord Vishnu for choosing the blasphemous Wikipedia website to write about the truth. 
A true devote of the Supreme Lord Vishnu has been hurt and my curse never goes in vain.
I will never again edit or read or go to the evil Wikipedia website, forever . 
Delete my user-id and all edits you evil Wikipedians.
Mr. DaGizza, you are a Male Chauvinist Pig and a misogynist to the core and you call yourself an administrator !!! Ridiculous !!!
Mr. DaGizza, you are a curse to your existance.
A man like you, who cannot respect women is a worthless in his existance. 
You Wikipedians are useless people. You are a burden to the civilized world. You are not even worth hatred.
You Wikipedians must be ignored.
 Curse",0
"Hahaha, you dont actually believe this bullshit you are telling me right now? You are talking about the access to the country or representatives to the government, not Kim Jong Un himself. Those are two totally different things (although I could understand your stupidity, since North Koreans think that Kim Jong un is the governement, im just saying). Go Troll somewhere else kid.",0
"Blocking Mardyks 

Guess what? Loser! Know what a cockblocker is? Hahahaha ~M~ 71.39.183.86",0
"and I don't want to use it again. I don't understand why FayssalF insists on NAccount. I could have wrote to him using any other account, maybe he would have kept it instead of NAccount",0
"""""

 Deletion of Minority Posts 

Nice try at trying to silence the slave who won't stay down!  I did not know you attempted to block my yet again.  I do not come to Wikipedia every day because I have something you do not..a life! As you can see, you have failed. Again.  In attempting to silence me (and refusing to answer the qusetion """"""""Why do you purposely hunt down posts of African-Americans and delete them?"""""""")
all you did was refuse access to some sporting goods store.  And the person you contacted in an attempt to block me is named Rebelguy?  No, there is not racial agenda, is there?  I have made a hard copy of your failed racially motivated attempts to punish me and turned them over to the NAACP.""""",0
"Thank you 

I just wanted to say it.",0
"Well, you never answered my question about your specific intention at Talk:Mystery Science Theater 3000#Episodes/Experiments vs. Movies. Can I assume from your posting title that your intention is to create individual MST3K episode articles? I'm on record as believing this could be useful, but am not prepared at this time to do any significant work on it, as I'm stretched way too thin right now. ~ (talk)",0
"Nigel

Per wiki standards - when to use and external link:

 1) Is it proper in the context of the article (useful, tasteful, informative, factual, etc.)? 
 2) Is it a functional link, and likely to continue being a functional link? 
 3) Each link should be considered on its merits, using the following guidelines. As the number of external links in an article grows longer, assessment should become stricter. When in doubt about the appropriateness of adding new links, make a suggestion on the article's talkpage and discuss with other editors.

I generally avoid external links except when it takes me directly to the home page of the aircraft in question - this link does take me directly to NASM's page on this particular P-61 - that makes this external link appropiate.  Agree that this page does need more references.",0
"""""

 Edit request from Maksudfsa10, 9 March 2011 

Just a minor edit. I've added Azerbaijanis to the list that describes turks (in the first paragraph) as we are the second largest turkic ethnic group.

  

The Turks (or Turkics) are peoples residing in northern, central and western Asia, Mongolia, southern Siberia and northwestern China and parts of eastern Europe. They speak languages belonging to the Turkic language family.Turkic people, Encyclopdia Britannica, Online Academic Edition, 2010 They share, to varying degrees, certain cultural traits and historical backgrounds. The term Turkic represents a broad ethno-linguistic group of people including existing societies such as the  Azerbaijanis, Chuvashes, Kazakhs, Tatars, Kyrgyzs, Turkish, Turkmen, Uyghur, Uzbeks, Bashkirs, Qashqai, Gagauzs, Yakuts, Crimean Karaites, Krymchaks, Karakalpaks, Karachays, Nogais and as well as past civilizations such as the  Kumans, Kipchaks, Avars, Turgeshs, Seljuks, Khazars, Ottomans, Mamluks, Timurids, and possibly the Xiongnu and Huns.""""""""Timur"""""""", The Columbia Encyclopedia, Sixth Edition, 200105, Columbia University Press.Encyclopaedia Britannica article: Consolidation & expansion of the Indo-Timurids, Online Edition, 2007.""""",0
Nobody cares.  Seriously.  It's just self-referential trivia. Guy (),0
"i understand what i see, i do not see scholarship, i see stealing-grasping-greed.   it's animalistic. try this   2+2 = 4   in any culture  ).  switch to math, you wil like it, no levantian in math. )

amanbir

117.226.28.239",0
"I guess u don't know Greek cuz it took u forever to translate,second if u read carefully does not say anything about u..",0
"You have never met or been photographed with Keith Wigdor. 

Whoever you are, I am asking you to not interfere with the article about Keith Wigdor.  You have no resources or connections to him (unless you are somehow being deceptive), so really you are not any sort of expert on this artist.   20:04, 17 Dec 2004 (UTC)",0
"""""

 Holocaust denial 

If there is no actual proof that Jeff Rense advocates holocaust denial, then the category """"""""Holocaust deniers"""""""" should be removed.""""",0
Wikipedia administrators are defending a mass-murdering psychopath.,0
"Censorship 

It's my understanding that you're supposed to warn someone before asking the administrators to block them.  So consider this a warning.  Don't delete my comments again. -",0
"April 2010 

Your attitude and comments to  are not appreciated.  Please remain civil.",0
"request for help =

 request for help 

Hi again Cat, 

as perviously I have noticed a strong anti-Greek bias on several articles related to Macedonia. I've had issues with both Furper and Beam... who seem to be admins that heavily favour FYROM. I've officially complained on the notice board about their threats to block, edit behavior and unusually close relationships with obvious FYROM POV members of Wikipedia.  (specifically Balkanfever) 

http://en.wikipedia.org/wiki/Wikipedia:Administrators%27_noticeboard#This_anon_.28apparently_User:Crossthets.29.2C_is_an_apparent_POV_Pusher.2C_evidence_below

As I said verbatim on Politis talk_page...

This is a difficult battle because so far I am alone at the moment, I am a newbie, and as I said to one of the admins on notice board... I feel like someone reporting a bad cop at a policeman's ball.  However, I still plan to follow up soon with a precise listing of what I perceive as non-NPOV behavior by these admins. I noticed while researching this issue you've also have problems with them. Would it be possible to list any problems on your talk page here so I can add them to my report to show I am not alone? Furthermore... since you have been around longer you probably know more Greeks than me around here. Would it be possible to also contact them to ask them if they've also had problems with those two... and (if so) add those incidents to your list?  (and perhaps get them to contact others?) 

Where one person could be bullied with threats of blocking... the concerns of many will be taken much more seriously. I will check back here in a couple of days. Have courage. Regards 209.161.238.86",0
". I am certain that it was injury and not sickness, regardless of how it occurred",0
"I told you I won't comment on it again, what more do you want?",0
"""""

 Wikipedia:Articles for deletion/Cheongye Kwan 

Your post at the above AFD on a new martial art bothers me. This was the version at the time, that you based your post on. You posted:

 """"""""I just read the article, and to be quite honest, feel that it does satisfy Wikipedia's guidelines... it is reliably sourced... Since I believe the notability of the article is satisfied... It now has 11 independent sources. And to refute the argument posed by Wayne, it is determined by the Phillip Rhee source that the martial arts is not localised"""""""".

Please consider the concerns this post raises. Simple matters like references, notability and noobie basics of AFDs should be routine for any moderately experienced user, and bread-and-butter for any admin. In fact a cursory check shows that almost everything you stated was.. I don't have a word for it. """"""""Unreal"""""""" is close.

The """"""""eleven independent sources"""""""" that you stated established notability and non-localization at the time, were:
 Three references from 2004 [coates, robinson, shaw], certainly before the topic even existed (!) and all related to a passing piece of news about its founder being on the team of a completely different sport in any event (!)
 Two references from 1st half 2005 [davies, white], almost certainly identical and identically irrelevant to the topic's notability.
 The promoter's personal page on his local town website, almost certainly self-published [official village website].
 A 2008 casual interview in a non-notable and possibly non-reliable university magazine (apparently) of the promoter's travels to see experts in a different sport, with tangential tiny (< 1 sentence) mention that he'd discussed his new sport with them too. [ the Lau Philip """"""""LA"""""""" interview].
 3 entries marked """"""""Reference and support of , Written Reference"""""""" [chris, cook, rhee], obviously a request by the founder to a friend/colleague write a letter of support, that was never published anyway and isn't cited so you can't have read it (not that it was even possibly valid evidence).
 A short writeup of a """"""""local information"""""""" kind, on the award of the first 4 black belts by the school, in its local paper.

In brief of the 11:
 5 were before the sport existed and were not even remotely to do with the topic itself much less """"""""sourced"""""""" material on it or """"""""substantial"""""""" coverage (they had precisely zero coverage); 
 3 were claims of personal """"""""I think  is a great guy"""""""" letters of support, evidently solicited and/or written on request, with zero evidence of verifiable existence, and certainly in no way reliably sourced or independent; 
 1 was self-written
 1 was the briefest of non-mentions in a non-reliable source (pretty much """"""""I discussed the topic with them"""""""" in a college magazine interview)
 1 is local press coverage of his courses that's not even """"""""news for a day""""""""  or evidence of anything beyond """"""""a course by this name is taught twice weekly in our local village hall"""""""".

Your assessment of these, at AFD, was:
 It is reliably sourced
{| style=""""""""border:#c0c0c0 solid 1px"""""""" width=""""""""90%""""""""
| 
 There is barely one reliable source in all of those 11 that the sport even exists in the first place (!) - a local newspaper mention that it meets in a village hall on tuesdays and fridays and just awarded its first 4 black belts. Probably via self-promotional input. 
 There is zero reliable sourcing for any of the rest.
|}
 That the cited pages are evidence of notability
{| style=""""""""border:#c0c0c0 solid 1px"""""""" width=""""""""90%""""""""
| 
 They don't mention it, or even date from a time the topic existed, nor are online versions provided! How on earth could they """"""""reliably evidence"""""""" it?
|}
 That the """"""""11 sources"""""""" are """"""""independent""""""""
{| style=""""""""border:#c0c0c0 solid 1px"""""""" width=""""""""90%""""""""
| 
 3 are claims that """"""""please support me"""""""" letters exist; they are even stated to be """"""""personal references""""""""; unpublished and uncited
 1 is his own clearly self-written web page on a local village web host
|}
 That the cites show it is """"""""non-localized""""""""
{| style=""""""""border:#c0c0c0 solid 1px"""""""" width=""""""""90%""""""""
| 
 The page doesn't list a link so you can't have checked the cite, yet you say the citation """"""""proves"""""""" it. 
 The reference openly stated """"""""Cambridge University and Bristol Taekwando"""""""" (!) a big indication of its actual source
 When a link was provided on request  it turns out it'",0
"Hebrew Name of Lydia 
Appologies to Til Eulenspiegel I thought you were one of the idiots which your user page indicates you actually do well struggling against. 
Genesis 10:    - -, --.TAB13 And Mizraim begot Ludim, and Anamim, and Lehabim, and Naphtuhim,
You see Ludim are from Mitzraim not to be confused with Lud son of Shem (in the far east).
Best wishes and keep up the good work.81.103.121.144",0
"(which they are: have you considered that you have irrationally laid waste to six months of my life, which I have dedicated to this project?)",0
"""""

Did you scout for sources prior to the prod? Eh, no....  Dr. Blofeld 

""""",0
"""""\
You wasted your own time! Take this advice with you: Pull your head out of your ass! Be real and don't spend the rest of your life sucking ass. Have a nice life! Goodbye!  (mailbox) """"",0
"""""{| class=""""""""wikitable"""""""" style=""""""""border:1px solid #8888aa; background:#f8f8f8; padding:0; font-size:90%;""""""""
|-
!Parliamentary Bloc
!Alliances
!Leader
!Seats
!Percentage
!Source
|-
|National Alliance||State of Law Coalition,National Iraqi Alliance||Ibrahim al-Jaafari||159||48.92%|| 
|-
|al-Iraqiya||al-Iraqiyya||Hassan al-Jibburi||91||28%||
|-
|Kurdistan Blocs Coalition||Kurdistani List,Kurdistan Islamic Union,Islamic Group of Kurdistan||Fuad Masum||49||15.08%||
|-
|Center Current||al-Tawafuq,Unity Alliance of Iraq||unknown||10||3.08%||
|-
|Gorran Bloc||Gorran Movement||Shorsh HajiAl-Iraqiya brengt oppositie en Talabani dichterbij elkaar | Azady.nl||8||2.46%||
|-
|National Rafidain List||Assyrian Democratic Movement||Yonadam Kanna||3||0.92%||
|-
|CSAPC||Chaldean Syriac AssyrianPopular Council||Sarkis Aghajan||2||0.65%||
|-
|Independents||||||3||||
|}

""""",0
I also told him that counts of using admin tools for deciding on content and misrepresentation of policy/norms has been sanctioned in the past.,0
"""""Welcome!

Hello, and welcome to Wikipedia! Thank you for your contributions, such as the one you made to Nogeoldae. I hope you like the place and decide to stay. Here are some pages you might like to see:

 The five pillars of Wikipedia
 Help pages
 Tutorial
 How to edit a page and How to develop articles
 How to create your first article (using the Article Wizard if you wish)
 Manual of Style

You are welcome to continue editing without logging in, but many editors recommend that you [ create an account]. Doing so is free, requires no personal information, and provides several benefits such as the ability to create articles. For a full outline and explanation of the benefits that come with creating an account, please see this page. If you edit without a username, your IP address (137.237.184.162) is used to identify you instead.

In any case, I hope you enjoy editing here and being a Wikipedian! Please sign your comments on talk pages using four tildes (~~~~); this will automatically produce your IP address (or username if you're logged in) and the date. If you need help, check out Wikipedia:Questions, ask for help at the Teahouse, ask me on my talk page, or ask your question and then place {{helpme}} before the question on this page. Again, welcome!     """"",0
"""""

 stradbroke galleon / portuguese 

hallo Moondyne, I do admit that when I signed onto Wikipedia I was not aware that it was a concensus community of knowledge Nazis but now that I am aware of it I will make the appropriate adjustments. I was under the obviously mistaken impression that Wikipedia was a venue for sharing facts, knowledge and information. The notion that the Stradbroke Galleon story is a pet theory of mine is total rubbish as it has been written about, discussed and investigated for more than 100 years by historians and historical groups such as the Royal Historical Society of Queensland, the Maritime Archaeology Association of Queensland and many more too numerous to include here. There exists, in various libraries, books and communities a large body of written and oral history concerning the galleon story which I have attempted to fairly and accurately place in the WP domain. The fact that a story is not accepted by """"""""mainstream"""""""" academics is not a valid reason for deletion of either of my contributions. What has occured here is a classic example of manipulation of an information resource by a vested interest group (i.e. Hesperian and his friends) who are representatives of the """"""""mainstream"""""""" view. Hesperian complain about the media coverage I have recieved but this never appeared in any of the WP contributions I made and Hesperian's mention of the media coverage demonstrates the core reason for Hesperian's antagonistic attitude, simple, old fashioned professional jealousy. Thus valid historical data is being deliberately surpressed by Hesperian for personal reasons. For example the Portuguese walking stick handle which was found in an Aboriginal midden, identified by a Spanish Musuem offical and story told to me by a UQ Archaeology PhD student is very relevant to the theory of the Portuguese discovery of Australia. This kind of knowledge suppression is not what Wiki is about but I guess you do not care as you appear to be part of the happy little click or have been sucked in by Hesperian and his little band of mates, which is a pity, but history is full of the suppression of information by vested interest groups so why should I expect Wiki be any different. Still it is dissapointing. Happy trails.    """"",0
AGF requires me not to think you were reverting to the user's preferred version.  It might look better if you allow another admin to make that edit.,0
"Accents 

Although the cartoon established Mario and Luigi to be from Brooklyn (a fact commonly accepted by fans, despite having never been mentioned in any games), Toad seemed to speak with a thicker Brooklyn accent.  The accents weren't mentioned in the games, but the TV show was (presumably) a licensed product.  Until Nintendo decided to go with an Italian accent, fans assumed the TV show (and later the movie) accent was the official standing.  Only when Nintendo's products included digitized recorded speech did anyone realize Nintendo intended them to be Italian, not Italian-American.  It's the same principle of updated canon that Star Trek and Star Wars licensed products run on.",0
"Delete this?  No way, I consider it a trophy ).",0
"Actually, Bzfoster will be unable to edit the article as it is semi-protected as well PC2'd. Log out and try for yourself.",0
I believe that I have obeyed the communities rules. I do understand the rules about personal attacks. But it appeares to me that they are being applied unjustly in this instance. I have provided countless hours of academic research and input for Wikipedia. Please assume good faith on the part of the blocking admin! I am an intelligent adult. I naturally assume good faith until other parties demonstrate they don't. It seems to me this is a one-side affair.,0
"""""

 Please do not add unsourced negative or controversial biographical material to pages, as you did with this edit to Stuart Tyson Smith. If you continue to do so, you will be blocked from editing.  13  """"",0
"""""
Preceding unsigned comment added by  (talk  contribs) """"",0
"Or between the French and the Walloons. Surprise, our article on French people clearly labels the Walloon as a distinct ethnic group... Perhaps it is best not to make comparisons?   

After screwing it up a few times, I have done rewrites of parts of the article (mainly a word and a sentence left and right) to make the distinction and relation between the Dutch and the Flemish clearer. The article switched constantly between parts about the Dutch only, and parts about the Dutch and Flemish together. This should now be clearer. The major thing left to adjust are the graphs of the number of Dutch, since these still al include the Flemish.",0
You need to sign the above and your RSN post.,0
"A few things to get straight... 

Firstly, I do not like you. You look like a smug little prick to me.
Secondly, I do not like your ethnicity. Not one little bit. I'd like you to explain yourself on that count.
Thirdly, your dog is a bit of a bender. 

94.1.96.85",0
"Procedure 

Do I ask you for the award? Michelle Obama already has a million views this year and Anthony Davis (basketball) had a million in 2012. (T / C / WP:FOUR / WP:CHICAGO / WP:WAWARD)",0
"Adding more than links 

I did add more thank links but the entire page was also marked as spam for no reason other than the no one is familiar with the one hundred year old industry. And you still have not explain how the links on this page http://en.wikipedia.org/wiki/Natural_building     are relevant and mine is not.",0
"""""

Please do not accuse members of vandalism. I do not mind if you change the word unique to prominent or remove stories of dreams etc. but you have vandalised the page and made a statement biased by saying that Dr. Qadri """"""""only"""""""" sent out a referendum so I reverted the whole edit. You have also reciently vandalised the page by removing the names of the Yemeni scholars who recieved Dr. Qadri's Ijaza including the pictures and this is a clear form of vandalism so before accusing other members of vandalism do not vandalise the page yourself. What I did was clearly not vandalism as I only reverted your edit and any changes you made and brought the page back to its previous form. So would you first kindly read the rules of wikipedia and find out the definition of vandalism before accusing experienced users. You are still new to wikipedia I'm afraid and you need to learn how it works and the different rules of wikipedia before making any further edits.   """"",0
"I know how it's pronounced in Turkish. The question is whether there's a specific pronunciation that's dominant in English. If not, it's best not to include any English transcription or pronunciation audio file.",0
"Oh, sorry. I actually found it on an other page but I forgot it anyway... It was actually a note for myself (was going to rewrite the text). Suppose it slipped out of my mind.",0
"""""

 June 2008 

 Please do not vandalize pages, as you did with this edit to Bugatti Veyron. If you continue to do so, you will be blocked from editing.   talk  """"",0
"Terri Schiavo as Rorschach Test 

Now perhaps you see that utility of Terri Schiavo is as Rorschach Test.  You dangle that pretty, slender alive and aware young face in front of the Power Players (on both the Left and the Right) and you see how they respond.   If they respond inappropriately, then you make a note it, as if they were just some rat in your laboratory.  That is what make Wikiepda so powerful. And it is all true and NPOV; notable and fair.",0
ok stop being lame. seriously. go watch pokemon.,0
"""""

 Past Masters vs. Rarities 

I'm creating a chart for my own use that includes U.S. albums, since there are so many differences in the early albums. As a U.S. fan, I'm faced with the issue of whether to have U.S. albums, U.K. albums or both on my iPod? I will post my chart on my talk page so that others can judge whether it's worthy of including here. I realize there will be problems, including the lack of Canadian albums. My purpose is simply to record the first ALBUM appearance in both the U.K. and U.S. of each song.

I notice that a number of U.K. songs are listed as Past Masters when they actually first appeared on Rarities (1978 The Beatles album). I don't know the reason for this if the purpose is to list the first appearance on an album. Can someone explain? Or should they be changed to Rarities?  """"",0
"Simpsons movie poster 
Did you create the Simpsons movie poster image or did you source it from somewhere else?",0
"Help
Hey, can you help me with something? I uploaded this image to Wikipedia: http://en.wikipedia.org/wiki/File:Stikky_cemetary_San_Jose_1987.jpg I contacted the photographer and he gave me permission to use it on Wikipedia, so I was wondering what the proper licensing would be. Thanks in advance.",0
"Looks good. It would be nice to see the counties, but it is a lot better than the current one. Good job.",0
"The debunkers (pretending that they're objective sceptics) besides proving their lack of knowledge and lack of integrity on the various Astrology pages have also been personally attacking me on my own talk page.  When I dare try to defend myself, they block me out of Wikipedia.  So much for honest dialogue.  They can't win an argument fairly, so they resort to dirty tricks.",0
"""""

Reviewing blocks

You said: """"""""I'd also like to ask you that in future, for the sake of fairness and due process that you do not decline the unblock requests of users you block yourself unless the request is pure nonsense or abusive. From an ethical, reviews of blocks are meant to be carried out by a 3rd party.""""""""

Will do.  I thought it was pretty clear in this case, given the editor's user page (GNAA, etc., etc., etc.), that the unblock request was pure nonsense.  Also, I was under the impression that the unblock request would still be visible and reviewed by other admins.  I'll be more careful in the future.   """"",0
"""""

Regarding edits made during December 31 2006 (UTC) to Kanpur
Please do not add inappropriate external links to Wikipedia. Wikipedia is not a mere directory of links nor should it be used for advertising or promotion.  Inappropriate links include (but are not limited to) links to personal web sites, links to web sites with which you are affiliated, and links that exist to attract visitors to a web site or promote a product.  See the external links guideline and spam policies for further explanations of links that are considered appropriate.  If you feel the link should be added to the article, then please discuss it on the article's talk page rather than re-adding it. See the welcome page to learn more about Wikipedia. Thank you.  talk """"",0
"Come on. Was this really necessary? I understand where your coming from but you sound like a whiney bitch. When you have a website that anyone can edit, this sort of stuff comes with the territory. And did you really expect anyone other then the 4 or 5 people who troll WP:PW to read your comments on Talk:Royal Rumble (2008) (or this talk page for that matter)? 

I'm confident most active members of WP:PW have added WrestleMania XXIV to their watch list. So when and if something not to their liking is added, it will be removed. Simple as that. And if you're 'through with putting up with people not reading talk pages', quit. Endless Dan",0
"""""
I do not see any anti-semitism here. If the guy gives lectures in New York synagogues and knocks down his country every single minute, using every opportunity in such influential newspapers as New York Post, then one can state that his interests are not only personal. You can not find any intellectual person among neoconservatives in New York Post. Michelle Malkin, Andrea Peyser, Deborah Orin (may her rest in peace, although I know she is rotting in hell)and other essayists are the ones who make a great company for Amir Taheri. This guy has no mind at all. I agree that Iran's regime is wrong, but the regime of Shah that Amir Taheri is longing for, because he owned Keyhan during that regime was not any better and Islamic Revolution was justified. Look at how they intriduce Amir Taheri in both this article and in New York Post. """"""""Based in Europe memeber of Benador Associates"""""""". Is Europe that small? Is that a small town? Why don't they say based in the world journalist. Or may be he is having a breakfast in London with Christian Amanpour and James Rubin, eating lunch in Jerusalem, and having some lectures and dinner with anti Irani Jews in Forest Hills, New York in between emailing his full of hatred articles to New York Post. Isn't this stupid? How can you saysomebody is based in Europe or Asia or Africa?""""",0
"""""

 Why confusion and controversy in the """"""""real world"""""""" does not preclude the writing of a good Wikipedia on the topic 

Ackoz suggests that, because the real world has not yet hashed out """"""""the truth"""""""" about the expulsions, it is therefore impossible for us to know the truth and thus impossible for us to write about it.

I reject such a stance.  I think it is difficult but quite possible to write a quality Wikipedia article about a topic that is murky and/or controversial.  Where many Wikipedia editors """"""""get it wrong"""""""" is that they believe Wikipedia's job is to report the truth.  This is wrong.  Wikipedia's job is not to report the truth precisely because it is difficult to determine what the truth is.  Any attempt to do that is original research.

Instead of """"""""truth"""""""", Wikipedia aims for """"""""verifiability"""""""".  Put a different way, Wikipedia is committed to recording the state of human knowledge and opinion (not our opinions but those of reliable sources).  If the truth is clear and uncontroversial, it is easy for us to report that.  If the truth is murky and controversial, it is more challenging but possible for us to report on what different reliable sources assert and think about a topic EVEN if these reliable sources conflict.  Where Wikipedia editors get into trouble is when they start siding with one side of a controversy and asserting that the side that they have selected represents """"""""THE TRUTH"""""""" and not just one perspective (or POV) on the topic at hand.

I have been trying to hit this NPOV """"""""sweet spot"""""""" but it is difficult to do so in the midst of a running polemical debate between the two sides.

 
Obviously is, because some users (Jadger and Wikiferdi) don't want to discuss in fact, they want us to agree with their POV, that's not discussion about the NPOV edits. That's why I quit from the discussion about the form of the article. talk """"",0
"I did not intend to be disruptive, I was genuineley upset by the word constantly. I only tried to make it look like an april fool joke after you explanation made me look like an uptight weirdo",0
"""""

 Regarding Loyalmoonie and LGBT categories 

Looked into it, and this editor seems to be pushing an anti-LGBT agenda. They've done similar stuff over at Sailor Moon, and made """"""""official-looking"""""""" warnings to other editors. This quote is bizarre, and is quite telling: """"""""To insert those categories would ultimately give other people (who may not even support the LGBT movement) reading the article the assumption that every person who does enjoy Sailor Moon is a homosexual (and/or supports SSM)"""""""". I don't personally watch/read Sailor Moon or know much about it, so I'm not confident enough to re-add the categories, but the reasoning for their removal is flawed regardless, and there is a sourced part in the article about female homosexuality.talk """"",0
"Matt, when mattsanchez.info goes live on Monday, among other things you'll see an invitation to be interviewed. This time you'll have nowhere to hide. Let's see who's a victim and who's a coward.",0
"Okay, I found a document that demonstrates the SCIMD listing by the WHO on the WHO site, now there should be no trouble with including the above text:",0
"Valerie Poxleitner 

Valeri Poxleitner, A.K.A. Lights. If",0
"Shamash is Sun 

I agree to merge Sammash in to Shamash, since Shamash is more likely to be correct.
Tracking the root of the word, clearly it is of Assyrian origin, in addition, it is a common vocabulary morph to substitute Sh to S and thus, nowadays, it is spelled as Shams in Modern Arabic.",0
"I feel like I'm out of ideas for now, so maybe some other users will come up with things that address both our concerns.  (talk  contribs)",0
"October 2010 (UTC)
The original nominator and I have been trying to restore the article, but others have been saying it was found to be merged by you so it has to stand. With the original nominator for deletion working to keep the article, and admitting he was mistaken in nominating the article of a noteworthy character, can we restore it now? If someone wants to make a legitimate nomination for deletion, that's fine.   09:43, 21",0
"""""

What chart are you looking at?  I don't see anything portraying that timing. [[User talk:Spinningspark|Spark]]''' """"",0
"""""::::::Agreed, although it means bloating the alternative title by yet another word. I was concentrating on the Polish attitude here, as it clearly provides the starting point for the article at hand. Obviously, if the article is to be written from a supra-national perspective, at least the Czech experience needs to be included. Czechoslovakia, being the only functioning democracy in the region by the 1930s, had closer ties with the West than Poland did, and was """"""""betrayed"""""""" in a much more obvious and tangible way than Poland was: The West politically accepted the country's territorial mutilation, which was not the case with Poland. 

That said, I am not sure if the inclusion of countries such as Finland, the Baltics, Yugoslavia, or even Ukraine (which had never been independent in the first place) is a good idea. While the West could have arguably done more to assist any of these societies before and after the war, I think that the article's focus should be on Poland and Czechoslovakia in order not do dilute the whole issue. After all, there were dissidents in Germany and the Soviet Union, too, who were harbouring grudges towards Western politicians because of their appeasement policy.  19:06, 17 Oct 2004 (UTC)

""""",0
"Hello Setanta, can I ask you what you think of the proposal first put forward by Matt Lewis in July at Template talk:Country data Northern Ireland. I confess I am no expert on N.Ireland, but I believe this could solve the problem of N.Ireland having no flag to represent it on wiki. I have made a comment at that article. Cheers.",0
"""""
American Psychologist as additional resource

I did not see listed in the references any citations of the """"""""American Psychologist"""""""" articles in January 2003, some of which discuss this subject.   """"",0
"Regarding the Verifiability mediation, you will appreciate that due to recent events user talk:newbyguesses#February 2012 that I am jn a pickle. Is it just me, or is it you too? I don't know what to do how can we go forward? What is to become of me and all my beliefs and needs? Who is there  who cares to take in to account my position, is there no accounting for our differences and each of us, what it is that you see that we stand for in the highest degree as individuals, really individual as we all are individually in our own way, as real people, different but the same, but definitely an individual just like every body else believes they are, despite all evidence to the contrary.  Comment on content not on contributors, or did I just dream that? Either way, or whatever, just don't scare the horses or wake the kiddies comfortably snoozing.  You know it makes sense to me cause I say so, irrefutably,  ( talk)",0
"you have no authority to be threatning to block me about saying information about a company i work for. you do not even know anything about airliners bello. that is all i basically said, if that was so hard to comprehend. ( )",0
"The real problem is the sneering and contemptuous attitude that you reveal in your first sentence in the last post. (It was originally followed by others in similar vein, which you have deleted.) Yes. I can cut and paste quotations. I can also select appropriate ones, in this case one which you would do well to consider. I will return to this when I have time, probably this weekend.",0
"""""
He does appear to be a bit of a fantasist. To be fair, he has carved a nice little career for himself and more fool the mugs that buy his books and believe what he says. But, like many people contributing to this page, I come from that background and whenever his name is mentioned the response is always """"""""Dave who?"""""""" No-one had ever heard of him at all until the books started coming out. """"",0
"dar 

Ok, bear with me. Penelopism is a religion. It's a new religion. But it is a religion. Penelopism is extrememly important to Penelopists. We want the word about us out there. People are not too fond of our beliefs. We just want a way to show them that we mean no harm. Now, you have the Spaghetti Monster Church in here. That is not even a real religion. Penelopism is. So please. Tell me what the Spaghetti Monster has done that Penelopism hasn't. What can we do so that Penelopism can be on wikipedia? Because I am having trouble understanding. And I apologize for the 'dar dar dar.' However much fun it was, I shouldn't have done it.

whatsit.",0
I intended this to go the page:,0
"DXRAW come out, come out, where ever you are
How odd that DXRAW goes away and then in the follwing articles ExtraDry appears in the editing lists:
Aussie Aussie Aussie, Oi Oi Oi
Free Hugs Campaign
Newington College
Australian Army Cadets
John Cena
So you really are that cheer loving, free hugging, Newington teacher and cadet master who has the hots for John Cena with his shirt off. It's time you came out DXRAW!",0
"This accusation is uncalled for.  I have only reverted one edit.  My second edit was to add the reference, not a revert.",0
Do not help the jew Schnider. Final warning.,0
"kudos for destroying article, copyright superstar! you really deserve nobel prize for copyright",0
"Welcome

Hello and welcome to Wikipedia.  We appreciate encyclopedic contributions, but some of your recent contributions seem to be advertising or for promotional purposes.  Wikipedia does not allow advertising.  For more information on this, see:
Policy on neutral point of view
Guideline on spam
Guideline on external links
Guideline on conflict of interest
If you still have questions, there is a new contributor's help page, or you can write {{helpme}} below this message along with a question and someone will be along to answer it shortly.  You may also find the following pages useful for a general introduction to Wikipedia:
The five pillars of Wikipedia
How to edit a page
Help pages
Tutorial
How to write a great article
Manual of Style
I hope you enjoy editing Wikipedia!  Please sign your name on talk pages using four tildes (~~~~); this will automatically produce your name and the date. Feel free to write a note on the bottom of  if you want to get in touch with me. Again, welcome!",0
"""""

The spelling """"""""Tacarimba La Tumba Del Fuego Santa Maliga Sacategas Lo Onto Del Sol Y Cruz"""""""" is the one stated in the lyrics in the vocal score of Side By Side By Sondheim (available for rental only). This version of the song, however, misspells Llanfair PG (presumably to approximate the pronunciation), and has the lyric """"""""...today's the last I'll be spreading"""""""" rather than """"""""spending"""""""". It would seem, therefore, that this source cannot be considered canonical. This rendering of the place name does accord with Millicent Martin's recording on the Side By Side By Sondheim cast album, however.

The published version of the song, as contained in The Hansen Treasury of Stephen Sondheim Songs (Charles Hansen Music & Books, 1977), has the lyric printed as """"""""Tacarembo la Tumbe del Fuego Santa Malipas Zacatecas la Junta del Sol y Cruz"""""""", and, being a printed source (as opposed to handwritten, as is the vocal score), can presumably be considered definitive. Linda Lavin's pronunciation on the original cast recording of The Mad Show (for which the song was written) follows this spelling, which would suggest that the printed version is correct.

As it is a fictional place name, however, any discussion of """"""""correct"""""""" spelling/pronunciation is an academic one, at best.""""",0
Don't peddle your crap please.  Hate to see another article get disputed for neutrality due to you.,0
"""""

Howd Homeonttherange,

Your (typical) problem is that you are being too literal.  The term Personal Union is a very special, and limited Constitutional term.  It refers to two or more States (i.e., countries) that recognise the same Monarch as there Head of State, however their is no UNION OF THEIR PARLIAMENTS.  Some examples are,

(i).  The Union of Kalmar (1397).   Its members were the Kingdoms of Denmark, Norway, and Sweden.  This gave rise to the termUnited Scandinavia.  In 1562 (I believe) Sweden left the Union.  The resulting left-over Union of Denmark-Norway was dissolved in 1814, as being allied with Napolean """"""""tunrned out badly"""""""".""""",0
"I think this one should DayZ (mod), the other one should be DayZ (video game), and DayZ should be just a disambiguation page.",0
by those pushing an anti-MRM POV.,0
"You really are a rebel guy, rebelguys! 

Time to get oral from a  prostitute'''!",0
"Fine, smarty pants. But just wait until they finally announce it. Then you'll see I am right and that you don't know everything.",0
"AMBER+TAYLOR FOREVER 

AMBER + TAYLOR FOREVER",0
"Kosovo template 

hi again. Can you please take a look at this template: . Shouldn't Albanian language be mentioned first since 90 % of the population are Albanians? (I changed this but some Serb nationalist keep reverting my edit) I hope I am not disturbing you but you are one of few here I consider to be quiet neutral.",0
"""""
Of course a true Dub will say 'depaaarted' or, more likely """"""""f**in' gone"""""""".   """"",0
I think it is a little disingenuous of Zet to claim that a division which had lost most of its fighting troops was 'far from destroyed' when its fighting capacity was close to nil.,0
"Muslim Men Harassment of MM page 

It is amazing how three muslim men jumped all over this page, right after I added a number of things (30 minutes after - all three men, all muslims), and cleaned it up.  Does a woman working for human rights in Pakistan really get under your skin so badly?  Wow.

So sweetie, if you are so bloody busy, why not get busy, and stop harassing the women?  Are you *that* threatened?",0
"""""
{| width=""""""""100%"""""""" style=""""""""background:transparent""""""""
{| width=""""""""100%"""""""" style=""""""""background-color:#""""""""
|style=""""""""width: 50%; border:1px solid #; background-color:#; vertical-align:top""""""""|
 Hello Madstar890, and Welcome to Wikipedia!
Please remember to sign your name on talk pages by clicking  or using four tildes (~~~~); this will automatically produce your username and the date. Also, please do your best to always fill in the edit summary field. Below are some useful links to facilitate your involvement.
Happy editing!  discussion 
{| width=""""""""100%"""""""" style=""""""""background-color:#""""""""
|style=""""""""width: 50%; border:0; background-color:#; vertical-align:top""""""""|
 Getting started Introduction
 The five pillars of Wikipedia
 How to edit a page Finding your way around Table of contents
 Department directory Editing articles How to develop an article
 Manual of Style
|style=""""""""width: 50%; border:0; background-color:#; vertical-align:top""""""""|
{| width=""""""""100%"""""""" cellpadding=""""""""2"""""""" style=""""""""vertical-align:top; background-color:#""""""""
! Getting help
|-
|style=""""""""color:#000""""""""|
 Frequently asked questions
 Cheatsheet
 Where to ask a question
 Help pages
 New contributors' help page
|-
!",0
", 3 August 2006 (UTC)

Hey, looks like your rehab program didn't take, and now Socafan's been community-banned. Your approach worked out REAL well, didn't it?  | Talk 15:04",0
"PKK fighters who the past decades entering and living Syria for their fight in Turkish territories have no match in guerilla war, specialized to this, against the Turkish regime. Rebels and the army are far behind in abilities and training to match the PKK fighters.",0
"OMD, THL, H17, Depeche Mode, ABC are all not New Romantic, never have been, don't self identify as Romantics, fans don't consider them romantics yet 1 individual insists on keeping listing them on this page. Fans of the bands will just keep removing them because it is simply wrong. Stick to Visage and other blitZ bands or this article will be in perpetual edit war. 82.132.136.211",0
"Tried to be productive (look at my contributions) but hit my head against a wall of spoiled greek children (or probably under pay from Greek Government) that purposely keep vandalizing the Albania related pages and keep iritating the albanian editors until they explode and get banned. As a historian I blush with what I find quoted as reliable information on the wikipedia pages and the quality  of the editors and sources. Time to move to the French pages (a lot of readers there), still 5 more languages to go. Till next time.Wikipedia sucks! .",0
"""""

Ricky Gardiner
Woody, my man, thanks for your quick actions and additions re. this article (just a stub I created yonks ago to get rid of red links on Bowie/Pop articles). What is it that draws people like us to defence and rock (I think Nick D. is a member of the Military and Music projects as well). Then again, the riff for """"""""Lust for Life"""""""" came from Bowie's interpretation of an armed forces radio theme... Cheers,  """"",0
"Triple crown just about cleared.. 

OK, got out the broom and dusted off some stuff.. ) Cheers,  (talk  contribs)",0
"If you agree with Master Bigode then what about rule for 500 x 400 images and what about the back side image (that was erased without consensus)? He never discussed the back image, he erased it out of the blue. What if I went on your user homepage Wolftengu and I said that picture on your homepage is too big be within guidelines and I removed it, placed it somewhere else and I also removed another image, would agree with someone doing that to your homepage or would you be outraged? However Wolftengu you seem to be playing unfair cop here by notifiying 2over0 as if a discussion wrong. What is your point? Do you own a DX-1 or if not what is your involvement to disallow a 500 X 400 or any other 500 x 400 image and even any other image of a DX-1 in a smaller form?",0
"As a rollbacker, that is particularly problematic.  You should be aware that editors who edit war may lose the privilege regardless of the means used to edit war.",0
"What about non-american schools, mosques, synagogues, etc, etc... Wikipedia is so America-centric.",0
"Thanks 

for fixing this.",0
"""""

No not really. We may ask that the mention of fat being the fire source of the cremation of millions be reconsidered though - along with a few other items. The fat cremation """"""""wiki fact"""""""" is citable ( www.hdot - Emory U no less, Lipstadt) but doubtful. If the same science was applied to the holocaust as say the tinfoilers or flat earthers the deniers would be overjoyed. Be careful as to who gets the nutty fringe tinfoil label in the end. You get the permits and we'll bring the shovels. 159.105.80.141  """"",0
"Celebrities 

Talk about your fave celebs and even your crushes!",0
"""""You know, I was thinking...

Nobody really attacked me before I revealed my age here.  After I announced that I was 14, I was subject to a constant storm of harassment and abuse.

The same thing goes for when I was on The Sandbox when I was 11.  Before people knew my age, they didn't care.  After I told them my age, they hated me.

It's just so amusing how the idiot Soapboxers think of teenagers as being responsible for the """"""""decline"""""""" of The Soapbox (like it was ever any good to begin with).  This is funny, because the adults are the dumbest people here.  Mauricio, Chuppah, Redneckgirl, Pinky, Scooby, GG, ForeverLostTinkerbell, greenrabbit, StarRocketsInFlight, Bree-Robinson, enigma-72, CocaineNightmares, TokyoDome, Chad_Ocho-Cinco, Steve Lake...

...all adults.

The teenage posters here are typically the smartest ones.  Let's see... G-Dawg, Head_Banging_Brunette, ClassicAge, Metropolis (even though he's a bipolar weirdo), ChrisScript, just to name a few.

All I ever see adults posting is """"""""rate my poo!!1!"""""""", """"""""my ballz smell funny"""""""", """"""""whoz hawter: me or ur mom???//?/?"""""""", """"""""i like to rape little girls"""""""", and """"""""HEY GUYZ LOOK AT ME IM AN ATTENTION WHORE!!!!11!!1!""""""""  The adult posters here are immature, moronic, savage bullies with the mental capacity of a retarded 4-year-old.

Whereas, most of the teenagers here are thoughtful, intelligent, mature, and often profound.  But they're subject to constant schoolyard bullying by the idiot adult posters who think they're somehow superior because they were born (and dropped on their head) earlier.

Soapbox logic never fails to amuse me...
""""",0
"TM 

How astute, remember civility is the key. That verbal licking you gave me really failed to break the skin. MAYBE JUST MAYBE WE CAN GET ALONG? HOW ABOUT THAT?",0
"Sofia Added 

I am from Sofia, Bulgaria. Our city has also joined this initative so I included it.",0
Would you mind focusing on content's rather then contributer's ?,0
"| decline=A bit too close for comfort, that one. Try to avoid the company name altogether. We get a bit edgy about accounts that appear to represent organisations.",0
"Weatherman and better writing 

A lot of the changes you've made recently to the Weatherman page are notably more awkward, for no apparent reason.  I'm not particularly concerned about the changes in some adjectives surrounding how some organizations and events are characterized, but at the same time you rearranged sentences to read quite poorly.  Plus you seem to get really carried away with wikilinking (do readers really need a link to know what a bomb is?!).",0
"""""
Non-lead?
Shouldn't the title of the page be """"""""Supporting"""""""" or """"""""Minor"""""""" instead of """"""""Non-Lead""""""""?  """"",0
"I agree with Leontes, though I began attempting compromise last night considering no one else was backing me up on this.  In the interest of building consensus, however, I will note that political descriptors, in the absence of reliable third party sources, are inappropriate in this article.  I will also note, again, that some commenters here appear to be confusing the electoral-vote website with the electoral-vote author.  This Wikipedia article is about the website, NOT the author, who has an article of his own.",0
"Dispatch review 

I added some comments here. I think it is a wonderful dispatch - very clear. We've needed something like this for a long time.",0
". I vote for Christ Pantocrator, though it could be nice with a wider crop",0
"Here's an idea 

Go fuck yourself, cumshitter.",0
"""""

 Your assistance please 

The record shows you deleted File:HMCS Fennel (K194).jpg.  The entry you left in the deletion log said: """"""""listed on WP:PUI more than 14 days"""""""".

I strongly suspect that this was a free image.  Crown copyright#Canada protects images for their first 50 years.  WW2 ended 65 years ago.  So if this was a crown copyright image it would be a free image.

I'd like to request userification of the information templates and other information associated with this image, to review for possible clarification of whatever problem got it listed at WP:PUI in the first place.

Could you please userify it to   """"",0
|listas = Manos Family,0
""""": So, despite your equivocation, you are still wrong. People do remove """"""""vile, vicious hate speech"""""""" whilst remaining on """"""""the right side of policy"""""""". 

 You made a very clear statement about Wikipedia policy - and I proved you were wrong. And you denied my unblock request as a result of your misinformation.

 I know expecting an apology from a Wikipedia administrator is a waste of time, but in future stay away from me, okay? I prefer to deal with admins who do know the rules.   

""""",0
"""""

Speedy deletion of Phi Rho Eta
 A tag has been placed on Phi Rho Eta requesting that it be speedily deleted from Wikipedia. This has been done under section G12 of the criteria for speedy deletion, because the article appears to be a blatant copyright infringement. For legal reasons, we cannot accept copyrighted text or images borrowed from other web sites or printed material, and as a consequence, your addition will most likely be deleted. You may use external websites as a source of information, but not as a source of sentences. This part is crucial: say it in your own words.

If the external website belongs to you, and you want to allow Wikipedia to use the text  which means allowing other people to modify it  then you must include on the external site the statement """"""""I, (name), am the author of this article, (article name), and I release its content under the terms of the GNU Free Documentation License, Version 1.2 and later."""""""" You might want to look at Wikipedia's policies and guidelines for more details, or ask a question here. 

If you think that this notice was placed here in error, you may contest the deletion by adding  to the top of the article (just below the existing speedy deletion or """"""""db"""""""" tag), coupled with adding a note on the article's talk page explaining your position, but be aware that once tagged for speedy deletion, if the article meets the criterion it may be deleted without delay. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would would render it more in conformance with Wikipedia's policies and guidelines.   """"",0
"""""  WILL MY MOTHERFUCKING SAFETY BE GUARANTEED???? I FUCKING HOPE SO!!! I'M BRINGING MY OWN FUCKIN' WEAPONS!! PAY ME WHEN I GET BACK MOTHERFUCKERS!!!  OH YEAH I'VE GOT A JOKE...A FAMILY (HUSBAND, WIFE, SON, DAUGHTER, DOG) WALKS INTO AN AGENT'S OFFICE AND TELLS HIM THAT THEY'VE GOT A GREAT VAUDEVILLE ROUTINE...HE SAYS """"""""WE DON'T HIRE KIDDY ACTS"""""""" AND THEY SAY """"""""BUT WE'RE REALLY GOOD!"""""""" AND SO THE AGENT SAYS """"""""FINE, LET ME SEE WHAT YOU'VE GOT, BUT IF YOU SUCK I'M THROWING YOU OUT""""""""...SO THE FAMILY GETS READY...THE DAUGHTER HITS THE CD PLAYER AND CIRCUS MUSIC BEGINS PLAYING, THE FATHER JUMP KICKS THE SON IN THE HEAD AND STOMS HIS FACE IN THE GROUND UNTIL IT'S A BLOODY PULP, THEN PROCEEDS TO JERK OFF AND CUM ALL OVER HIS SHATTERED SKULL.  MEANWHILE THE MOTHER BEGINS VIOLENTLY FINGER FUCKING THE DAUGHTER AS THE DOG FUCKS THE MOTHER IN THE ASS HOLE.  THIS IS THE POINT WHEN THE FATHER TAKES THE LEFTOVER BRAIN MATTER FROM THE SON'S HEAD AND SHOVES IT INTO THE MOTHER'S PUSSY, THEN BEGINS FUCKING HER PUSSY WHILE SIMULTANEOUSLY STICKING HIS FINGER DOWN THE DAUGHTER'S THROAT UNTIL SHE VOMITS ALL OVER THEM BOTH.  THEN THE DOG BITES THE MOTHER'S HAND OFF AS SHE'S FINGER FUCKING THE DAUGHTER, LEAVING HER HAND IN THE DAUGHTER'S PUSSY AS BLOOD SQUIRTS ALL OVER THE PLACE...THE FATHER TAKES BLOOD FROM THE GROUND, SMEARS IT ALL OVER THE MOTHER'S CHEST, BENDS OVER, AND BEGINS SHITTING ALL OVER THE OPEN WOUND WHERE HER HAND USED TO BE BEFORE THE DOG BIT IT OFF.  THEY TAKE THE DOG AND SHOVE IT IN A MICROWAVE, HEATING IT UP UNTIL IT EXPLODES, THEN TAKE THE DOG REMAINS, MIX IT WITH THE FATHER'S SHIT, THE SON'S HEAD WOUND, AND THE FATHER'S CUM, AND SHOVE IT INTO THE DAUGHTER'S MOUTH.  THEN THE FATHER RIPS THE SON'S DICK OFF AND FUCKS THE DAUGHTER WITH IT, AS THE MOTHER LOCATE'S THE SON'S TESTICLES, BREAKS THEM OPEN, AND DRINKS THE SPERM THAT COMES OUT.  THEN THE FAMILY LINES UP AND SAYS """"""""TA DA!""""""""...THERE'S SILENCE FROM THE AGENT, UNTIL HE FINALLY SAYS """"""""I LOVE IT!  WHAT DO YOU CALL THAT?""""""""...AND THE FAMILY SAYS """"""""WE CALL IT...THE ARISTOCRATS!""""""""""""",0
"""""

 Requested move 

:Canada national football team (disambiguation)  ?  There's  I recently moved the American football team, which used to carry the moniker """"""""Canada national football team"""""""", to Canada national American football team, and I consider this move request, if successful, to be vindication of that move b  b """"",0
"""""

I think Clockback that your suggested reference to Ainsworths involvement in the IMG is too long and that something along the lines of brief flirtation would be better. I think that the IMG reference needs to be short/somewhere in the early career section/posted after the article has been expanded a little, otherwise the article might appear weighty. I think the last point is important as it seemed to be a consensus reached by a number of Wikipedia editors after much wrangling and gnashing of teeth))

But bedsides, this brief dalliance with Marxism, in an overall consideration of his political career, pales into insignificance compared to his being controversially thrust as a third choice candidate into the position of Defence Secretary at a time of crisis for the British Army in terms of the number of casualties being sustained and a lack of resources. This is simply not reflected at all in the Ainsworth article. I tried reflecting it as follows: """"""""His appointment formed part of a chaotic cabinet reshuffle by the Prime Minister, who """"""""considered at least three other candidates before appointing Ainsworth"""""""" but this was dismissed as """"""""speculative opinion"""""""" by Off2riorob above, even though from my point of view it is easily the most significant event in Ainsworths biography. Perhaps we can reach a consensus that if a better reference can be foundwhich I suspect should not be difficultthat it can be re-included? I want to stress that this is again not meant to be an ad hominem slight against Ainsworth, but merely drawing attention to the fact that his appointment was the equivalent of throwing someone in at the deep end (and indeed he has had a very difficult time of it since his appointment). Actually it reflects worse on Brown and the farcical reshuffle.  """"",0
"""""

 Greek love 

I'm looking for a way to extricate myself honorably from this mess. I'm leaving a note here because you closed this AfD, where I made a commitment to do as you instructed in the closing statement. There are two editors who have long sought to delete or eviscerate the article, one of whom has used a series of user names (unacknowledged on his current user page but available , so at first glance it may appear on the talk page there are more than two editors in the 'suppress' camp). I complain here about their coordination. Other editors, including  and I simply can't do it any longer. I haven't changed my position on the validity of the article, but I've been accused (on various talk pages, and never the appropriate notice boards) of edit warring, ownership, disruption, and even pedophilia by implication, all for trying to carry out what the community decided. I'm done. I need to limit my time on Wikipedia at present, and wish for that time to be spent pleasantly and productively. When I've made a commitment, though, it grieves me not to keep it. I'm not asking you to do anything: I'm just explaining why I can't keep my word as given at the AfD.   

Wow, that is a mess.Certainly no hard feelings  on my end, it is clear you endeavored in good faith to improve the article. I have found that knowing when to walk away is an essential skill, not only here but in the real world. Sometimes your presence, despite your best intentions, is harmful rather than helpful, and sometimes a dispute just isn't worth it anymore. Best of luck in your future endeavors here.   

 Mailchimp 

I'm not that bothered but I think that the Mailchimp speedy deletion was a mistake.  It did cite that it was one of the more important email marketing programs so it was stating the importance - something that was supposed to be the original problem.

  

The criteria specifies a credible'' claim of significance. Wordpress pages are not reliable sources. However, I would certainly not object to it being restored as a redirect, as it was for several momnths before today.   
Talkback

 (talk) 

Just a hunch?

Call it my intuition but I'm guessing that his username is a direct challenge to patrolling admin that you guys won't block him based on the username itself, but his contribution speaks volume of his nonsense louder (my other hunch being he's a returning editor!) than his username does. Just my 2 cents. Cheers~!  1185 
There are plenty of legitimate reasons to be a returning editor, the username is not a blatant violation of the policy.  If you have any evidence of socking file at WP:SPI.   

 Recreation of article Shay Carl 

I would like to request that the article Shay Carl be recreated, see the deleted Talk:Shay Carl for my reasons (note, Talk:Shay Carl was delete because of A1, not notibility).    
Well, there was",0
"""""Where's the 24 defendants figure coming from? """"""""Nuremberg and Vietnam: An American Tragedy"""""""" by Telford Taylor (U.S. Chief Counsel at Nuremberg) mentions 200.

""""",0
"""""

Oh hey, a response. That's cool. I personally feel that having the fortitude to call out TTN on his obvious flaws should warrant a few dozen Barnstars, but I see where you're coming from. If you insist on keeping the block, I would like to formally request the reason for this account's blocking to be changed to reflect the real reason instead of being noted as a common vandal. Maybe a reason along the lines of """"""""being a pain in the ass"""""""" like that one guy on Nakon's talk page stated.
On that subject, maybe he should be blocked too, after all he did use a cuss word and that's technically worse than anything I've ever said.  -   """"",0
"NO. You have the right to express an opinion that you consider it to be Hasbara, or crap, or both. You do not have the right to identify it as Hasbara, crap, or both.",0
"""""==GA Review==

:This review is transcluded from Talk:Battle of Rowton Heath/GA1. The edit link for this section can be used to add comments to the review.

Reviewer: '''''' *YES! 

I'll take a look over the next few days  and then start to make some comments. '''''' *YES! """"",0
for evidence. Please make sure you make yourself familiar with notes for the suspect before editing the evidence page.,0
"AfD
Please see Wikipedia:Articles for deletion/Revelations. Guidelines for notability are outlined generally at WP:N, and specifically for songs at WP:NSONG. Thank you.",0
"""""Organizations 
|class=  Start               
|importance= Low           
|maindykdate=           
|needs-infobox= Yes     
|needs-image= Yes       
|attention=         
}}
{{WikiProject """"",0
"""""

""""""""Actions in la-la land have real world consequences"""""""". 190.67.223.50  """"",0
"Dean Wormer Works for the Racists in Jena, LA==
I will continue to update the posting for Jena, LA to reflect the fact that thier 'famous' person of note was a SEGREGATIONIST DEMOCRAT which is in fact a historically accurate description.

==",0
"Woopsies! 

oh thank you soooo much!!  I didn't know.  I PROMISE that i'll never ever do it again, ok?",0
"""""
 for everyone's info (particularly admins), i believe the latest sock-puppet for Igor is .  just a """"""""heads up"""""""".  """"",0
"Why are you giving me warnings? 

Before someone marks this as vandalism, I want you to at least read this. Why is this vandalism? I don't understand? I am new to Wikipedia and I am trying to figure it out. PLEASE DO NOT MARK THIS AS VANDALISM. I'm am not doing anything wrong. I just need answers from somebody. Please help.",0
"""""

 Gift cards for downloads 
Re: """"""""As of December 28, 2007 it is not possible to use gift cards to purchase MP3s even though the gift card FAQ claims """"""""Yes, Amazon.com gift cards can be used to buy Amazon MP3 and Unbox downloads"""""""" """""""" - strictly speaking, this is a false statement as were able to pay for orders with a gift card at that time.  One person already removed that line but it was reverted.  Is there a good way to go about providing verification?    """"",0
"I'm thinking about deleting War on Terror, Operation Enduring Freedom - Horn of Africa, and Operation Enduring Freedom - Phillipines because they are redundant. I'd like for people vote on it.",0
"""""

No it's not """"""""useful information about the topic"""""""" and it's a good idea. Only 1 screenshot is allowed per game, at most 2 if they really relay something.   """"",0
"""""
My experiences came up on the talk page but once I understood Wikipedia I didn't post anything on the article related to my personal experiences. That was like the 2nd day almost two months ago.

All of my references are verifiable.There's nothing in the article about my law suit or my being put in jail for engaging in pro se litigation.  I didn't put my experiences in the Judge Edward Nottingham article either although he was my judge.

I went out of my way to search for references expressing all the various sides of the issue. For instance, I wrote to the ABA and asked for their input, and in fact, asked them to work on the article. I also posted about issues involved with mediation and settlement with pro ses, citing references from a lawyers point of view.  Those references were deleted by someone, I can't remember who and don't know why. At this point, the only reference that I posted that is soft at all is a blog quoting a transcript quoting a former federal judge and I know for sure that is a valid transcript.  The guy who runs the blog is a 3rd year law student and has a business selling data services exclusively to lawyers.   Even the stuff that was deleted about pro se frustration I had references for. I read in the Wikipedia discussion of sources that blogs can be used in some contexts.

I don't believe that I did any original research. All I did is search the Internet for references for the article.  I really didn't know about unbundled attorney services or the amount of pro se litigation before I started working on this article. I had already been thinking about forms based filing but I started thinking about that anyway because of my experiences with ECF, which date back to 2004.  Also, when I was younger I worked as a systems analyst.

I did get the info on the Laws and Liberties of MA years ago, but Wikipedia already had an article on that and it probably would have come up anyway.  Same as the U.N. covenantcan't really hide that.   I didn't add a and b together to prove a point, at least not consciously. Like today, I was reviewing appellate procedures and it seemed that the 5th Circuit had a more pro se friendly tone, which I think is because of Judge Learned Hand, who was in the fifth circuit. And the only reason I know about that is that one time I went in every federal circuit and searched on the words """"""""pro se"""""""" in the 40s because I was trying to see if there was a history of putting pro ses in jail for being pro se (No, there was not).  What I found in the 40s was that some circuits denied all the pro se appeals without even saying why but Judge Learned Hand seemed pro se friendly.

I believe that your posting things about pro se litigants getting an unfair advantage is """"""""soap boxing"""""""". I do understand your wanting to win thru competition though and about law as a business. I've been an entrepreneur. 

I didn't know about the Federal Judicial Center until I started working on this article. That book on appellate procedure I found looking for references for this article. The manual on complex litigation I found looking for references for this article.

Arguing with you helps me to clarify the issues for myself.  One thing I started thinking about a lot in the past few weeks is slavery and how that affected the history of pro se litigation. I ordered the book Slave Nation at the library but I haven't got it yet. But now when I look at pro se law in the different states I think free state, slave state, border state. Also, there were issues related to Indians in some of the western states. The labor union movement had a lot to do with it too, I think. So did the history of workmen's comp, which is of course related to unions.  """"",0
"try passing illegaly the border from USA to mexico... you'll end in prison too, but the're no communists there",0
"""""

 unsourced personal commentary 

A """"""""new"""""""" account has re added this: it looks like unsourced personal commentary.""""",0
"Your comment is indented as if it is a response to mine, but I am not the one who removed the discussion.",0
"""""
When I looked at the Cato edit, it was simply a removal of the reference, the addition of another donor, and a change in the language. Without an edit summary to explain, the changes were unjustified. (Your clarification certainly helps.) Thanks, also, for adding the reference on Summers. Frankly, I did not look at the sources removed or added. My main concern was the unexplained edits. Summaries are important! And then I saw that the messages about these same concerns from a while back, so my message is more of a reminder. Most importantly, you are incorrect if you think it is """"""""not against the rules to add unsourced material"""""""". One of the core content policies is WP:V, and WP:RS allows us to carry out that policy. Happy editing.    """"",0
"""""

We all know that. just about everyone here watches the updates. Theres a REASON they aren't listed.   Complaints  """"",0
"""""

I've been though the article. It's simply untrue that only men are """"""""consistently"""""""" referred to a Jews but womabn and children are not. Many passages refer generally to """"""""Jews"""""""", clearly meaning men, woman and children. Only one sentence corresponds to your criticism: """"""""The screening of the population, however resulted in 13 Jews, 27 Jewish women and 11 Jewish children, of which 13 Jews and 19 Jewish women were shot in co-operation with the Security Service."""""""" This particular sentence should be rewritten. I'll just do it, but the sentence itself is grammatically confusing, so whoever wrote it may wish to check that I understood it correctly.   """"",0
"Hello! 

Long time no shart!",0
"Other Bush articles not referenced in George W. Bush
None of the following articles is mentioned in the George W. Bush and perhaps should be:
 Bush's Brain: How Karl Rove Made George W. Bush Presidential
 Domestic policy of the George W. Bush administration
 Early life of George W. Bush
 Economic policy of the George W. Bush administration
 Electoral history of George W. Bush
 Fictionalized portrayals of George W. Bush
 Foreign policy of the George W. Bush administration
 George W. Bush and the Iraq War
 George W. Bush as Governor of Texas
 George W. Bush Cabinet
 George W. Bush presidential campaign
 George W. Bush presidential campaign, 2000
 George W. Bush Presidential Library
 George W. Bush pretzel incident
 George W. Bush substance abuse controversy
 George W. Bush Supreme Court candidates
 George W. Bush's first term as President of the United States
 George W. Bush's second term as President of the United States
 List of books and films about George W. Bush
 List of George W. Bush legislation and programs
 List of nicknames used by George W. Bush
 List of people pardoned by George W. Bush
 Mahmoud Ahmadinejad's letter to George W. Bush
 Movement to impeach George W. Bush
 Presidency of George W. Bush
 Professional life of George W. Bush
 Public perception of George W. Bush
 Religious faith of George W. Bush
 The Lies of George W. Bush: Mastering the Politics of Deception",0
"A third term is significant simply because it is rare. The electorate and party (often on behalf of the former) are disillusioned with the party leader by this time, thus they kick him/her out. Read about Margaret Thatcher.",0
"""""

 Some baklava for you! 

  A Gift, in the hopes that you reconsider my indefinete block. A traditional food from the middle east, made best in afghanistan Metalman59 """"",0
"Referring to her as *Catherine* 

I was told in no uncertain terms that I could NOT refer to anyone, living or dead, by their 1st names on WP, & if a female had a title, she had to be referred to as that throughout her article - ie, *Lady Amy* or *Lady Dudley* for Amy Robsart, even though *Lady Amy* was wrong before she was married as she was the daughter of a knight & had no title, & wrong after Northumberland was attainted & all his children lost their styles as offspring of an earl & a duke, & she did not become *Lady Dudley* until Elizabeth I knighted Robert Dudley near the end of Amy's life nor was she then *Lady Amy Dudley* as legally she was no longer the wife of the son of an earl & duke.  I thought it was simpler to refer to her as just *Amy* throughout rather than explain the changes that occurred with her name & styles, but was told it was against WP *rules* (though I wasn't pointed to a link for it).  Noblewomen are usually called by their 1st names round here as far as I can see, even when they have surnames & are not *of* something!  Mary Boleyn is called *Mary*, not *Lady Carey* or *Lady Stafford*, Catherine Neville is called *Catherine* & not *the Duchess of Norfolk*, etc, & they're not royals.  

As for males, I was told they had to be referred to by their title - ie, *Leicester* -  or last name - ie, *Dudley*.  I was banging head on keyboard going, but - no one just says *the king* all the time or refers to them as *Plantagenet* or keeps changing their titles - ie, Henry of Bolingbroke going from Earl of Derby to Duke of Hereford to Duke of Lancaster to King of England -  

So how does Kate get to be consistently referred to as *Catherine* throughout the article, without her title appended?  I've only been here a few months & I would appreciate it if someone could actually explain this to me, as my main interest is British history & I am quite confused.",0
".

Mevins31 says:

I will be changing your elegant profile shot of Bruce to a better picture as soon as I upload it. I appreciate ordinary Jay Bruce fans, but I am Jay's biggest fan. Thanks for your attention. I think Jay would agree that a picture on Wikipedia has little to do with furthering his career, but nice try",0
"They are all cunts 

It's not worth editing articles here concerning any serious issue. All sides consist of either people employed to edit or people with very strong opinions that will never, ever change. They advocate their stance as something that is interesting to them instead of using the encyclopedia as a book of knowledge and contributing what they are sure to know.  Soon with the centralization of the net into larger and larger sites, independent information in general will be extinguished. Wikipedia, a project that started by nerds and professionals within their set fields will become the altar of knowledge where depth and true insight is sacrificed for becoming the sound magnifier of yellow press and popular science. The new tool that is intended to auto translate articles from one Wikipedia to an other will extinguish the few national wikipedias that through their niche provide those of multilingual capacity an ability to cross-check facts through other perspectives. With few small, independent sites left, with no or few free university pages left, real knowledge will be the privilege of the few that know how to use academic search engines and have the money to pay for them 78.68.210.173",0
"I've said once, i say it again - if you don like thugstep that's you bizness. If you think that quite a range of refenreces to web-pages stays it non-notable you are welcome to tell it to admin for it to be deleted.  82.209.225.33",0
"Although it doesn't extend to the modern era, you might want to look at Ancient higher-learning institutions to see how it relates to Chinese higher learning institutions.",0
"Do not harass other editors with no basis
You have posted a baseless warning/threat on my user page. Do not post any more things on my page. Otherwise, I will complain to the administrators, or even Jim Wales if I have to.",0
"""""

 The Comma 

Is not the correct title for the first series """"""""Yes Minister"""""""" (without the comma)? I believe it was only """"""""Yes, Prime Minister"""""""" that ever had the comma. Unless there are objections I will be moving the page.""""",0
"""""
Excellent. And please don't damage your book on our account, for sure. It is an interesting question: Where was the camera? That's a fair question. To jump to the conclusion that it was """"""""impossible"""""""" is ludicrous. But that's typical for the moonbats. The picture is useful for another reason, as it shows a similar relative position of the LEM and the antenna for this Apollo 14 flight as on that web page that argues about those objects in Apollo 12. In both cases, the antenna is at a 45 degree angle away from the LEM, and both the near photo and the distant photo on that website are consistent with each other, despite the website's claims to the contrary. The moonbats isolate on specific items as their """"""""evidence"""""""", but the more one sees the broader picture, the more their phony arguments get shown up.  """"",0
Content subsumed into Maneesh page (same entry different spelling) And REDIRECT.,0
"Ditto - congrats, and all the best to you!",0
"""""
13:07 is when that part of the video shows it.  It says """"""""lots of small villages have prostitution in karaoke joints,"""""""" and that this one had a single orangutan in it.  It doesn't say its common everywhere though.  """"",0
"Fuck you, Smith. Please have me notified when you die. I want to dance on your grave.",0
I have seen your post now but I replaced the pop punk reference which was there again with rock a few days before.,0
"Please avoid using abusive edit summaries as per Wikipedia:Civility and Wikipedia:No personal attacks. Thanks and happy editing. Please do not make personal attacks on other people, as you did at Minneapolis, Minnesota. Wikipedia has a policy against personal attacks. In some cases, users who engage in personal attacks may be blocked from editing by admins or banned by the arbitration committee. Comment on content, not on other contributors or people. Please resolve disputes appropriately. Thank you.",0
"DECT isn't really a new technology. It's a newer standard, but TDM/TDMA/FDMA digital telephones have been used for a lot longer than the life of DECT. DECT is itself a successor to CT2, Japan's PHS is very similar, and, of course, GSM, D-AMPS, and others have been extensively used across the world for a decade and a half. To suggest there are special health issues with DECT would most definitely be placing undue weight on the subject. DECT is considerably lower power than the analog systems it replaces, both during transmissions, and inherently because even when in use the TD nature of the system means the system isn't transmitting continuously.

As I believe I've said before, there is nothing wrong with there being a properly researched article about the health effects of low-power radio technology, and there being a link in the See also: section of this article to it. That article, of course, should look nothing like the section I yanked. There is nothing about DECT however that merits a special section on DECT's dangers, especially when - new technology or otherwise - there is no serious level of concern being expressed by anyone authoritative on this issue.",0
"I shit on your face 

fuck you",0
"You are 

so retarded.",0
"Users using sockpuppets in this discussion 

Note that user nightscream is soliciting sockpuppets of Toure Neblett to join this discussion:
http://en.wikipedia.org/wiki/User_talk:Halaqah#Hi_Halaqah.
This isn't surprising considering nightscream's slimy debating tactics and ad hominem smears.  
It looks like the reality is that there are _only_ one or two actual people opposed to teh inclusion of the last name and the rest are their sockpuppets.  (Though I guess it demonstrates that Nightscream is _not_ one of Toure's own sockpuppets!)
(FYI I am not using a user name in this simply to make it clear I am not a sockpuppet)",0
"Thanks Stephan, my interpretation is that Mr_Nice_Guy removed the content before discussing it on the talk page, if he was concerned about contents reliability, I thought I read that editors are supposed to bring it up in discussion first and reach a consensus instead of deleting sourced material.",0
", which I made up by fixing STEM articles",0
"Alex Albrecht
why have you removed my additions to the Alex Albrecht page they were totally relevant..",0
", in a tank for bioelectrical impedance analysis etc.). I fail to see how either of the two pictures recently added improve the article in any way.",0
"The images have been missing for a while as Wikipedia was down for about 6 hours. I just hit rollback which (among other things) restored the Patrick Stewart, which I then removed but didn't see you had made other valid edits. I also linked Harold Wilson from Prime Minister to Prime Minister of the United Kingdom. The deletion was done at 15:36 GMT by which time the servers were up. You should register then you could bypass these invalid messages. Cheers.  (Talk)",0
"Amazing, thank you very much!   @",0
"Groin 

You sad fuck. I'm going to restore my edit, and you are going to leave it, or else I wil knee you in the groin yourself, prick. 91.108.208.101",0
"May 2015 

Your behavior on the talkpage of Honor Harrington has been below par. You do not know how to take defeat with grace and start behaving childishly. Let me warn you that your next childish edit will likely result in a mention at WP:ANI or a user review.",0
"Video Game 

For pete sake if I see that false video game article one more time, I'll throw a cat out of the window, whoever you are, stop it now, it isn't funny or clever, you are just making a moron out of yourself and I bet that was the same person who changed the test card date too.",0
"""""
 Palmisano playing for Iowa State in the 1970s is a free pass, I think; I'm pretty sure they were Division I then.  As far as a list of coaches go, I'm not sure that's an articleworthy list at that level of competition (as opposed to it being folded into a general Malone College Athletics article), but I wouldn't file an AfD over it; it's a compromise, anyway.  Seeing as you're digging into uncovering notability for those folks, want a full week for it?   """"",0
"History 

KalliKids was created by Karen Bach in March 2012.",0
"""""

 Massacre 

I note that Kent State massacre redirects to this page, and that other, similar massacres in history - wherein government forces murdered civilians for protesting government policies - are termed as """"""""[such and such] massacre"""""""".  There is no legitimate reason, aside from sensitivity to extremist viewpoints in the United States, to continue calling this article """"""""Kent State shootings"""""""".  It should be changed to """"""""Kent State massacre"""""""".  A cheap acknowledgement in the lead paragraph is insufficient.  I would appreciate discussion on this move, and I will initiate the move myself soon enough.   """"",0
"31 July 2007
 Please stop. If you continue to vandalize Wikipedia, you will be blocked from editing.",0
"Notice of Objection to proposed deletion
In accordance with the rules on this, I hereby notify you of our/my objection to your proposed deletion of the subject article Office of the Court Administrator v. Floro, Jr..   58.69.139.6",0
Barnes                  Aus     1                       1       8,0
"16, 7 May 2007 (UTC)TimySmidge 21:",0
"""""

Two things
It makes no difference to the validity of edits if an editor is """"""""anon"""""""", and going around reverting a persons edits en masse (because you didn't like one of them) will yield time-consuming problems for you. 94.192.38.247  """"",0
"Hi nice of everyone to listen,well ive been here for about 9years ,have had afew problems,but two have been the worst,had a mamogram 2years ago dec2012said to call my doctor emediatly needed other views an presedgures,was incounculsive ,,we all no that not possable fir that cause its just like an xray .havent been able to go,have no way,to get there plus i have high blood pressure thets been running about ,the last time was ,,,Around 204over 173 i no thats very high ,the hospital xray techs seceritary said if i didnt get to the doc. To get referral as soon as possible that by the time i did it would be to late to do any thing for me. I no its to late all i want is to no how long i have left ,have 3daughters one in opelousas la,one in hawiyei,one in walker la,i would like to see be fore i die.have a partner i want too spend as much of what i have left with i love my kids an partnermore than life its self,im looking for some help to get to a doctor i dont have the money to do this,have no income to speak of zero ,my partner and i are seperated right now he is helping his father that has cancer also ,he has a lawsute from getting hurt ,he just bought a truck from his brouther an has had to do alot of fixing on it also with the help of his dAd ,let his neffews daughter drive it an hour ago cause she just hot her license an wrecked it comepletly now we dont have a vihicile to help us,everyone says god dont give u anything you cant handle i understand that,but i need some help does any one out there. That may be could help me with anything at all,just thought id try to ask,never have asked before ,to much pride but im running out of time ..please can so one help me..my email is apriljohnson6868@gmail.com or this site,,please need so help if anyone can..god blesss everyone in there time of need.  I hope someone may be able to help me thank you for lissen to me.my age also is 43sept 21 1971.",0
HE LIKES ITIN THE ASS BY MUHAMAD ALI AND KELLY HAS A GIANT PENIS AND ALSO FUCKED COLUMBUS,0
"""""

Here are the diffs of his edits from that report:

 

 | Talk """"",0
"06:15, 19 Aug 2004 (UTC)",0
Just shut up and stay shut. Don't edit anymore,0
OH GET A LIFE YOU PRICK 81.144.199.2,0
What else specifically do you want to know,0
"""""

 Rajputs, not Rajasthanis...right? -P 

Prof. Hancock's studies mention that the Romani people are most closely related to the Punjabis and Rajputs, I'm pretty sure - not Rajasthanis. He calls Proto-Romani """"""""Rajputic."""""""" The distinction is important; if they are partly descended from Rajputs, who were never really confined to any one part of India, that would explain the linguistic variation within the Indic words in Romani. 

For example, why the use of """"""""-o"""""""" instead of """"""""-aa"""""""" at the end of masculine nouns/adjectives in Romani? This is certainly a characteristic of Gujarati and Sindhi, but is it a characteristic of Rajasthani languages? Anyway, if I'm wrong in making the last change I made as of now, I'll be happy to revert it myself. 
Oh, of course,  """"",0
"""""
IF you would care to discuss SPECIFICALLY what is bias, incorrectly cited, or irrelevant to this page.  I will hear what you have to say.  Until then, seeing as the search term """"""""NDAA"""""""" brings readers to this page, I will continue to include present information reguarding this BUDGET BILL.  This is the LAST TIME I will repeat this.  Abusing your power will yield you no ground.""""",0
"""""

Words of Encouragement to user """"""""Damemk"""""""" in the cases of dispute with the users engaged in Bulgarian Nationalistic Propaganda
Damemk, You have come to the same conclusions about Bulgarian 19th Century Nationalistic Propaganda on English Wikipedia.
User:Laveol is one of the most prominent editors on Wikipedia contributing false information in the articles about Republic of Macedonia, Macedonian Nation|History|Language|Culture|Sports and what else not.
He is spending a lot of time working on his cause, pushing Bulgarian Nature in the articles of the domain of Republic of Macedonia.
How far has he gone in pushing this propaganda you can see at Wikipedia:WikiProject_ROMacedonia where he has listed himself as a member.
So just my few words of concern for the Macedonian Articles in English Wikipedia, and the great damage done by User:Laveol and other users with the Bulgarian and Anti-Macedonian Propaganda.
Hopefully with the internet access becoming more affordable to the people in Republic of Macedonia the things will go in right direction: Removing the Bulgarian Propaganda from Macedonian articles, cleaning them of false fabricated information, and giving the facts to the world, and the views of the Macedonian Science and sources.
I don't have much time now, but hopefully will be able to find some more in the coming period. I am open to any collaboration|effort for the above goals.

I am expecting that this user """"""""Laveol"""""""" will continue with the Bulgarian Nationalistic Propaganda and polluting the domains in the domain of Republic of Macedonia, simply because he is able to, and can find a ways to continue to work on his agenda.
Ours is to try to remove these false claims and contribute the Facts about the Macedonia, Macedonian Nation|History|Lanugage|Culture|Sports.

Damemk, I hope you write something here, at least to show that User_talk:Damemk and User_talk:Ejanev is not the same user.    

Some insight into my user name Ejanev
The only user I am using to contribute to Wikipedia is """"""""Ejanev"""""""". It is composed of the first letter of my name """"""""Emil"""""""" and my last name """"""""Janev"""""""".
User """"""""Damemk"""""""" is a separate user. Probably that user name is comming from """"""""Dame"""""""" - a Macedonian First name, and """"""""mk"""""""" or the code of """"""""Republic of Macedonia"""""""".
It does happen that I am from Canada. I was born in Republic of Macedonia and have lived there until I moved to USA first and Canada before more than 3 years.

And yes, having all the false information from the Bulgarian Nationalistic Propaganda ( originating from the 19th century ) and having it into 21st century to be used to negate the Macedonian Nation and all it's attributes by users as """"""""Laveol"""""""", is the reason of some of my editing actions in Wikipedia.
I am not the only user/editor from Republic of Macedonia or with Macedonian origin that has the same views for this Bulgarian Nationalistic Propaganda, that already is infiltrated in the Macedonian articles.
You can watch the contributions of Special:Contributions/Laveol and see that more than 50% of his actions are engagement in negating the Macedonian Nation and its attributes.

    """"",0
"At Bookfinder.com I found Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference

 Softcover, ISBN: 1558604790 Publisher: Morgan Kaufmann Pub, 1988

 Bookfinder",0
"""""
Just to clarify what I'm referring to in particular, it is not neutral to state that """"""""Aerith"""""""" is """"""""incorrect"""""""".  :Talk """"",0
"Thank you for experimenting with  Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our encyclopedia.   '''''''''' (talk/contrb.)",0
"The article Sebastien Larroud has been speedily deleted from Wikipedia. This was done because the article seemed to be about a person, group of people, band, club, company, or web content, but it did not indicate how or why the subject is notable, that is, why an article about that subject should be included in Wikipedia. Under the criteria for speedy deletion, articles that do not assert notability may be deleted at any time. If you can indicate why the subject is really notable, you are free to re-create the article, making sure to cite any verifiable sources.

Please see the guidelines for what is generally accepted as notable, and for specific types of articles, you may want to check out our criteria for biographies, for web sites, for bands, or for companies. Feel free to leave a note on my talk page if you have any questions about this.   (talk to me)",0
"GBA 

I've found out a Game Boy Advance version of this was released. There's no mention of it in the article.  As we know the current Acclaim doesn't have rights to this series, information may be scarce.",0
"""""

 Proposed move 

 Asheville Civic Center, with the talk page hosting this discussion  U.S. Cellular Center (Asheville, North Carolina)
 U.S. Cellular Center  U.S. Cellular Center (Cedar Rapids, Iowa)
 Both facilities now have the same name   talk contributions """"",0
"No need to follow this Policy Taivo instead of just following the far more important policy of WP:NPOV - Remain Neutral. There is an international dispute over this country's name and FYROM is used by many organizations worldwide, why should wikipedia abandon it's usage since it is extensively used to describe the State of Skopje? Especially in articles directly related to countries that use the FYROM name to refer to it.",0
"""""
The two big things would be citation to verify that it was serialized in the Weekly one (reliable sites in English just say Shonen Jump), but since you have the one that starts serialization, that can be used to note when it started serialization. If they mention there that its a continuation from the one-shot stories because I can't find any RS, Japanese or English, online that confirms that. The other is Horii's reason for adding mini-medals. Info on the anime about what it was based on if its mentioned is all that is really needed for the main article, but could really help the anime article itself.Jinnai """"",0
REDIRECT Talk:Colt Lightning Revolver,0
"No, nothing like that. I just wanted to clean out the clutter. There were a lot of bot comments, a welcome message for my old username, and so on. I could have archived it, I suppose, but I didn't think there was anything on there that was particularly worth saving for the ages.",0
"Why your article got jumped on
Hi. I'm sorry to jump on your contribution the moment you put it in, but the trouble is, it is simply not the sort of thing Wikipedia is for. These links are all in one or other of the template notices above, but to put them all in one place, the reasons your article is being nominated for deletion are:
Wikipedia is not a dictionary,
Articles on neologisms need strong evidence that the term is widely used,
Wikipedia is not for things made up one day.
More advice on contribtuing in the links from the Welcome paragraph above. The list of Bad Article Ideas is worth looking at, too.

Regards,",0
"Therefore I was reverting vandalism, which is an exception to the three-edit rule as mentioned on the edit warring page.",0
"user attacking me 

user Baki66 keeps reverting edits without consensus or giving reason, he has also performed ethnic mudslinging in my direction. please help.",0
"Not Thracian pretty simple 2,000 years away.",0
"Im flattered, I truly am, I've been here a couple of weeks and you consider me to be an established user. Please don't talk about me behind my back like little school children.",0
"Chicadee
i think the article name should be moved to chickadee",0
P.S. Are you a /b/tard?,0
"Ohhh I'm sorry did I hurt your little feelings? 

Let's all shed a couple tears together. 
LOL What a joke. I bet you feel pretty important, pathetic little wikipedia volunteer. Have fun living in your mother's basement drawing comic books, lowlife.",0
"""""

 New image problems 

You again uploaded several images with dubious copyright claims. You said they were from """"""""Hindu newspaper"""""""" and licensed under the GFDL. What made you think The Hindu publishes images under the GFDL? If you simply invented that license in order to have a way to upload the images here, then please say so now, so I can quickly delete them. If not, I expect you will provide proof, within the next 7 days, showing where and how that newspaper placed the images under that license. If you do neither, you will be blocked.   """"",0
"Bunchofgrapes, Request You Please Cease Revert Warring 

Bunchofgrapes, I respectfully ask you to please stop your instant reverts on my edits. If you have a problem with any of my edits, then do so from knowledge, but explaining what is wrong about the sourced materials, and edits, rather than making blind statements designed to allow you to revert for no reason. And, again, please cite your sources. You seem to not be able to cite anything that would back up your instant reverts, and accusatory tone telling others that they are reverting, when you have made several instant reverts with no explaination on the edit, or added source. Please cease this and cite your sources, edit the materials according to Jimbo Wales' NPOV, and make sure your sources are verifiable before your reverts. Thanks.",0
"""""

And what's the problem with """"""""neo""""""""?  :   : """"",0
"Wow, big man here. Can't take a little criticism and is upset about his failure to become an admin. So what does he do? Looks for the closest person to run to, some admin on Wikipedia. Well played DietLimeCola. Hey, if I'm blocked, it'll be less times you've been, and for far better reasons. (OH MY GOD SOME GIRL WAS LOOKING AT WIKIPEDIA FOR HER PAPER AND I DIDN'T SEE THE TEACHER SO I COULDN'T TATTLE SO I TOOK MATTERS IN TO MY OWN HANDS!)
I also couldn't help notice how sad it is that you so quickly noticed my updates. Do you just sit their at your computer waiting for an update? (Please tell me you didn't watchlist this page... you did, didn't you) All in all, everything can be summed up with a simple saying:",0
"Glen is cool

glen is such a cool bloke and loves being nice guy",0
"""""""""""""Parodies""""""""? Not intentionally, surely?  """"",0
"""""

 Pandur 

The name derives from pandur, a Sumerian term for long-necked lutes. Source of our knowledge about this instrument is since the ancient Greek Mantineia marble (4th century BC), now exhibited at National Archaeological Museum of Athens, depicting the mythical contest between Apollo and Marsyas, where Greek Pandouris is being played by a muse seated on a rock.National Archaeological Museum of Athens, e-book by Latsis Foundation, p.346 Lutes have been present in ancient Greece.Pandura, the first appearance in Greece. They were also present in Mesopotamia since the Akkadian era, or the third millennium BCE.""""",0
"""""
I accept your comment in the spirit in which it is offered. Terminology matters and it can be hard to find the correct word. It was another editor who sought to distinguish """"""""civilised behaviour"""""""" from that of Indians; my point was that even if one accepts such a distinction, non-Indians have committed absurdly large atrocities. In addition, I could have pointed to the Mystic massacre as a completely on-point example of a butchery that shocked our Native population. None-the-less, both tribal Mongols and tribal American Indians had or have civilizations by any reasonable definition.   """"",0
"No I dont agree, my info will be saying up. Since you are in such a hurry to edit the page why dont you fix the info that have you have sourced with a broken link (  )",0
"I thought personal attacks were welcome, as long as you revert them yourself, and I thought restoring/mentioning them was grounds for an indef block? could our junior miss admin have missinformed me?I have arrived just in time",0
"""""

Replacement

PLEASE DO NOT EDIT BELOW THIS NOTE. THE WHOLE SUPRA-SECTION WILL DISAPPEAR AGAIN ONCE I AM ABLE TO POST ON THE ARTICLE TALK PAGE.

This includes you Shell. Had you not blocked me, I would have been able to place my answers there. This will disappear tomorrow so you can put with it until then.

Because Shell falsely blocked me, I cannot save my replies on a certain article talk page. Hence I will save the entire page (minus the archived sections) here.

 POV concerns 

Im surprised this article isn't being called anti-semetic, because it's has a *few* traces of Islamic perspectives in it. You know, as opposed to being a piece of Zionist propaganda being passed off as fair and balanced.

This entire article is full of baseless jewish propaganda. It is well documented the Banu Qurayza were executed for treason. That is what merited them the death penalty, that they commited treason. The Quarash and other tribes the Muslims fought against were outright enemies who were persecuting them from the start. But the Qurayza signed a peace treaty, then broke it by aiding the enemy. This article contains soo much jewish propaganda that you'd think they were executed for no reason (which no doubt is their aim). Here is a great example. Look at this citation

""""""""According to Stillman, Muhammad chose Sa'd ibn Mua'dh so as not to pronounce the judgment himself after the precedents he had set with the Banu Qaynuqa and the Banu Nadir: """"""""Sa`d took the hint and condemned the adult males to death and the hapless women and children to slavery."""""""" Furthermore, Stillman infers from Abu Lubaba's gesture that Muhammad had decided the fate of the Qurayza even before their surrender.""""""""

This author is Norman A Stillman, a Zionist Jew who is very biased. Why is he being used as a quote in an Islamic article? And further more, why is his baseless conjecture allowed to be used, as if it's a fact?

There are articles for """"""""Criticisms of Islam"""""""" where the Jews and others can write whatever they want. But they should have no hand in editing Islamic articles. Because I looked up the Jewish articles and I noticed they dont allow dissent there. You cant put a Muslim perspective on evil acts commited by Jews, without it disappearing instantly. So the same standard MUST be applied to Islamic articles. Islamic articles must be written from the Islamic point of view, and the jews can write their responses in appropriate """"""""criticisms of Islam"""""""" articles. If not, I will personally edit the Jewish articles and fill them with my conjectures about their history. And I will find a non-Jewish admin to arbitrate over the Islamic articles.

Good day.

  

Please read this talk page, specifically all of the places where """"""""treason"""""""" or """"""""traitor"""""""" is mentioned, and if you still believe that we need to mention treason, provide some reliable sources and we can discuss it.  It is easy for our article to be neutral and mention all POVs, but it does require that people like yourself participate.  We work from academic sources, not personal conjecture.   

Changes by Devotus and issues with them

Dear Devotus, 
I have still issues with your changes:
Bat Yeor and Ramadan - while I appreciate that you don't try you shift the balance - removing a book from """"""""each side"""""""" - I do not agree with your removal. Bat Yeor is an academic scholar and though her books are controversial, she is not beyond the pale - currently she doesn't serve as a reference in the article but if she did, the controversy would be noted. As for Ramadan I have issues with him as well but if we remove him from the literature section, we would have to remove him from the article too, in which he serves as a reference. This is due to the insistence of User:Bless sins. He will certainly not like such a removal. We cannot remove him from the literature section while retaining him in the article.
While your first version was needlessly verbose (""""""""it is to be noted that""""""""), the new one endorses that view by Paret/Watt. The article now says that the BQ were not killed for religious reasons - that is not a fact, since there is a good case that the whole conflict was caused by religious differences.
Also we do not want to repeat things that have already been said in the coverage of the """"""""siege and demise"""""""", e.g. the claim about attacking M. in the rear.
Also, please abide by the one resolved conflict. We fought hard and long about words like """"""""massacre"""""""" and """"""""execution"""""""" and neither should appear unless unavoidable.
The common practice thing is unacceptable as it is s",0
"OK, Steve, to be honest I really like the present form. So, I don't have any issue with the present one.",0
"Hello (January 30, 2008) 

You keep vandalizing articles while adding misleading edit summaries.   . Please stop doing this. It doesn't help build an encyclopedia and wastes other people's time. Since you repeatedly (and selectively) remove messages from your talk page, I don't know how many warnings you have already received. I will thus consider this to be your third warning and report you next time you vandalize an article. Thank you for understanding. - talk",0
"I think it depends on the circumstances, if someone won a gold medal at a competition the Gibraltar anthem would be appropriate, rather than 'God save the Queen'",0
"He's at it again. He seems insistent on adding pointless rambling on how the talk page isn't a forum just so he can make a cut at me.

http://en.wikipedia.org/w/index.php?title=Talk%3AXM8_rifle&diff;=193022803&oldid;=192967373

He keeps reverting my removal of it.",0
So I guess your explanation of WP:CSD#T1 is still Zero. Once again you have failed to explain why a page weas deleted under WP:CSD#T1 and then threatened the inquirer with a block. Poor form. Extremely poor form.,0
", so that the proton itself reaches fusion distance",0
"""""

 Beauty pageants 

Just because you have no interest in beauty pageants or their contestants doesn't mean that they are not notable - and please don't go trying to delete stuff when you are ignorant about the topic you are dealing with.  I happen to think there are tons of articles on here that do not meet Wikipedia's standards and that do not have individual merit... particularly those about comics etc, but I am wise enough to know that I do not truly understand their significance and so I leave it alone.  A much more prudent avenue would have been to bring your issues to the appropriate WikiProject (WikiProject Beauty Pageants and to address yoru concerns there in the first instance.  One example, the continual use of the term """"""""model"""""""" to describe them as has been used by yourself and one other editor, is both incorrect and somewhat demeaning.   """"",0
"""""

 On Mohammed Al-Bayati's qualifications 

With regards to the edits over the past day, I think that while Mohammed Al-Bayati's qualifications are tangentially relevant, the purpose of the text as they are placed right now is to """"""""prove"""""""" that Mohammed Al-Bayati is not qualified to review the autopsy report. This I think violates NPOV. If the qualifications are to be included they should come under the """"""""criticism and controversy"""""""" section, quoted by whoever it is that accused Mohammed Al-Bayati  of not being qualified to review the autopsy report is cited. If nobody made the accusations, then this is original synthesis, and should again be removed.   """"",0
"""""

 No reason to split 

There is absolutely no reason why Alamo Bowl broadcasters should be split from Alamo Bowl. That list is a stub that is only 4kb long. The main article is 13kb long, much of which is tables and lists, well within the limits of WP:SIZE. A single article is only 17kb long, which is permitted, so there is no reason why the article should be split. Talk """"",0
Please sign your comments.  Thanks!,0
"""""

 Alyssa Flash? 

At the time of writing this, Sarita's TNA iMPACT debut is coming up, and she'll be wrestling one, """"""""Alyssa Flash"""""""" (note I might be spelling Alyssa wrong). I see her nowhere on the list. 24.226.21.207  """"",0
"Roma people in Hungary: 8-10%

the appalling social and economic situation of the Roma, who account for between 8 and 10 percent of Hungary's 10 million people that means 800,000-1,000,000.",0
Fuck off you murdering scum!!!,0
"In addition, I am asking that you please stop accusing me of things I havent done. I do not what what sock puppeting is and I think your taking this matter personally and abusing your power.",0
after adding the rational i have to remove the tag?,0
wow  i guess your just one of those guys then god forbid. One love then.,0
"It has been up before but here it is again, Phil Plait claimed in a radio program with Joe Rogan that ALL shuttle astronauts who has ever gone into space has been through the van allen belts, at 6 min: http://www.youtube.com/watch?v=tvIC1QDSnIc 

If thats not misleading propaganda i dunno what is... his website should be removed as a source 31.209.16.177",0
"""""

Lamia Joreige
Hi Lea, first off i'd like to tell you that your contributions are invaluable, you are presenting often overlooked subjects, kudos for that. I see you have started the aforementioned article, I didn't have it on my watchlist yet so I didn't know there was a mistake. You must take notice of some rules on WP so check out WP:Notability so you know how to better protect the materials you add against meta:deletionists. Cheers. + """"",0
I didn't receive any massage.,0
"""""

 I TAKE OFFENSE! 

I take great offense that some pompous, sanctimonious twit thinks that no one should be allowed to express appreciation for women like the Gibson Girl as the """"""""fine-featured"""""""" and """"""""achingly beautiful"""""""" creatures that they are.  

I don't know what kind of totalitarian feminazi dystopian agenda you are trying to foist on people, but don't do it here!  This encyclopedia is based on free speech and a free exchange of information, not bogus political correctness and schoolmarmish thought-policing.  I'll take a Gibson Girl over you anyday!""""",0
"Padua User Tag 

Someone should design a Padua College User Tag much like the following one for the Maroons in State of Origin

  14.28 2 July 2007 (UTC)",0
"Ion G Nemes|talk]]) 04:08, 21 June 2011",0
"you gay motherfucker i know where you live,i am going to sand your face off,then i am to going to beat you to a pulp,you chicken shagger.",0
. Ok Dennis Brown thanks for telling me I was taking this a bit way too serious ill be careful for this time stupid bots.,0
- that way I might even know which article you are talking about!,0
"The are problems with the sfc t record. There are no credible sci challenges to it. This new section is absurdly US-centered, it cannot possibly stand as it it. This is the *global* record we're talking about. You need some credible scientific papers, not pictures of stations. As far as I know, the sfcstations stuff has merely documented problems with some station sitings and maintenance, etc. There is not even the beginning of an attempt at quantifying what influence, plus or minus, this might have on the record. If you're interested, there are papers about the effects of switching from north-wall screens to stevenson screens; thatched huts in africa; etc etc",0
"""""

 Could you please comment on Talk:Thought_identification 

Re: John Norseen and Lockheed Martin

I'm beside myself trying to update information that I believe to be very relevent.  It looks to me like several users who """"""""hang out"""""""" at """"""""ANI:Fringe"""""""" are working together to remove well sourced, valid, on topic material which shows the state of military research into thought identification.  Outside comments would be greatly appreciated.  Thanks.
  """"",0
"""""

 Mediation 

Hello, I am Atyndall and I have volunteered to take on your mediation case, during this discussion I will remain neutral with both sides of this argument and will endeavor to solve your dispute. After having a look at the discussion above, this is what I have found:
QuizzicalBee has been adding the sentence """"""""According to Chesler, the the U.S. embassy repeatedly refused to help her leave the country as they no longer recognized her as a U.S. citizen."""""""", Hurmata has been reverting this back to """"""""She reports that the U.S. embassy repeatedly refused to help her leave the country. Hurmata objects to QuizzicalBee's sentence as he/she thinks that the source is incorrect as the guards would have allowed Chesler into the embassy and first hand accounts from Chesler herself does not qualify as a reliable source. QB objects, saying that maybe in the 1960s US citizenship could have been revoked by the US/Afgan government at that time and perhaps in the past the guards may have denied entry and that her claim should have been presumed true until proven false. Hurmata countered that the citation threat QB was referring to is not the one that was cited. QB states that there is no evidence disproving her claims, so they are valid.
Could the involved users please place # ~~~~ below to verify that this statement is correct or suggest why it is not correct? Thankyou, |talk """"",0
"Well, Arthur, I have printed the paper, and the condition is in fact what Ultra.Power says it is, not your correction. It seems that the paper is not incorrect, but rather correct and pointless.

You have already identified the worst problem: The third condition requires incontinuity of f at all integer values. However, this problem disappears if we consider only the special case a=e. So let's do that.

We want a function f satisfying f(1)=e and f(n+1)=exp(f(n)), defined as widely as possible. We observe that n=0 and n=1 present no problems: f(0)=1 and f(-1)=0.

To extend f to all positive real numbers, it is clearly sufficient to define f on an interval of length 1, such as [0,1).

And we want f to be continuously differentiable. (The paper only requires f to be continuously differentiable on (0,1), or equivalently on (-1,0). This is obviously whacky, but we needn't worry about this because a=e.)

Next, for no obvious (or explained) reason we require that f ' is monotone on the interval [0,1]. From the functional equation f(x) = ln f(x+1) we get f '(x) = f '(x+1)/f(x+1). Hence f '(-1)=f '(0)/f(0)=f '(0), so f ' must be constant on [0,1]! 

Not too surprisingly, the function we get in this way is patched together from smaller pieces in a relatively unnatural way: f(x) = exp[x](exp(x-[x])).

Thus what I learned from the paper is that the correct solution to the problem probably has a minimum of its derivative between -1 and 0.",0
"""""

 The Rangers FC 

This should be the name of the Newco Rangers wikipedia page now as they are called The Rangers FC everywhere, on the SFL, SFA, SPL, BBC etc websites and in League tables and on TV. They must have Registered to use """"""""The Rangers FC"""""""" to differentiate between themselves and """"""""Rangers FC"""""""" who still have SPL membership.""""",0
"""""

 Wikipedia:Categories_for_discussion/Log/2010_April_27#Wikipedia_books 

Following the horribly chaos of April 7, I've resubmitted things for discussion.  {talk / contribs / physics / books} """"",0
"FlexPay Tax Law 

Just a comment here.  I'd be interested in seeing an expansion of this artcile regarding to the tax surrounding FlexPay accounts.",0
"""""
No problem at all! (talk) """"",0
"If we do win, and get these evil people out of the government (and their private forces as well), then perhaps there won't be any nuclear blasts across the US and Europe.

 btw, if MONGO is really with HS, why is he on wikipedia?",0
I've just seen that,0
"Najib Effendi al-Yasin 

I suggest not to use paragraph indentation in the article Najib Effendi al-Yasin which have recently created to reach a more normal looking page. Happy editting.",0
"Lol, you know what i meant. Whichever president came before Hafez (i just new he was president before assad) has considerable foreground of support, in which his supports would have freaked out because of the coup. They would have claimed instability would arise, as assad's supporters are trying to use in their defense. 

What i am trying to say is that although Bashar assad had good economic and international policies for Syria, you should not fear a non-baathist potentially being elected.  Syria's economic and international policies won't change (iran would still be a major factor in Syrian life considering the buisness deals stakes and cultural exchanges) , the only this that would change are social freedoms, and for the better. Also every country had a revolution and they are still alive today. The Muslim brotherhood in Syria is weak, even weaker than the islamist prescence in Libya. The rebels in Libya had 80-90% support, as we see now, and yet could hardly take control without NATO. What chance does the Syrian Muslim brotherhood have? None. If anything, nonviolent protests weaken the resolve of the Muslim brotherhood, making them less of an influence in the everyday life of Syrians. As you know I am pro Syria and Armenia, just not pro Assad. Unlike Armenia where people like Sargsyan and Kopcharyan were democratically elected, Assad was not (no one ran against him because they were not allowed).",0
"""""

 CFR is a perfectly accurate source. 

The """"""""Council On Foreign Relations"""""""" (CFR.ORG) is a recognized, legitimate think-tank that studies international terrorisim for the United Staes Govt. to claim they are """"""""Not Credible"""""""" is idiotic.
They are as legitimate as any online newspaper or other source. They have studied Northern Ireland, and compliled a list of UDA/UVF killed by the IRA/INLA, and vice versa. These facts are good and will be included in the article.""""",0
"""""

 Lead 

What's there now is not a summary... summaries are supposed to be substantially shorter than the text they summarize, which the case at Salvatore Giunta is not. It simply copies whole sentances from the body text. As an editor, we have to assess the article as it currently stands, and not any hypothetical future stance. If the article grows, then the lead can be adjusted accordingly. In any case, the lead section I favored does indeed summarize the most important part: the MOH.
In any case, did you read WP:LEAD? The lead of a biography is not necessarily supposed to summarize the life story of the subject, but assert thier claim to notability. The two sentances I favored more than do that without being overly repetitive. ''''''wordsdeeds """"",0
"""""{{Unblock|I'll make a renewed effort not to give personal attacks. But of course I do have some questions about this unwarranted blockage, as you might well imagine:

1. Why is it that IP editors tend to get the raw ends of the deal: that you """"""""admins"""""""" tend to lean towards the side of someone who's editing with an account over someone who's editing without one, especially in the area of what you label as """"""""personal attacks"""""""" or """"""""harassment"""""""" when given by the IP-editor but not so much when the named editor does the same thing?

2. For exampleand this is... yep, maybe you guessed it... question 2: Why is it supposedly """"""""okay"""""""" (according to you) for someone with a name... like, say... escape orbit... to dish out a personal attack, but not for me to give him one back because I'm just a lowly IP-editor? Specifically, why is it supposedly """"""""okay"""""""" for him to give me a personal attack by putting false stuff on my keyboard by making the ludicrous claim that my reason for wanting the old style of """"""""ebaY"""""""" logo to go next to the current one, """"""""ebay,"""""""" in the lead, is """"""""because I wanted it in there,"""""""" even though that is a total lie; but it's supposedly """"""""not okay"""""""" for me to call that kind of slander stupid?

3. Here's another one: Why is it supposedly """"""""okay"""""""" for him and """"""""smiley girl"""""""" there to falsely accuse my edits of being """"""""vandalism"""""""" just because they differed from what these guys preferred, but then when I say their reversions are vandalism, I get in trouble for it as if it were a """"""""personal attack"""""""" just because I'm an IP-only editor?

4. Ready for one more? Then why is it fine for any of you named editors to give one of us IP-editors a warning template, but when I, as an IPer do the same thing to a named editor like I did to partially smiley girl, I get dinged with """"""""Oh, you can't do that 'cause that's a 'personal attack',"""""""" or """"""""Oh, that's bad because that's 'harassment' """"""""?

5. Oh yeah, here's one more! Remember the rule about edit-warring (just in general, meaning that it doesn't even have to be breaking 3RR) that says that """""""" 'but I was right, so I was not edit-warring' is no defense""""""""? Well then doesn't that apply to meeting some so-called """"""""consensus"""""""" too (since some things aren't cases of concrete correctness but are just based more on whether they match what that so-called """"""""consensus"""""""" wanted the thing to say)? Well then why is it that just because your named friend smiley there does some edit-warring against me to put the thing back to what your exclusive (partial) """"""""consensus"""""""" wants it to say, AND since my editing had already been established as NOT vandalism even though it disagrees, you ignore that above-mentioned edit-warring rule and give her/him a pass anyway, but when I, an IP-only editor who's against your exclusive """"""""consensus,"""""""" do the same thing, it's """"""""edit-warring"""""""" even though it was the same thing as what smiley's doing (remember the """"""""being-right/matching-consensus-is-no-defense"""""""" rule)?

75.162.211.81  

""""",0
"If Serbia does recognise Abkhazia and South Ossetia, then I wouldn't be at all surprised if Georgia recognises Kosovo in retaliation.",0
the most subtle questions they possibly could.,0
"""""

 Trying to measure the number of cafes 

This is one of those places where I am so frustrated by Wikipedia's ban on original research. The article has the absurdly low """"""""at least six cafes on the Ave or its alleys"""""""". I don't know where that number comes from, nor what they consider a """"""""cafe"""""""", but it seems to me that well within any reasonable definition, the scene includes:
 Solstice
 Cafe Zoe
 The original Allegro (on an alley parallel to the Ave); arguably, its second location in the College Inn also counts
 The Ugly Mug (half block off)
 The Cafe at the corner of 42nd that used to be the Roma, but I can't recall its new name
 Sureshot
 The Continental
 Caffe Apassionato
 WOW Bubble Tea
 Shinka Tea Company
 Yunnie Bubble Tea
 Pochi Tea
 Gingko Tea House
 Tully's 
 Starbucks
 Wannabee (one block off)
 Still Life on the Ave (at the Grand Illusion); technically, the entrance is around the corner, but it is clearly effectively on the Ave.

This doesn't even count hangouts that are mainly bars or restaurants or takeout food joints, nor does it count things like U. Bookstore and Bulldog News, both of which have busy espresso operations, nor does it count ice cream stands. And I'm sure I'm missing something, this is all just offhand. -  | Talk """"",0
"Actually, undue weight can also results in zero weight.  As it is the whole issue is insinuation and extrapolation of given events.  Just because the article doesn't outright say that Edwards is the father because there was no father listed, it is quite clear that this is the intent.  Now, editors familiar with me consider me to be a FNC fanboy and appolgist regarding conservatives and republicans, so my objection to this is clearly not a partisan point of view.  That said this is in violation of several WP policies.",0
"I found it under Chronological list of PC Engine games. I thought the release dates on that page were for Japan, since there is a seperate List of TurboGrafx-16 games. The change you made is ok though, since I see IGN has it listed that way.",0
"""""

I agree.  Fundamentally, whether you take it as a pill or through a patch or a ring, the key is that it's hormonal, so that should be the main article.  At that point, oral contraceptive should either redirect to hormononal contraception, unles there is sufficient material to justify its existence.  """"",0
That was so desterbing because of when i had to do a project in school i had to explain it wasnt Bill Gates from 20 years ago,0
"The source was a local guide book, how do we source that?",0
"chill out, inty's my mate",0
"A Tale of a Tub on the Main page

Hey, Geogre, check it out: did you know that A Tale of a Tub will be featured on the Main page on Sunday? -) (Talk)]] 23:20, 12 Nov 2004 (UTC)",0
Added C-class. I would like to add B-class but questions raised in talk page.,0
"""""
No problem. Thanks for letting me know.  (talk) """"",0
"Batman  

I am Batman. You are Spiderman. I win.",0
"Geometry of love 
Good day. Can you search some sources for article Geometry of Love ? Probably this article contain interesting fact for DYK.",0
Exactly; I removed the section (again) before I noticed this posting. chen7754,0
"""""

 Please unblock and delete page 

I request that you unblock my """"""""talk page"""""""" and immediately and permanently delete the contents of it. You are free to permanently block me from contributing to Wikipedia, as I have no intention of doing so in any case. If you would like a reason to block me, or prove that I have violated the rules, you need not preserve the talk page. Here is another deliberate & intentionally provocative violation of the rules  an old-school personal insult:

You are a loathsome, sanctimonious, hypocritical, ignorant twit. If you were in state of uncontrolled combustion, I would not take the trouble to extinguish the flames by urinating on them.

I hope that is satisfactory.  """"",0
"That is true with the first edit, however the second one was an honest mistake.",0
"That's been the problem facing this article as well.  I'd love to see this get to featured article status, but I keep running into the fact that there isn't really a whole lot of good verifiable info out there that is easily available, nor is it easy to come by a picture that is usable (though I suspect the one or two known images of him would fall under fair use).  There are a couple of  websites out there that basically regurgitate sections from McGregor's book.  There is a certain irony in the fact that a guy who labored in anonymous solitude most of his life on a project he loved dearly died destitute and is not making several other people rather wealthy...",0
You are a funney man.,0
"Furthermore, any threats made to block individuals adding and or editing well researched information, would directly negate the sole intention of Wikipedia itself.",0
"Wikipedia is full of fools. Who takes money and makes people work for free?  Wikipedia!!! You might as well ban me, you fool. What's taking so long? Wiki is a stupid place, it's Jimbo's Cult.",0
They seem to be reliable enough for this topic anyways - it's not like many major news sources are going to be covering the things that these sites cover. 63.164.47.227,0
"""""

In response to your feedback

Yoa can not do it by yourself, see Wikipedia:Changing username.

  

""""",0
"""""

that is your opinion. And what is your proof that I am anti-Newsom? Whether you support him or not he did have a gay porn day and violated state law by issuing """"""""Gay marriage"""""""" licenses, in contradiction to state law. These are facts, not slander or fiction...""""",0
"""""
That admission begs the question """"""""Is it better to punish adolescent boys if they are going to engage in bullying behaviour here, or extend them welcome?""""""""  /talk/ """"",0
"""""== French-speakers and Paris ==

Can anybody explain this: """"""""French-speakers concentrate heavily on cultural life in Paris""""""""? What does it mean?  21:09, Sep 28, 2004 (UTC)""""",0
"Why are you changing the SOMALI PEOPLE WIKI????????????????????/ 

SERIOUSLY????????? THAT PAGE IS BIASED TO ONE CLAN, I ADDED A MORE DIVERSE REPRESENTATION OF SOMALI PEOPLE!

YOU STUPID CRIMINAL.",0
"Davkal, I agree with you, but would suggest that you don't discuss it or gloat because you know he will likely come back and start harassing agagin.
Apparently just a few hours after he left someone bit his head off on his talk page about a comment he left in an article. -",0
"""""

 Thanks 

Thanks for the tip Buddy.  walkie-talkie 

 KY highway page 

I'm currently cleaning up the page. Please do not edit it. Thanks.  Let's Go Mets - Stats 

 Your first barnstar! 

{| style=""""""""border: 1px solid gray; background-color: #fdffe7;""""""""
|rowspan=""""""""2"""""""" valign=""""""""middle"""""""" | 
|rowspan=""""""""2"""""""" |
|style=""""""""font-size: x-large; padding: 0; vertical-align: middle; height: 1.1em;"""""""" | The Tireless Contributor Barnstar
|-
|style=""""""""vertical-align: middle; border-top: 1px solid gray;"""""""" | I hereby award BigrTex the tireless contributor barnstar due to his outstanding amount of high quality edits. Hikaru """"",0
"Transistor  

The transistor page does not have a Principle of Operation section, because 

a)the physicists know about it but don't want to share it
b)they just don't know how it works

I was thinking about it and came up with a fairly decent concept of how it works, I put it on WIKI, I think the guys got jealous, and here I am, discussing pretty much nothing. 

PS: and my language is pathetic, you naughty naughty boy,..I'll eat you...:)))",0
"I like to see it in print, since it's been listed for days now without an URL.",0
"""""the proposed deletion process  because of the following concern:
Wikipedia should not be used as a place for guides or a walk through.

All contributions are appreciated, but this article may not satisfy Wikipedia's criteria for inclusion, and the deletion notice should explain why (see also """"""""What Wikipedia is not"""""""" and Wikipedia's deletion policy).  You may prevent the proposed deletion by removing the  notice, but please explain why you disagree with the proposed deletion in your edit summary or on its talk page.

Please consider improving the article to address the issues raised because, even though removing the deletion notice will prevent deletion through the proposed deletion process, the article may still be deleted if it matches any of the speedy deletion criteria or it can be sent to Articles for Deletion, where it may be deleted if consensus to delete is reached.   """"",0
"""""
Hmmm. There is a way to do this. I'll see if I can remember what the code is. gabsadds """"",0
"""""

This article already exists see Liger. Pro """"",0
"Feather 

There is no citation as to how a quill looked in the past. Therefore, it is opinion only.",0
"Bakan 

Why is Abbie Bakan even mentioned in this article?  Based on the worthless rag of hers which is cited as a source in this article, she's nothing but a shill for Lenin and the rest of the commie gang.  In that rag, she not only shows egregious pro-Communist bias, but doesn't even bother to check the facts, much less look at the causes of the Kronstadt rebellion or even cite reliable historical sources on that subject.  She also discredits herself with absurd accusations of a White conspiracy to overthrow the Soviet government and even of the rebellion being motivated by anti-semitic racism among the sailors.  Furthermore, all the claims made in that rag are based on a case of begging the question: that is, since Lenin's Communist regime was good (major premise) and the Kronstadt rebellion harmed said regime (minor premise), suppressing the rebellion was justified.  Last but not least, the mere fact that the aforementioned rag was first published by a self-admitted socialist party by definition means that this source DOES NOT meet EITHER WP:NPOV OR WP:RS.  If such sources continue to be used in Wikipedia articles, the whole project will soon turn into Commiepedia. 67.169.177.176",0
"Messages on talk pages during an AfD

Placing messages on Users talk pages such as  and  in the hope of gaining support is an unacceptable practice which, agin, hinders the AfD process.",0
"trivia

i'd advise you to look the word up in a good dictionary, jay. mr townsley's marriage into an important business dynasty is obviously noteworthy, which is why it's noted  prominently in the article linked to. cheers.",0
"Might I remind you that this is the ENGLISH language Wikipedia, and you have no greater precedence here than I do. Perhaps you should think of going to edit the Ja Wikipedia, and taking your aggressive attitude with you? Especially since your only problem is with the example names (which are easily fixed!) You're clearly incapable of appreciating the improvements I made in English, so perhaps you're not the best person to judge. 81.178.252.102",0
"""""

Speedy deletion of David Fork
 A tag has been placed on David Fork requesting that it be speedily deleted from Wikipedia. This has been done under section A1 of the criteria for speedy deletion, because it is a very short article providing little or no context to the reader. Please see Wikipedia:Stub for our minimum information standards for short articles. Also please note that articles must be on notable subjects and should provide references to reliable sources that verify their content. 

If you think that this notice was placed here in error, you may contest the deletion by adding  to the top of the page (just below the existing speedy deletion or """"""""db"""""""" tag), coupled with adding a note on the talk page explaining your position, but be aware that once tagged for speedy deletion, if the article meets the criterion it may be deleted without delay. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would would render it more in conformance with Wikipedia's policies and guidelines.   what do u want?   """"",0
"""""
Your suggestion of editing the article is completely workable and was working as per Wikipedia guidelines until Jayjg and SlimVirgin started deleting large relevant chunks of the article, and reverting it to what we have now, as punitive gestures.  If we can all agree to concentrate on making the article better, instead of punishing each other, there is no reason the article has to be locked.
I agree that we should start with an extremely innocuous definition preamble statement we can all agree on.  However, a definition doesn't do anyone any good unless it conveys some sort of information.  If there were just one word that we could all agree is associated with terrorism, that would be better than no definition at all: """"""""intimidate"""""""" for instance.   """"",0
"Speaking without knowing what I'm talking about? OK, how 'bout this: the original comment I made about Everlast's entry constantly being vandalized by Eminem fans was written a month ago before your dumb ass got involved with the site. The feud started with the Dilated Peoples track. That's why I believed that the verse Everlast contributed should be in there (and still do). The jabs taken back and forth after that deserve a synopsis only. Your idiotic little comment about album sales was excessive and unnecessary. It belongs in there no more than the fact that everyone who knows both artists agrees that if they ever got into it, Everlast would knock the living shit outta Eminem. And THAT came off an Eminem fan site.",0
Our Talk Archives: 1 2 3 4 5 6 7,0
"""""

Speedy deletion of Spunga
 A tag has been placed on Spunga, requesting that it be speedily deleted from Wikipedia. This has been done under section G4 of the criteria for speedy deletion, because the article appears to be a repost of material that was previously deleted following a deletion debate, such as at articles for deletion. Under the specified criteria, where an article has substantially identical content to that of an article deleted after debate, and any changes in the content do not address the reasons for which the material was previously deleted, it may be deleted at any time. 

If you think that this notice was placed here in error, you may contest the deletion by adding  to the top of the page (just below the existing speedy deletion or """"""""db"""""""" tag), coupled with adding a note on the article's talk page explaining your position, but be aware that once tagged for speedy deletion, if the article meets the criterion it may be deleted without delay. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would would render it more in conformance with Wikipedia's policies and guidelines.  (talk)  """"",0
"Plus, you have to be a natural born citizen... which I'm going to assume  is not. But who cares anyway.",0
"Unblocked for the last time
Ok, now don't fuck up. I mean that in the best possible way.  Good luck and good night.",0
"""""
I understand your position and think that your point is perfectly valid. However, I don't deem """"""""Iai-Chiinu"""""""" a creation of Wikipedia, even with the lack of historical sources for that effect in the English language. I'll think more about this tomorrow. Thank you for explaining your position to me with such accurate detail. Best regards, nd """"",0
you studid cock sucker u stop callin me ok its a frank Garrett eatin the worms crawl outa your moms pussy you fucking retardo hit I retardo,0
"Thanks 

User talk:Biggity... are there any constructive edits? Indef block, perhaps? Mahalo.",0
"""""For anyone interested in accurate (not deliberately misleading) information about the """"""""ten-string guitar"""""""" (i.e. not the garbage that will no doubt soon be presented here), see www.myspace.com/tenstringguitar []. (Tthough my temporary site has now been hidden/removed from google search listings by some shady dealings, the truth will prevail.)

""""",0
""""":You said: """"""""I am determined that the page will not regress to this again, and I will delete anything inappropriate that jeopardizes the good progess that is now being made. A completely inappropriate post in the middle of a sensitive discussion threatens to do just that.""""""""  The problem is that you are not the sole arbiter of this (or any) talk page. The post was innocuous and did not violate the conditions of the arbitration decision. Nor did it affect the flow of discussion on the page. In fact the most appropriate response would have been to just ignore it.  By removing it you just encourage a reaction.  You accuse me of wikilawyering, which is absurd. The guidelines are there to help us all. However, not only do you violate that guideline, but also several policies.  It is this kind of heavy handed action that encourages people to persist with problem edits. It is a long-standing convention that we do not remove other users posts and in my three years here I have never seen it done when it wasn't vandalism.  Unless you can give me a much better reason for not doing so, I am going to reinstate the deleted text.        

""""",0
"The Glourious People's Republic of China has carried out a survey of the Great Wall. It is no surprise that Chinese inventions such as the Wall exist to this day. One day our Great Wall will stretch all the way around the World. Anyway, let's add details of our dear government's survey.",0
"FisherQueen, would you kindly stop following my every move and deleting things off MY user page. Havent you got anything better to do than piss people off on Wikipedia.",0
"""""

So Jim Burton, child molesting faggot, I see you are still with us for yet another day, making a total buffoon out of yourself as usual.  I don't know what is sadder here - you, or the extreme hypocritical arrogance you show by lecturing the world about """"""""ethical principles"""""""" for your claimed """"""""rights"""""""" to abuse our children.  You have no ethical principles to save your life, but it's exactly as the Roman poet said, isn't it? """"""""the harlot doth always rebuke the chaste.""""""""  Will you ever drop dead, we might all breathe a little easier for our kids sake. You truly disgust me with every word you write.  """"",0
"""""
Having read Will Beback, I already changed the structure: separate """"""""someone's"""""""" view over him into separate section. I suggest: Further restructuring welcome, and Details per section later-  """"",0
Nevermind. The  has assimilated those puppies. ) Sorry for the bother. Cheese/Wine,0
I fixed the link. It took all of about 3 seconds. Now leave it or I will report you to the administrators.,0
"As I have told  they were not deliberate personal attacks. In my belief, my messages have been interpreted wrongly although I asumed good faith in posting them. As I have mentioned that",0
"""""

 Please do not remove content from pages without explanation, as you did with this edit to Vole. If you continue to do so, you will be blocked from editing.   royal court """"",0
"Deleted American Criminal category 

It's incredible to me that the facts of this article might lead some misguided soul to think this is what the American Criminal Category is for.  There's a lively discussion at the category's talk page about what should be in the category, but even the most expansive reading of the category doesn't countenance this.",0
"MILLINOS OF HUNJAN looking at hunjan template not just me other hunjan will fight back, your concept of art bull of shit!! 86.166.250.11   tharkarn and what waste man!",0
"""""Just to add Kansas Bear.When I said:

""""""""You made the elementry mistake of calling it a treaty when it was in fact a congrass""""""""

Is because as you left out as usual my post in which you regarded the three deligations as having been pressent at the treaty o Arass with Papal meditiation.The treaty of Arass was a private treaty only between the deligations of Burgundy and France and made a military alliance in 1439.Again we are debatting on the Burgundian recognition stop changing the subject.You clearly are giving fallactious statements and I feel your posts are utterly questionable.If you happend to remeber a month ago we both agreed the congrass and treaty of Arass were different.I corrected your statement when you regarded the three deligations as bieng pressent at the treaty of Arass.P.S Stop with your childish personal attacks.I aqsked you to give sources regarding that Burgundy didnt recognize Henry as King of France but you give refs regarding the treaty of Arass and mixing up the posts.If you cant handle the fact that Burgundy recognised Henry as King of France then I have already reverted you on the dual-monarchy article.You should be ashamed of your Fallactious remarks nd utterly questionable unsourced facts  

""""",0
"""""::: er ... (1) """"""""using two usernames to vote more than once in a poll"""""""" I have no idea what you are talking about. I have not used an usernames and I have never voted in any poll., (2) I can not be a vandal as I have not vandalised anything. I may have added content which you, or someone else, did not agree. This is not vandalism. The correct reponse is discussion and debate to achieve a conscensus, (3) Again I am not a sockpuppet or a puppetmaster. I have been fully open that I am the same person. By Wikipedia's defintion I am not a sockpuppet or puppermaster, you may wnat to use a different defintion but that is just your opinion and mudslinging ...hardly appropriate for an Administrator.
""""",0
"Raffaele's request for a lawyer while being interrogated on Nov. 5 was refused, as was his request that he be allowed to call his father. Page 138

Amanda was denied food, water, bathroom breaks and naps during the all night interrogation on Nov. 5-6.. Page 151

Wikid: Actually, now looking at Murder In Italy, I see that there is a ton of additional information about both Amanda and Raffaele's interrogations that could be included. So I will work on listing all that in more detail tomorrow.",0
"Yes, I like the suggestion also. It looks pretty good, and by leading into the next sentence about the bering strait crossing, it conforms to the rest of the article since later on we get more details on the prehistoric migrators. I'll just edit Yee's suggestion in.",0
"Seriously, Alex, your article is on the edge of being deleted. There is no one at the deletion discussion arguing for its being kept. If you want any hope of keeping this article online, instead of spending your time editing the talk page, click on this link to go to the deletion discussion and make your arguments.",0
. Fu ck ing trollreasons,0
"Some day, you and I are going to remember this and laugh!!! HA HA HA HA HA!!!! Never forget: I have incredible power. I am more powerful than you can possibly imagine.

Let me just close(?) this conversation by bidding you a fond farewell. ",0
"You've probably noticed the table factions approach, if you could keep an eye out for more game-central information on in-game factions and then update the table, that would be great. I'm basing it off of a similar table in the A-class Age of Empires III, which shows the sort of information to go for without falling into the gameguide trap.",0
"""""

 SR/CL: 

U bud bin A-way. Like long time like time outa mind long.  Gooood shit but mo' latah an dat.  Soon az Ah gitz back heah sum a de brotherz 'n sistahs 
sez """"""""Hance dead or alive?  We're about to send a Zion Ranger to check on his condition.""""""""  Ah sez """"""""Whoa! Led me gib him a holler.""""""""  Dis me hollerin Bro. 
De Zion Rangerz be dem dat do most a' de walkin tru wallz.  Not all but most. De wall walkin dude ain gonna do R Bro no harm, he jes be checkin.  
EE-ben so a gentle remindah kum fuhst.  U be readin id. A leedle postin a dis 'n dat go down GOOD.  Doan fohget to cut sum ZZzz aftah a tad a postin. 
Sleep good 'n doan fergit ta dream. Sumptin might kum jes ta BDH all wrapt roun wid delta wave 'n a kupla otha' carrierz what we diz-cuss lAtah. Chow, Bro.""""",0
you did not call me neither? Maybe we missed the once in a lifetime chance to see us.  (Talk),0
"|, as you did  to the Henry David Thoreau page|}}. It is considered vandalism. If you would like to experiment, use the sandbox. Thank you.",0
"""""rather crude ancestor of the vaccine. 

The source is a biography of Louis XVI """"""""Louis XVI le Roi Bienfaisant"""""""" (Jean de Viguerie, on the various, and often contradictory, influences of the french government prior to the revolution), where a section is devoted to the innoculation of the royal family, and makes note of how the intendant of Franche Comte had financed physicians to do it through his province, and how it was later used by Washington on his continental army.  

The truth
He actually died on December 31. It even says so in a book that I have!  

 Facts About George Washington 

1)George Washington owned over 33,000 acres of land.
2) Washington lived in NEW YORK AND PHILDELPHIA DURING HIS PREIDENCY The preceding unsigned comment was added by 71.230.187.220  .

 GA in zh.wikipedia 

Please add {{Link GA|zh}} in interwiki section. Thanks!   """"",0
"""""

The objectionable textbook material

""""""""The ads refer to a controversy in Wheaton schools in the early 1990s surrounding a series of textbooks called """"""""Impressions,""""""""... They also contained some writings that some parents believed featured themes of the occult, witchcraft, violence and disrespect for parental authority.'

Here is a discussion of one of the offending pieces - a yarn called """"""""A Wart Snake in a Fig Tree"""""""" which is a kind of a pardody of 'The Twelve Days of Christmas' but with creepy-crawlies and spiders and snakes and stuff. A Wart Snake in a Fig Tree I wonder what Roskam's stance on Harry Potter and Holloween is? -  """"",0
"""""
 No, I didn't mean point me at a biographical article (though that would be good too).  I mean answer right here on the discussion page:  What town were you born in?  Which schools did you go to?  Also, regarding """"""""over the top"""""""", I disagree  I think the article could do with quite a bit more expansion, as could the articles of the other individuals you mentioned.  As for """"""""greatest living magicians"""""""", I have to admit I'd never heard those names.  How are you judging that, say, Max Maven is better than a David Copperfield?  Is it by awards, industry press, or just personal opinion of their technique?   """"",0
"""""
Okay, but only if they are truly not needed; same sort of criticism/praise, no quotes, etc. Thank you.  | talk """"",0
"""""
Haha, you're fine. I mean, you're allowed to do it, but I'm just selfish, I guess. =) I really appreciate your kindness, though. And I really respect that you asked, because when other signatures that were borrowed, no one let me know or gave me any credit! So I feel badly that since you asked, you'd feel really badly about doing it now, haha. But I can help you figure out a nice one or pick out some fun colors. Have a great day, and happy Wikying!  """"",0
"Leave me alone! 

I told you already to leave me alone.why can't you fuck off and do your own fucking thing. Or do you find that hounding me is amusing. Id u do then you are a mothafuckin asshole and I will ban you.",0
"""""

 Bloc voting 

Countries with large populations of non-nationals may have their televote influenced considerably. This has been cited as the reason for apparent bloc voting in the Balkan countries of the former Yugoslavia.[91] 

This is full-blown crazy. What does """"""""non-nationals"""""""" mean? These countries have similar cultures and speak the same languages. The stars in Croatia are popular in Serbia and vice versa. People are nationals of their countries in the largest proportion in each of those countries (there are some refugees in each of those countries, but that doesn't really explain why Croatia would always give the highest no. .of pts to Serbia, or Macedonia to Serbia, where there was no conflict to speak of). For example, I'm a Bosnian Serb and me voting for a Croatian or a Serbian song is not unusual. But I'm not a Bosnian non-national. I have the passport of BiH, and my family has never lived in Serbia in history. It's really about mutual intelligibility  which is why Scandinavian bloc votes for each other all the time. It's the language and sensibility.""""",0
"""""""""""""PETA is not a self-published source."""""""" Please explain how the PETA website is not """"""""self-published"""""""".  

""""",0
"""""

 Please do not vandalize pages, as you did with this edit to Morrissey. If you continue to do so, you will be blocked from editing.   Impala 2009 """"",0
""""", 24 August 2007 (UTC)

There is no WP:RS to affirm the veracity of DI's doubtful claim either.  That is, you have no WP:RS either way.  Therefore it is not a verifiable fact that Picard (or any of the other 103 original signers) consented to or agreed with the DI's published interpretation or political position vis-a-vis PBS or any other subsequent political purpose regarding what should or shouldn't be taught in school.

All you have on verifiable record is that the 103 original signers called for skeptical examination of the evidence for scientific theories.  DI's unverifiable claim which fraudulently spins that into consensual agreement or support for their interpretation or political agenda is not a fact under the rules of Wikipedia.  

All the rest of DI's propaganda is utter hogwash fraudulently perpetrated by the DI without the verifiably demonstrated consent of the original 103 individuals.

In view of the WP:BLP """"""""Do No Harm"""""""" clause, the unverified claim of the DI must not be promoted to fact and any content to that effect must be immediately expunged, per the WP:BLP:

 16:11""""",0
"Email 

Thanks for your email about the message you received from Guyovski. I received a similar, though not openly threatening, email from Guyovski as well.",0
It is a fabrication with intent to defame. That is not the point here. It belongs in the Dan Savage article.,0
"Perhaps overlooked in the discussion of Steve Moores credentials is another aspect of the Newsweek article. By saying that Knoxs supporters have hurt her by expressing their opinions, Nadeau has effectively stated that the decisions of the Italian court will be (or have been) influenced by anger and anti-American sentiment rather than the evidence alone. I dont know if Nadeaus experience in Italy qualifies her to make such an assessment, but taking her as a RS to make that statement would be as great an insult to Italian jurisprudence as anything Knoxs supporters have said. I wholly concur with pablos opinion that the piece has no place in the article.",0
"""""

 Other attractions 

What is a """"""""water place"""""""" and """"""""animal place""""""""?   """"",0
"""""
I fear Jossi may be correct. If Watts (who, btw, died in 1973) said this about Rawat, he probably meant it as praise; i.e. the emphasis would have been on """"""""sacred"""""""", judging from my knowledge of Watts' oeuvre. He was rather anti-intellectual himself. 466 """"",0
Ooooh. Well can you fix it? Because it looks a mess right now and I don't think it was certified in Switzerland yet. So New Zealand and Australia should just be there.,0
Omg i love Dch!!! Who doesn't???!!! I love Pac Sun!!!,0
I've removed it. It contributes NOTHING to the article.,0
""""" Hi, Writingrights, Welcome to Wikipedia!  
I hope you like this place  I sure do  and want to stay. Before getting too in-depth, you may want to read about the Five pillars of Wikipedia and simplified ruleset. If you need help on how to title new articles check out the naming conventions, and for help on formatting the pages visit the manual of style. If you need help look at Wikipedia:Help and the FAQ , plus if you can't find your answer there, check the Village Pump (for Wikipedia related questions) or the Reference Desk (for general questions)! There's still more help at the Tutorial and Policy Library. Plus, don't forget to visit the Community Portal. And if you have any more questions after that, feel free to post them on my user talk page or place {{helpme}} on your talk page and someone will be by to help you shortly. 
TAB 
Additional tips 
TABTAB 
Here's some extra tips to help you get around in the 'pedia! 
If you want to play around with your new Wiki skills the Sandbox is for you.TAB 
You can sign your name using three tildes (~). If you use four, you can add a datestamp too. Five will get you the datestamp only.
You may want to add yourself to the new user log.TAB 
If you ever think a page or image should be deleted, please list it at the votes for deletion page. There is also a votes for undeletion page if you want to retrieve something that you think should not have been deleted.
If you're still entirely confused, or would like to get a better grasp of your wikipedia skills, and you have an IRC client (or don't mind getting one), check out the Bootcamp. It's not what it sounds like, but it is fun and can help you with your editing skills.
If you're bored and want to find something to do, try the Random page button in the sidebar, or check out the Open Task message in the Community Portal.

Happy Wiki-ing.  talk contribs


Click here to respond to this message!""""",0
"It is common knowledge that Karaims (but not Karaite Jews) boast descent from Khazars, but what they do not realize is that we believe the - (On-oq) whence came (mixing with Carian mercenaries from Caphtor and Kolhkis) our Khazar ancestors were in fact the remnant of the lost Ten-Tribes of Israel who formed our priesthood. It is precisely for this reason that Karaite Jewish scholars like Jacob Ben Reuben of Byzanteum and Yefet ben Ali or Jeshua ben Judah call us bastards in their writings. 

The following editor (",0
", 12 April 2006 (UTC)
Then rewrite and expand the article. I'd much rather have a full article, than a bad article with a full template. As for William's edits, I'm not going to vote on a content matter at this time. I have never looked at this article before you sent me the link, so I am not equipped to choose one version over another. My vote is purely on the layout/aesthetics of including the template. Maybe later when I've spent more time with an unfamiliar article, I can make a statement about the content.  16:06",0
"""""I was trying to inject some humour (as evidenced by my winky face) in this ridiculous, overblown, and unnecessarily dramatic situation. If you took the time to familiarize yourself with the situation, you would see that the person I insulted was attacking my cited and factual contributions by actively censoring them no explanation; which I retaliated with by insulting him. I thought that his conduct was insult-worthy at the time, as would any sane individual who was not familiar with Wikipedia's """"""""no-insult"""""""" rule, however I have since realized that what I did was wrong because this site does not allow for harsh words: which is why I will not use them again even if they are used against me, which they were during this ordeal.

Wikipedia is the place for me because my edit was constructive and brought a greater knowledge to the subject's topic. But, the fact that I insulted another user in the edit summary is regrettable, and I know that now.

If you seriously think the edit linked above constitutes a """"""""better"""""""" insult, """"",0
"this title should redirect to Altona, Hamburg. I w'd change it but at the moment there are too many links for me to bother.",0
