post,label
"<p>Suppose I have a vector that is nested in a dataframe one or two levels.  Is there a quick and dirty way to access the last value, without using the <code>length()</code> function?  Something ala PERL's <code>$#</code> special var?</p>

<p>So I would like something like:</p>

<pre><code>dat$vec1$vec2[$#]
</code></pre>

<p>instead of</p>

<pre><code>dat$vec1$vec2[length(dat$vec1$vec2)]
</code></pre>
",1
"<p>I have a function inside a loop inside a function. The inner function acquires and stores a large vector of data in memory (as a global variable... I'm using """"R"""" which is like """"S-Plus""""). The loop loops through a long list of data to be acquired. The outer function starts the process and passes in the list of datasets to be acquired.</p>

<pre><code>for (dataset in list_of_datasets) {
  for (datachunk in dataset) {
    &lt;process datachunk&gt;
    &lt;store result? as vector? where?&gt;
  }
}
</code></pre>

<p>I programmed the inner function to store each dataset before moving to the next, so all the work of the outer function occurs as side effects on global variables... a big no-no. Is this better or worse than collecting and returning a giant, memory-hogging vector of vectors? Is there a superior third approach?</p>

<p>Would the answer change if I were storing the data vectors in a database rather than in memory? Ideally, I'd like to be able to terminate the function (or have it fail due to network timeouts) without losing all the information processed prior to termination.</p>
",1
"<p>I've been mystified by the R quantile function all day.  </p>

<p>I have an intuitive notion of how quantiles work, and an M.S. in stats, but boy oh boy, the documentation for it is confusing to me.  </p>

<p>From the docs:</p>

<blockquote>
  <p>Q[i](p) = (1 - gamma) x[j] + gamma
  x[j+1],</p>
</blockquote>

<p>I'm with it so far.  For a type <em>i</em> quantile, it's an interpolation between x[j] and x [j+1], based on some mysterious constant <em>gamma</em></p>

<blockquote>
  <p>where 1 &lt;= i &lt;= 9, (j-m)/n &lt;= p &lt;
  (j-m+1)/ n, x[j] is the jth order
  statistic, n is the sample size, and m
  is a constant determined by the sample
  quantile type. Here gamma depends on
  the fractional part of g = np+m-j. </p>
</blockquote>

<p>So, how calculate j?   m?</p>

<blockquote>
  <p>For the continuous sample quantile
  types (4 through 9), the sample
  quantiles can be obtained by linear
  interpolation between the kth order
  statistic and p(k): </p>
  
  <p>p(k) = (k - alpha) / (n - alpha - beta
  + 1),
  where α and β are constants determined
  by the type. Further, m = alpha + p(1
  - alpha - beta), and gamma = g.</p>
</blockquote>

<p>Now I'm really lost.  p, which was a constant before, is now apparently a function.  </p>

<p>So for Type 7 quantiles, the default...</p>

<blockquote>
  <p>Type 7</p>
  
  <p>p(k) = (k - 1) / (n - 1). In this case, p(k) = mode[F(x[k])]. This is used by S. </p>
</blockquote>

<p>Anyone want to help me out?  In particular I'm confused by the notation of p being a function and a constant, what the heck <em>m</em> is, and now to calculate j for some particular <em>p</em>.  </p>

<p>I hope that based on the answers here, we can submit some revised documentation that better explains what is going on here.  </p>

<p><a href=""""https://svn.r-project.org/R/trunk/src/library/stats/R/quantile.R"""" rel=""""noreferrer"""">quantile.R source code</a>
or type:  quantile.default</p>
",1
"<p>How can I test for the <code>EOF</code> flag in R? </p>

<p>For example:</p>

<pre><code>f &lt;- file(fname, """"rb"""")
while (???) {
    a &lt;- readBin(f, """"int"""", n=1)
}
</code></pre>
",1
"<p>I'm looking for a an <code>R</code> package which can be used to train a Dirichlet prior from counts data.  I'm asking for a colleague who's using <code>R</code>, and don't use it myself, so I'm not too sure how to look for packages.  It's a bit hard to search for, because """"R"""" is such a nonspecific search string.  There doesn't seem to be anything on <a href=""""http://cran.r-project.org/web/packages/index.html"""" rel=""""nofollow noreferrer"""">CRAN</a>, but are there any other places to look?</p>
",1
"<p>Does anyone know of any optimization packages out there for R (similar to NUOPT for S+)?</p>
",1
"<p>I know that R works most efficiently with vectors and looping should be avoided. I am having a hard time teaching myself to actually write code this way. I would like some ideas on how to 'vectorize' my code. Here's an example of creating 10 years of sample data for 10,000 non unique combinations of state (<code>st</code>), plan1 (<code>p1</code>) and plan2 (<code>p2</code>):</p>

<pre><code>st&lt;-NULL
p1&lt;-NULL
p2&lt;-NULL
year&lt;-NULL
i&lt;-0
starttime &lt;- Sys.time()

while (i&lt;10000) {
    for (years in seq(1991,2000)) {
        st&lt;-c(st,sample(c(12,17,24),1,prob=c(20,30,50)))
        p1&lt;-c(p1,sample(c(12,17,24),1,prob=c(20,30,50)))
        p2&lt;-c(p2,sample(c(12,17,24),1,prob=c(20,30,50)))    
        year &lt;-c(year,years)
    }
        i&lt;-i+1
}
Sys.time() - starttime
</code></pre>

<p>This takes about 8 minutes to run on my laptop. I end up with 4 vectors, each with 100,000 values, as expected. How can I do this faster using vector functions?</p>

<p>As a side note, if I limit the above code to 1000 loops on i it only takes 2 seconds, but 10,000 takes 8 minutes. Any idea why?</p>
",1
"<p>So earlier I answered my own question on thinking in vectors in R. But now I have another problem which I can't 'vectorize.' I know vectors are faster and loops slower, but I can't figure out how to do this in a vector method:</p>

<p>I have a data frame (which for sentimental reasons I like to call my.data) which I want to do a full marginal analysis on. I need to remove certain elements one at a time and 'value' the data frame then I need to do the iterating again by removing only the next element. Then do again... and again... The idea is to do a full marginal analysis on a subset of my data. Anyhow, I can't conceive of how to do this in a vector efficient way. </p>

<p>I've shortened the looping part of the code down and it looks something like this:</p>

<pre><code>for (j in my.data$item[my.data$fixed==0]) { # &lt;-- selects the items I want to loop 
                                            #     through
    my.data.it &lt;- my.data[my.data$item!= j,] # &lt;-- this kicks item j out of the list
    sum.data &lt;-aggregate(my.data.it, by=list(year), FUN=sum, na.rm=TRUE) #&lt;-- do an
                                                                         # aggregation

    do(a.little.dance) &amp;&amp; make(a.little.love) -&gt; get.down(tonight) # &lt;-- a little
                                                                   #  song and dance

    delta &lt;- (get.love)                                         # &lt;-- get some love
    delta.list&lt;-append(delta.list, delta, after=length(delta.list)) #&lt;-- put my love
                                                                    #    in a vector 
}
</code></pre>

<p>So obviously I hacked out a bunch of stuff in the middle, just to make it less clumsy. The goal would be to remove the j loop using something more vector efficient. Any ideas?</p>
",1
"<p>I can't find it anywhere on the web (and I don't want to install it). Is the <a href=""""http://en.wikipedia.org/wiki/R_(programming_language)"""" rel=""""nofollow noreferrer"""">R language</a> a compiled language? How fast does it run a pre-written script? Does it do any kind of compilation, or just execute instructions line by line?</p>
",1
"<p>I have a CSV of file of data that I can load in R using <code>read.csv()</code></p>

<p>Some of the data is missing, so I want to reduce the data frame down to set that consists entirely of non-missing data, i.e. if a <code>NULL</code> appears anywhere, I want to exclude that column and row from the filtered data set.</p>

<p>I know I can probably do this fairly simply with the inbuilt R vector operations, but I am not quite sure how to do this exactly?</p>

<p>To make my question a little more concrete, here is a quick sample of the data so you can see what I want to do.</p>

<pre><code>DocID       Anno1    Anno7  Anno8
1           7        NULL   8
2           8        NULL   3
44          10       2      3
45          6        6      6
46          1        3      4
49          3        8      5
62          4        NULL   9
63          2        NULL   4
67          11       NULL   3
91          NULL     9      7
92          NULL     7      5
93          NULL     8      8
</code></pre>

<p>So given this input, I need some code that will reduce the output to this.</p>

<pre><code>DocID       Anno8
44          3
45          6
46          4
49          5
</code></pre>

<p>As <code>Anno8</code> is the only column with non-NULL data, and there are only four rows with non-NULL data.</p>
",1
"<p>I would like to import a time-series where the first field indicates a period:</p>

<pre><code>08:00-08:15
08:15-08:30
08:30-08:45
</code></pre>

<p>Does R have any features to do this neatly?</p>

<p>Thanks!</p>

<hr>

<p><strong>Update:</strong></p>

<p>The most promising solution I found, as suggested by Godeke was the cron package and using substring() to extract the start of the interval.</p>

<p>I'm still working on related issues, so I'll update with the solution when I get there.</p>
",1
"<p>I have a standard c# application that acts as a GUI front end for a an """"R"""" statistics engine. """"R"""" consists of approx 600 files in approx 50 different folders and can be """"installed"""" on a machine through xcopy deployment.</p>

<p>I would like to package up both the R engine and my c# gui into one setup.exe so that the user doesn't need to go and install R first and then my c# application seperately.</p>

<p>I know that I can produce a setup project and then add in the R files one by one but adding all 600 files will be very tedious!</p>

<p>Is there an easier way of doing what I want? Can I add the single R folder and automatically add the subfolders and files to save me adding them in one by one? Or maybe do an unzip procedure in my setup project which will unzip the R engine in one go?</p>
",1
"<p>I've imported a csv file with lots of columns and sections of data.</p>

<pre><code>v &lt;- read.csv2(""""200109.csv"""", header=TRUE, sep="""","""", skip=""""6"""", na.strings=c(""""""""))
</code></pre>

<p>The layout of the file is something like this:</p>

<pre><code>Dataset1
time, data, .....
0       0
0       &lt;NA&gt;
0       0

Dataset2
time, data, .....
00:00   0
0       &lt;NA&gt;
0       0
</code></pre>

<p>(The headers of the different datasets is exactly the same.</p>

<p>Now, I can plot the first dataset with:</p>

<pre><code>plot(as.numeric(as.character(v$Calls.served.by.agent[1:30])), type=""""l"""")
</code></pre>

<p>I am curious if there is a better way to:</p>

<ol>
<li><p>Get all the numbers read as numbers, without having to convert.</p></li>
<li><p>Address the different datasets in the file, in some meaningfull way.</p></li>
</ol>

<p>Any hints would be appreciated. Thank you.</p>

<hr>

<p>Status update:</p>

<p>I haven't really found a good solution yet in R, but I've started writing a script in Lua to seperate each individual time-series into a seperate file. I'm leaving this open for now, because I'm curious how well R will deal with all these files. I'll get 8 files per day.</p>
",1
"<p>Anyone know if R has quote-like operators like Perl's <code>qw()</code> for generating character vectors? </p>
",1
"<p>I think this is a completely unique question on Stack Overflow.  First some background:</p>

<p>I've been asked to write a new GUI on top of a calculation engine called BRCAPRO (brack-a-pro).  BRCAPRO implements a Mendelian computational model based on a piece of software called BayesMendel.  BRCAPRO calculation are used by doctors and surgeons specializing in cancer treatment to show patients:</p>

<ul>
<li>The probability of being diagnosed with cancer based on their genetics and family history.</li>
<li>The change in life expectancy based on different forms of treatment and/or the age at which these treatments are started.</li>
</ul>

<p>I've done enough research to know that the BRCAPRO formulas are far too complicated to reasonably implement in my own code.</p>

<p>There is an existing well-known (to cancer doctors) software package called CancerGene: <a href=""""http://www8.utsouthwestern.edu/utsw/cda/dept47829/files/65844.html"""" rel=""""nofollow noreferrer"""">http://www8.utsouthwestern.edu/utsw/cda/dept47829/files/65844.html</a>.  This program is very old, runs on Windows 95 and includes calculating engines for several forms of cancer my client does not work with.  Ideally my client would like his application to run on the web so that he can share information with other doctors easily.</p>

<p>My task is take the CancerGene application, which is built on the BRCAPRO engine, and:</p>

<ol>
<li>Duplicate 90% of its functionality</li>
<li>Remove unnecessary functionality</li>
<li>Modify the output of reports</li>
<li>If possible, make it web-based</li>
</ol>

<p>Now my question:</p>

<p>Does anybody have any idea how to code against BRCAPRO?  I have Googled for two days and found no API documentation or development information of any kind.  Wikipedia says that the BayesMendel modeling software is written in R, but I don't have any idea what BRCAPRO is written in.  I know absolutely nothing about R.  </p>

<p>To be clear, I don't need to modify the behavior or calculating engine of BRCAPRO.  I just need to know how to feed it input so that it returns numbers to me.</p>

<p>--  Edit to add more information --</p>

<p>I downloaded the CancerGene application in the above link and installed it.  There was a small amount of documentation, including the data format that BRCAPRO expects to receive.  Without getting into an unnecessary level of detail, BRCAPRO expects matrix-formatted data where each column represents a genetic trait and each row represents a family member.  Now I just need to know how to pass this matrix to the BRCAPRO engine once I collect it from my Web/Windows form.</p>

<p>Here's hoping there are a couple of doctor/developers here on Stack Overflow!</p>

<p>KN</p>
",1
"<p>I have binned data that looks like this:</p>

<pre><code>  (8.048,18.05] (-21.95,-11.95] (-31.95,-21.95]   (18.05,28.05] (-41.95,-31.95]
             81              76              18              18             12
    (-132,-122]     (-122,-112]     (-112,-102]     (-162,-152]  (-102,-91.95]
              6               6               6               5              5
(-91.95,-81.95]     (-192,-182]   (28.05,38.05]   (38.05,48.05]  (58.05,68.05]
              5               4               4               4              4
  (78.05,88.05]     (98.05,108]     (-562,-552]     (-512,-502]    (-482,-472]
              4               4               3               3              3
    (-452,-442]     (-412,-402]     (-282,-272]     (-152,-142]  (48.05,58.05]
              3               3               3               3              3
  (68.05,78.05]       (118,128]       (128,138]     (-582,-572]    (-552,-542]
              3               3               3               2              2
    (-532,-522]     (-422,-412]     (-392,-382]     (-362,-352]    (-262,-252]
              2               2               2               2              2
    (-252,-242]     (-142,-132] (-81.95,-71.95]       (148,158]  (-1402,-1392]
              2               2               2               2              1
  (-1372,-1362]   (-1342,-1332]     (-942,-932]     (-862,-852]    (-822,-812]
              1               1               1               1              1
    (-712,-702]     (-682,-672]     (-672,-662]     (-632,-622]    (-542,-532]
              1               1               1               1              1
    (-502,-492]     (-492,-482]     (-472,-462]     (-462,-452]    (-442,-432]
              1               1               1               1              1
    (-432,-422]     (-352,-342]     (-332,-322]     (-312,-302]    (-302,-292]
              1               1               1               1              1
    (-202,-192]     (-182,-172]     (-172,-162] (-51.95,-41.95]  (88.05,98.05]
              1               1               1               1              1
      (108,118]       (158,168]       (168,178]       (178,188]      (298,308]
              1               1               1               1              1
      (318,328]       (328,338]       (338,348]       (368,378]      (458,468]
              1               1               1               1              1
</code></pre>

<p>How can I plot this data so that the bin is sorted from most negative on the left to most positive on the right? Currently my graph looks <a href=""""http://docs.google.com/Doc?id=dcvdrfrh_5cm5qkchw"""" rel=""""nofollow noreferrer"""">like this</a>.  Notice that it is not sorted at all.  In particular the second bar (<code>value = 76</code>) is placed to the right of the first:</p>

<pre><code> (8.048,18.05] (-21.95,-11.95]
            81              76
</code></pre>

<p>This is the command I use to plot:</p>

<pre><code>barplot(x,ylab=""""Number of Unique Tags"""", xlab=""""Expected - Observed"""")
</code></pre>
",1
"<p>I am working with a survey dataset. It has two string vectors, start and finish, indicating the time of the day when the interview was started, and finished, respectively.</p>

<p>They are character strings that look like: """"9:24 am"""", """"12:35 pm"""", and so forth. i am trying to calculate the duration of the interview based on these two. what is the best way of doing this?</p>

<p>i know that, for dates, there are lots of classes or functions like <code>as.date()</code>, <code>as.Date()</code>, <code>chron()</code>, or <code>as.POSIXct()</code>. So i was looking for something like <code>as.time()</code>, but could not find it. Should I just append a made-up date and convert the whole thing into a <code>POSIX()</code> date-time class, then use <code>difftime()</code>? </p>

<p>What is the best practice of handling time in R?</p>
",1
"<p>I have 12 data frames to work with. They are similar and I have to do the same processing to each one, so I wrote a function that takes a data frame, processes it, and then returns a data frame. This works. But I am afraid that I am passing around a very big structure. I may be making temporary copies (am I?) This can't be efficient. What is the best way to avoid passing a data frame around? Thank you.</p>

<pre><code>doSomething &lt;- function(df) {
  // do something with the data frame, df
  return(df)
}
</code></pre>
",1
"<p>A friend of mine asked me if I understood the Y function. I didn't even know what it was. <code>? Y</code> did not get me anywhere.</p>

<p>What is it?</p>
",1
"<p>I have a list and I want to remove a single element from it.  How can I do this?</p>

<p>I've tried looking up what I think the obvious names for this function would be in the reference manual and I haven't found anything appropriate.</p>
",1
"<p>I have data that looks like this.
In which I want to plot accumulative value of dat1 with respect
to x-axis. Also plot it together with dat2.</p>

<pre><code>#x-axis dat1              dat2
-10     0.0140149       0.0140146
-9      0.00890835      0.00891768
-8      0.00672276      0.00672488
-7      0.00876399      0.00879401
-6      0.00806879      0.00808141
-5      0.0088366       0.00885121
-4      0.00856872      0.00857769
-3      0.0195384       0.0196094
-2      0.0160239       0.0161829
-1      0.0254455       0.0257845
0       0.0397413       0.0400913
1       0.0743316       0.0755453
2       0.0247501       0.0253324
3       0.0214285       0.021778
4       0.0241462       0.0244967
5       0.0150943       0.015241
6       0.0141398       0.0142373
7       0.0101515       0.0102948
8       0.0308843       0.031294
9       0.0095504       0.00960626
10      0.00729676      0.0073713
</code></pre>

<p>What's the common way to do it in R?</p>

<p>I looked at ECDF from Hmisc, it doesn't seem to do what I want.
In particular it doesn't allow us to give x-axis value.</p>
",1
"<p>I've really been struggling to make SQL Server into something that, quite frankly, it will never be. I need a database engine for my analytical work. The DB needs to be fast and does NOT need all the logging and other overhead found in typical databases (SQL Server, Oracle, DB2, etc.) </p>

<p>Yesterday I listened to <a href=""""http://itc.conversationsnetwork.org/shows/detail4009.html"""" rel=""""noreferrer"""">Michael Stonebraker speak at the Money:Tech conference</a> and I kept thinking, """"I'm not really crazy. There IS a better way!"""" He talks about using <a href=""""http://en.wikipedia.org/wiki/Column-oriented_DBMS"""" rel=""""noreferrer"""">column stores</a> instead of row oriented databases. I went to the Wikipedia page for <a href=""""http://en.wikipedia.org/wiki/Column-oriented_DBMS"""" rel=""""noreferrer"""">column stores</a> and I see a few open source projects (which I like) and a few commercial/open source projects (which I don't fully understand). </p>

<p>My question is this: In an applied analytical environment, how do the different column based DB's differ? How should I be thinking about them? Anyone have practical experience with multiple column based systems? Can I leverage my SQL experience with these DBs or am I going to have to learn a new language?</p>

<p>I am ultimately going to be pulling data into R for analysis. </p>

<p><strong>EDIT:</strong> I was requested for some clarification in what exactly I am trying to do. So, here's an example of what I would like to do:
Create a table that has 4 million rows and 20 columns (5 dims, 15 facts). Create 5 aggregation tables that calculate max, min, and average for each of the facts. Join those 5 aggregations back to the starting table. Now calculate the percent deviation from mean, percent deviation of min, and percent deviation from max for each row and add it to the original table. This table data does not get new rows each day, it gets TOTALLY replaced and the process is repeated. Heaven forbid if the process must be stopped. And the logs... ohhhhh the logs! :)</p>
",1
"<p>How expensive is it to compute the eigenvalues of a matrix? </p>

<p>What is the complexity of the best algorithms? </p>

<p>How long might it take in practice if I have a 1000 x 1000 matrix? I assume it helps if the matrix is sparse?</p>

<p>Are there any cases where the eigenvalue computation would not terminate? </p>

<p>In <code>R</code>, I can compute the eigenvalues as in the following toy example:</p>

<pre><code>m&lt;-matrix( c(13,2, 5,4), ncol=2, nrow=2 )
eigen(m, only.values=1)
$values
[1] 14  3
</code></pre>

<p>Does anyone know what algorithm it uses? </p>

<p>Are there any other (open-source) packages that compute the eigenvalue?</p>
",1
"<p>I generated <a href=""""http://farm4.static.flickr.com/3622/3411762935_b9429d9d68_o.png"""" rel=""""nofollow noreferrer"""">this dendrogram</a> using R's <code>hclust()</code>, <code>as.dendrogram()</code> and <code>plot.dendrogram()</code> functions.</p>

<p>I used the <code>dendrapply()</code> function and a local function to color leaves, which is working fine.</p>

<p>I have results from a statistical test that indicate if a set of nodes (<em>e.g.</em> the cluster of """"<code>_+v\_stat5a\_01_</code>"""" and """"<code>_+v\_stat5b\_01_</code>"""" in the lower-right corner of the tree) are significant or important.</p>

<p>I also have a local function that I can use with <code>dendrapply()</code> that finds the exact node in my dendrogram which contains significant leaves.</p>

<p>I would like to either (following the example):</p>

<ol>
<li>Color the edges that join """"<code>_+v\_stat5a\_01_</code>"""" and """"<code>_+v\_stat5b\_01_</code>""""; or,</li>
<li>Draw a <code>rect()</code> around """"<code>_+v\_stat5a\_01_</code>"""" and """"<code>_+v\_stat5b\_01_</code>""""</li>
</ol>

<p>I have the following local function (the details of the """"nodes-in-leafList-match-nodes-in-clusterList"""" condition aren't important, but that it highlights significant nodes):</p>

<pre><code>markSignificantClusters &lt;&lt;- function (n) {
  if (!is.leaf(n)) {
     a &lt;- attributes(n)
     leafList &lt;- unlist(dendrapply(n, listLabels))
     for (clusterIndex in 1:length(significantClustersList[[1]])) {
       clusterList &lt;- unlist(significantClustersList[[1]][clusterIndex])
       if (nodes-in-leafList-match-nodes-in-clusterList) {
          # I now have a node """"n"""" that contains significant leaves, and
          # I'd like to use a dendrapply() call to another local function
          # which colors the edges that run down to the leaves; or, draw
          # a rect() around the leaves
       }
     }
  }
}
</code></pre>

<p>From within this <code>if</code> block, I have tried calling <code>dendrapply(n, markEdges)</code>, but this did not work:</p>

<pre><code>markEdges &lt;&lt;- function (n) {
  a &lt;- attributes(n)
  attr(n, """"edgePar"""") &lt;- c(a$edgePar, list(lty=3, col=""""red""""))
}
</code></pre>

<p>In my ideal example, the edges connecting """"<code>_+v\_stat5a\_01_</code>"""" and """"<code>_+v\_stat5b\_01_</code>"""" would be dashed and of a red color.</p>

<p>I have also tried using <code>rect.hclust()</code> within this <code>if</code> block:</p>

<pre><code>ma &lt;- match(leafList, orderedLabels)  
rect.hclust(scoreClusterObj, h = a$height, x = c(min(ma), max(ma)), border = 2)
</code></pre>

<p>But the result does not work with horizontal dendrograms (<em>i.e.</em> dendrograms with horizontal labels). <a href=""""http://farm4.static.flickr.com/3331/3410126060_f8f06c4498_o.png"""" rel=""""nofollow noreferrer"""">Here is an example</a> (note the red stripe in the lower-right corner). Something is not correct about the dimensions of what <code>rect.hclust()</code> generates, and I don't know how it works, to be able to write my own version.</p>

<p>I appreciate any advice for getting <code>edgePar</code> or <code>rect.hclust()</code> to work properly, or to be able to write my own <code>rect.hclust()</code> equivalent.</p>

<p><strong>UPDATE</strong></p>

<p>Since asking this question, I used <code>getAnywhere(rect.hclust())</code> to get the functional code that calculates parameters and draws the <code>rect</code> object. I wrote a custom version of this function to handle horizontal and vertical leaves, and call it with <code>dendrapply()</code>.</p>

<p>However, there is some kind of clipping effect that removes part of the <code>rect</code>. For horizontal leaves (leaves that are drawn on the right side of the tree), the rightmost edge of the <code>rect</code> either disappears or is thinner than the border width of the other three sides of the <code>rect</code>. For vertical leaves (leaves that are drawn on the bottom of the tree), the bottommost edge of the <code>rect</code> suffers the same display problem.</p>

<p>What I had done as a means of marking significant clusters is to reduce the width of the <code>rect</code> such that I render a vertical red stripe between the tips of the cluster edges and the (horizontal) leaf labels. </p>

<p>This eliminates the clipping issue, but introduces another problem, in that the space between the cluster edge tips and the leaf labels is only six or so pixels wide, which I don't have much control over. This limits the width of the vertical stripe. </p>

<p>The worse problem is that the <code>x</code>-coordinate that marks where the vertical stripe can fit between the two elements will change based on the width of the larger tree (<code>par[""""usr""""]</code>), which in turn depends on how the tree hierarchy ends up being structured.</p>

<p>I wrote a """"correction"""" or, better termed, a hack to adjust this <code>x</code> value and the <code>rect</code> width for horizontal trees. It doesn't always work consistently, but for the trees I am making, it seems to keep from getting too close to (or overlapping) edges and labels.</p>

<p>Ultimately, a better fix would be to find out how to draw the <code>rect</code> so that there is no clipping. Or a consistent way to calculate the specific <code>x</code> position in between tree edges and labels for any given tree, so as to center and size the stripe properly.</p>

<p>I would also be very interested in a method for annotating edges with colors or line styles.</p>
",1
"<p>I am trying to use the random forests package for classification in R.</p>

<p>The Variable Importance Measures listed are:</p>

<ul>
<li>mean raw importance score of variable x for class 0</li>
<li>mean raw importance score of variable x for class 1</li>
<li><code>MeanDecreaseAccuracy</code></li>
<li><code>MeanDecreaseGini</code></li>
</ul>

<p>Now I know what these """"mean"""" as in I know their definitions.  What I want to know is how to use them.</p>

<p>What I really want to know is what these values mean in only the context of how accurate they are, what is a good value, what is a bad value, what are the maximums and minimums, etc.</p>

<p>If a variable has a high <code>MeanDecreaseAccuracy</code> or <code>MeanDecreaseGini</code> does that mean it is important or unimportant?  Also any information on raw scores could be useful too.
I want to know everything there is to know about these numbers that is relevant to the application of them.  </p>

<p>An explanation that uses the words 'error', 'summation', or 'permutated' would be less helpful then a simpler explanation that didn't involve any discussion of how random forests works.</p>

<p>Like if I wanted someone to explain to me how to use a radio, I wouldn't expect the explanation to involve how a radio converts radio waves into sound.</p>
",1
"<p>In <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a> is there any way to produce plots which have no title and which use the space the title would otherwise have taken up?</p>

<p>In <code>plot()</code>, <code>main</code>, <code>sub</code>, <code>xlab</code>, and <code>ylab</code> all default to <code>NULL</code>, but this just leaves blank space where they would have been, ditto for setting them to ''.  It would be nice if not including them meant that the entire plot space was utilized rather than leaving extra empty space on the edges.  This is all especially relevant in printing plots to file devices like <code>pdf()</code>, <code>png()</code>, etc.</p>
",1
"<p>Given the following matrix lets assume I want to find the maximum value in column two:</p>

<pre><code>mat &lt;- matrix(c(1:3,7:9,4:6), byrow = T, nc = 3)
mat
     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    7    8    9
[3,]    4    5    6
</code></pre>

<p>I know <code>max(mat[,2])</code> will return 8. How can I return the row index, in this case row two?</p>
",1
"<p>I'm trying to use R to calculate the moving average over a series of values in a matrix. The normal R mailing list search hasn't been very helpful though. There doesn't seem to be a <a href=""""http://www.statmethods.net/management/functions.html"""" rel=""""noreferrer"""">built-in function</a> in R will allow me to calculate moving averages. Do any packages provide one? Or do I need to write my own?</p>
",1
"<p>I have a number of bash scripts which invoke R scripts for plotting things.  Something like:  </p>

<pre><code>#!/bin/bash
R --vanilla --slave &lt;&lt;RSCRIPT
cat(""""Plotting $1 to $2\n"""")
input &lt;- read.table(""""$1"""")
png(""""$2"""")
plot(as.numeric(input[1,]))
dev.off()
RSCRIPT
</code></pre>

<p>The problem is that despite <code>--slave</code>, the call to <code>dev.off()</code> prints the message <code>null device 1</code>.  Once there are a lot of plots being done, or for more complex scripts which plot to a number of files, this gets to be a real hassle.</p>

<p>Is there some way to suppress this message?</p>
",1
"<p>It's very convenient to have R scripts for doing simple plots from the command line.  However, running R from bash scripts is not convenient at all.  The ideal might be something like</p>

<pre><code>#!/path/to/R
...
</code></pre>

<p>or</p>

<pre><code>#!/usr/bin/env R
...
</code></pre>

<p>but I haven't been able to make either of those work.</p>

<p>Another option is keeping the scripts purely in R, e.g. <code>script.R</code>, and invoking it with <code>R --file=script.R</code> or similar.  However, occasionally a script will rely on obscure command line switches at which point part of the code exists outside the script.  Example: sneaking things into R from bash via a local .Rprofile, the desired switches are then everything <code>--vanilla</code> implies except <code>--no-init-file</code>.</p>

<p>Another option is a bash script to store the R flags and be painlessly executable, which then calls the R script.  The problem is that this means a single program just got split into two files which now have to be keep in sync, transferred to new machines together, etc.</p>

<p>The option I currently despise least is embedding the R in a bash script:</p>

<pre><code>#!/bin/bash
... # usage message to catch bad input without invoking R
... # any bash pre-processing of input
... # etc
R --random-flags &lt;&lt;RSCRIPT
# R code goes here
RSCRIPT
</code></pre>

<p>Everything's in a single file.  It's executable and easily handles arguments.  The problem is that combining bash and R like this pretty much eliminates the possibility of any IDE not failing on one or the other, and makes my heart hurt real bad.</p>

<p>Is there some better way I'm missing?</p>
",1
"<p>I've been trying to learn more about R (and writing C extensions) and I thought it might help to read the source for some well known packages.  I decided to start with rpart which is defined as:</p>

<pre><code>rpart &lt;- function(formula, data, weights, subset,
       na.action=na.rpart, method, model=FALSE, x=FALSE, y=TRUE,
       parms, control, cost, ...)
</code></pre>

<p>I did a quick search through the source and I don't see formula mentioned anywhere in the function body yet I know that somehow rpart is using that parameter.  How is it that rpart is using formula without its name being in the function body?</p>
",1
"<p>I am using the Emacs-Speaks-Statistics (ESS) mode for Emacs.  When editing R code, any comment lines (those starting with #) automatically get tabbed to the far right when I create a new line above it.  How should I change my .emacs.el file to fix this?</p>

<p>For example, I have:</p>

<pre><code># Comment
</code></pre>

<p>Now, after putting my cursor at the beginning of the line and pressing Enter, I get:</p>

<pre><code>                                # Comment
</code></pre>

<p>Thanks for any hints.</p>
",1
"<p>From the question you can probably tell that I don't know much about code! My question is this:</p>

<p>What does this code mean?</p>

<pre><code>mnlong &lt;- 280.460 + .9856474 * time
mnlong &lt;- mnlong %% 360
mnlong[mnlong &lt; 0] &lt;- mnlong[mnlong &lt; 0] + 360
</code></pre>

<p>I understand that the <code>mnlong</code> and <code>time</code> are variables but the <code>%%</code> confuses me.</p>

<p>Could someone give me a basic description?</p>
",1
"<p>When R creates PDFs using pdf() it includes a CreationDate and a ModDate in the PDF.  I have a number of such generated PDFs in an svn repository and the effect is that when figures are remade by R, even with the same data, they appear as modified (rightly so) to svn.  What's the best way to get the two to play nicely together?</p>

<p>I could simply remove those lines from the PDFs outside of R, but this extra step is undesirable.<br>
I could set the system time to some fixed value as part of the running the scripts, but this is even less desirable.<br>
I could probably even convince svn to use a specialized diff which ignored changes on those lines, but that sounds like more trouble than it's worth.</p>

<p>A very pleasant solution would be if there were a way to prevent R putting those lines in the PDF file in the first place.  I have a file system to tell me when files were created and modified thank-you-very-much, I don't need that info stored within the file as well.</p>
",1
"<p>In R (or S-PLUS), what is a good way to aggregate String data in a data frame?</p>

<p>Consider the following:</p>

<pre><code>myList &lt;- as.data.frame(c(""""Bob"""", """"Mary"""", """"Bob"""", """"Bob"""", """"Joe""""))
</code></pre>

<p>I would like the output to be:</p>

<pre><code> [Bob,  3
  Mary, 1
  Joe,  1]
</code></pre>

<p>Currently, the only way I know how to do this is with the summary function.</p>

<pre><code>&gt; summary(as.data.frame(myList))

 Bob :3                                
 Joe :1                                
 Mary:1      
</code></pre>

<p>This feels like a hack. Can anyone suggest a better way?</p>
",1
"<p>I have a comma separated file named <code>foo.csv</code> containing the following data:</p>

<pre><code>scale, serial, spawn, for, worker
5, 0.000178, 0.000288, 0.000292, 0.000300
10, 0.156986, 0.297926, 0.064509, 0.066297
12, 2.658998, 6.059502, 0.912733, 0.923606
15, 188.023411, 719.463264, 164.111459, 161.687982
</code></pre>

<p>I essentially have two questions:</p>

<p>1) How do I plot the first column (x-axis) versus the second column (y-axis)? I'm trying this (from reading <a href=""""http://www.ats.ucla.edu/stat/R/gbe/scatter.htm"""" rel=""""noreferrer"""">this site</a>):</p>

<pre><code>data &lt;- read.table(""""foo.csv"""", header=T,sep="""","""")
attach(data)
scale &lt;- data[1]
serial &lt;- data[2]
plot(scale,serial)
</code></pre>

<p>But I get this error back:</p>

<pre><code>Error in stripchart.default(x1, ...) : invalid plotting method
</code></pre>

<p>Any idea what I'm doing wrong? A <a href=""""http://www.nabble.com/Problems-producing-a-simple-plot-td23347296.html"""" rel=""""noreferrer"""">quick Google search</a> reveals someone else with the same problem but no relevant answer. UPDATE: It turns out it works fine if I skip the two assignment statements in the middle. Any idea why this is?</p>

<p>The second question follows pretty easily after the first:</p>

<p>2) How do I plot the first column (x-axis) versus all the other columns on the y-axis? I presume it's pretty easy once I get around the first problem I'm running into, but am just a bit new to R so I'm still wrapping my head around it.</p>
",1
"<p>I'm working in R, and I'd like to define some variables that I (or one of my collaborators) cannot change. In C++ I'd do this:</p>

<pre><code>const std::string path( """"/projects/current"""" );
</code></pre>

<p>How do I do this in the R programming language?</p>

<p>Edit for clarity: I know that I can define strings like this in R:</p>

<pre><code>path = """"/projects/current""""
</code></pre>

<p>What I really want is a language construct that guarantees that nobody can ever change the value associated with the variable named """"path.""""</p>

<p>Edit to respond to comments:</p>

<p>It's technically true that const is a compile-time guarantee, but it would be valid in my mind that the R interpreter would throw stop execution with an error message. For example, look what happens when you try to assign values to a numeric constant:</p>

<pre><code>&gt; 7 = 3
Error in 7 = 3 : invalid (do_set) left-hand side to assignment
</code></pre>

<p>So what I really want is a language feature that allows you to assign values once and only once, and there should be some kind of error when you try to assign a new value to a variabled declared as const. I don't care if the error occurs at run-time, especially if there's no compilation phase. This might not technically be const by the Wikipedia definition, but it's very close. It also looks like this is not possible in the R programming language.</p>
",1
"<p>I'm creating a package that is going to be used by R (the statistical program), I'm not an expert using this application but I have managed to create a very simple package, using the following logic, I have some classes in C++, as the code has to be compiled using the R compiler and it only allows C code, I have a wrapper C code that call the C++ methods, and later I have an R script that call the methods exposed by the C code, so basically is a communication like R &lt;-> C&lt;->C++.</p>

<p>The full tutorial that I used to create this package is found <a href=""""http://www.stat.columbia.edu/~gelman/stuff_for_blog/AlanRPackageTutorial.pdf"""" rel=""""nofollow noreferrer"""">here</a>, I add it as a reference.</p>

<p>Now my problem is that I need to add some functionality to the package that I already created, what I need to do is to add code for late binding to a COM object which is another product that I created and that is registered using regasm tool.</p>

<p>This is the c++ code that I'm using to try to late bind to the COM object, I'm trying to use IDispatch to do so:</p>

<pre><code>{
...
CLSID clsid;    
HRESULT hr = CLSIDFromProgID((WCHAR*)""""My Com object ProgId"""", &clsid);
if(FAILED(hr))                      
  return;   
...     
}
</code></pre>

<p>I didn't paste the whole code because only with these lines the compiler is giving me troubles already, the command I use to compile is </p>

<pre><code>R CMD SHLIB Cclass.cc C++class.cc</code></pre>

<p>Where """"Cclass.cc"""" has the C code that call the c++ methods and """"C++class.cc"""" is actually the C++ code.</p>

<p>When I compile these classes the compiler says <pre><code>""""undefined reference to `CLSIDFromProgID@8'collect2: ld returned 1 exit status""""</pre></code></p>

<p>I""""m sure I have added all the header files that I need, that's why I believe my problem is that I'm not including ole32.lib and oleaut32.lib which are static libraries.</p>

<p>So, my question is, how can I include this libraries in order to be able to use the methods for late binding, like CLSIDFromProgID(...) or QueryInterface(...). Also if anyone believes that my problem is not linking this libraries, but something else, it would be great if can point me to which my problem may be.</p>

<p>Also have in mind that I need to link with those statics libraries in a way that they can be compiled without problem by the R compiler, which if I'm not wrong is a merely c compiler.</p>
",1
"<p>In R, is it possible to extract group capture from a regular expression match?  As far as I can tell, none of <code>grep</code>, <code>grepl</code>, <code>regexpr</code>, <code>gregexpr</code>, <code>sub</code>, or <code>gsub</code> return the group captures.</p>

<p>I need to extract key-value pairs from strings that are encoded thus:</p>

<pre><code>\((.*?) :: (0\.[0-9]+)\)
</code></pre>

<p>I can always just do multiple full-match greps, or do some outside (non-R) processing, but I was hoping I can do it all within R.  Is there's a function or a package that provides such a function to do this?</p>
",1
"<p>I've got about 100M value/count pairs in a text file on my Linux machine.  I'd like to figure out what sort of formula I would use to generate more pairs that follow the same distribution.  </p>

<p>From a casual inspection, it looks power law-ish, but I need to be a bit more rigorous than that.  Can R do this easily?  If so, how?  Is there something else that works better?</p>
",1
"<p>I was reading about the <a href=""""http://en.wikipedia.org/wiki/Slope_One#Slope_one_collaborative_filtering_for_rated_resources"""" rel=""""nofollow noreferrer"""">Weighted slope one algorithm</a> ( and more
formally <a href=""""http://www.daniel-lemire.com/fr/documents/publications/lemiremaclachlan_sdm05.pdf"""" rel=""""nofollow noreferrer"""">here (PDF)</a>) which is supposed to take item ratings from different users and, given a user vector containing at least 1 rating and 1 missing value, predict the missing ratings.</p>

<p>I found a <a href=""""http://www.serpentine.com/wordpress/wp-content/uploads/2006/12/slope_one.py.txt"""" rel=""""nofollow noreferrer"""">Python implementation of the algorithm</a>, but I'm having a hard time porting it to <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a> (which I'm more comfortable with). Below is my attempt. Any suggestions on how to make it work?</p>

<p>Thanks in advance, folks.</p>

<pre><code># take a 'training' set, tr.set and a vector with some missing ratings, d
pred=function(tr.set,d) {
    tr.set=rbind(tr.set,d)
    n.items=ncol(tr.set)

    # tally frequencies to use as weights
    freqs=sapply(1:n.items, function(i) {
        unlist(lapply(1:n.items, function(j) {
            sum(!(i==j)&amp;!is.na(tr.set[,i])&amp;!is.na(tr.set[,j])) })) })

    # estimate product-by-product mean differences in ratings
    diffs=array(NA, dim=c(n.items,n.items))
    diffs=sapply(1:n.items, function(i) {
        unlist(lapply(1:n.items, function(j) {
            diffs[j,i]=mean(tr.set[,i]-tr.set[,j],na.rm=T) })) })

    # create an output vector with NAs for all the items the user has already rated
    pred.out=as.numeric(is.na(d))
    pred.out[!is.na(d)]=NA

    a=which(!is.na(pred.out))
    b=which(is.na(pred.out))

    # calculated the weighted slope one estimate
    pred.out[a]=sapply(a, function(i) {
        sum(unlist(lapply(b,function (j) {
            sum((d[j]+diffs[j,i])*freqs[j,i])/rowSums(freqs)[i] }))) })

    names(pred.out)=colnames(tr.set)
    return(pred.out) }
# end function

# test, using example from [3]
alice=c(squid=1.0, octopus=0.2, cuttlefish=0.5, nautilus=NA)
bob=c(squid=1.0, octopus=0.5, cuttlefish=NA, nautilus=0.2)
carole=c(squid=0.2, octopus=1.0, cuttlefish=0.4, nautilus=0.4)
dave=c(squid=NA, octopus=0.4, cuttlefish=0.9, nautilus=0.5)
tr.set2=rbind(alice,bob,carole,dave)
lucy2=c(squid=0.4, octopus=NA, cuttlefish=NA, nautilus=NA)
pred(tr.set2,lucy2)
# not correct
# correct(?): {'nautilus': 0.10, 'octopus': 0.23, 'cuttlefish': 0.25}
</code></pre>
",1
"<p>I have a function in R that I call multiple times. I want to keep track of the number of times that I've called it and use that to make decisions on what to do inside of the function. Here's what I have right now:</p>

<pre><code>f = function( x ) {
   count &lt;&lt;- count + 1
   return( mean(x) )
}

count = 1
numbers = rnorm( n = 100, mean = 0, sd = 1 )
for ( x in seq(1,100) ) {
   mean = f( numbers )
   print( count )
}
</code></pre>

<p>I don't like that I have to declare the variable count outside the scope of the function. In C or C++ I could just make a static variable. Can I do a similar thing in the R programming language?</p>
",1
"<p>I was wondering if it was possible to graph three lines in R using functions. For instance, how could I get the functions:</p>

<pre><code>3x+1 
4x+2
x+1 
</code></pre>

<p>to show up on the same graph in r?</p>
",1
"<p>I have installed R-2.9.1 and I am using Emacs+ESS. When I start an R process, though, the version of R that gets used by Emacs is 2.6.  I thought maybe Emacs was running R from a weird starting directory.  However, if I select my home directory ESS still starts R 2.6. (Running R at the terminal correctly brings up version 2.9.1.)</p>

<p>How do I add a new ESS process, or change the properties of the current R process, so that I can run my newer version of R?</p>
",1
"<p>I have two variables, <code>key</code> and <code>value</code>, and I want to add them as a key/value pair to a list:</p>

<pre><code>key = """"width""""
value = 32

mylist = list()
mylist$key = value
</code></pre>

<p>The result is this:</p>

<pre><code>mylist
# $key
# [1] 32
</code></pre>

<p>But I would like this instead:</p>

<pre><code>mylist
# $width
# [1] 32
</code></pre>

<p>How can I do this?</p>
",1
"<p>Is there any usable emacs mode for <code>Rscript</code>? </p>

<p>(<code>Rscript</code> is the script front-end for the <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a> language.)</p>

<p>If I type this:</p>

<pre><code>#!/usr/bin/Rscript
print(commandArgs(TRUE))
</code></pre>

<p>and do <code>indent</code> in the <a href=""""http://ess.r-project.org/"""" rel=""""nofollow noreferrer"""">ESS</a> R-mode it indents the first line like crazy, since it sees it as a comment:</p>

<pre><code>                          #!/usr/bin/Rscript
print(commandArgs(TRUE))
</code></pre>
",1
"<p>How do you print to <code>stderr</code> in <code>R</code>?</p>

<p>This would especially useful for scripts written in <code>Rscript</code>.</p>
",1
"<p>Is there a package to process command-line options in R? </p>

<p>I know <code>commandArgs</code>, but it's too basic. Its result is basically the equivalent to <code>argc</code> and <code>argv</code> in <code>C</code>, but I'd need something on top of that, just like <code>boost::program_options</code> in <code>C++</code>, or <code>GetOptions::Long</code> in <code>perl</code>.</p>

<p>In particular, I'd like to specify in advance what options are allowed and give an error message if the user specifies something else. </p>

<p>The call would be like this (with user options --width=32 --file=foo.txt):</p>

<pre><code>R --vanilla --args --width=32 --file=foo.txt &lt; myscript.R
</code></pre>

<p>or, if <code>Rscript</code> is used:</p>

<pre><code>myscript.R --width=32 --file=foo.txt 
</code></pre>

<p>(Please don't say, """"why don't you write it yourself, it's not that hard"""". In other languages you don't have to write it yourself either. :)</p>
",1
"<p>I have a data.frame with 2 columns: Node A, Node B. Each entry in the frame implies an edge in a graph between node A and B. </p>

<p>There must be a nice one-liner to convert this data.frame into an adjacency list. Any hints?</p>
",1
"<p>I was trying to create a graph in R Plot and was just wondering if there was any way to move the side header label closer to the graph.</p>

<p>I've made the font smaller and put the label into two lines, but when I put it into two lines the top line falls off the screen and the bottom line is rather far away from the numbered Y-Axis of the graph.  Is there anyway to move the label closer to the y-axis so the whole thing is visible?</p>
",1
"<p>I wrote some code in school to basically bring up different graphs from R and I had wanted to use it on a Mac computer.  </p>

<p>Is there are way to use R terminal commands on a Mac computer and is there a place where I could get more information about these Mac R Terminal commands? Thanks so much!</p>
",1
"<p>I am building an application that I want to have extended with modules that does some nr crunching and I would like to have R for that. What are my best options for extending my Java application with R?</p>
",1
"<p>I have an SVM in R and I would now like to plot the classification space for this machine. I have found some examples on the Internet, but I can't seem to make sense of them.</p>

<p>My R script is as follows:</p>

<pre><code>library(e1071)
day_of_week &lt;- c(0,1,2,3,4,5,6)
holiday &lt;- factor( c(T, F, F, F, F, F, T) )
model &lt;- svm(day_of_week, holiday)
plot(model, day_of_week, holiday)
</code></pre>

<p>I cannot get the plot command to work. I would like a graph something like this <a href=""""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/e1071/man/images/plot.svm_001.png"""" rel=""""noreferrer"""">http://bm2.genes.nig.ac.jp/RGM2/R_current/library/e1071/man/images/plot.svm_001.png</a> </p>
",1
"<p>I was just wondering if there is a way to get rid of axis values, either the x-axis or y-axis respectively, in an r-plot graph. I know that axes = false will get rid of the entire axis, but I would only like to get rid of the numbering.  Thanks so much!                 </p>
",1
"<p>I have a histogram with several hundred items, for which I do a Q-Q plot. This results in EPS that is 2.5 megabytes large. This is too much for a figure that is only going to be included in a publication and is not going to be viewed at 100x magnification.</p>

<p>Is there any option in R to somehow output smaller EPS? I have searched docs to no avail. Or is my best option to, say, rasterize it afterwards at 300 dpi? If that's the case, any recommendations for the tool for this job?</p>

<p>The R code for the plot is nothing fancy:</p>

<pre><code>postscript(filename)
qqnorm(n, main=title))
qqline(n)
dev.off()
</code></pre>

<p>Thanks.</p>

<p>EDIT: Doh! My question mentioned outputting EPS, and then converting it to some raster format. When of course I could just generate PNG in the first place from R. Thanks for all the answers.</p>
",1
"<p>Assume I have huge huge data and no money for hardware for more RAM for R AND software like Windows or any non open source</p>

<p>. Just an internet connection. and an university Amazon ec2 account.</p>

<p>Could you please guide me to a step by step- copy and paste coding tutorial on building a model using any Package on Amazon ec2.</p>

<p>Note- I know BIOCEP can do this, and Robert Grossman gave a tutorial on using R on Amazon Ec2. I just need a tutorial that say uses a R GUI like Rattle to build model on Amazon Ec2.</p>

<p>Assume I am a statistican with no knowledge of Amazon ec2 or using R there</p>
",1
"<p>There are at least two sparse matrix packages for R.  I'm looking into these because I'm working with datasets that are too big and sparse to fit in memory with a dense representation.  I want basic linear algebra routines, plus the ability to easily write C code to operate on them.  Which library is the most mature and best to use?</p>

<p>So far I've found</p>

<ul>
<li><a href=""""http://cran.r-project.org/web/packages/Matrix"""" rel=""""noreferrer"""">Matrix</a> which has many reverse dependencies, implying it's the most used one.</li>
<li><a href=""""http://cran.r-project.org/web/packages/SparseM/index.html"""" rel=""""noreferrer"""">SparseM</a> which doesn't have as many reverse deps.</li>
<li>Various graph libraries probably have their own (implicit) versions of this; e.g. <a href=""""http://cran.r-project.org/web/packages/igraph/index.html"""" rel=""""noreferrer"""">igraph</a> and <a href=""""http://cran.r-project.org/web/packages/network/index.html"""" rel=""""noreferrer"""">network</a> (the latter is part of <a href=""""http://statnetproject.org/"""" rel=""""noreferrer"""">statnet</a>).  These are too specialized for my needs.</li>
</ul>

<p>Anyone have experience with this?</p>

<p>From searching around <a href=""""http://rseek.org"""" rel=""""noreferrer"""">RSeek.org</a> a little bit, the <a href=""""http://cran.r-project.org/web/packages/Matrix"""" rel=""""noreferrer"""">Matrix</a> package seems the most commonly mentioned one.  I often think of <a href=""""http://cran.r-project.org/web/views/"""" rel=""""noreferrer"""">CRAN Task Views</a> as fairly authoritative, and the <a href=""""http://cran.r-project.org/web/views/Multivariate.html"""" rel=""""noreferrer"""">Multivariate Task View</a> mentions Matrix and SparseM.</p>
",1
"<p>In R, how do you test a vector to see if it contains a given element?</p>
",1
"<p>I understand that some databases have native support in R (e.g. MySQL) but you can connect to other DBs like MS SQL Server using RODBC. How much speed improvement does one gain for reading/writing with the native drivers vs. RODBC? What other DBs have native drivers in R? Is reading faster or slower than writing generally?</p>
",1
"<p>After creating large objects and running out of RAM, I will try and delete the objects in my current environment using</p>

<pre><code>rm(list=ls())
</code></pre>

<p>When I check my RAM usage, nothing has changed.  Even after calling <code>gc()</code> nothing has changed.  I can only replenish my RAM by quitting R.</p>

<p>Anybody have advice for dealing with memory-intensive objects within R?</p>
",1
"<p>What's the most efficient way to create a moving average or rolling sum in R? How do you do the rolling function along with a """"group by""""?</p>
",1
"<p>Suppose I have the following vector:</p>

<pre><code>&gt; x &lt;- sample(1:10,20,replace=TRUE)
&gt; x
 [1]  8  6  9  9  7  3  2  5  5  1  6  8  5  2  9  3  5 10  8  2
</code></pre>

<p>How can I find which elements are either 8 or 9?</p>
",1
"<p>I have a data frame detailing edge weights among N nodes.  Is there a package for working with this sort of data?</p>

<p>For example, I would like to plot the following information as a network:</p>

<pre><code>  p1 p2 counts
1  a  b    100
2  a  c    200
3  a  d    100
4  b  c     80
5  b  d     90
6  b  e    100
7  c  d    100
8  c  e     40
9  d  e     60
</code></pre>
",1
"<p>R provides two different methods for accessing the elements of a list or data.frame- the <code>[]</code> and <code>[[]]</code> operators.</p>

<p>What is the difference between the two? In what situations should I use one over the other?</p>
",1
"<p>I often write functions that need to see other objects in my environment.  For example:</p>

<pre><code>&gt; a &lt;- 3
&gt; b &lt;- 3
&gt; x &lt;- 1:5
&gt; fn1 &lt;- function(x,a,b) a+b+x
&gt; fn2 &lt;- function(x) a+b+x
&gt; fn1(x,a,b)
[1]  7  8  9 10 11
&gt; fn2(x)
[1]  7  8  9 10 11
</code></pre>

<p>As expected, both these functions are identical because <code>fn2</code> can """"see"""" a and b when it executes.  But whenever I start to take advantage of this, within about 30 minutes I end up calling the function without one of the necessary variables (e.g. a or b).  If I don't take advantage of this, then I feel like I am passing around objects unnecessarily.</p>

<p>Is it better to be explicit about what a function requires?  Or should this be taken care of via inline comments or other documentation of the function?  Is there a better way?</p>
",1
"<p>I want to do a linear regression in R using the <code>lm()</code> function. My data is an annual time series with one field for year (22 years) and another for state (50 states). I want to fit a regression for each state so that at the end I have a vector of lm responses. I can imagine doing for loop for each state then doing the regression inside the loop and adding the results of each regression to a vector. That does not seem very R-like, however. In SAS I would do a 'by' statement and in SQL I would do a 'group by'. What's the R way of doing this?</p>
",1
"<p>I am used to writing data manipulation logic in SQL and now that I am learning R I find myself sometimes just wanting to do something that would be simple in SQL but I have to learn a bunch of stuff with R to do the same manipulation on an R data frame. Is there a simple work around? </p>
",1
"<p>Suppose I want perform a simulation using the following function:</p>

<pre><code>fn1 &lt;- function(N) {
  res &lt;- c()
  for (i in 1:N) {
    x &lt;- rnorm(2)
    res &lt;- c(res,x[2]-x[1])
  }
  res
}
</code></pre>

<p>For very large <code>N</code>, computation appears to hang.  Are there better ways of doing this?</p>

<p>(Inspired by: <a href=""""https://stat.ethz.ch/pipermail/r-help/2008-February/155591.html"""" rel=""""noreferrer"""">https://stat.ethz.ch/pipermail/r-help/2008-February/155591.html</a>)</p>
",1
"<p>This may seem menial, but it affects my productivity. I am using R in terminal mode on Linux. Unlike the Windows IDE, Linux limits the number of columns to 80, thus making harder the inspection of data sets. Is there a way to set the max number of columns?</p>
",1
"<p>How do you pause an R script for a specified number of seconds or miliseconds? In many languages, there is a <code>sleep</code> function, but <code>?sleep</code> references a data set. And <code>?pause</code> and <code>?wait</code> don't exist.</p>

<p>The intended purpose is for self-timed animations. The desired solution works without asking for user input.</p>
",1
"<p>I am creating an R package that I intend to submit to CRAN that has a function calling a routine written in C.  How do I load the compiled C routine in the R function in platform-independent way?  I am able to make my package work on my intel-based Mac with:</p>

<pre><code>function(mydata)
{
dyn.load(file.path(.Library,""""mypkg/libs/i386"""",paste(""""mypkg"""", .Platform$dynlib.ext, sep=""""""""))) 
try(
    output &lt;- .C(""""myfunc_cversion"""",
                 in_data    = as.double(mydata),
                 res_data   = as.double(res),
                 PACKAGE    = """"mypkg"""")
    )
    result &lt;- as.matrix(output$res_data)
    return(result)
}
</code></pre>

<p>The problem is the call to dyn.load where I cannot figure out how to specify the full path to the shared library for my installed package in a portable way.</p>

<p>Is there another variable in R besides .Library that I should use, or is there a better function than dyn.load for this case?</p>
",1
"<p>How do I add a column in the middle of an R data frame? I want to see if I have a column named """"LastName"""" and then add it as the third column if it does not already exist. </p>
",1
"<p>I am often ending up with a function producing output for which I don't understand the output data type. I'm expecting a list and it ends up being a list of lists or a data frame or something else. What's a good method or workflow for figuring out the output data type when first using a function?</p>
",1
"<p>I have a matrix and I would like to know if it is diagonalizable. How do I do this in the R programming language? </p>
",1
"<p>What functions do you use in R to fit a curve to your data and test how well that curve fits?  What results are considered good?</p>
",1
"<p><strong>EDIT:</strong> This bug was found in 32-bit versions of R was fixed in R version 2.9.2.</p>

<hr>

<p>This was tweeted to me by @leoniedu today and I don't have an answer for him so I thought I would post it here. </p>

<p>I have read the documentation for agrep() (fuzzy string matching) and it appears that I don't fully understand the max.distance parameter. Here's an example:</p>

<pre><code>pattern &lt;- """"Staatssekretar im Bundeskanzleramt""""
x &lt;- """"Bundeskanzleramt""""
agrep(pattern,x,max.distance=18) 
agrep(pattern,x,max.distance=19)
</code></pre>

<p>That behaves exactly like I would expect. There are 18 characters different between the strings so I would expect that to be the threshold of a match. Here's what's confusing me:</p>

<pre><code>agrep(pattern,x,max.distance=30) 
agrep(pattern,x,max.distance=31)
agrep(pattern,x,max.distance=32) 
agrep(pattern,x,max.distance=33)
</code></pre>

<p>Why are 30 and 33 matches, but not 31 and 32? To save you some counting, </p>

<pre><code>&gt; nchar(""""Staatssekretar im Bundeskanzleramt"""")
[1] 34
&gt; nchar(""""Bundeskanzleramt"""")
[1] 16
</code></pre>
",1
"<p>I know I must be making a simple syntax mistake, but I want to have a windows batch file that fires up 9 instances of R and runs a different routine in each one. I want these to run simultaneously (i.e. asynchronously). I can fire up 9 command prompt windows and type a command in each one, but it seems like with the START command I should be able to make them start from a single batch file. </p>

<p>Here's an example of how I start one of the instances of R:</p>

<pre><code>""""C:\Program Files (x86)\R\R-2.8.1\bin\R"""" CMD BATCH """"C:\Users\jd\Documents\mexico\Estado\getdata1.r"""" 
</code></pre>

<p>Reading this <a href=""""https://stackoverflow.com/questions/72671/how-to-create-batch-file-in-windows-using-start-with-a-path-and-command-with-sp"""">previous stackoverflow question</a> along with <a href=""""https://stackoverflow.com/questions/154075/using-the-dos-start-command-with-parameters-passed-to-the-started-program"""">this previous question</a> makes me think I should be able to do this:</p>

<pre><code>START """""""" """"C:\Program Files (x86)\R\R-2.8.1\bin\R"""" CMD BATCH """"C:\Users\jd\Documents\mexico\Estado\getdata1.r"""" /b
</code></pre>

<p>That does not return an error, it just returns a prompt and R never starts. What am I missing?</p>
",1
"<p>Hierarchical Bayes models are commonly used in Marketing, Political Science, and Econometrics. Yet, the only package I know of is <code>bayesm</code>, which is really a companion to a book (<em>Bayesian Statistics and Marketing</em>, by Rossi, et al.) Am I missing something? Is there a software package for R or Python doing the job out there, and/or a worked-out example in the associated language? </p>
",1
"<p>I have a data frame containing a factor.  When I create a subset of this data frame using <code>subset()</code> or another indexing function, a new data frame is created.  However, the factor variable retains all of its original levels -- even when they do not exist in the new data frame.</p>

<p>This creates headaches when doing faceted plotting or using functions that rely on factor levels.</p>

<p>What is the most succinct way to remove levels from a factor in my new data frame?</p>

<p>Here's my example:</p>

<pre><code>df &lt;- data.frame(letters=letters[1:5],
                    numbers=seq(1:5))

levels(df$letters)
## [1] """"a"""" """"b"""" """"c"""" """"d"""" """"e""""

subdf &lt;- subset(df, numbers &lt;= 3)
##   letters numbers
## 1       a       1
## 2       b       2
## 3       c       3    

## but the levels are still there!
levels(subdf$letters)
## [1] """"a"""" """"b"""" """"c"""" """"d"""" """"e""""
</code></pre>
",1
"<p>I have an Excel file with a large set of data. The built-in graphs available in Excel are <em>not</em> enough to analyze these data, so I am thinking about using some tool like octave or R.</p>

<p>I was thinking about some method to load an Excel file directly into octave or R. I searched the web and found that many people have succeeded using by exporting data from Excel into a CSV file.</p>

<p>The question:
Is there a direct way to load an Excel file in R or Octave?</p>
",1
"<p>This is probably a very stupid question for SQL stalwarts, but I just want one SQL command.</p>

<p>Details,</p>

<p>I am using a data analysis tool called R, this tool uses ODBC to read data from XLS. I am now trying to read data from an XLS file. The ODBC tool in R accepts SQL commands.</p>

<p>Question,</p>

<p>Can someone give me an SQL command that will read data from an XLS file's
- Specified sheet
- Specified column [by name]
- Specified row [Specified just by Row Index]</p>

<p>Thanks ... </p>
",1
"<p>Very newbie (to Java) question:</p>

<p>I opened an Rserve connection (<a href=""""http://www.rforge.net/Rserve/"""" rel=""""nofollow noreferrer"""">http://www.rforge.net/Rserve/</a>) on localhost, and I would like to use the REngine client (src/client/java-new in the Rserve package) to connect to it.</p>

<p>What do I need to do to get the """"RTest.java"""" (located in src/client/java-new/Rserve; pasted below) to compile?</p>

<p>I gather that I need to compile the org.rosuda.* libraries. How can I do this using Eclipse 3.5? I tried copying the """"src/client/java-new"""" folder into my Java project's """"src"""" directory, right clicking in Eclipse -> Build path -> Use as source folder.  But I don't think this is enough to create the """"org.rosuda"""" package, because I don't see an """"org/rosuda"""" directory structure created anywhere (and those ominous red lines in Eclipse don't disappear). </p>

<p>Anyone done this recently, care to offer a pointer? Thanks plenty.</p>

<pre><code>import org.rosuda.REngine.*;
import org.rosuda.REngine.Rserve.*;

class TestException extends Exception {
    public TestException(String msg) { super(msg); }
}

public class test {
    public static void main(String[] args) {
    try {
        RConnection c = new RConnection();

        System.out.println(""""&gt;&gt;""""+c.eval(""""R.version$version.string"""").asString()+""""&lt;&lt;"""");

        {
            System.out.println(""""* Test string and list retrieval"""");
            RList l = c.eval(""""{d=data.frame(\""""huhu\"""",c(11:20)); lapply(d,as.character)}"""").asList();
            int cols = l.size();
            int rows = l.at(0).length();
            String[][] s = new String[cols][];
            for (int i=0; i&lt;cols; i++) s[i]=l.at(i).asStrings();
            System.out.println(""""PASSED"""");
        }

        {
        System.out.println(""""* Test NA/NaN support in double vectors..."""");
        double R_NA = Double.longBitsToDouble(0x7ff00000000007a2L);
        // int R_NA_int = -2147483648; // just for completeness
        double x[] = { 1.0, 0.5, R_NA, Double.NaN, 3.5 };
        c.assign(""""x"""",x);
        String nas = c.eval(""""paste(capture.output(print(x)),collapse='\\n')"""").asString();
        System.out.println(nas);
        if (!nas.equals(""""[1] 1.0 0.5  NA NaN 3.5""""))
            throw new TestException(""""NA/NaN assign+retrieve test failed"""");
        System.out.println(""""PASSED"""");
        }

        {
            System.out.println(""""* Test assigning of lists and vectors ..."""");
            RList l = new RList();
            l.put(""""a"""",new REXPInteger(new int[] { 0,1,2,3}));
            l.put(""""b"""",new REXPDouble(new double[] { 0.5,1.2,2.3,3.0}));
            System.out.println(""""  assign x=pairlist"""");
            c.assign(""""x"""", new REXPList(l));
            System.out.println(""""  assign y=vector"""");
            c.assign(""""y"""", new REXPGenericVector(l));
            System.out.println(""""  assign z=data.frame"""");
            c.assign(""""z"""", REXP.createDataFrame(l));
            System.out.println(""""  pull all three back to Java"""");
            REXP x = c.parseAndEval(""""x"""");
            System.out.println(""""  x = """"+x);
            x = c.eval(""""y"""");
            System.out.println(""""  y = """"+x);
            x = c.eval(""""z"""");
            System.out.println(""""  z = """"+x);
            System.out.println(""""PASSED"""");
        }
        {
            System.out.println(""""* Test support for logicals ... """");
            System.out.println(""""  assign b={true,false,true}"""");
            c.assign(""""b"""", new REXPLogical(new boolean[] { true, false, true }));
            REXP x = c.parseAndEval(""""b"""");
            System.out.println(""""  """" + ((x != null) ? x.toDebugString() : """"NULL""""));
            if (!x.isLogical() || x.length() != 3)
                throw new TestException(""""boolean array assign+retrieve test failed"""");
            boolean q[] = ((REXPLogical)x).isTRUE();
            if (q[0] != true || q[1] != false || q[2] != true)
                throw new TestException(""""boolean array assign+retrieve test failed (value mismatch)"""");
            System.out.println(""""  get c(TRUE,FLASE,NA)"""");
            x = c.parseAndEval(""""c(TRUE,FALSE,NA)"""");
            System.out.println(""""  """" + ((x != null) ? x.toDebugString() : """"NULL""""));
            if (!x.isLogical() || x.length() != 3)
                throw new TestException(""""boolean array NA test failed"""");
            boolean q1[] = ((REXPLogical)x).isTRUE();
            boolean q2[] = ((REXPLogical)x).isFALSE();
            boolean q3[] = ((REXPLogical)x).isNA();
            if (q1[0] != true || q1[1] != false || q1[2] != false ||
                q2[0] != false || q2[1] != true || q2[2] != false ||
                q3[0] != false || q3[1] != false || q3[2] != true)
                throw new TestException(""""boolean array NA test failed (value mismatch)"""");
        }

        { // regression: object bit was not set for Java-side generated objects before 0.5-3
            System.out.println(""""* Testing functionality of assembled S3 objects ..."""");
            // we have already assigned the data.frame in previous test, so we jsut re-use it
            REXP x = c.parseAndEval(""""z[2,2]"""");
            System.out.println(""""  z[2,2] = """" + x);
            if (x == null || x.length() != 1 || x.asDouble() != 1.2)
                throw new TestException(""""S3 object bit regression test failed"""");
            System.out.println(""""PASSED"""");
        }

        { // this test does a pull and push of a data frame. It will fail when the S3 test above failed.
            System.out.println(""""* Testing pass-though capability for data.frames ..."""");
            REXP df = c.parseAndEval(""""{data(iris); iris}"""");
            c.assign(""""df"""", df);
            REXP x = c.eval(""""identical(df, iris)"""");
            System.out.println(""""  identical(df, iris) = """"+x);
            if (x == null || !x.isLogical() || x.length() != 1 || !((REXPLogical)x).isTrue()[0])
                throw new TestException(""""Pass-through test for a data.frame failed"""");
            System.out.println(""""PASSED"""");
        }

            { // factors
                System.out.println(""""* Test support of factors"""");
                REXP f = c.parseAndEval(""""factor(paste('F',as.integer(runif(20)*5),sep=''))"""");
                System.out.println(""""  f=""""+f);
                System.out.println(""""  isFactor: """"+f.isFactor()+"""", asFactor: """"+f.asFactor());
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""""factor test failed"""");
                System.out.println(""""  singe-level factor used to degenerate:"""");
                f = c.parseAndEval(""""factor('foo')"""");
                System.out.println(""""  isFactor: """"+f.isFactor()+"""", asFactor: """"+f.asFactor());
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""""single factor test failed (not a factor)"""");
                if (!f.asFactor().at(0).equals(""""foo"""")) throw new TestException(""""single factor test failed (wrong value)"""");
                System.out.println(""""  test factors with null elements contents:"""");
                c.assign(""""f"""", new REXPFactor(new RFactor(new String[] { """"foo"""", """"bar"""", """"foo"""", """"foo"""", null, """"bar"""" })));
                f = c.parseAndEval(""""f"""");
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""""factor assign-eval test failed (not a factor)"""");
                System.out.println(""""  f = """"+f.asFactor());
                f = c.parseAndEval(""""as.factor(c(1,'a','b',1,'b'))"""");
                System.out.println(""""  f = """"+f);
                if (!f.isFactor() || f.asFactor() == null) throw new TestException(""""factor test failed (not a factor)"""");
                System.out.println(""""PASSED"""");
            }


        {
            System.out.println(""""* Lowess test"""");
            double x[] = c.eval(""""rnorm(100)"""").asDoubles();
            double y[] = c.eval(""""rnorm(100)"""").asDoubles();
            c.assign(""""x"""", x);
            c.assign(""""y"""", y);
            RList l = c.parseAndEval(""""lowess(x,y)"""").asList();
            System.out.println(""""  """"+l);
            x = l.at(""""x"""").asDoubles();
            y = l.at(""""y"""").asDoubles();
            System.out.println(""""PASSED"""");
        }

        {
            // multi-line expressions
            System.out.println(""""* Test multi-line expressions"""");
            if (c.eval(""""{ a=1:10\nb=11:20\nmean(b-a) }\n"""").asInteger()!=10)
                throw new TestException(""""multi-line test failed."""");
            System.out.println(""""PASSED"""");
        }
        {
            System.out.println(""""* Matrix tests\n  matrix: create a matrix"""");
            int m=100, n=100;
            double[] mat=new double[m*n];
            int i=0;
            while (i&lt;m*n) mat[i++]=i/100;
            System.out.println(""""  matrix: assign a matrix"""");
            c.assign(""""m"""", mat);
            c.voidEval(""""m&lt;-matrix(m,""""+m+"""",""""+n+"""")"""");
            System.out.println(""""matrix: cross-product"""");
            double[][] mr=c.parseAndEval(""""crossprod(m,m)"""").asDoubleMatrix();
            System.out.println(""""PASSED"""");
        }

        {
            System.out.println(""""* Test serialization and raw vectors"""");
            byte[] b = c.eval(""""serialize(ls, NULL, ascii=FALSE)"""").asBytes();
            System.out.println(""""  serialized ls is """"+b.length+"""" bytes long"""");
            c.assign(""""r"""", new REXPRaw(b));
            String[] s = c.eval(""""unserialize(r)()"""").asStrings();
            System.out.println(""""  we have """"+s.length+"""" items in the workspace"""");
            System.out.println(""""PASSED"""");
        }


        { // string encoding test (will work with Rserve 0.5-3 and higher only)
            System.out.println(""""* Test string encoding support ..."""");
            String t = """"ひらがな""""; // hiragana (literally, in hiragana ;))
            c.setStringEncoding(""""utf8"""");
            // -- Just in case the console is not UTF-8 don't display it
            //System.out.println(""""  unicode text: """"+t);
            c.assign(""""s"""", t);
            REXP x = c.parseAndEval(""""nchar(s)"""");
            System.out.println(""""  nchar = """" + x);
            if (x == null || !x.isInteger() || x.asInteger() != 4)
                throw new TestException(""""UTF-8 encoding string length test failed"""");
            // we cannot really test any other encoding ..
            System.out.println(""""PASSED"""");
        }

        } catch (RserveException rse) {
        System.out.println(rse);
    } catch (REXPMismatchException mme) {
        System.out.println(mme);
        mme.printStackTrace();
        } catch(TestException te) {
            System.err.println(""""** Test failed: """"+te.getMessage());
            te.printStackTrace();
    } catch (Exception e) {
        e.printStackTrace();
    }
    }
}
</code></pre>
",1
"<p>is there a good library on the market to visualize big datas in Java. Maybe a library for statistical outputs. I know the programming language R to visualize statistical data in R. I also have seen a solution to connect Java and R. It would be better if a have a pure Java solution. </p>
",1
"<p>I am writing a function that takes two variables and separately regresses each of them on a set of controls expressed as a one-sided formula. Right now I'm using the following to make the formula for one of the regressions, but it feels a bit hacked-up:</p>

<pre><code>foo &lt;- function(x, y, controls) {
    cl &lt;- match.call()
    xn &lt;- cl[[""""x""""]]
    xf &lt;- as.formula(paste(xn, deparse(controls)))
}
</code></pre>

<p>I'd prefer to do this using <code>update.formula()</code>, but of course <code>update.formula(controls, x ~ .)</code> and <code>update.formula(controls, as.name(x) ~ .)</code> don't work. What should I be doing?</p>
",1
"<p>I'd like to know if anybody can provide a step-by-step how to on how to use mediation analysis using <a href=""""http://imai.princeton.edu/software/mediation.html"""" rel=""""nofollow noreferrer"""">Keele, Tingley, Yamamoto and Imai's mediation package</a>. I think there are two approaches to this - <a href=""""http://www.public.asu.edu/~davidpm/classes/psy536/Baron.pdf"""" rel=""""nofollow noreferrer"""">the classic Baron and Kenny (1986)</a> and the new one by <a href=""""http://kuscholarworks.ku.edu/dspace/bitstream/1808/1658/1/preacher_rucker_hayes_2007.pdf"""" rel=""""nofollow noreferrer"""">Preacher, Rucker and Hayes (2007)</a> - I'd like to know how to do both approaches in R</p>
",1
"<p>In the past I have used a DCOM connection to call R functions from Excel and from VBA inside of Excel. I just got a new laptop and have been looking for the install files for the R add in for Excel. I find references to it all over the place but they all point to R (D)COM Server project's home page at <a href=""""http://sunsite.univie.ac.at/rcom"""" rel=""""nofollow noreferrer"""">http://sunsite.univie.ac.at/rcom</a>. That URL has been down now for some time. Is there another way to get the same functionality with another method? Is there a new project page? </p>

<p>I've never tried to use the DCOM server without the Excel Add-in. Is that a possibility?</p>
",1
"<p>I (sort of) already know the answer to this question.  But I figured it is one that gets asked so frequently on the R Users list, that there should be one solid good answer.  <strong>To the best of my knowledge there is no multiline comment functionality in R.  So, does anyone have any good workarounds?</strong></p>

<p>While quite a bit of work in R usually involves interactive sessions (which casts doubt on the need for multiline comments), there are times when I've had to send scripts to colleagues and classmates, much of which involves nontrivial blocks of code.  And for people coming from other languages it is a fairly natural question.  </p>

<p>In the past I've used quotes. Since strings support linebreaks, running an R script with</p>

<pre><code>""""
Here's my multiline comment.

""""
a &lt;- 10
rocknroll.lm &lt;- lm(blah blah blah)
 ...
</code></pre>

<p>works fine.  Does anyone have a better solution?</p>
",1
"<p>I have <a href=""""http://rss.acs.unt.edu/Rdoc/library/coin/html/LocationTests.html"""" rel=""""nofollow noreferrer"""">this example</a> from the coin package of R:</p>

<pre><code>  library(coin)
  library(multcomp)
  ### Length of YOY Gizzard Shad from Kokosing Lake, Ohio,
  ### sampled in Summer 1984, Hollander &amp; Wolfe (1999), Table 6.3, page 200
  YOY &lt;- data.frame(length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44, 
                               42, 60, 32, 42, 45, 58, 27, 51, 42, 52, 
                               38, 33, 26, 25, 28, 28, 26, 27, 27, 27, 
                               31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
                    site = factor(c(rep(""""I"""", 10), rep(""""II"""", 10),
                                    rep(""""III"""", 10), rep(""""IV"""", 10))))

  ### Nemenyi-Damico-Wolfe-Dunn test (joint ranking)
  ### Hollander &amp; Wolfe (1999), page 244 
  ### (where Steel-Dwass results are given)
  NDWD &lt;- oneway_test(length ~ site, data = YOY,
      ytrafo = function(data) trafo(data, numeric_trafo = rank),
      xtrafo = function(data) trafo(data, factor_trafo = function(x)
          model.matrix(~x - 1) %*% t(contrMat(table(x), """"Tukey""""))),
      teststat = """"max"""", distribution = approximate(B = 90000))

  ### global p-value
  print(pvalue(NDWD))

  ### sites (I = II) != (III = IV) at alpha = 0.01 (page 244)
  print(pvalue(NDWD, method = """"single-step""""))
</code></pre>

<p>I want to assign alpha a different value, how can I do this??</p>

<p>This doesn't work!</p>

<pre><code>  library(coin)
  library(multcomp)
  ### Length of YOY Gizzard Shad from Kokosing Lake, Ohio,
  ### sampled in Summer 1984, Hollander &amp; Wolfe (1999), Table 6.3, page 200
  YOY &lt;- data.frame(length = c(46, 28, 46, 37, 32, 41, 42, 45, 38, 44, 
                               42, 60, 32, 42, 45, 58, 27, 51, 42, 52, 
                               38, 33, 26, 25, 28, 28, 26, 27, 27, 27, 
                               31, 30, 27, 29, 30, 25, 25, 24, 27, 30),
                    site = factor(c(rep(""""I"""", 10), rep(""""II"""", 10),
                                    rep(""""III"""", 10), rep(""""IV"""", 10))))

  ### Nemenyi-Damico-Wolfe-Dunn test (joint ranking)
  ### Hollander &amp; Wolfe (1999), page 244 
  ### (where Steel-Dwass results are given)
  NDWD &lt;- oneway_test(length ~ site, data = YOY,
      ytrafo = function(data) trafo(data, numeric_trafo = rank),
      xtrafo = function(data) trafo(data, factor_trafo = function(x)
          model.matrix(~x - 1) %*% t(contrMat(table(x), """"Tukey""""))),
      teststat = """"max"""", distribution = approximate(B = 90000),
      alpha = 0.05)

  ### global p-value
  print(pvalue(NDWD))

  ### sites (I = II) != (III = IV) at alpha = 0.05 (default was 0.01) (page 244)
  print(pvalue(NDWD, method = """"single-step""""))
</code></pre>
",1
"<p>I am a newbie in R programming. Though I am poking into the manuals, I also wanted to ask the community <strong>""""How can we set global variables inside a function?""""</strong></p>

<p>Any pointers will help.</p>

<p>Question-2: Regarding plotting,</p>

<p>I am using plotting multiple graphs in a single sheet, and to differentiate each one of them, I want to add title for each one of them. Can anyone tell me how I can achieve this?</p>
",1
"<p>I'm looking at the <a href=""""http://bm2.genes.nig.ac.jp/RGM2/R_current/library/psych/man/00.psych-package.html"""" rel=""""nofollow noreferrer"""">psych package</a> and the <a href=""""http://www.personality-project.org/R/html/VSS.html"""" rel=""""nofollow noreferrer"""">VSS tutorial</a>, do I simply replace VSS with MAP? Like this:</p>

<pre><code>MAP(x, n = 8, rotate = """"varimax"""", diagonal = FALSE, fm = """"pa"""", n.obs=NULL,plot=TRUE,title=""""Very Simple Structure"""",...)
</code></pre>

<p>or is there another way to do this?
I've doing factor analysis right now and I'm using the elbow method on a scree plot. I'm trying to see if I can try to use Velicer's MAP criterion also</p>
",1
"<p>Realizing that loops are usually not ideal in R, sometimes they are necessary.</p>

<p>When writing large loops, doesn't </p>

<pre><code>for (i in 1:large_number) 
</code></pre>

<p>waste memory, since a vector of size large_number must be created?</p>

<p>Would this make while loops the best choice for large, necessary loops?</p>
",1
"<p>If I create a plotting window in R with m rows and n columns, how can I give the """"overall"""" graphic a main title?</p>

<p>For example, I might have three scatterplots showing the relationship between GPA and SAT score for 3 different schools. How could I give one master title to all three plots, such as, """"SAT score vs. GPA for 3 schools in CA""""?</p>
",1
"<p>I'm trying to generate a histogram in R with a logarithmic scale for y. Currently I do:</p>

<pre><code>hist(mydata$V3, breaks=c(0,1,2,3,4,5,25))
</code></pre>

<p>This gives me a histogram, but the density between 0 to 1 is so great (about a million values difference) that you can barely make out any of the other bars.</p>

<p>Then I've tried doing:</p>

<pre><code>mydata_hist &lt;- hist(mydata$V3, breaks=c(0,1,2,3,4,5,25), plot=FALSE)
plot(rpd_hist$counts, log=""""xy"""", pch=20, col=""""blue"""")
</code></pre>

<p>It gives me sorta what I want, but the bottom shows me the values 1-6 rather than 0, 1, 2, 3, 4, 5, 25.  It's also showing the data as points rather than bars. <code>barplot</code> works but then I don't get any bottom axis.</p>
",1
"<p>I'm trying to normalize some data which I have in a data frame. I want to take each value and run it through the pnorm function along with the mean and standard deviation of the column the value lives in. Using loops, here's how I would write out what I want to do:</p>

<pre><code>#example data
hist_data &lt;- data.frame( matrix( rnorm( 200,mean=5,sd=.5 ),nrow=20 ) )

n &lt;- dim( hist_data )[2] #columns=10
k &lt;- dim( hist_data )[1] #rows   =20

#set up the data frame which we will populate with a loop
normalized &lt;- data.frame( matrix( nrow = nrow( hist_data ), ncol = ncol( hist_data ) ) )

#hot loop in loop action
for ( i in 1:n ){
   for ( j in 1:k ){
      normalized[j,i] &lt;- pnorm( hist_data[j,i], 
                                mean = mean( hist_data[,i] ), 
                                sd = sd( hist_data[,i] ) )
   }  
}
normalized
</code></pre>

<p>It seems that in R there should be a handy dandy vector way of doing this. I thought I was smart so tried using the apply function:</p>

<pre><code>#trouble ahead
hist_data &lt;- data.frame( matrix( rnorm( 200, mean = 5,sd = .5 ), nrow=10 ) )
normalized &lt;- apply( hist_data, 2, pnorm, mean = mean( hist_data ), sd = sd( hist_data ) )
normalized
</code></pre>

<p>Much to my chagrin, that does NOT produce what I expected. The upper left and bottom right elements of the output are correct, but that's it. So how can I de-loopify my life? </p>

<p>Bonus points if you can tell me what my second code block is actually doing. Kind of a mystery to me still. :)</p>
",1
"<p>I would like to place two plots side by side using the <a href=""""http://crantastic.org/packages/ggplot2"""" rel=""""noreferrer"""">ggplot2 package</a>, i.e. do the equivalent of <code>par(mfrow=c(1,2))</code>.</p>

<p>For example, I would like to have the following two plots show side-by-side with the same scale.</p>

<pre><code>x &lt;- rnorm(100)
eps &lt;- rnorm(100,0,.2)
qplot(x,3*x+eps)
qplot(x,2*x+eps)
</code></pre>

<p>Do I need to put them in the same data.frame?</p>

<pre><code>qplot(displ, hwy, data=mpg, facets = . ~ year) + geom_smooth()
</code></pre>
",1
"<pre><code>862 2006-05-19 6.241603 5.774208     
863 2006-05-20 NA       NA      
864 2006-05-21 NA       NA      
865 2006-05-22 6.383929 5.906426      
866 2006-05-23 6.782068 6.268758      
867 2006-05-24 6.534616 6.013767      
868 2006-05-25 6.370312 5.856366      
869 2006-05-26 6.225175 5.781617      
870 2006-05-27 NA       NA     
</code></pre>

<p>I have a data frame x like above with some NA, which i want to fill using neighboring non-NA values like for 2006-05-20 it will be avg of 19&amp;22 </p>

<p>How do it is the question?</p>
",1
"<p>I have some data in CSV like:</p>

<pre><code>""""Timestamp"""", """"Count""""
""""2009-07-20 16:30:45"""", 10
""""2009-07-20 16:30:45"""", 15
""""2009-07-20 16:30:46"""", 8
""""2009-07-20 16:30:46"""", 6
""""2009-07-20 16:30:46"""", 8
""""2009-07-20 16:30:47"""", 20
</code></pre>

<p>I can read it into R using read.cvs. I'd like to plot:</p>

<ol>
<li>Number of entries per second, so:

<pre>
""""2009-07-20 16:30:45"""", 2
""""2009-07-20 16:30:46"""", 3
""""2009-07-20 16:30:47"""", 1
</pre></li>
<li>Average value per second:

<pre>
""""2009-07-20 16:30:45"""", 12.5
""""2009-07-20 16:30:46"""", 7.333
""""2009-07-20 16:30:47"""", 20
</pre></li>
<li>Same as 1 &amp; 2 but then by Minute and then by Hour.</li>
</ol>

<p>Is there some way to do this (collect by second/min/etc &amp; plot) in R? </p>
",1
"<p>Here I make a new column to indicate whether myData is above or below its median</p>

<pre><code>### MedianSplits based on Whole Data
#create some test data
myDataFrame=data.frame(myData=runif(15),myFactor=rep(c(""""A"""",""""B"""",""""C""""),5)) 

#create column showing median split
myBreaks= quantile(myDataFrame$myData,c(0,.5,1))
myDataFrame$MedianSplitWholeData = cut(
    myDataFrame$myData,
    breaks=myBreaks, 
    include.lowest=TRUE,
    labels=c(""""Below"""",""""Above""""))

#Check if it's correct
myDataFrame$AboveWholeMedian = myDataFrame$myData &gt; median(myDataFrame$myData)
myDataFrame
</code></pre>

<p>Works fine. Now I want to do the same thing, but compute the median splits within each level of myFactor.</p>

<p>I've come up with this:</p>

<pre><code>#Median splits within factor levels
byOutput=by(myDataFrame$myData,myDataFrame$myFactor, function (x) {
     myBreaks= quantile(x,c(0,.5,1))
     MedianSplitByGroup=cut(x,
       breaks=myBreaks, 
       include.lowest=TRUE,
       labels=c(""""Below"""",""""Above""""))
     MedianSplitByGroup
     })
</code></pre>

<p>byOutput contains what I want. It categorizes each element of factors A, B, and C correctly. However I'd like to create a new column, myDataFrame$FactorLevelMedianSplit, that shows the newly-computed median split.</p>

<p>How do you convert the output of the """"by"""" command into a useful data-frame column?</p>

<p>I think perhaps the """"by"""" command is not R-like way to do this ... </p>

<p><strong>Update</strong>:</p>

<p>With Thierry's example of how to use factor() cleverly, and upon discovering the """"ave"""" function in Spector's book, I've found this solution, which requires no additional packages.</p>

<pre><code>myDataFrame$MediansByFactor=ave(
    myDataFrame$myData,
    myDataFrame$myFactor,
    FUN=median)

myDataFrame$FactorLevelMedianSplit = factor(
    myDataFrame$myData&gt;myDataFrame$MediansByFactor, 
    levels = c(TRUE, FALSE), 
    labels = c(""""Above"""", """"Below""""))
</code></pre>
",1
"<p>There are clearly a number of packages in R for all sorts of spatial analysis. That can by seen in the <a href=""""http://cran.r-project.org/web/views/Spatial.html"""" rel=""""noreferrer"""">CRAN Task View: Analysis of Spatial Data</a>. These packages are numerous and diverse, but all I want to do is some simple <a href=""""http://images.google.com/images?q=thematic+map&amp;oe=utf-8&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a&amp;um=1&amp;ie=UTF-8&amp;ei=EYiBSqywF5TYNZW8sJ0L&amp;sa=X&amp;oi=image_result_group&amp;ct=title&amp;resnum=4"""" rel=""""noreferrer"""">thematic maps</a>. I have data with county and state FIPS codes and I have ESRI shape files of county and state boundaries and the accompanying FIPS codes which allows joining with the data. The shape files could be easily converted to other formats, if needed. </p>

<p>So what's the most straight forward way to create thematic maps with R? </p>

<p>This map looks like it was created with an ESRI Arc product, but this is the type of thing I would like to do with R:</p>

<p><a href=""""http://www.infousagov.com/images/choro.jpg"""" rel=""""noreferrer"""">alt text http://www.infousagov.com/images/choro.jpg</a> Map <a href=""""http://www.infousagov.com/thematicmap.asp"""" rel=""""noreferrer"""">copied from here</a>. </p>
",1
"<p>I am loading a table in which the first column is a URL and reading it into R using <code>read.table()</code>.  </p>

<p>It seems that R is dropping about 1/3 of the columns and does not return any errors.  </p>

<p>The URLs do not contain any <code>#</code> characters or tabs (my separator field), which I understand could be an issue.  If I convert the URLs to integer IDs first, the problem goes away.</p>

<p>Is there something about the field that might be causing R to drop the rows?</p>
",1
"<p>Let's say you have this data in R, and you want to post a question on stackoverflow. For others to best help you, it would be nice if they could have a copy of your object (dataframe, vector, etc) to work with.</p>

<p>Let's say your data is in a data frame called site.data</p>

<pre><code>&gt; site.data
    site year     peak
1  ALBEN    5 101529.6
2  ALBEN   10 117483.4
3  ALBEN   20 132960.9
8  ALDER    5   6561.3
9  ALDER   10   7897.1
10 ALDER   20   9208.1
15 AMERI    5  43656.5
16 AMERI   10  51475.3
17 AMERI   20  58854.4
</code></pre>

<p>How do you package it up so that the users can recreate the data exactly as you have it? </p>

<p>You want to do this without having people download a text file and import it.  </p>

<p>(Note: These data subsetted from an example of the REvolutions blog)</p>
",1
"<p>When I undertake an R project of any complexity, my scripts quickly get long and confusing. </p>

<p>What are some practices I can adopt so that my code will always be a pleasure to work with? I'm thinking about things like</p>

<ul>
<li>Placement of functions in source files</li>
<li>When to break something out to another source file</li>
<li>What should be in the master file</li>
<li>Using functions as organizational units (whether this is worthwhile given that R makes it hard to access global state)</li>
<li>Indentation / line break practices. 

<ul>
<li>Treat ( like {? </li>
<li>Put things like )} on 1 or 2 lines?</li>
</ul></li>
</ul>

<p>Basically, what are your rules of thumb for organizing large R scripts?</p>
",1
"<p>I have a data.frame with column headers. </p>

<p>How can I get a specific row from the data.frame as a list (with the column headers as keys for the list)?</p>

<p>Specifically, my data.frame is </p>

<pre>
      A    B    C
    1 5    4.25 4.5
    2 3.5  4    2.5
    3 3.25 4    4
    4 4.25 4.5  2.25
    5 1.5  4.5  3
</pre>

<p>And I want to get a row that's the equivalent of</p>

<pre><code>&gt; c(a=5, b=4.25, c=4.5)
  a   b   c 
5.0 4.25 4.5 
</code></pre>
",1
"<p>After learning about the <a href=""""https://stackoverflow.com/questions/1167448/most-mature-sparse-matrix-package-for-r"""">options for working with sparse matrices in R</a>, I want to use the <a href=""""http://cran.r-project.org/web/packages/Matrix/index.html"""" rel=""""nofollow noreferrer"""">Matrix</a> package to create a sparse matrix from the following data frame and have all other elements be <code>NA</code>.</p>

<pre><code>     s    r d
1 1089 3772 1
2 1109  190 1
3 1109 2460 1
4 1109 3071 2
5 1109 3618 1
6 1109   38 7
</code></pre>

<p>I know I can create a sparse matrix with the following, accessing elements as usual:</p>

<pre><code>&gt; library(Matrix)
&gt; Y &lt;- sparseMatrix(s,r,x=d)
&gt; Y[1089,3772]
[1] 1
&gt; Y[1,1]
[1] 0
</code></pre>

<p>but if I want to have the default value to be NA, I tried the following:</p>

<pre><code>  M &lt;- Matrix(NA,max(s),max(r),sparse=TRUE)
  for (i in 1:nrow(X))
    M[s[i],r[i]] &lt;- d[i]
</code></pre>

<p>and got this error</p>

<pre><code>Error in checkSlotAssignment(object, name, value) : 
  assignment of an object of class """"numeric"""" is not valid for slot """"x"""" in an object of class """"lgCMatrix""""; is(value, """"logical"""") is not TRUE
</code></pre>

<p>Not only that, I find that one takes much longer to access to elements.</p>

<pre><code>&gt; system.time(Y[3,3])
   user  system elapsed 
  0.000   0.000   0.003 
&gt; system.time(M[3,3])
   user  system elapsed 
  0.660   0.032   0.995 
</code></pre>

<p>How should I be creating this matrix?  Why is one matrix so much slower to work with?</p>

<p>Here's the code snippet for the above data:</p>

<pre><code>X &lt;- structure(list(s = c(1089, 1109, 1109, 1109, 1109, 1109), r = c(3772, 
190, 2460, 3071, 3618, 38), d = c(1, 1, 1, 2, 1, 7)), .Names = c(""""s"""", 
""""r"""", """"d""""), row.names = c(NA, 6L), class = """"data.frame"""")
</code></pre>
",1
"<p>I have a panel containing three plots. How can I use <code>par</code> to specify the width and height of the main panel so it is always at a fixed size?</p>
",1
"<p>I want to sort a data.frame by multiple columns. For example, with the data.frame below I would like to sort by column <code>z</code> (descending) then by column <code>b</code> (ascending): </p>

<pre><code>dd &lt;- data.frame(b = factor(c(""""Hi"""", """"Med"""", """"Hi"""", """"Low""""), 
      levels = c(""""Low"""", """"Med"""", """"Hi""""), ordered = TRUE),
      x = c(""""A"""", """"D"""", """"A"""", """"C""""), y = c(8, 3, 9, 9),
      z = c(1, 1, 1, 2))
dd
    b x y z
1  Hi A 8 1
2 Med D 3 1
3  Hi A 9 1
4 Low C 9 2
</code></pre>
",1
"<p>I have fit a regression using lme4 thanks to a <a href=""""https://stackoverflow.com/questions/1169539/linear-regression-and-group-by-in-r"""">previous answer</a>. Now that I have a regression fit for each state I'd like to use lattice to plot QQ plots for each state. I would also like to plot error plots for each state in a lattice format. How do I make a lattice plot using the results of a lme4 regression? </p>

<p>Below is a simple sample (yeah, I like a good alliteration) using two states. I would like to make a two panel lattice made from the object fits. </p>

<pre><code>library(lme4)
d &lt;- data.frame(state=rep(c('NY', 'CA'), c(10, 10)), year=rep(1:10, 2), response=c(rnorm(10), rnorm(10)))
fits &lt;- lmList(response ~ year | state, data=d)
</code></pre>
",1
"<p>Given two data frames:</p>

<pre><code>df1 = data.frame(CustomerId = c(1:6), Product = c(rep(""""Toaster"""", 3), rep(""""Radio"""", 3)))
df2 = data.frame(CustomerId = c(2, 4, 6), State = c(rep(""""Alabama"""", 2), rep(""""Ohio"""", 1)))

df1
#  CustomerId Product
#           1 Toaster
#           2 Toaster
#           3 Toaster
#           4   Radio
#           5   Radio
#           6   Radio

df2
#  CustomerId   State
#           2 Alabama
#           4 Alabama
#           6    Ohio
</code></pre>

<p>How can I do database style, i.e., <a href=""""http://en.wikipedia.org/wiki/Join_%28SQL%29"""" rel=""""noreferrer"""">sql style, joins</a>? That is, how do I get:</p>

<ul>
<li>An <a href=""""http://en.wikipedia.org/wiki/Join_%28SQL%29#Inner_join"""" rel=""""noreferrer"""">inner join</a> of <code>df1</code> and <code>df2</code>:<br>
Return only the rows in which the left table have matching keys in the right table.</li>
<li>An <a href=""""http://en.wikipedia.org/wiki/Join_%28SQL%29#Outer_join"""" rel=""""noreferrer"""">outer join</a> of <code>df1</code> and <code>df2</code>:<br>
Returns all rows from both tables, join records from the left which have matching keys in the right table.</li>
<li>A <a href=""""http://en.wikipedia.org/wiki/Join_%28SQL%29#Left_outer_join"""" rel=""""noreferrer"""">left outer join (or simply left join)</a> of <code>df1</code> and <code>df2</code><br>
Return all rows from the left table, and any rows with matching keys from the right table.</li>
<li>A <a href=""""http://en.wikipedia.org/wiki/Join_%28SQL%29#Right_outer_join"""" rel=""""noreferrer"""">right outer join</a> of <code>df1</code> and <code>df2</code><br>
Return all rows from the right table, and any rows with matching keys from the left table.</li>
</ul>

<p>Extra credit:</p>

<p>How can I do a SQL style select statement?</p>
",1
"<p>Formulas are a very useful feature of R's statistical and graphical functions. Like everyone, I am a user of these functions. However, I have never written a function that takes a formula object as an argument. I was wondering if someone could help me, by either linking to a readable introduction to this side of R programming, or by giving a self-contained example.</p>
",1
"<p><strong>Note:</strong> <em>I changed the example from when I first posted. My first example was too simplified to capture the real problem.</em> </p>

<p>I have two data frames which are sorted differently in one column. I want to match one column and then merge in the value from the second column. The second column needs to stay in the same order. </p>

<p>So I have this:</p>

<pre><code>state&lt;-c(""""IA"""",""""IA"""",""""IA"""",""""IL"""",""""IL"""",""""IL"""")
value1&lt;-c(1,2,3,4,5,6)
s1&lt;-data.frame(state,value1)
state&lt;-c(""""IL"""",""""IL"""",""""IL"""",""""IA"""",""""IA"""",""""IA"""")
value2&lt;-c(3,4,5,6,7,8)
s2&lt;-data.frame(state,value2)

s1
s2
</code></pre>

<p>which returns this:</p>

<pre><code>&gt; s1
  state value1
1    IA      1
2    IA      2
3    IA      3
4    IL      4
5    IL      5
6    IL      6
&gt; s2
  state value2
1    IL      3
2    IL      4
3    IL      5
4    IA      6
5    IA      7
6    IA      8
</code></pre>

<p>and I want this:</p>

<pre><code>  state value1 value2
1    IA      1      6
2    IA      2      7
3    IA      3      8
4    IL      4      3
5    IL      5      4
6    IL      6      5
</code></pre>

<p>I'm about to drive myself silly trying to solve this. Seems like it should be a simple subscript problem. </p>
",1
"<p>I am currently working on an algorithm to implement a rolling median filter (analogous to a rolling mean filter) in C. From my search of the literature, there appear to be two reasonably efficient ways to do it. The first is to sort the initial window of values, then perform a binary search to insert the new value and remove the existing one at each iteration.</p>

<p>The second (from Hardle and Steiger, 1995, JRSS-C, Algorithm 296) builds a double-ended heap structure, with a maxheap on one end, a minheap on the other, and the median in the middle. This yields a linear-time algorithm instead of one that is O(n log n).</p>

<p>Here is my problem: implementing the former is doable, but I need to run this on millions of time series, so efficiency matters a lot. The latter is proving very difficult to implement. I found code in the Trunmed.c file of the code for the stats package of R, but it is rather indecipherable.</p>

<p>Does anyone know of a well-written C implementation for the linear time rolling median algorithm?</p>

<p>Edit: Link to Trunmed.c code <a href=""""http://google.com/codesearch/p?hl=en&amp;sa=N&amp;cd=1&amp;ct=rc#mYw3h_Lb_e0/R-2.2.0/src/library/stats/src/Trunmed.c"""" rel=""""nofollow noreferrer"""">http://google.com/codesearch/p?hl=en&amp;sa=N&amp;cd=1&amp;ct=rc#mYw3h_Lb_e0/R-2.2.0/src/library/stats/src/Trunmed.c</a></p>
",1
"<p>Many intro R books and guides start off with the practice of attaching a <code>data.frame</code> so that you can call the variables by name. I have always found it favorable to call variables with <code>$</code> notation or square bracket slicing <code>[,2]</code>. That way I can use multiple <code>data.frame</code>s without confusing them and/or use iteration to successively call columns of interest. I noticed Google recently posted <a href=""""http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html"""" rel=""""nofollow noreferrer"""">coding guidelines for R</a> which included the line</p>

<blockquote>
  <p>1) attach: avoid using it </p>
</blockquote>

<p>How do people feel about this practice?</p>
",1
"<p>What is the most efficient way to make a matrix of lagged variables in R for an arbitrary variable (i.e. not a regular time series)</p>

<p>For example:</p>

<p><strong><em>Input</em></strong>:</p>

<pre><code>x &lt;- c(1,2,3,4) 
</code></pre>

<p><strong><em>2 lags, output</em></strong>:</p>

<pre><code>[1,NA, NA]
[2, 1, NA]
[3, 2,  1]
[4, 3,  2]
</code></pre>
",1
"<p>How do I limit the number of panels shown on a single page using lattice? I am graphing the results of a regression for multiple states and putting 50 of these on a single page makes them unreadable. I would like to limit the output to 4 wide and as many tall as needed. </p>

<p>Here's my lattice code:</p>

<pre><code>xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)
</code></pre>

<p>There are 50 different values for State_CD</p>
",1
"<p>I've been experimenting with both <code>ggplot2</code> and <code>lattice</code> to graph panels of data. I'm having a little trouble wrapping my mind around the <code>ggplot2</code> model. In particular, how do I plot a scatter plot with two sets of data on each panel:</p>

<p>in <code>lattice</code> I could do this:</p>

<pre><code>xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)
</code></pre>

<p>and that would give me a panel for each State_CD with each column</p>

<p>I can do one column with <code>ggplot2</code>: </p>

<pre><code>pg &lt;- ggplot(dd, aes(x_value, Predicted_value)) + geom_point(shape = 2) 
      + facet_wrap(~ State_CD) + opts(aspect.ratio = 1)
print(pg)
</code></pre>

<p>What I can't grok is how to add Actual_value to the ggplot above. </p>

<p><strong>EDIT</strong> Hadley pointed out that this really would be easier with a reproducible example. Here's code that seems to work. Is there a better or more concise way to do this with ggplot? Why is the syntax for adding another set of points to ggplot so different from adding the first set of data?</p>

<pre><code>library(lattice)
library(ggplot2)

#make some example data
dd&lt;-data.frame(matrix(rnorm(108),36,3),c(rep(""""A"""",24),rep(""""B"""",24),rep(""""C"""",24)))
colnames(dd) &lt;- c(""""Predicted_value"""", """"Actual_value"""", """"x_value"""", """"State_CD"""")

#plot with lattice
xyplot(Predicted_value + Actual_value ~ x_value | State_CD, data=dd)

#plot with ggplot
pg &lt;- ggplot(dd, aes(x_value, Predicted_value)) + geom_point(shape = 2) + facet_wrap(~ State_CD) + opts(aspect.ratio = 1)
print(pg)

pg + geom_point(data=dd,aes(x_value, Actual_value,group=State_CD), colour=""""green"""")
</code></pre>

<p>The lattice output looks like this:
<a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/08/lattice.png"""" rel=""""nofollow noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/08/lattice.png</a></p>

<p>and ggplot looks like this:
<a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/08/ggplot.png"""" rel=""""nofollow noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/08/ggplot.png</a></p>
",1
"<p>Call me lazy, but I just hate typing things like <code>paste(""""a"""",""""b"""",sep='')</code> all the time. </p>

<p>I know that """"(t)his is R. There is no if, only how."""" (<code>library(fortunes);(fortune(109)</code>). So, my follow up question is: Is it possible to easily change this behavior? </p>
",1
"<p>I am trying to get the rcom package for R working.  It seems to have installed ok:</p>

<pre>
> install.packages(""""rcom"""");
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://mira.sunsite.utk.edu/CRAN/bin/windows/contrib/2.9/rcom_2.2-1.zip'
Content type 'application/zip' length 204632 bytes (199 Kb)
opened URL
downloaded 199 Kb

package 'rcom' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Users\solomon\AppData\Local\Temp\Rtmpzb5oi4\downloaded_packages
updating HTML package descriptions
</pre>

<p>Then I try to run something:</p>

<pre>
>comCreateObject(""""Excel.Application"""");
Error: could not find function """"comCreateObject""""
</pre>

<p>What am I missing, the <a href=""""http://cran.r-project.org/web/packages/rcom/rcom.pdf"""" rel=""""noreferrer"""">manual</a> tells me that comCreateObject is the appropriate command.  However, the manual's version is somewhat old.  Anyone else have any insights?</p>
",1
"<p>This is a very basic question - but apparently google is not very good at searching for strings like """"%+%"""". So my question is - what and when is """"%+%"""" and similar used. I guess its a kind of merge?.</p>

<p>EDIT: Ok - I believe my question is answered. %X% is binary operator of some kind. So now I think I will google around for knowledge about how/when to use these. My question was partly inspired by yesterday's question - but only after I saw this <a href=""""http://learnr.wordpress.com/2009/03/16/ggplot2-barplots/"""" rel=""""nofollow noreferrer"""">post</a> on the """"learning R"""" blog. The passage that gave rise to my question was this:<br>
    In order to do this, a new dataframe with the annual totals will be created and later merged with the existing dataset (variable names in both dataframes should be identical for this to work). Then we just change the dataframe the plot is based on.</p>

<pre><code>## add total immigration figures to the plot
total &lt;- cast(df.m, Period ~ ., sum)
total &lt;- rename(total, c(""""(all)"""" = """"value""""))
total$Region &lt;- """"Total""""
df.m.t &lt;- rbind(total, df.m)
c1 &lt;- c %+% df.m.t
</code></pre>
",1
"<p>Goal: from a list of vectors of equal length, create a matrix where each vector becomes a row.</p>

<p>Example:</p>

<pre><code>&gt; a &lt;- list()
&gt; for (i in 1:10) a[[i]] &lt;- c(i,1:5)
&gt; a
[[1]]
[1] 1 1 2 3 4 5

[[2]]
[1] 2 1 2 3 4 5

[[3]]
[1] 3 1 2 3 4 5

[[4]]
[1] 4 1 2 3 4 5

[[5]]
[1] 5 1 2 3 4 5

[[6]]
[1] 6 1 2 3 4 5

[[7]]
[1] 7 1 2 3 4 5

[[8]]
[1] 8 1 2 3 4 5

[[9]]
[1] 9 1 2 3 4 5

[[10]]
[1] 10  1  2  3  4  5
</code></pre>

<p>I want:</p>

<pre><code>      [,1] [,2] [,3] [,4] [,5] [,6]
 [1,]    1    1    2    3    4    5
 [2,]    2    1    2    3    4    5
 [3,]    3    1    2    3    4    5
 [4,]    4    1    2    3    4    5
 [5,]    5    1    2    3    4    5
 [6,]    6    1    2    3    4    5
 [7,]    7    1    2    3    4    5
 [8,]    8    1    2    3    4    5
 [9,]    9    1    2    3    4    5
[10,]   10    1    2    3    4    5 
</code></pre>
",1
"<p>I have a plot where the x-axis is a factor whose labels are long.  While probably not an ideal visualization, for now I'd like to simply rotate these labels to be vertical.  I've figured this part out with the code below, but as you can see, the labels aren't totally visible.</p>

<pre><code>data(diamonds)
diamonds$cut &lt;- paste(""""Super Dee-Duper"""",as.character(diamonds$cut))
q &lt;- qplot(cut,carat,data=diamonds,geom=""""boxplot"""")
q + opts(axis.text.x=theme_text(angle=-90))
</code></pre>

<p><a href=""""https://i.stack.imgur.com/pcJr3.png"""" rel=""""noreferrer""""><img src=""""https://i.stack.imgur.com/pcJr3.png"""" alt=""""enter image description here""""></a></p>
",1
"<p>Suppose I have a data.frame with N rows.  The <code>id</code> column has 10 unique values; all those values are integers greater than 1e7.  I would like to rename them to be numbered 1 through 10 and save these new IDs as a column in my data.frame.</p>

<p>Additionally, I would like to easily determine 1) <code>id</code> given <code>id.new</code> and 2) <code>id.new</code> given <code>id</code>.</p>

<p>For example: </p>

<pre><code>&gt; set.seed(123)
&gt; ids &lt;- sample(1:1e7,10)
&gt; A &lt;- data.frame(id=sample(ids,100,replace=TRUE),
                  x=rnorm(100))
&gt; head(A)
       id          x
1 4566144  1.5164706
2 9404670 -1.5487528
3 5281052  0.5846137
4  455565  0.1238542
5 7883051  0.2159416
6 5514346  0.3796395
</code></pre>
",1
"<p>I've found R's ifelse statements to be pretty handy from time to time.  For example:</p>

<pre><code>ifelse(TRUE,1,2)
# [1] 1
ifelse(FALSE,1,2)
# [1] 2
</code></pre>

<p>But I'm somewhat confused by the following behavior.</p>

<pre><code>ifelse(TRUE,c(1,2),c(3,4))
# [1] 1
ifelse(FALSE,c(1,2),c(3,4))
# [1] 3
</code></pre>

<p>Is this a design choice that's above my paygrade?</p>
",1
"<p>I need to make a topographic map of a terrain for which I have only fairly sparse samples of <em>(x,&nbsp;y,&nbsp;altitude)</em> data.  Obviously I can't make a completely accurate map, but I would like one that is in some sense """"smooth"""".  I need to quantify """"smoothness"""" (probably the reciprocal the average of the square of the surface curvature) and I want to minimize an objective function that is the sum of two quantities:</p>

<ul>
<li>The roughness of the surface</li>
<li>The mean square distance between the altitude of the surface at the sample point and the actual measured altitude at that point</li>
</ul>

<p>Since what I actually want is a topographic map, I am really looking for a way to construct contour lines of constant altitude, and there may be some clever geometric way to do that without ever having to talk about surfaces.  Of course I want contour lines also to be smooth.</p>

<p>Any and all suggestions welcome.  I'm hoping this is a well-known numerical problem.  I am quite comfortable in C and have a working knowledge of FORTRAN.  About Matlab and R I'm fairly clueless.</p>

<hr>

<p>Regarding where our samples are located: we're planning on roughly even spacing, but we'll take more samples where the topography is more interesting.  So for example we'll sample mountainous regions more densely than a plain.  But we definitely have some choices about sampling, and could take even samples if that simplifies matters.  The only issues are</p>

<ul>
<li><p>We don't know how much terrain we'll need to map in order to find features that we are looking for.</p></li>
<li><p>Taking a sample is moderately expensive, on the order of 10 minutes.  So sampling a 100x100 grid could take a long time.</p></li>
</ul>
",1
"<p>Is there an easy way to have R record all input and output from your R session to disk while you are working with R interactively?  </p>

<p>In <code>R.app</code> on <code>Mac OS X</code> I can do a <code>File-&gt;Save...</code>, but it isn't much help in recovering the commands I had entered when R crashes.</p>

<p>I have tried using <code>sink(...,split=T)</code>, but it doesn't seem to do exactly what I am looking for.</p>
",1
"<p>I have basically two questions.</p>

<ol>
<li><p>How do I locate the default <code>Rprofile</code> which is running? I have not setup a <code>Rprofile</code> yet, so I am not sure where it is running from.</p></li>
<li><p>I am trying to install a few packages using the command (after doing a SUDO in the main terminal).</p></li>
</ol>



<pre><code>install.packages(""""RODBC"""",""""/home/rama/R/i486-pc-linux-gnu-library/2.9"""")
</code></pre>

<p>and I get back an error which says:</p>

<blockquote>
  <p>ERROR: failed to lock directory ‘/home/rama/R/i486-pc-linux-gnu-library/2.9’ for modifying Try removing ‘/home/rama/R/i486-pc-linux-gnu-library/2.9/00LOCK’</p>
  
  <p>The downloaded packages are in ‘/tmp/RtmpkzDMVU/downloaded_packages’ Warning message: In install.packages(""""RODBC"""", """"/home/rama/R/i486-pc-linux-gnu-library/2.9"""") : installation of package 'RODBC' had non-zero exit status</p>
</blockquote>
",1
"<p>I have a set of survey data, and I'd like to generate plots of a particular variable, grouped by the respondent's country.  The code I have written to generate the plots so far is:</p>

<pre><code>countries &lt;- isplit(drones, drones$v3)
foreach(country = countries) %dopar% {
  png(file = paste(output.exp, """"/Histogram of Job Satisfaction in """", country$key[[1]], """".png"""", sep = """"""""))
  country.df &lt;- data.frame(country)  #ggplot2 doesn't appreciate the lists nextElem() produces
  ggplot(country.df, aes(x = value.v51)) + geom_histogram()
  dev.off()
}
</code></pre>

<p>The truly bizarre thing?  I can run the isplit(), set <code>country &lt;- nextElem(countries)</code>, and then run through the code without sending the foreach line - and get a lovely plot.  If I send the foreach, I get some blank .png files.</p>

<p>Thanks in advance for your help.</p>

<p>I can definitely do this with standard R loops, but I'd really like to get a better grasp on <code>foreach</code>.</p>
",1
"<p>I could solve this using loops, but I am trying think in vectors so my code will be more R-esque. </p>

<p>I have a list of names. The format is firstname_lastname. I want to get out of this list a separate list with only the first names. I can't seem to get my mind around how to do this. Here's some example data:</p>

<pre><code>t &lt;- c(""""bob_smith"""",""""mary_jane"""",""""jose_chung"""",""""michael_marx"""",""""charlie_ivan"""")
tsplit &lt;- strsplit(t,""""_"""")
</code></pre>

<p>which looks like this:</p>

<pre><code>&gt; tsplit
[[1]]
[1] """"bob""""   """"smith""""

[[2]]
[1] """"mary"""" """"jane""""

[[3]]
[1] """"jose""""  """"chung""""

[[4]]
[1] """"michael"""" """"marx""""   

[[5]]
[1] """"charlie"""" """"ivan""""   
</code></pre>

<p>I could get out what I want using loops like this:</p>

<pre><code>for (i in 1:length(tsplit)){
    if (i==1) {t_out &lt;- tsplit[[i]][1]} else{t_out &lt;- append(t_out, tsplit[[i]][1])} 
}
</code></pre>

<p>which would give me this:</p>

<pre><code>t_out
[1] """"bob""""     """"mary""""    """"jose""""    """"michael"""" """"charlie""""
</code></pre>

<p>So how can I do this without loops?</p>
",1
"<p>What tricks do people use to manage the available memory of an interactive R session?  I use the functions below [based on postings by Petr Pikal and David Hinds to the r-help list in 2004] to list (and/or sort) the largest objects and to occassionally <code>rm()</code> some of them. But by far the most effective solution was ... to run under 64-bit Linux with ample memory. </p>

<p>Any other nice tricks folks want to share?  One per post, please.</p>

<pre><code># improved list of objects
.ls.objects &lt;- function (pos = 1, pattern, order.by,
                        decreasing=FALSE, head=FALSE, n=5) {
    napply &lt;- function(names, fn) sapply(names, function(x)
                                         fn(get(x, pos = pos)))
    names &lt;- ls(pos = pos, pattern = pattern)
    obj.class &lt;- napply(names, function(x) as.character(class(x))[1])
    obj.mode &lt;- napply(names, mode)
    obj.type &lt;- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.size &lt;- napply(names, object.size)
    obj.dim &lt;- t(napply(names, function(x)
                        as.numeric(dim(x))[1:2]))
    vec &lt;- is.na(obj.dim)[, 1] &amp; (obj.type != """"function"""")
    obj.dim[vec, 1] &lt;- napply(names, length)[vec]
    out &lt;- data.frame(obj.type, obj.size, obj.dim)
    names(out) &lt;- c(""""Type"""", """"Size"""", """"Rows"""", """"Columns"""")
    if (!missing(order.by))
        out &lt;- out[order(out[[order.by]], decreasing=decreasing), ]
    if (head)
        out &lt;- head(out, n)
    out
}
# shorthand
lsos &lt;- function(..., n=10) {
    .ls.objects(..., order.by=""""Size"""", decreasing=TRUE, head=TRUE, n=n)
}
</code></pre>
",1
"<p>I'm looking for a non-linear curve fitting routine (probably most likely to be found in R or Python, but I'm open to other languages) which would take x,y data and fit a curve to it.</p>

<p>I should be able to specify as a string the type of expression I want to fit.</p>

<p>Examples:</p>

<pre><code>""""A+B*x+C*x*x""""
""""(A+B*x+C*x*x)/(D*x+E*x*x)""""
""""sin(A+B*x)*exp(C+D*x)+E+F*x""""
</code></pre>

<p>What I would get out of this is at least the values for the constants (A, B, C, etc.) And hopefully stats about the fitness of the match.</p>

<p>There are commercial programs to do this, but I expected to be able to find something as common as fitting to a desired expression in a language library nowadays. I suspect SciPy's optimization stuff might be able to do this, but I can't see that it lets me define an equation. Likewise, I can't seem to find exactly what I want in R.</p>

<p>Is what I'm looking for out there, or do I need to roll my own? I hate to do it if it's there and I'm just having trouble finding it.</p>

<hr>

<p>Edit: I want to do this for a bit more control over the process than I get from LAB Fit. The LAB Fit UI is dreadful. I'd also like to be able to break the range into multiple pieces and have different curves represent the different pieces of the range. In the end, the result has to be able to (speed-wise) beat a LUT with linear interpolation or I'm not interested.</p>

<p>In my current set of problems, I have trig functions or exp() and I need to execute them 352,800 times per second in real time (and use only a fraction of the CPU). So I plot the curve and use the data to drive the curve fitter to get less expensive approximations. In the old days, LUTs were almost always the solution, but nowadays skipping the memory lookups and doing an approximation is sometimes faster.</p>
",1
"<p>I have a data that looks like <a href=""""http://dpaste.com/88561/plain/"""" rel=""""nofollow noreferrer"""">this</a>.</p>

<p>And I intend to create multiple density curve into one plot, where each curve
correspond to the unique ID.</p>

<p>I tried to use """"sm"""" package, with this code, but without success.</p>

<pre><code>library(sm)
dat &lt;- read.table(""""mydat.txt"""");
plotfn &lt;- (""""~/Desktop/flowgram_superimposed.pdf"""");
pdf(plotfn);

sm.density.compare(dat$V1,dat$V2, xlab = """"Flow Signal"""")
colfill &lt;- c(2:10);
legend(locator(1), levels(dat$V2), fill=colfill)

dev.off();
</code></pre>

<p>Please advice what's the right way to do it or if  there is
alternative way to do it?</p>

<p>I am trying to get this kind of plot  at the end. 
<a href=""""http://img524.imageshack.us/img524/2736/testl.png"""" rel=""""nofollow noreferrer"""">figure http://img524.imageshack.us/img524/2736/testl.png</a></p>
",1
"<p>Is this even possible?  I had a dataset for training that included about 1500 entries.  The randomForest created its decision rules and applied them to the randomly chosen (from the original dataset) Out of Bag training sample (bootstrapped 10,000 times).  I have a separate (unclassified) dataset that I would like to apply the 10,000 created trees to in order to predict classification for these new entries.  Is there an easy way to index the underlying Forest trees to this new unclassified dataset?</p>
",1
"<p>I'm building an R package and need to build a jni library for OSX (called <code>myPackage.jnilib</code>) as part of my build process and then have R's automatic installation mechanisms put it inside the libs directory of my package.</p>

<p>The problem is that R's default is to try and build an object called <code>myPackage.so</code>. I'd like to be able to customize this but can't see how.</p>

<p>I can get part of the way by subverting R's mechanisms using a phony """"all"""" target in Makevars (described <a href=""""http://stat.ethz.ch/R-manual/R-patched/doc/manual/R-exts.html#Using-Makevars"""" rel=""""nofollow noreferrer"""">here</a>) and then copying the file to the <code>inst</code> directory of my package.  This is OK for my own local uses but generates headaches when trying to build universal binaries and isn't very portable. I'm currently preparing the package for CRAN so this method isn't likely to work.</p>

<p>I can see two potential solutions but haven't got either to work yet</p>

<ol>
<li><p>Copy my library manually to the libs directory of my package during installation.  Since this directory is created on the fly, how would I find out what it is from within Makevars or a configure script</p></li>
<li><p>The best solution: Tell R CMD SHLIB the name of my output file so I can use R's normal package mechanisms and let it copy the file to the right directory.  </p></li>
</ol>
",1
"<p>I am trying to plot lattice type data with GGPLOT2 and then superimpose a normal distribution over the sample data to illustrate how far off normal the underlying data is. I would like to have the normal dist on top to have the same mean and stdev as the panel. </p>

<p>here's an example:</p>

<pre><code>library(ggplot2)

#make some example data
dd&lt;-data.frame(matrix(rnorm(144, mean=2, sd=2),72,2),c(rep(""""A"""",24),rep(""""B"""",24),rep(""""C"""",24)))
colnames(dd) &lt;- c(""""x_value"""", """"Predicted_value"""",  """"State_CD"""")

#This works
pg &lt;- ggplot(dd) + geom_density(aes(x=Predicted_value)) +  facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>That all works great and produces a nice three panel graph of the data. How do I add the normal dist on top? It seems I would use stat_function, but this fails:</p>

<pre><code>#this fails
pg &lt;- ggplot(dd) + geom_density(aes(x=Predicted_value)) + stat_function(fun=dnorm) +  facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>It appears that the stat_function is not getting along with the facet_wrap feature. How do I get these two to play nicely?</p>

<p><strong>------------EDIT---------</strong></p>

<p>I tried to integrate ideas from two of the answers below and I am still not there:</p>

<p>using a combination of both answers I can hack together this:</p>

<pre><code>library(ggplot)

#make some example data
dd&lt;-data.frame(matrix(rnorm(108, mean=2, sd=2),36,2),c(rep(""""A"""",24),rep(""""B"""",24),rep(""""C"""",24)))
colnames(dd) &lt;- c(""""x_value"""", """"Predicted_value"""",  """"State_CD"""")

DevMeanSt &lt;- ddply(dd, c(""""State_CD""""), function(df)mean(df$Predicted_value)) 
colnames(DevMeanSt) &lt;- c(""""State_CD"""", """"mean"""")
DevSdSt &lt;- ddply(dd, c(""""State_CD""""), function(df)sd(df$Predicted_value) )
colnames(DevSdSt) &lt;- c(""""State_CD"""", """"sd"""")
DevStatsSt &lt;- merge(DevMeanSt, DevSdSt)

pg &lt;- ggplot(dd, aes(x=Predicted_value))
pg &lt;- pg + geom_density()
pg &lt;- pg + stat_function(fun=dnorm, colour='red', args=list(mean=DevStatsSt$mean, sd=DevStatsSt$sd))
pg &lt;- pg + facet_wrap(~State_CD)
print(pg)
</code></pre>

<p>which is really close... except something is wrong with the normal dist plotting:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/09/ggplot1.png"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/ggplot1.png</a></p>

<p>what am I doing wrong here?</p>
",1
"<p>Is there a package in Perl that allows you to compute the height of probability distribution at each given point. For example this can be done in R this way:</p>

<pre><code>&gt; dnorm(0, mean=4,sd=10)
&gt; 0.03682701
</code></pre>

<p>Namely the probability of point x=0 falls into a normal distribution, with mean=4 and sd=10, is 0.0368.
I looked at <a href=""""http://search.cpan.org/~mikek/Statistics-Distributions-1.02/Distributions.pm"""" rel=""""nofollow noreferrer"""">Statistics::Distribution</a> but it doesn't give that very 
function to do it. </p>
",1
"<p>One of the things I deal with most in data cleaning is missing values. R deals with this well using its """"NA"""" missing data label. In python, it appears that I'll have to deal with masked arrays which seem to be a major pain to set up and don't seem to be well documented. Any suggestions on making this process easier in Python? This is becoming a deal-breaker in moving into Python for data analysis. Thanks</p>

<p><strong>Update</strong> It's obviously been a while since I've looked at the methods in the numpy.ma module. It appears that at least the basic analysis functions are available for masked arrays, and the examples provided helped me understand how to create masked arrays (thanks to the authors). I would like to see if some of the newer statistical methods in Python (being developed in this year's GSoC) incorporates this aspect, and at least does the complete case analysis.</p>
",1
"<p>I have a data that looks like <a href=""""http://dpaste.com/89376/plain/"""" rel=""""nofollow noreferrer"""">this</a>. And my code below
simply compute some value and binds the output vector to the
original data frames.</p>

<pre><code>options(width=200)

args&lt;-commandArgs(trailingOnly=FALSE)
dat &lt;- read.table(""""http://dpaste.com/89376/plain/"""",fill=T);

problist &lt;- c();

for (lmer in 1:10) {
   meanl &lt;- lmer;
   stdevl &lt;- (0.17*sqrt(lmer));
   err_prob &lt;- pnorm(dat$V4,mean=meanl, sd=stdevl);
   problist &lt;- cbind(problist,err_prob);
}

dat &lt;- cbind(dat,problist)
#print(dat,row.names=F, column.names=F,justify=left)

# Why this breaks?
write(dat, file=""""output.txt"""", sep=""""\t"""",append=F);
</code></pre>

<p>I have couple of questions regarding the above:</p>

<ol>
<li><p>But why the 'write()' function above gives this error. Is there a way to fix it?</p>

<p>Error in cat(list(...), file, sep, fill, labels, append) : 
  argument 1 (type 'list') cannot be handled by 'cat'
Calls: write -> cat
Execution halted</p></li>
<li><p>Names for binded vector in the data frame is added as """"errprob"""" for all 10 new 
columns. Is there a way to name them like """"errprob1"""", """"errprob2"""", etc? </p></li>
</ol>
",1
"<p>I'm looking to streamline my <a href=""""http://en.wikipedia.org/wiki/Sweave"""" rel=""""noreferrer"""">Sweave</a> document creation, and I'd like to hear about people's current setups.  I feel like the holy grail goes something like this:</p>

<ul>
<li>Editing Rnw code on one half of the
screen </li>
<li>Single keybinding compiles
Sweave document and runs pdflatex </li>
<li>View PDF
on the other half of the screen; once
compiled, PDF is refreshed and centered around the portion of the document you're editing</li>
<li>If compilation has errors, replace the PDF with the results of the compilation (e.g. latex errors or Sweave errors)</li>
</ul>

<p>I am guessing/hoping that the solution is part Emacs/ESS combined with some code for the Emacs profile and/or a nice Makefile.  But I would really like to hear about everybody's preferred way of creating Sweave and/or Latex documents.</p>
",1
"<p>Given data of the following form</p>

<pre><code>myDat = structure(list(Score = c(1.84, 2.24, 3.8, 2.3, 3.8, 4.55, 1.13, 
2.49, 3.74, 2.84, 3.3, 4.82, 1.74, 2.89, 3.39, 2.08, 3.99, 4.07, 
1.93, 2.39, 3.63, 2.55, 3.09, 4.76), Subject = c(1L, 1L, 1L, 
2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 7L, 
7L, 7L, 8L, 8L, 8L), Condition = c(0L, 0L, 0L, 1L, 1L, 1L, 0L, 
0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 
1L), Time = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 
1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L)), .Names = c(""""Score"""", 
""""Subject"""", """"Condition"""", """"Time""""), class = """"data.frame"""", row.names = c(NA, 
-24L))
</code></pre>

<p>I would like to model Score as a function of Subject, Condition and Time. Each (human) Subject's score was measured three times, indicated by the variable Time, so I have repeated measures.</p>

<p>How can I build in R a random effects model with Subject effects fitted as random?</p>

<p><strong>ADDENDUM</strong>: It's been asked how I generated these data. You guessed it, the data are fake as the day is long. Score is time plus random noise and being in Condition 1 adds a point to Score. It's instructive as a typical Psych setup. You have a task where people's score gets better with practice (time) and a drug (condition==1) that enhances score.</p>

<p>Here are some more realistic data for the purposes of this discussion. Now simulated participants have a random """"skill"""" level that is added to their scores. Also, the factors are now strings.</p>

<pre><code>myDat = structure(list(Score = c(1.62, 2.18, 2.3, 3.46, 3.85, 4.7, 1.41, 
2.21, 3.32, 2.73, 3.34, 3.27, 2.14, 2.73, 2.74, 3.39, 3.59, 4.01, 
1.81, 1.83, 3.22, 3.64, 3.51, 4.26), Subject = structure(c(1L, 
1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 
6L, 7L, 7L, 7L, 8L, 8L, 8L), .Label = c(""""A"""", """"B"""", """"C"""", """"D"""", """"E"""", 
""""F"""", """"G"""", """"H""""), class = """"factor""""), Condition = structure(c(1L, 
1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 
2L, 1L, 1L, 1L, 2L, 2L, 2L), .Label = c(""""No"""", """"Yes""""), class = """"factor""""), 
    Time = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 
    2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), .Label = c(""""1PM"""", 
    """"2PM"""", """"3PM""""), class = """"factor"""")), .Names = c(""""Score"""", """"Subject"""", 
""""Condition"""", """"Time""""), class = """"data.frame"""", row.names = c(NA, 
-24L))
</code></pre>

<p>See it:</p>

<pre><code>library(ggplot2)
qplot(Time, Score, data = myDat, geom = """"line"""", group = Subject, colour = factor(Condition))
</code></pre>
",1
"<p>I want to remove the space between the axes of the plot and the plot contents themselves. Any ideas?</p>
",1
"<p>I want to create a pairs plot in R that has labels on the diagonal written as greek letters.  I've tried creating a custom text.panel function that wraps the labels in an <code>expression()</code> call, but this does not work.</p>

<p>Here is a simple test case:</p>

<pre><code>pairs.greek &lt;- function(x, ...)
{
  panel.txt &lt;- function(x, y, labels, cex, font, ...)
  {
    lab &lt;- labels
    text(0.5, 0.5, expression(lab), cex=cex, font=font)
  }
  pairs(x, text.panel=panel.txt)
}
dat &lt;- data.frame(alpha=runif(10), beta=runif(10), gamma=runif(10))
pairs.greek(dat)
</code></pre>
",1
"<p>I guess there will be a very simple answer to this. But here goes.</p>

<p>Data in long format. like this</p>

<pre><code>d &lt;- data.frame(cbind(numbers = rnorm(10), 
                         year = rep(c(2008, 2009), 5), 
                         name = c(""""john"""", """"David"""", """"Tom"""", """"Kristin"""", """"Lisa"""",""""Eve"""",""""David"""",""""Tom"""",""""Kristin"""",""""Lisa"""")))
</code></pre>

<p>How do I get a new dataframe only with rows for names that occur in both 2008 and 2009? (i.e. with only David, Kristin, Lisa and Tom).</p>

<p>Thanks in advance</p>
",1
"<p>S-Plus has a great object explorer and data editor built into its GUI.  It allows you to easily see all the objects in the workspace at a glance, and sort them by name, size, or date.  </p>

<p>As far as I'm aware, the only equivalent for R is the object browser in JGR (<a href=""""http://jgr.markushelbig.org/"""" rel=""""noreferrer"""">http://jgr.markushelbig.org/</a>).   </p>

<p>Otherwise I just use the search() and ls() commands most of the time (along with grep() when I have a lot of objects).  </p>

<pre><code># trivial example of routine:
search()
utils.list &lt;- ls(pos=""""package:utils"""")
utils.list[grep(""""edit"""",utils.list)]
</code></pre>

<p>Does anyone have any tricks or suggestions for browsing the R workspace?  Are there any point-and-click solutions?</p>
",1
"<p>How come R does not have a 64bit windows pre-built binaries?</p>
",1
"<p>Is there a good way to deal with time periods such as 05:30 (5 minutes, 30 seconds) in R?</p>

<p>Alternatively what's the fastest way to convert it into an integer with just seconds?</p>

<p>I can only convert to dates and can't really find a data type for time.</p>

<p>I'm using R with zoo.</p>

<p>Thanks a lot ! </p>

<hr>

<p>Seconds was the best way to deal with this. I adapted Shane's code below to my purposes, here's the result.</p>

<pre><code># time - time in the format of dd hh:mm:ss
#       (That's the format used in cvs export from Alcatel CCS reports)
#
time.to.seconds &lt;- function(time) {

   t &lt;- strsplit(as.character(time), """" |:"""")[[1]]
   seconds &lt;- NaN

   if (length(t) == 1 )
      seconds &lt;- as.numeric(t[1])
   else if (length(t) == 2)
      seconds &lt;- as.numeric(t[1]) * 60 + as.numeric(t[2])
   else if (length(t) == 3)
      seconds &lt;- (as.numeric(t[1]) * 60 * 60 
          + as.numeric(t[2]) * 60 + as.numeric(t[3]))   
   else if (length(t) == 4)
      seconds &lt;- (as.numeric(t[1]) * 24 * 60 * 60 +
         as.numeric(t[2]) * 60 * 60  + as.numeric(t[3]) * 60 +
         as.numeric(t[4]))

   return(seconds)
}
</code></pre>
",1
"<p>I am trying to install the
<a href=""""http://www.omegahat.org/RSPython/"""" rel=""""nofollow noreferrer"""">R/SPlus - Python Interface (RSPython)</a> on my Mac OS X 10.4.11 with R version 2.7.2 (2008-08-25) and python 2.6.2 from fink.</p>

<p>The routine:</p>

<pre><code>sudo R CMD INSTALL -c RSPython_0.7-1.tar.gz
</code></pre>

<p>produced this error message:</p>

<pre><code>* Installing to library '/Library/Frameworks/R.framework/Resources/library'
* Installing *source* package 'RSPython' ...
checking for python... /sw/bin/python
Python version 2.6
Using threads
checking for gcc... gcc
checking for C compiler default output file name... configure: error: C compiler cannot create executables
See `config.log' for more details.
ERROR: configuration failed for package 'RSPython'
** Removing '/Library/Frameworks/R.framework/Versions/2.7/Resources/library/RSPython'
</code></pre>

<p>The config.log was not created o my system.</p>

<p>The contact e-mail address to the author does not work anymore, so I just hope somebody here tried the same already or can give me an alternative for running R routines in python.</p>

<p>Best regards,</p>

<p>Simon</p>
",1
"<p>I have a text file similar to this (separated by spaces):</p>

<pre><code>x &lt;- """"DF12 This is an example 1 This
DF12 This is an 1232 This is
DF14 This is 12334 This is an
DF15 This 23 This is an example
""""
</code></pre>

<p>and I know the field lengths of each variable (there is 5 variables in this data set), which are:</p>

<pre><code>varlength &lt;- c(2, 2, 18, 5, 18)
</code></pre>

<p>How can I import this kind of data into R, using the varlength variable as an field separator indicator?</p>
",1
"<p>In the nlme package there are two functions for fitting linear models (lme and gls). </p>

<ol>
<li>What are the differences between
them in terms of the types of models
that can be fit, and the fitting
process?  </li>
<li>What is the design
rational for having two functions to
fit linear mixed models where most
other systems (e.g. SAS SPSS) only
have one?</li>
</ol>

<p>Update: Added bounty. Interested to know differences in the fitting process, and the rational.</p>
",1
"<p>I would like to add <code>LaTeX</code> typesetting to elements of plots in <code>R</code> (e.g: the title, axis labels, annotations, etc.) using either the combination of <code>base/lattice</code> or with <code>ggplot2</code>.</p>

<p><strong>Questions:</strong></p>

<ul>
<li>Is there a way to get <code>LaTeX</code> into plots using these packages, and if so, how is it done?  </li>
<li>If not, are there additional packages needed to accomplish this.</li>
</ul>

<p>For example, in <code>Python matplotlib</code> compiles <code>LaTeX</code> via the <code>text.usetex</code> packages as discussed here: <a href=""""http://www.scipy.org/Cookbook/Matplotlib/UsingTex"""" rel=""""noreferrer"""">http://www.scipy.org/Cookbook/Matplotlib/UsingTex</a></p>

<p>Is there a similar process by which such plots can be generated in <code>R</code>?</p>
",1
"<p>I frequently create nonparametric statistics (loess, kernel densities, etc) on data I pull out of a relational database. To make data management easier I would like to store R output back inside my DB. This is easy with simple data frames of numbers or text, but I have not figured out how to store R objects back in my relational database. So is there a way to store a vector of kernel densities, for example, back into a relational database? </p>

<p>Right now I work around this by saving the R objects to a network drive space so others can load the objects as needed. </p>
",1
"<p>If I have a date like this in London time: """"2009-06-03 19:30"""", how can I convert it to the equivalent time in the US West Coast?</p>
",1
"<p>Suppose I simulate a data set using </p>

<pre><code>set.seed(1234); 
rnorm(100);
</code></pre>

<p>Later, I would like to find the <code>90th</code> data value simulated without re-simulating the whole data set.  </p>

<ul>
<li>How can this be done?  </li>
<li>Does <code>.Random.seed</code> play a role?  </li>
</ul>

<p>While this may seem to be an overly simplified problem (especially when one could just run the whole code again), this type of problem occurs in more complicated <code>Monte Carlo</code> simulations where perhaps a 1,000 data sets are simulated and something goes wrong on data set #90. One would want to view data set #90 without having to simulate data sets #1- #89.</p>
",1
"<p>Most looping code looks like this</p>

<pre><code>retVal=NULL
for i {
  for j {
    result &lt;- *some function of vector[i] and vector[j]* 
    retVal = rbind(retVal,result)
  }
}
</code></pre>

<p>Since this is so common, is there a systematic way of translating this idiom?</p>

<p>Can this be extended to most loops?</p>
",1
"<p>In an effort to help populate the R tag here, I am posting a few questions I have often received from students. I have developed my own answers to these over the years, but perhaps there are better ways floating around that I don't know about.</p>

<p>The question: I just ran a regression with continuous <code>y</code> and <code>x</code> but factor <code>f</code> (where <code>levels(f)</code> produces <code>c(""""level1"""",""""level2"""")</code>)</p>

<pre><code> thelm &lt;- lm(y~x*f,data=thedata)
</code></pre>

<p>Now I would like to plot the predicted values of <code>y</code> by <code>x</code> broken down by groups defined by <code>f</code>. All of the plots I get are ugly and show too many lines.</p>

<p>My answer: Try the <code>predict()</code> function.</p>

<pre><code>##restrict prediction to the valid data 
##from the model by using thelm$model rather than thedata

 thedata$yhat &lt;- predict(thelm,
      newdata=expand.grid(x=range(thelm$model$x),
                          f=levels(thelm$model$f)))

 plot(yhat~x,data=thethedata,subset=f==""""level1"""")
 lines(yhat~x,data=thedata,subset=f==""""level2"""")
</code></pre>

<p>Are there other ideas out there that are (1) easier to understand for a newcomer and/or (2) better from some other perspective?</p>
",1
"<p>Starting with this data frame</p>

<pre><code>myDF = structure(list(Value = c(-2, -1, 0, 1, 2)), .Names = """"Value"""", row.names = c(NA, 5L), class = """"data.frame"""")
</code></pre>

<p>Suppose I want to run this function on every row of myDF$Value </p>

<pre><code>getNumberInfo &lt;- function(x) {
if(x %% 2 ==0) evenness = """"Even"""" else evenness=""""Odd""""
if(x &gt; 0) positivity = """"Positive"""" else positivity = """"NonPositive""""
if (positivity == """"Positive"""") logX = log(x) else logX=NA
c(evenness,positivity,logX)
} 
</code></pre>

<p>... to get this data frame</p>

<pre><code>structure(list(Value = c(-2, -1, 0, 1, 2), Evenness = c(""""Even"""", 
""""Odd"""", """"Even"""", """"Odd"""", """"Even""""), Positivity = c(""""NonPositive"""", 
""""NonPositive"""", """"NonPositive"""", """"Positive"""", """"Positive""""), Log = c(NA, 
NA, NA, """"0"""", """"0.693147180559945"""")), row.names = c(NA, 5L), .Names = c(""""Value"""", 
""""Evenness"""", """"Positivity"""", """"Log""""), class = """"data.frame"""")
</code></pre>
",1
"<p>I have data representing the paths people take across a fixed set of points (discrete, e.g., nodes and edges).  So far I have been using <code>igraph</code>. </p>

<p>I haven't found a good way yet (in <code>igraph</code> or another package) to create <code>canonical paths</code> summarizing what significant sub-groups of respondents are doing.  </p>

<p>A <code>canonical path</code> can be operationalized in any reasonable way and is just meant to represent a typical path or sub-path for a significant portion of the population.  </p>

<p>Does there already exist a function to create these within <code>igraph</code> or another package?</p>
",1
"<p>I read a table from Microsoft Access using RODBC. Some of the variables had a name with a space in it.</p>

<p>R has no problem with it but I do.
I cannot find out how to specify the space</p>

<pre><code>names(alltime)
 [1] """"ID""""            """"LVL7""""          """"Ref Pv No""""     """"Ref Pv Name""""   """"DOS""""           """"Pt Last Name""""  """"Pt First Name"""" """"MRN""""           """"CPT""""           """"CPT Desc""""      """"DxCd1""""         """"DxCd2""""         """"DxCd3""""         """"DxCd4""""        
[15] """"DOE""""    
</code></pre>

<p>But what do I do if I want to do something such as this</p>

<pre><code>&gt; alltime[grep(""""MIDDLE EAR EXPLORE"""",alltime$CPT Desc,]
Error: unexpected symbol in """"alltime[grep(""""MIDDLE EAR EXPLORE"""",alltime$CPT Desc""""
</code></pre>
",1
"<p>That is, is there an embedded R interpreter available?</p>
",1
"<p>In a matrix, if there is some missing data recorded as `NA.</p>

<ul>
<li>how could I delete rows with <code>NA</code> in the matrix? </li>
<li>can I use <code>na.rm</code>?</li>
</ul>
",1
"<p>I have a data frame with several columns, one of which is a factor called """"site"""". How can I split the data frame into blocks of rows each with a unique value of """"site"""", and then process each block with a function? The data look like this:</p>

<pre><code>site year peak
ALBEN 5 101529.6
ALBEN 10 117483.4
ALBEN 20 132960.9
ALBEN 50 153251.2
ALBEN 100 168647.8
ALBEN 200 184153.6
ALBEN 500 204866.5
ALDER 5 6561.3
ALDER 10 7897.1
ALDER 20 9208.1
ALDER 50 10949.3
ALDER 100 12287.6
ALDER 200 13650.2
ALDER 500 15493.6
AMERI 5 43656.5
AMERI 10 51475.3
AMERI 20 58854.4
AMERI 50 68233.3
AMERI 100 75135.9
AMERI 200 81908.3
</code></pre>

<p>and I want to create a plot of <code>year</code> vs <code>peak</code> for each site.</p>
",1
"<p>I have two vectors, <code>subject</code> and <code>target</code>. I want to create a new vector based on comparisons between the two existing vectors, with elements being compared <code>lagged</code>. I've solved this okay using the loop below, but I'm essentially wondering whether there's a more elegant solution using <code>apply</code>?</p>

<pre><code>subject &lt;- c(200,195,190,185,185,185,188,189,195,200,210,210)
target &lt;- c(subject[1],subject[1]-cumsum(rep(perweek,length(subject)-1)))
adjtarget &lt;- target                                               

for (i in 1:(length(subject)-1)) {
  if (subject[i] &gt; adjtarget[i]) {                
    adjtarget[i+1] &lt;- adjtarget[i]           
   } else {                                       
    adjtarget[i+1] &lt;- adjtarget[i]-perweek  }
   }
 }
</code></pre>
",1
"<p>I would like to increase (or decrease) the amount of memory available to R.  What are the methods for achieving this?</p>
",1
"<p>Say I have the following function:</p>

<pre><code>foo &lt;- function(x, y = min(m)) {
    m &lt;- 1:10
    x + y
}
</code></pre>

<p>When I run <code>foo(1)</code>, the returned value is <code>2</code>, as expected. However, I cannot run <code>foo(1, y = max(m))</code> and receive <code>11</code>, since lazy evaluation only works for default arguments. How can I supply an argument but have it evaluate lazily?</p>
",1
"<p>Is there any link between R and Clojure?</p>

<p>I am aware of <a href=""""http://incanter.org/"""" rel=""""noreferrer"""">Incanter</a>, but am ideally looking for an R package for Clojure
or any future plans for one, in order to call clojure from within R.</p>
",1
"<p>Currently, I generate results from statistical analyses (e.g., a three dimensional plot) and then """"manually"""" move it to <a href=""""http://www.procesing.org"""" rel=""""nofollow noreferrer"""">processing</a> - a graphics programming language) where I can (with some simple coding) export an interactive java applet (e.g., allow the person viewing the plot to move in, out and around the data points).  Can I keep this whole process within R?  Specifically, I want to create an applet (doesn't have to be Java but would need to be web embeddable, interactive (so not a movie) and not require the user to work in R or have to download things) that can be passed on.
Thanks.</p>
",1
"<p>Hadley turned me on to the <a href=""""http://had.co.nz/plyr/"""" rel=""""noreferrer"""">plyr</a> package and I find myself using it all the time to do 'group by' sort of stuff. But I find myself having to always rename the resulting columns since they default to V1, V2, etc. </p>

<p>Here's an example:</p>

<pre><code>mydata&lt;-data.frame(matrix(rnorm(144, mean=2, sd=2),72,2),c(rep(""""A"""",24),rep(""""B"""",24),rep(""""C"""",24)))
colnames(mydata) &lt;- c(""""x_value"""", """"acres"""",  """"state"""")
groupAcres &lt;- ddply(mydata, c(""""state""""), function(df)c(sum(df$acres)))
colnames(groupAcres) &lt;- c(""""state"""",""""stateAcres"""")
</code></pre>

<p>Is there a way to make ddply name the resulting column for me so I can omit that last line?</p>
",1
"<p>I am trying to have the x-axis labels to be split into two lines. I would also like the labels to be rotated 45 degrees. How can I do this?</p>

<p>What I have so far:</p>

<pre><code>N &lt;- 10
dnow &lt;- data.frame(x=1:N, y=runif(N), labels=paste(""""This is observation """",1:N))
with(dnow, plot(x,y, xaxt=""""n"""", xlab=""""""""))
atn &lt;- seq(1,N,3)
axis(1, at=atn, labels=labels[atn])
</code></pre>
",1
"<p>I have a list of <code>lm</code> (linear model) objects.</p>

<p>How can I select a particular element (such as the intercept, rank, or residuals) from all the objects in a single call?</p>
",1
"<p>I use R under Windows on several machines.</p>

<p>I know you can set the working directory from within an R script, like this</p>

<pre><code>setwd(""""C:/Documents and Settings/username/My Documents/x/y/z"""")
</code></pre>

<p>... but then this breaks the portability of the script. It's also annoying to have to reverse all the slashes (since Windows gives you backslashes)</p>

<p>Is there a way to start R in a particular working directory so that you don't need to do this at the script level?</p>
",1
"<p>I have a quad-core laptop running Windows XP, but looking at Task Manager R only ever seems to use one processor at a time. How can I make R use all four processors and speed up my R programs?</p>
",1
"<p>What graphics devices let me use system fonts for text within charts? The base graphics system only has a small amount of documentation around the <code>par(family=...)</code> options.</p>

<p>Ideally I'd like to be able to use any font I can browse through a tool like <code>xfontsel</code> on Linux or the equivalent utilities on other platforms.</p>

<p>My current solution is to plot out as PDF and then use a 3rd party program to replace the fonts from within the PDF. This is not ideal.</p>
",1
"<p>Is there an easy way to read the value of the cells rather than the formula?
By the way I only get this problem in a spreadsheet that I have published but not in spreadsheets that are private.
So for instance in a cell whose value was created by simply using the value from the cell immediately to the left in the Google spreadsheet I would prefer to get the value rather than  <code>=RC[-1]</code></p>

<p>When one exports with Google Spreadsheets as a csv then that does not happen.</p>

<p>I am using the following line of code in R</p>

<pre><code>y2009&lt;-sheetAsMatrix(ts2$y2009,header=TRUE, as.data.frame=TRUE, trim=TRUE)
</code></pre>
",1
"<p>I know that </p>

<pre><code> pdf(""""myOut.pdf"""")
</code></pre>

<p>will print to a PDF in R. What if I want to</p>

<ol>
<li><p>Make a loop that prints subsequent graphs on new pages of a PDF file (appending to the end)?</p></li>
<li><p>Make a loop that prints subsequent graphs to new PDF files (one graph per file)?</p></li>
</ol>
",1
"<p>I want to subtract 1 day from a POSIX date and end up at the same time around DST.  </p>

<p>For example, when I add a day:</p>

<pre><code>&gt; as.POSIXct('2009-03-08 23:00:00.000') + 86400
[1] """"2009-03-09 23:00:00 EDT""""
</code></pre>

<p>But when I go past, it offsets:</p>

<pre><code>&gt; as.POSIXct('2009-03-08 23:00:00.000') - 86400
[1] """"2009-03-07 22:00:00 EST""""
</code></pre>

<p>What's the best way to deal with absolute time differences around DST?  Usually I deal with this by converting the times into strings and dealing with them separately so that DST isn't applied.</p>
",1
"<p>I would like to read a binary file -- of indeterminate length -- directly from a URL in R.  Using <code>readBin</code> to read from a URL, without specifying the file size, does not work.</p>

<pre><code> anImage &lt;- readBin('http://user2010.org/pics/useR-large.png','raw')
</code></pre>

<p>Is there another approach that would allow this?</p>
",1
"<p>Are there any R-project packages that implement AOP?  Or even better an example of an R package that uses any such AOP library.</p>
",1
"<p>How do I scrape html tables using the XML package?</p>

<p>Take, for example, this wikipedia page on the <a href=""""http://en.wikipedia.org/wiki/Brazil_national_football_team"""" rel=""""noreferrer"""">Brazilian soccer team</a>. I would like to read it in R and get the """"list of all matches Brazil have played against FIFA recognised teams"""" table as a data.frame. How can I do this?</p>
",1
"<p>I have a plot() that I'm trying to make, but I do not want the x-values to be used as the axis labels...I want a different character vector that I want to use as labels, in the standard way: Use as many as will fit, drop the others, etc. What should I pass to plot() to make this happen?</p>

<p>For example, consider</p>

<pre><code>d &lt;- data.frame(x=1:5,y=10:15,x.names=c('a','b','c','d','e'))
</code></pre>

<p>In barplot, I would pass <code>barplot(height=d$y,names.arg=d$x.names)</code>, but in this case the actual x-values are important. So I would like an analog such as <code>plot(x=d$x,y=d$y,type='l',names.arg=d$x.names)</code>, but that does not work.</p>
",1
"<p>Code written using lapply and friends is usually easier on the eyes and more Rish than loops.  I love lapply just as much as the next guy, but how do I debug it when things go wrong? For example:</p>

<pre><code>&gt; ## a list composed of numeric elements 
&gt; x &lt;- as.list(-2:2)
&gt; ## turn one of the elements into characters
&gt; x[[2]] &lt;- """"what?!?""""
&gt; 
&gt; ## using sapply
&gt; sapply(x, function(x) 1/x)
Error in 1/x : non-numeric argument to binary operator
</code></pre>

<p>Had I used a  for loop:</p>

<pre><code>&gt; y &lt;- rep(NA, length(x))
&gt; for (i in 1:length(x)) {
+     y[i] &lt;-  1/x[[i]]
+ }
Error in 1/x[[i]] : non-numeric argument to binary operator
</code></pre>

<p>But I would know where the error happened:</p>

<pre><code>&gt; i
[1] 2
</code></pre>

<p>What should I do when using lapply/sapply?</p>
",1
"<p>In ggplot2, how could I change the color of coloring in scatter plot?</p>
",1
"<p>These days I am extensively using R to scatter plots.
Most of the plotting is concerned with image processing,
Recently I was thinking of plotting the scatter plots over an image. </p>

<p>For example, I want something like this,
The background needs to be filled with my image. With a particular scale.
And I should be able to draw points (co-ordinates) on top of this image ...</p>

<p>Is this possible in R?
If not, do you guys know of any other tool that makes this easy ...</p>
",1
"<p>While I can change annotations with the generic plot command turning off axes and 
annotations and specifying them again using the axis command e.g.</p>

<pre><code>cars &lt;- c(1, 3, 6, 4, 9)

plot(cars, type=""""o"""", col=""""blue"""", ylim=range(0, cars), axes=FALSE, ann=FALSE)  
axis(1, at=1:5, lab=c(""""Mon"""",""""Tue"""",""""Wed"""",""""Thu"""",""""Fri""""))
</code></pre>

<p>I cant do it with time series object e.g.</p>

<pre><code>www &lt;- """"http://www.massey.ac.nz/~pscowper/ts/Maine.dat""""  
Maine.month &lt;- read.table(www, header = TRUE)  
attach(Maine.month)  
Maine.month.ts &lt;- ts(unemploy, start = c(1996, 1), freq = 12)  
Maine.98 &lt;- window(Maine.month.ts, start = c(1998,1), end = c(1998,11))
</code></pre>

<p>How can I plot <code>Maine.98</code> with annotations looking like:</p>

<pre><code>""""Jan-98""""   """"Feb-98""""   """"Mar-98""""   """"Apr-98""""   """"May-98""""  etc?
</code></pre>
",1
"<p>How to use gsub with more than 9 backreferences? 
I would expect the output in the example below to be """"e, g, i, j, o"""".</p>

<pre><code>&gt; test &lt;- """"abcdefghijklmnop""""
&gt; gsub(""""(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)(\\w)"""", """"\\5, \\7, \\9, \\10, \\15"""", test, perl = TRUE)
[1] """"e, g, i, a0, a5""""
</code></pre>
",1
"<p>we have to fit about 2000 or odd time series every month,
they have very idiosyncratic behavior in particular, some are arma/arima, some are ewma, some are arch/garch with or without seasonality and/or trend (only thing in common is the time series aspect).</p>

<p>one can in theory build ensemble model with aic or bic criterion to choose the best fit model but is the community aware of any library which attempts to solve this problem?</p>

<p>Google made me aware of the below one by Rob J Hyndman
<a href=""""http://robjhyndman.com/software/forecast"""" rel=""""nofollow noreferrer"""">link</a></p>

<p>but are they any other alternatives? </p>
",1
"<p>I need to calculate the within and between run variances from some data as part of developing a new analytical chemistry method.  I also need confidence intervals from this data using the R language</p>

<p>I assume I need to use anova or something ?</p>

<p>My data is like</p>

<pre><code>&gt; variance
   Run Rep Value
1    1   1  9.85
2    1   2  9.95
3    1   3 10.00
4    2   1  9.90
5    2   2  8.80
6    2   3  9.50
7    3   1 11.20
8    3   2 11.10
9    3   3  9.80
10   4   1  9.70
11   4   2 10.10
12   4   3 10.00
</code></pre>
",1
"<p><a href=""""http://www.stat.columbia.edu/~cook/movabletype/archives/2009/08/upgrading_r.html"""" rel=""""noreferrer"""">Andrew Gelman recently lamented the lack of an easy upgrade process for R</a> (probably more relevant on Windows than Linux).  Does anyone have a good trick for doing the upgrade, from installing the software to copying all the settings/packages over?</p>

<p>This suggestion was contained in the comments and is what I've been using recently.  First you install the new version, then run this in the old verion:</p>

<pre><code>#--run in the old version of R
setwd(""""C:/Temp/"""")
packages &lt;- installed.packages()[,""""Package""""]
save(packages, file=""""Rpackages"""")
</code></pre>

<p>Followed by this in the new version:</p>

<pre><code>#--run in the new version
setwd(""""C:/Temp/"""")
load(""""Rpackages"""")
for (p in setdiff(packages, installed.packages()[,""""Package""""]))
install.packages(p)
</code></pre>
",1
"<p>Is it possible to perform a bulk insert into an MS-SQL Server (2000, 2005, 2008) using the RODBC package?</p>

<p>I know that I can do this using freebcp, but I'm curious if the RODBC package implements this portion of the Microsoft SQL API and if not, how difficult it would be to implement it.</p>
",1
"<p>I would like to incorporate variable names that imply what I should do with them. I imagine a dataframe """"survey"""".</p>

<pre><code>library(Rlab) # Needed for rbern() function.
survey &lt;- data.frame(cbind(  
id = seq(1:10),  
likert_this = sample(seq(1:7),10, replace=T),  
likert_that = sample(seq(1:7), 10, replace=T),  
dim_bern_varx = rbern(10, 0.6),  
disc_1 = sample(letters[1:5],10,replace=T)))
</code></pre>

<p>Now I would like to do certain things with all variables that contain <em>likert</em>, other things with variables that contain <em>bern</em> etc. </p>

<p>How can this be done in R?</p>
",1
"<p>I am using R for scatter plots, and now also for 3D cloud plots on top of an image.
I have an application that generates a lot of such 3D coordinates and I need to see those coordinates on top of the image at run-time (for debugging purposes).</p>

<p>Is it possible for my Windows application to communicate to R at run-time?</p>
",1
"<p>How would it be possible in the example below to skip the step of writing to file """"test.txt"""", i.e. assign the cat-result to an object, and still achieve the same end result?</p>

<p>I thought I'd include the full example to give background to my problem.</p>

<pre><code>test &lt;- c(""""V 1"""", """"x"""", """"1 2 3"""", """"y"""", """"3 5 8"""", """"V 2"""", """"x"""", """"y"""", """"V 3"""", """"y"""", """"7 2 1"""", """"V 4"""", """"x"""", """"9 3 7"""", """"y"""")

# Write selection to file
cat(test, """"\n"""", file=""""test.txt"""")
test2 &lt;- readLines(""""test.txt"""")
test3 &lt;- strsplit(test2, """"V """")[[1]][-1]

# Find results
x &lt;- gsub(""""([0-9]) (?:x )?([0-9] [0-9] [0-9])?.*"""", """"\\1 \\2 """", test3, perl = TRUE)
y &lt;- gsub(""""([0-9]).* y ?([0-9] [0-9] [0-9])?.*"""", """"\\1 \\2 """", test3, perl = TRUE)

# Eliminate tests with no results
x1 &lt;- x[regexpr(""""[0-9] ([^0-9]).*"""", x) == -1]
y1 &lt;- y[regexpr(""""[0-9] ([^0-9]).*"""", y) == -1]

# Dataframe of results
xdf1 &lt;- read.table(textConnection(x1), col.names=c(""""id"""",""""x1"""",""""x2"""",""""x3""""))
ydf1 &lt;- read.table(textConnection(y1), col.names=c(""""id"""",""""y1"""",""""y2"""",""""y3""""))
closeAllConnections()

# Dataframe of tests with no results
x2 &lt;- x[regexpr(""""[0-9] ([^0-9]).*"""", x) == 1]
y2 &lt;- y[regexpr(""""[0-9] ([^0-9]).*"""", y) == 1]

df1 &lt;- as.integer(x2[x2 == y2])
df1 &lt;- data.frame(id = df1)

# Merge dataframes
results &lt;- merge(xdf1, ydf1, all = TRUE)
results &lt;- merge(results, df1, all = TRUE)
results
</code></pre>

<p>Results in:</p>

<pre><code>  id x1 x2 x3 y1 y2 y3
1  1  1  2  3  3  5  8
2  2 NA NA NA NA NA NA
3  3 NA NA NA  7  2  1
4  4  9  3  7 NA NA NA
</code></pre>
",1
"<p>I have a nice surface that represents nonlinear multi-part regression results on a regression with two independent variables. I would like to plot the regression predicted values as a nice 3D surface and then show the actual values as point that bounce around the surface. This would be the 3D version of plotting a regression line and showing the actuals as points around the line. I can't figure out how to do this with lattice. I'm happy to use another graphing library in R, but I don't know of others that do 3D plots. </p>

<p>Here's a simplified version of what I want to do:</p>

<pre><code>library(lattice)
#set up some simplified data
x &lt;- seq(-.8, .8, .1)
y &lt;- seq(-.8, .8, .1)
myGrid &lt;- data.frame(expand.grid(x,y))
colnames(myGrid) &lt;- c(""""x"""",""""y"""")
myGrid$z &lt;- myGrid$x + myGrid$y
noise &lt;- rnorm(length(myGrid$z),.3,.2)
myGrid$z2 &lt;- myGrid$x + myGrid$y + noise
</code></pre>

<p>z is my smooth surface and z2 are my noisy points mostly slightly above the surface. So the surface looks like this:</p>

<pre><code>wireframe(myGrid$z ~ myGrid$x * myGrid$y, xlab=""""X"""", ylab=""""Y"""", zlab=""""Z"""")
</code></pre>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/09/wireframe.png"""" rel=""""noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/wireframe.png</a></p>

<p>and the cloud of points looks like this:</p>

<pre><code>cloud(myGrid$z2 ~ myGrid$x * myGrid$y, xlab=""""X"""", ylab=""""Y"""", zlab=""""Z"""")
</code></pre>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/09/cloud.png"""" rel=""""noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/cloud.png</a></p>

<p>Is it possible to get both of these in one lattice panel?</p>
",1
"<p>Early in my R life I discovered the pain of R and windows being on different pages when it came to the separator between directories and subdirectories. Eventhough I know about the problem, I am still pained by manually having to put a backslash in front of all my backslashes or replacing all of them with forward slashes. </p>

<p>I love copying a path name or an entire filename with any one of several applications that I have running on my computer (eg. XYPlorer, Everything by voidtools) and then pasting it into Tinn-R. Is there anyway that I could automate the task that I am currently doing manually.</p>

<ul>
<li>Is there a setting in Tinn-R?</li>
<li>Is there a setting in R?</li>
<li>Is there a autohotkey script that could do it for me by default?</li>
</ul>

<hr>

<p>Background for those who don't know what I am talking about</p>

<p>Quoting from R for Windows FAQ, Version for R-2.9.2, B. D. Ripley and D. J. Murdoch</p>

<blockquote>
  <p>Backslashes have to be doubled in R
  character strings, so for example one
  needs
  `""""d:\R-2.9.2\library\xgobi\scripts\xgobi.bat""""'.
  You can make life easier for yourself
  by using forward slashes as path
  separators: they do work under Windows</p>
</blockquote>
",1
"<p>A week ago I would have done this  manually: subset dataframe by group to new dataframes. For each dataframe compute means for each variables, then rbind. very clunky ... </p>

<p>Now i have learned about <code>split</code> and <code>plyr</code>, and I guess there must be an easier way using these tools. Please don't prove me wrong.</p>

<pre><code>test_data &lt;- data.frame(cbind(
var0 = rnorm(100),
var1 = rnorm(100,1),
var2 = rnorm(100,2),
var3 = rnorm(100,3),
var4 = rnorm(100,4),
group = sample(letters[1:10],100,replace=T),
year = sample(c(2007,2009),100, replace=T)))

test_data$var1 &lt;- as.numeric(as.character(test_data$var1))
test_data$var2 &lt;- as.numeric(as.character(test_data$var2))
test_data$var3 &lt;- as.numeric(as.character(test_data$var3))
test_data$var4 &lt;- as.numeric(as.character(test_data$var4))
</code></pre>

<p>I am toying with both <code>ddply</code> but I can't produce what I desire - i.e. a table like this, for each group</p>

<pre><code>group a |2007|2009|
________|____|____|
var1    | xx | xx |
var2    | xx | xx |
etc.    | etc| ect|
</code></pre>

<p>maybe <code>d_ply</code> and some <code>odfweave</code> output would work to. Inputs are very much appreciated.</p>

<p>p.s. I notice that data.frame converts the rnorm to factors in my data.frame? how can I avoid this - I(rnorm(100) doesn't work so I have to convert to numerics as done above</p>
",1
"<p>I have a text file with an <code>id</code> and <code>name</code> column, and I'm trying to read it into a data frame in R:</p>

<pre><code>d = read.table(""""foobar.txt"""", sep=""""\t"""")
</code></pre>

<p>But for some reason, a lot of lines get merged -- e.g., in row 500 of my data frame, I'll see something like</p>

<pre><code>row 500: 500 Bob\n501\tChris\n502\tGrace
</code></pre>

<p>[So if my original text file has, say, 5000 lines, the dimensions of my table will only end up being 1000 rows and 2 columns.]</p>

<p>I've had this happen to me quite a few times. Does anyone know what the problem is, or how to fix it?</p>
",1
"<p>If I have the following dataframe called result</p>

<pre><code>&gt; result
     Name       CV      LCB       UCB
1  within 2.768443 1.869964  5.303702
2 between 4.733483 2.123816 18.551051
3   total 5.483625 3.590745 18.772389

&gt; dput(result,"""""""")
structure(list(Name = structure(c(""""within"""", """"between"""", """"total""""
), .rk.invalid.fields = list(), .Label = character(0)), CV = c(2.768443, 
4.733483, 5.483625), LCB = c(1.869964, 2.123816, 3.590745), UCB = c(5.303702, 
18.551051, 18.772389)), .Names = c(""""Name"""", """"CV"""", """"LCB"""", """"UCB""""
), row.names = c(NA, 3L), class = """"data.frame"""")
</code></pre>

<p>What is the best way to present this data nicely?  Ideally I'd like an image file that can be pasted into a report, or possibly an HTML file to represent the table?</p>

<p>Extra points for setting number of significant figures.</p>
",1
"<p>I have <code>GNU R</code> installed (the <code>S-like</code> statistics package; version 2.8.1) and <code>PostgreSQL (8.4.1)</code>, but I cannot connect <code>GNU R</code> to my <code>RDBMS</code>.</p>

<p>When I first did this (years ago - code lost) <code>DBI</code> for <code>R</code> didn't exist. Now it does. I am also confused as to which <code>R</code> package to use. A quick search returns:</p>

<ul>
<li><a href=""""http://cran.r-project.org/web/packages/RPostgreSQL/"""" rel=""""nofollow noreferrer"""">RPostgreSQL</a> seems to be the most up-to-date</li>
<li><code>RPgSQL</code> Looks abandoned. I wish they would put a date on their webpage. ;-(</li>
</ul>

<p>My <code>Linux distribution</code> doesn't package <code>R</code> packages (irony) but I am comfortable running <code>R CMD INSTALL package.tar.gz</code>. </p>

<p>I installed <code>RPostgreSQL</code>: a lot of documentation says to call <code>dbConnect</code> but I get the following error message: <code>Error: object """"dbConnect"""" not found</code>.</p>
",1
"<p>A colleague of mine needs to plot 101 bull's-eye charts.  This is not her idea.  Rather than have her slave away in Excel or God knows what making these things, I offered to do them in R; mapping a bar plot to polar coordinates to make a bull's-eye is a breeze in <code>ggplot2</code>.</p>

<p>I'm running into a problem, however: the data is already aggregated, so Hadley's example <a href=""""http://had.co.nz/ggplot2/coord_polar.html"""" rel=""""nofollow noreferrer"""">here</a> isn't working for me.  I could expand the counts out into a factor to do this, but I feel like there's a better way - some way to tell the geom_bar how to read the data.</p>

<p>The data looks like this:</p>

<pre><code>    Zoo Animals Bears Polar Bears
1 Omaha      50    10           3
</code></pre>

<p>I'll be making a plot for each zoo - but that part I can manage.</p>

<p>and here's its <code>dput</code>:</p>

<pre><code>structure(list(Zoo = """"Omaha"""", Animals = """"50"""", Bears = """"10"""", `Polar Bears` = """"3""""), .Names = c(""""Zoo"""", 
""""Animals"""", """"Bears"""", """"Polar Bears""""), row.names = c(NA, -1L), class = """"data.frame"""")
</code></pre>

<p>Note: it is significant that Animals >= Bears >= Polar Bears.  Also, she's out of town, so I can't just get the raw data from her (if there was ever a big file, anyway).</p>
",1
"<p>We are working on a social capital project so our data set has a list of an individual's organizational memberships. So each person gets a numeric ID and then a sub ID for each group they are in. The unit of analysis, therefore, is the group they are in. One of our variables is a three point scale for the type of group it is. Sounds simple enough?</p>

<p>We want to bring the unit of analysis to the individual level and condense the type of group it is into a variable signifying how many different types of groups they are in.</p>

<p>For instance, person one is in eight groups. Of those groups, three are (1s), three are (2s), and two are (3s). What the individual level variable would look like, ideally, is 3, because she is in all three types of groups.</p>

<p>Is this possible in the least?</p>
",1
"<p>Let's say I have just called a function, <code>f</code>, and an error occurred somewhere in the function.  I just want to be able to check out the values of different variables right before the error occurred.  </p>

<p>Suppose my gut tells me it's a small bug, so I'm too lazy to use <code>debug(f)</code> and too lazy to insert <code>browser()</code> into the part of the function where I think things are going wrong.  And I'm far too lazy to start putting in <code>print()</code> statements.</p>

<p>Here's an example:</p>

<pre><code>x &lt;- 1:5
y &lt;- x + rnorm(length(x),0,1)
f &lt;- function(x,y) {
  y &lt;- c(y,1)
  lm(y~x)
}
</code></pre>

<p>Calling <code>f(x,y)</code> we get the following error:</p>

<pre><code>Error in model.frame.default(formula = y ~ x, drop.unused.levels = TRUE) : 
  variable lengths differ (found for 'x')
</code></pre>

<p>In this example, I want grab the state of the environment just before <code>lm()</code> is called; that way I can call <code>x</code> and <code>y</code> and see that their lengths are different.  (This example may be too simple, but I hope it gets the idea across.)</p>
",1
"<p>If one has 4 judges and they each give a score for a particular performer or a particular topic then one could have 4 vectors with each containing the score.
But one would like to turn that into a rank to overcome grade inflation by one judge compared to another.
that is easy</p>

<pre><code>transform(assignment,judge1.rank=rank(judge1),judge2.rank=rank(judge2),
                     judge3.rank=rank(judge3), judge4.rank=rank(judge4))
</code></pre>

<p>But then for each row (performer or topic) I want another four columns that for each row states the rank of ranks (or parallel rank) for each judge.</p>

<p>I would like to do something such as</p>

<pre><code>prank(judge1.rank,judge2.rank,judge3.rank,judge4.rank)
</code></pre>

<p>I guess it would have to output as a dataframe.</p>

<p>I thought of using the reshape package to melt the data but that is just a preliminary thought.</p>
",1
"<p>Is there a command in R that will allow you to write a CSV file that has the row and column names of a matrix (dimnames(M))? Whenever I output the file, the names are gone. </p>

<pre><code>help(write)
</code></pre>

<p>doesn't mention that this is possible to do. </p>
",1
"<p>I love the Emacs ESS combination.  I love sending lines, functions, regions, and buffers of code to the command line for evaluation without using the mouse.  </p>

<p>However, I've noticed that the <code>Eval Function</code> command in Emacs is much slower than simply running <code>source(""""fns.R"""")</code>, where <code>fns.R</code> is the file that contains the function I want to evaluate.</p>

<p>Why is this the case?</p>
",1
"<p>Is it possible to source a file without printing all the charts etc (already tried with echo=F)? </p>

<p>In my case I call the png(""""filename%03d.png"""") device early in the script. It is not to big a hassle to comment this out - but all the charts do take a lot of time to render. (the specific file I am working with now uses base-graphics - but mostly I'll be using ggplot2 - which makes the issue somewhat more important (ggplot2 is excellent, but in the current implementation not the fastest))</p>

<p>Thanks</p>
",1
"<p>Here's my situation. I have an object that I've created using <code>read.spss</code>.</p>

<pre><code>&gt; a &lt;- read.spss(...)
&gt; attach(a)
</code></pre>

<p>Now in this object <code>a</code> is a set questions that I would like to pull out that follows a sequence of question numbers:</p>

<pre><code>&gt; q3 &lt;- data.frame(q3_1, q3_2, q3_4, ... q3_27)
</code></pre>

<p>Is there a way to automate it such that it pulls out all questions starting with <code>q3_</code> from the original object into the new <code>q3 data.frame</code>?</p>

<p>I've tried using the <code>paste</code> function to no avail.</p>

<pre><code>&gt; q3 &lt;- data.frame(paste(""""q3_"""",1:27,sep=""""""""))
</code></pre>

<p>That just returns a <code>data.frame</code> with the pasted sequence. </p>

<p>Ideally, I would like something that pulls in everything from a question beginning with a <code>qX_</code>, as some values are missing or outdated. </p>
",1
"<p>I have two random variables:</p>

<pre><code>X ~ binom(n, p1)
Y ~ binom(n, p2)
</code></pre>

<p>n is a known parameter (the total number of trials), while p1 and p2 are unknown.</p>

<p>I have one sample from each distribution (x from X, and y from Y). To give some context, x and y are numbers of true positives from two different classifiers, at a fixed selectivity.</p>

<p>I would like to use R to test the null hypothesis p1=p2 against p1 > p2.</p>

<p>In particular, I would like to be able to find the p-value P(X-Y=x-y | p1=p2), and if possible, a confidence interval for the difference between p1 and p2.</p>

<p>What is the best way to go about this?</p>
",1
"<p>I have a density object dd created like this:</p>

<pre><code>x1 &lt;- rnorm(1000) 
x2 &lt;- rnorm(1000, 3, 2) 
x &lt;- rbind(x1, x2)
dd &lt;- density(x) 
plot(dd)
</code></pre>

<p>Which produces this very non-Gaussian distribution:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/09/nongaus.png"""" rel=""""nofollow noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/09/nongaus.png</a></p>

<p>I would ultimately like to get random deviates from this distribution similar to how rnorm gets deviates from a normal distribution. </p>

<p>The way I am trying to crack this is to get the CDF of my kernel and then get it to tell me the variate if I pass it a cumulative probability (inverse CDF). That way I can turn a vector of uniform random variates into draws from the density. </p>

<p>It seems like what I am trying to do should be something basic that others have done before me. Is there a simple way or a simple function to do this? I hate reinventing the wheel. </p>

<p>FWIW I found <a href=""""http://tolstoy.newcastle.edu.au/R/help/01a/1957.html"""" rel=""""nofollow noreferrer"""">this R Help article</a> but I can't grok what they are doing and the final output does not seem to produce what I am after. But it could be a step along the way that I just don't understand. </p>

<p>I've considered just going with a <a href=""""http://hosho.ees.hokudai.ac.jp/~kubo/Rdoc/library/SuppDists/html/Johnson.html"""" rel=""""nofollow noreferrer"""">Johnson distribution from the suppdists package</a> but Johnson won't give me the nice bimodal hump which my data has. </p>
",1
"<p>Is there a mode in emacs that does syntax highlighting for the R programming language? R-mode doesn't seem to work...</p>
",1
"<p>I'm trying to write a function to automate doing a variance analysis, part of which involves doing some further calculations.  The method I've been using isn't very robust, if variable names change then it stops working.</p>

<p>For this dummy data</p>

<pre><code>&gt; dput(assayvar,"""""""")
structure(list(Run = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 
3L, 3L, 4L, 4L, 4L), .rk.invalid.fields = list(), .Label = c(""""1"""", 
""""2"""", """"3"""", """"4""""), class = """"factor""""), Actual = c(246.3, 253.6, 247.6, 
249, 249, 251.3, 254.9, 254.1, 253.2, 250, 248.9, 250.3)), .Names = c(""""Run"""", 
""""Actual""""), row.names = c(NA, 12L), class = """"data.frame"""")

&gt; assayaov&lt;-aov(Actual~Run+Error(Run),data=assayvar)
&gt; str(summary(assayaov))
List of 2
 $ Error: Run   :List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  3 variables:
  .. ..$ Df     : num 3
  .. ..$ Sum Sq : num 46.5
  .. ..$ Mean Sq: num 15.5
  ..- attr(*, """"class"""")= chr [1:2] """"summary.aov"""" """"listof""""
 $ Error: Within:List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  5 variables:
  .. ..$ Df     : num 8
  .. ..$ Sum Sq : num 36.4
  .. ..$ Mean Sq: num 4.55
  .. ..$ F value: num NA
  .. ..$ Pr(&gt;F) : num NA
  ..- attr(*, """"class"""")= chr [1:2] """"summary.aov"""" """"listof""""
 - attr(*, """"class"""")= chr """"summary.aovlist""""
</code></pre>

<p>But for this dummy data</p>

<pre><code>&gt; dput(BGBottles,"""""""")
structure(list(Machine = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 
3L, 3L, 3L, 4L, 4L, 4L), .rk.invalid.fields = structure(list(), .Names = character(0)), .Label = c(""""1"""", 
""""2"""", """"3"""", """"4""""), class = """"factor""""), Weight = c(14.23, 14.96, 14.85, 
16.46, 16.74, 15.94, 14.98, 14.88, 14.87, 15.94, 16.07, 14.91
)), .Names = c(""""Machine"""", """"Weight""""), row.names = c(NA, 12L), class = """"data.frame"""")

&gt; bgaov&lt;-aov(Weight~Machine+Error(Machine),data=BGBottles)
&gt; str(summary(bgaov))
List of 2
 $ Error: Machine:List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  3 variables:
  .. ..$ Df     : num 3
  .. ..$ Sum Sq : num 5.33
  .. ..$ Mean Sq: num 1.78
  ..- attr(*, """"class"""")= chr [1:2] """"summary.aov"""" """"listof""""
 $ Error: Within :List of 1
  ..$ :Classes ‘anova’ and 'data.frame':    1 obs. of  5 variables:
  .. ..$ Df     : num 8
  .. ..$ Sum Sq : num 1.45
  .. ..$ Mean Sq: num 0.182
  .. ..$ F value: num NA
  .. ..$ Pr(&gt;F) : num NA
  ..- attr(*, """"class"""")= chr [1:2] """"summary.aov"""" """"listof""""
 - attr(*, """"class"""")= chr """"summary.aovlist""""
</code></pre>

<p>So the code to get the mean square value</p>

<pre><code>machine&lt;-summary(bgaov)$""""Error: Machine""""[[1]]$""""Mean Sq""""
</code></pre>

<p>Doesn't work, because the Machine but won't always be Machine.</p>

<p>Any better way to do this ?</p>
",1
"<p>Could you please give an example on how that might be done using the doSNOW ?</p>

<p>(I asked the same question <a href=""""http://blog.revolution-computing.com/2009/08/parallel-programming-with-foreach-and-snow.html"""" rel=""""nofollow noreferrer"""">here</a>, but only got a partial reply)
Tal</p>
",1
"<p>I'm using ggplot2 to make some bullseye charts in R.  They look delightful, and everyone is very pleased - except that they'd like to have the values of the bullseye layers plotted on the chart.  I'd be happy just to put them in the lower-right corner of the plot, or even in the plot margins, but I'm having some difficulty doing this.</p>

<p>Here's the example data again:</p>

<pre><code>critters &lt;- structure(list(Zoo = """"Omaha"""", Animals = 50, Bears = 10, PolarBears = 3), .Names = c(""""Zoo"""", 
""""Animals"""", """"Bears"""", """"PolarBears""""), row.names = c(NA, -1L), class = """"data.frame"""")
</code></pre>

<p>And how to plot it:</p>

<pre><code>d &lt;- data.frame(animal=factor(c(rep(""""Animals"""", critters$Animals),
       rep(""""Bears"""", critters$Bears), rep(""""PolarBears"""", critters$PolarBears)),
       levels = c(""""PolarBears"""", """"Bears"""", """"Animals""""), ordered= TRUE))
grr &lt;- ggplot(d, aes(x = factor(1), fill = factor(animal))) +  geom_bar() +
  coord_polar() + labs(x = NULL, fill = NULL) +
  scale_fill_manual(values = c(""""firebrick2"""", """"yellow2"""", """"green3"""")) +
  opts(title = paste(""""Animals, Bears and Polar Bears:\nOmaha Zoo"""", sep=""""""""))
</code></pre>

<p>I'd like to add a list to, say, the lower right corner of this plot saying,</p>

<pre><code>Animals: 50
Bears: 10
PolarBears: 3
</code></pre>

<p>But I can't figure out how.  My efforts so far with <code>annotate()</code> have been thwarted, in part by the polar coordinates.  If I have to add the numbers to the title, so be it - but I always hold out hope for a more elegant solution.  Thanks in advance.</p>

<p>EDIT:
An important note for those who come after: the bullseye is a bar plot mapped to polar coordinates.  The ggplot2 default for bar plots is, sensibly, to stack them.  However, that means that the rings of your bullseye will also be stacked (e.g. the radius in my example equals the sum of all three groups, 63, instead of the size of the largest group, 50).  I <strong>don't</strong> think that's what most people expect from a bullseye plot, especially when the groups are nested.  Using <code>geom_bar(position = position_identity())</code> will turn the stacked rings into layered circles.</p>

<p>EDIT 2: Example from <a href=""""http://docs.ggplot2.org/current/coord_polar.html"""" rel=""""nofollow noreferrer"""">ggplot2</a> docs:<br>
<img src=""""https://i.stack.imgur.com/yL4zi.png"""" alt=""""enter image description here""""></p>
",1
"<p>In <code>R</code> on <code>Windows</code>, <code>tempdir()</code> returns a path that contains short names for <code>non 8dot3 directory names</code>. </p>

<p>How do I expand those to long names? </p>

<p>An answer that uses pure <code>R</code> code is favorable, but one that uses well-known shell commands used via <code>system()</code> is fine as a backup.</p>
",1
"<p>Let's say I have a matrix <code>x</code> which contains 10 rows and 2 columns. I want to generate a new matrix <code>M</code> that contains each unique pair of rows from <code>x</code> - that is, a new matrix with 55 rows and 4 columns.</p>

<p>E.g.,</p>

<pre><code>x &lt;- matrix (nrow=10, ncol=2, 1:20)

M &lt;- data.frame(matrix(ncol=4, nrow=55))
k &lt;- 1
for (i in 1:nrow(x))
for (j in i:nrow(x))
{
    M[k,] &lt;- unlist(cbind (x[i,], x[j,]))
    k &lt;- k + 1
}
</code></pre>

<p>So, <code>x</code> is:</p>

<pre><code>      [,1] [,2]
 [1,]    1   11
 [2,]    2   12
 [3,]    3   13
 [4,]    4   14
 [5,]    5   15
 [6,]    6   16
 [7,]    7   17
 [8,]    8   18
 [9,]    9   19
[10,]   10   20
</code></pre>

<p>And then <code>M</code> has 4 columns, the first two are one row from <code>x</code> and the next 2 are another row from <code>x</code>:</p>

<pre><code>&gt; head(M,10)
   X1 X2 X3 X4
1   1 11  1 11
2   1 11  2 12
3   1 11  3 13
4   1 11  4 14
5   1 11  5 15
6   1 11  6 16
7   1 11  7 17
8   1 11  8 18
9   1 11  9 19
10  1 11 10 20
</code></pre>

<p>Is there either a faster or simpler (or both) way of doing this in R?</p>
",1
"<p>I was wondering if anyone knew of a good way to get R or ESS to stop executing the rest of the code beyond the point at which an error occurs if I am evaluating a region or buffer (I've only found the opposite request in the help archives). I was looking in the R help files but <code>option(error=stop)</code> will only stop execution of the offending function or statement but not those that follow it. Thanks!</p>
",1
"<p>Does anyone know of an R package that solves <a href=""""http://en.wikipedia.org/wiki/Longest_common_substring_problem"""" rel=""""noreferrer"""">the longest common substring problem</a>? I am looking for something fast that could work on vectors.</p>
",1
"<p>Does anyone have any wisdom on workflows for data analysis related to custom report writing?  The use-case is basically this:</p>

<ol>
<li><p>Client commissions a report that uses data analysis, e.g. a population estimate and related maps for a water district.</p></li>
<li><p>The analyst downloads some data, munges the data and saves the result (e.g. adding a column for population per unit, or subsetting the data based on district boundaries).</p></li>
<li><p>The analyst analyzes the data created in (2), gets close to her goal, but sees that needs more data and so goes back to (1).</p></li>
<li><p>Rinse repeat until the tables and graphics meet QA/QC and satisfy the client.</p></li>
<li><p>Write report incorporating tables and graphics.</p></li>
<li><p>Next year, the happy client comes back and wants an update.  This should be as simple as updating the upstream data by a new download (e.g. get the building permits from the last year), and pressing a """"RECALCULATE"""" button, unless specifications change.</p></li>
</ol>

<p>At the moment, I just start a directory and ad-hoc it the best I can.  I would like a more systematic approach, so I am hoping someone has figured this out...  I use a mix of spreadsheets, SQL, ARCGIS, R, and Unix tools.</p>

<p>Thanks!</p>

<p>PS:</p>

<p>Below is a basic Makefile that checks for dependencies on various intermediate datasets (w/ <code>.RData</code> suffix) and scripts (<code>.R</code> suffix).  Make uses timestamps to check dependencies, so if you <code>touch ss07por.csv</code>, it will see that this file is newer than all the files / targets that depend on it, and execute the given scripts in order to update them accordingly.  This is still a work in progress, including a step for putting into SQL database, and a step for a templating language like sweave. Note that Make relies on tabs in its syntax, so read the manual before cutting and pasting. Enjoy and give feedback!</p>

<p><a href=""""http://www.gnu.org/software/make/manual/html_node/index.html#Top"""" rel=""""noreferrer"""">http://www.gnu.org/software/make/manual/html_node/index.html#Top</a></p>

<pre>
R=/home/wsprague/R-2.9.2/bin/R

persondata.RData : ImportData.R ../../DATA/ss07por.csv Functions.R
   $R --slave -f ImportData.R

persondata.Munged.RData : MungeData.R persondata.RData Functions.R
      $R --slave -f MungeData.R

report.txt:  TabulateAndGraph.R persondata.Munged.RData Functions.R
      $R --slave -f TabulateAndGraph.R > report.txt

</pre>
",1
"<p>I've never been able to figure out how to get the <code>PgDn/PgUp keys</code> to work in the <code>R Graphics Viewer</code>. </p>

<p>Even the <code>demo()</code> programs don't seem to support it. </p>

<p>Anyone able to point me to some code that shows how this can be implemented?</p>
",1
"<p>The function below works perfectly for my purpose. The display is wonderful. Now my problem is I need to be able to do it again, many times, on other variables that fit other patterns. </p>

<p>In this example, I've output results for """"q4a"""", I would like to be able to do it for sequences of questions that follow patterns like: q4 &lt; a - z > or q &lt; 4 - 10 >&lt; a - z >, automagically. </p>

<p>Is there some way to iterate this such that the specified variable (in this case q4a) changes each time?</p>

<p>Here's my function: </p>

<pre><code>require(reshape) # Using it for melt
require(foreign) # Using it for read.spss

d1 &lt;- read.spss(...) ## Read in SPSS file

attach(d1,warn.conflicts=F) ## Attach SPSS data

q4a_08 &lt;- d1[,grep(""""q4a_"""",colnames(d1))] ## Pull in everything matching q4a_X
q4a_08 &lt;- melt(q4a_08) ## restructure data for post-hoc

detach(d1)

q4aaov &lt;- aov(formula=value~variable,data=q4a) ## anova
</code></pre>

<p>Thanks in advance!</p>
",1
"<p>does anyone know how to use R to plot a histogram with the columns stacked up by more than 1 variables? Like the """"stacked column"""" graph in excel. </p>

<p>Thank you!</p>
",1
"<p>We all love robust measures like medians and interquartile ranges, but lets face it, in many fields, boxplots almost never show up in published articles, while means and standard errors do so all the time.</p>

<p>It's simple in lattice, ggplot2, etc to draw boxplots and the galleries are full of them. Is there an equally straightforward way to draw means and standard errors, conditioned by a categorical variable?</p>

<p>I'm taking about plots like these:</p>

<p><a href=""""http://freakonomics.blogs.nytimes.com/2008/07/30/how-big-is-your-halo-a-guest-post/"""" rel=""""noreferrer"""">http://freakonomics.blogs.nytimes.com/2008/07/30/how-big-is-your-halo-a-guest-post/</a></p>

<p>Or what are called """"means diamonds"""" in JMP (see Figure 3):</p>

<p><a href=""""http://blogs.sas.com/jmp/index.php?/archives/127-What-Good-Are-Error-Bars.html"""" rel=""""noreferrer"""">http://blogs.sas.com/jmp/index.php?/archives/127-What-Good-Are-Error-Bars.html</a></p>
",1
"<p>Is <a href=""""http://www.rforge.net/rJava/"""" rel=""""nofollow noreferrer"""">rjava</a> the only way to connect R to Java? I am asking because there is a disclaimer at the end of the web page:</p>

<blockquote>
  <p>This interface uses Java reflection
  API to find the correct method so it
  is much slower and may not be right
  (works for simple examples but may not
  for more complex ones). For now its
  use is discouraged in programs as it
  may change in the future.</p>
</blockquote>

<p>This is slightly concerning. How do you address this issue? I know that Rweka has a self-contained interface, so I may look into that package, but maybe many R users have already gone through the pains.</p>
",1
"<p>I've learned R by toying, and I'm starting to think that I'm abusing the tapply function. Are there better ways to do some of the following actions? Granted, they work, but as they get more complex I wonder if I'm losing out on better options. I'm looking for some criticism, here:</p>

<pre><code>tapply(var1, list(fac1, fac2), mean, na.rm=T)

tapply(var1, fac1, sum, na.rm=T) / tapply(var2, fac1, sum, na.rm=T)

cumsum(tapply(var1, fac1, sum, na.rm=T)) / sum(var1)
</code></pre>

<p>Update: Here's some example data...</p>

<pre><code>     var1    var2 fac1           fac2
1      NA  275.54   10      (266,326]
2      NA  565.89   10      (552,818]
3      NA  815.41    6      (552,818]
4      NA  281.77    6      (266,326]
5      NA  640.24   NA      (552,818]
6      NA   78.42   NA     [78.4,266]
7      NA 1027.06   NA (818,1.55e+03]
8      NA  355.20   NA      (326,552]
9      NA  464.52   NA      (326,552]
10     NA 1397.11   10 (818,1.55e+03]
11     NA  229.82   NA     [78.4,266]
12     NA  542.77   NA      (326,552]
13     NA  829.32   NA (818,1.55e+03]
14     NA  284.78   NA      (266,326]
15     NA  194.97   10     [78.4,266]
16     NA  672.55    8      (552,818]
17     NA  348.01   10      (326,552]
18     NA 1550.79    9 (818,1.55e+03]
19 101.98  101.98    4     [78.4,266]
20     NA  292.80    6      (266,326]
</code></pre>

<p>Update data dump:</p>

<pre><code>structure(list(var1 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, 101.98, NA), var2 = c(275.54, 
565.89, 815.41, 281.77, 640.24, 78.42, 1027.06, 355.2, 464.52, 
1397.11, 229.82, 542.77, 829.32, 284.78, 194.97, 672.55, 348.01, 
1550.79, 101.98, 292.8), fac1 = c(10L, 10L, 6L, 6L, NA, NA, NA, 
NA, NA, 10L, NA, NA, NA, NA, 10L, 8L, 10L, 9L, 4L, 6L), fac2 = structure(c(2L, 
4L, 4L, 2L, 4L, 1L, 5L, 3L, 3L, 5L, 1L, 3L, 5L, 2L, 1L, 4L, 3L, 
5L, 1L, 2L), .Label = c(""""[78.4,266]"""", """"(266,326]"""", """"(326,552]"""", 
""""(552,818]"""", """"(818,1.55e+03]""""), class = """"factor"""")), .Names = c(""""var1"""", 
""""var2"""", """"fac1"""", """"fac2""""), row.names = c(NA, -20L), class = """"data.frame"""")
</code></pre>
",1
"<p>Let's say I want to reproduce an example posted on StackOverflow.  Some have suggested posters use <a href=""""https://stackoverflow.com/questions/1265129/how-to-export-the-definition-of-an-r-object-to-plain-text-so-that-others-can-recr""""><code>dput()</code> to help streamline this process</a> or one of the <a href=""""http://stat.ethz.ch/R-manual/R-patched/library/datasets/html/00Index.html"""" rel=""""nofollow noreferrer"""">datasets available in the base package</a>.  </p>

<p>In this case, however, suppose I have only been given the output of the dataframe:</p>

<pre><code>&gt; site.data
    site year     peak
1  ALBEN    5 101529.6
2  ALBEN   10 117483.4
3  ALBEN   20 132960.9
8  ALDER    5   6561.3
9  ALDER   10   7897.1
10 ALDER   20   9208.1
15 AMERI    5  43656.5
16 AMERI   10  51475.3
17 AMERI   20  58854.4
</code></pre>

<p>Do I have other options besides saving this as a text file and using <code>read.table()</code>?</p>
",1
"<p>I use OS X and I am currently cooperating with a windows user and deploying the scripts on a linux server. We use git for version control, and I keep getting R scripts from his end where the character encoding used has  mixed  latin1 and utf8 encodings. So I have a couple of questions.</p>

<ol>
<li><p>Is there a simple to use editor for windows that handle UTF8 with more grace than Winedt that my coauthor currently uses?  I use emacs, but I am having a hard time selling getting him to switch.</p></li>
<li><p>How to set up R in Windows so that it defaults to reading and writing UTF8?</p></li>
</ol>

<p>This is driving me crazy. Has anyone found a solution for it (be it in the workflow or in the software used) who cares to share?  </p>
",1
"<p>I'm trying to write a function to do a particular job (in my case, analyse a data set for outliers) so the first things I want to do is look at how other people have done similar jobs.</p>

<p>I can do this to load a particular package and examine the code of a function, but some functions seem to depend on what class of object you throw at it</p>

<pre><code>&gt;library(outliers)
&gt; fix(outlier)

function (x, opposite = FALSE, logical = FALSE) 
{
    if (is.matrix(x)) 
        apply(x, 2, outlier, opposite = opposite, logical = logical)
    else if (is.data.frame(x)) 
        sapply(x, outlier, opposite = opposite, logical = logical)
    else {
        if (xor(((max(x) - mean(x)) &lt; (mean(x) - min(x))), opposite)) {
            if (!logical) 
                min(x)
            else x == min(x)
        }
        else {
            if (!logical) 
                max(x)
            else x == max(x)
        }
    }
}
</code></pre>

<p>How can you look at the code of something that changes depending on the object ?</p>

<p>Edit:</p>

<p>OK, Palm &lt;- face.  The function I used as an example just calls itself, but allt he code is there... I have seen other examples (but can't think of any offhand) where the function did do other things depending on the class of the object thrown at it, so the question stands, even though it's a bad example !</p>
",1
"<p>I would like to be able to create a sequence of letters in R (to assist in importing data from a SPSS file)</p>

<p>It's quite easy to create a sequence of numbers, for example:</p>

<pre><code>seq(1,1000)
[1] 1 2 3 4 5 6 ... 1000

paste(""""something_"""",1:12,sep="""""""")
[1] something1 something2 ... something12
</code></pre>

<p>But is there any functionality for appending, pasting, or creating sequences of letters like this? </p>

<pre><code>paste(""""This_"""",a:z,sep="""""""")
[1]This_a This_b This_c ... This_4z
</code></pre>

<p>Thanks in advance! </p>
",1
"<p>I have some US demographic and firmographic data.<br>
I would like to plot zipcode areas in a state or a smaller region (e.g. city). Each area would be annotated by color and/or text specific to that area. The output would be similar to <a href=""""http://maps.huge.info/"""" rel=""""nofollow noreferrer"""">http://maps.huge.info/</a> but a) with annotated text; b) pdf output; c) scriptable in R or Python.</p>

<p>Is there any package and code that allows me to do this?</p>
",1
"<p>As part of my data analysis workflow, I want to test for outliers, and then do my further calculation with and without those outliers.  </p>

<p>I've found the outlier package, which has various tests, but I'm not sure how best to use them for my workflow.</p>
",1
"<p>If I am running a long R script from the command line (R --slave script.R), how can I get it to give line numbers at errors?  </p>

<p>I don't want to add debug commands to the script if at all possible -- I just want R to behave like most other scripting languages ...</p>
",1
"<p>For the purposes of teaching and preparing written instructions about R, one of the things that's always frustrated me is that I can't simply copy commands and output from R and paste them into another R session. For example, if I do something trivial, such as</p>

<pre><code>&gt; x &lt;- rnorm(10)
&gt; x
 [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
 [7]  0.94437690  0.08083207  0.62260363  1.89305469
</code></pre>

<p>If I copy and paste that into a document or even here in this post, you (and my students) can not then just highlight it, copy it and paste it into an R session successfully</p>

<pre><code>&gt; &gt; x &lt;- rnorm(10)
Error: syntax error
&gt; &gt; x
Error: syntax error
&gt;  [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
Error: syntax error
&gt;  [7]  0.94437690  0.08083207  0.62260363  1.89305469
Error: syntax error
</code></pre>

<p>You might want to do this to test your installation of R, compare my output to yours, or simply to make use of a function I've offered.</p>

<p>So, what I'd like to be able to do is to change the default prompt from > to either an empty string or a blank space and also prefix all output lines with a hash mark #. That way, I could use R interactively to generate a session that looks like</p>

<pre><code>x &lt;- rnorm(10)
x
# [1]  1.76975998  1.19722850 -0.39274507 -1.10979974  0.52320473 -0.08643833
# [7]  0.94437690  0.08083207  0.62260363  1.89305469
</code></pre>

<p>which <em>could</em> be copy/pasted into an R session successfully. It would make prepping R code for a journal article, students, lectures, etc. much easier for me (and maybe for others?)</p>

<p>I've poked around the documentation with no luck... any ideas? pointers?</p>

<p>Currently, I'm using R on a Mac either via the R.app GUI or from Terminal.</p>
",1
"<p>How can I render the value of points in a <code>plot</code> in the <code>plot</code> itself?</p>

<p>Thank you.</p>
",1
"<p>I'm wondering about the best way to deploy R.  Matlab has the """"matlab compiler"""" (MCR).  There has been discussion about something similar in the past for R that would compile R into C or C++.  Does anyone have any experience with the <a href=""""http://www.hipersoft.rice.edu/rcc/"""" rel=""""noreferrer"""">R to C Compiler (RCC) that was developed by John Garvin at Rice</a>?</p>

<p>I've looked into it, and it seems to be the only project that worked on compiling R code into executable code.  And as far as I can tell, it isn't still being used.  </p>

<p><i> [Edit 1:]</i>: To be clear, I know that there are C and C++ (and Java, Python, etc.) interfaces to R (rJava, rcpp, Rpy, etc.).  I'm wondering about specific ways to compile and deploy R code without installing R in advance.</p>

<p><i> [Edit 2:]</i>: John Mellor-Crummey tells me that they're still working on RCC and hope to make it available in 4 months or so (at the earliest).  I'll update this further if I find anything else out.</p>
",1
"<p>I want to make a Flash or Flex front end for my R code, I want to call an R function from a website (using Flash) what is the best way to go about connecting Flash and R?</p>
",1
"<p>Sometimes on an R help page the phrase """"not run"""" appears in comments. Check out this from the help page for """"with()"""":</p>

<pre><code>Examples
require(stats); require(graphics)
#examples from glm:
**## Not run:** 
library(MASS)
with(anorexia, {
    anorex.1 &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt),
                    family = gaussian)
    summary(anorex.1)
})
## End(**Not run**)
</code></pre>

<p>What does the """"not run"""" mean in the example code?</p>
",1
"<p>Where each datapoint has a pairing of A and B and there multiple entries in A and multiple entires in B. IE multiple syndromes and multiple diagnoses, although for each datapoint there is one single syndrome-diagnoses pair.</p>

<p>Examples, suggestions, or ideas much appreciated</p>

<p>here's what the data is like. And I want to see connections between values of A and B (how many GG's are linked to TTs etc). Both are nominal datatypes.</p>

<pre><code>ID,A ,B 
1,GG,TT
2,AA,SS
3,BB,XX
4,DD,SS
5,DD,TT
6,CC,XX
7,HH,ZZ
8,AA,TT
9,CC,RR
10,DD,ZZ
11,AA,XX
12,AA,TT
13,DD,SS
14,DD,XX
15,AA,YY
16,CC,ZZ
17,FF,SS
18,FF,XX
19,BB,VV
20,GG,VV
21,GG,SS
22,AA,RR
23,AA,TT
24,AA,SS
25,CC,VV
26,CC,TT
27,FF,RR
28,GG,UU
29,CC,TT
30,BB,ZZ
31,II,TT
32,FF,RR
33,BB,SS
34,GG,YY
35,FF,RR
36,BB,VV
37,II,RR
38,CC,YY
39,FF,VV
40,AA,XX
41,AA,ZZ
42,GG,VV
43,BB,UU
44,II,UU
45,II,SS
46,DD,SS
47,AA,UU
48,BB,VV
49,GG,TT
50,BB,TT
</code></pre>
",1
"<p>How do I add the values from many variables?</p>

<p>If I just had two variables (columns) I could simply go:</p>

<pre><code>summation.variable &lt;- variable1 + variable2
</code></pre>

<p>or if it was all in a dataframe:</p>

<pre><code>transform(dataframe, summation.col = column1 + column2)
</code></pre>

<p>How do I do it if I have about 10 variables and I do not want to type each one as in col1+col2+col3+col4. To make matters worse my columns have quite long names and at times the exact columns that I use can change. I have a character vector with all the relevant column names in it but cannot think how to use it. </p>

<p>The following is useless since it adds every value in every column in every row and gives a single value for the whole lot.</p>

<pre><code>sum(metrics)
</code></pre>
",1
"<p>(Asking this on behalf of a member of our Bay Area R Group.  I did not have a ready answer as I run ESS within Emacs.  I assume this question refers to running R within the command-line environment that ships in the standard Windows distribution).</p>

<p>I'm new to R, but what I've found in searching for my answer is that there isn't anything about customizing R so that I can work faster.</p>

<p>One of my main problems is the lack of word wrapping in my version running on Windows XP. I noticed that my friends with the Mac OS have word wrapping.</p>

<p>Is there a way to enable word wrapping in R running on a Windows machine?</p>
",1
"<p>Periodically I program sloppily. Ok, I program sloppily all the time, but sometimes that catches up with me in the form of out of memory errors. I start exercising a little discipline in deleting objects with the rm() command and things get better. I see mixed messages online about whether I should explicitly call gc() after deleting large data objects. Some say that before R returns a memory error it will run gc() while others say that manually forcing gc is a good idea. </p>

<p>Should I run gc() after deleting large objects in order to ensure maximum memory availability?</p>
",1
"<p>Does anyone have any good thoughts on how to code complex tabulations in R?</p>

<p>I am afraid I might be a little vague on this, but I want to set up a script to create a bunch of tables of a complexity analogous to the stat abstract of the united states. </p>

<p>e.g.: <a href=""""http://www.census.gov/compendia/statab/tables/09s0015.pdf"""" rel=""""nofollow noreferrer"""">http://www.census.gov/compendia/statab/tables/09s0015.pdf</a> </p>

<p>And I would like to avoid a whole bunch of rbind and hbind statements.</p>

<p>In <code>SAS</code>, I have heard, there is a table creation specification language; I was wondering if there was something of similar power for <code>R</code>?</p>

<p>Thanks!</p>
",1
"<p>OK, I've got two named lists, one is """"expected"""" and one is """"observed"""". They may be complex in structure, with arbitrary data types. I want to get a new list containing just those elements of the observed list that are different from what's in the expected list. Here's an example:</p>

<pre><code>Lexp &lt;- list(a=1, b=""""two"""", c=list(3, """"four""""))
Lobs &lt;- list(a=1, c=list(3, """"four""""), b=""""ni"""")
Lwant &lt;- list(b=""""ni"""")
</code></pre>

<p>Lwant is what I want the result to be. I tried this:</p>

<pre><code>&gt; setdiff(Lobs, Lexp)
[[1]]
[1] """"ni""""
</code></pre>

<p>Nope, that loses the name, and I don't think setdiff pays attention to the names. Order clearly doesn't matter here, and I don't want <em>a=1</em> to match with <em>b=1</em>. </p>

<p>Not sure what a good approach is... Something that loops over a list of <em>names(Lobs)</em>? Sounds clumsy and non-R-like, although workable... Got any elegant ideas?</p>
",1
"<p>I'd like to use <code>correlation clustering</code> and I figure <code>R</code> is a good place to start.</p>

<p>I can present the data to <code>R</code> as a set of large, sparse vectors or as a table with a pre-computed dissimilarity matrix.</p>

<p>My questions are:</p>

<ul>
<li>are there existing <code>R</code> functions to turn this into a <code>hierarchical cluster</code> with <code>agnes</code> that uses <code>correlation clustering</code>?</li>
<li>will I have to implement the (admittedly simple) <code>correlation clustering</code>function by hand, if so how do I make it play well with <code>agnes</code>?</li>
</ul>
",1
"<p>A friend sent me along this great tutorial on <a href=""""http://www.stanford.edu/~cengel/cgi-bin/anthrospace/scraping-new-york-times-articles-with-r"""" rel=""""noreferrer"""">webscraping NYtimes with R</a>. I would really love to try it. However, the first step is to installed a package called RJSONIO from source.</p>

<p>I know R reasonably well, but I have no idea how to install a package from source.</p>

<p>I'm running Mac OSX.</p>
",1
"<p>I'm trying to """"apply"""" a function that does """"lag""""s on zoo objects in R.</p>

<p>The function works correctly if I pass a single zoo vector - it applys the lag and everything works.</p>

<p>However, if I <code>apply( data, 1, function )</code> then the lag doesn't work.  There is no error, just the equivalent of a zero lag.</p>

<p>This is also the case with a simple <code>apply( data, 1, lag )</code>.</p>

<p>Can anyone explain why this should be the case?  Is there anything I can do to make the lag to occur?</p>
",1
"<p><strong><em>Background:</em></strong> </p>

<p>I'm running a Monte Carlo simulation to show that a particular process (a cumulative mean) does <strong>not</strong> converge over time, and often diverges wildly in simulation (the expectation of the random variable = infinity).  I want to plot about 10 of these simulations on a line chart, where the x axis has the iteration number, and the y axis has the cumulative mean up to that point.</p>

<p><strong><em>Here's my problem:</em></strong></p>

<p>I'll run the first simulation (each sim. having 10,000 iterations), and build the main plot based on its current range.  But often one of the simulations will have a range a few orders of magnitude large than the first one, so the plot flies outside of the original range.  So, <strong>is there any way to dynamically update the ylim or xlim of a plot upon adding a new set of points or lines?</strong></p>

<p>I can think of two <strong>workarounds</strong> for this: 1. store each simulation, then pick the one with the largest range, and build the base graph off of that (not elegant, and I'd have to store a lot of data in memory, but would probably be laptop-friendly <strong>[[EDIT: as Marek points out, this is not a memory-intense example, but if you know of a nice solution that'd support far more iterations such that it becomes an issue (think high dimensional walks that require much, much larger MC samples for convergence) then jump right in]]</strong>) 2. find a seed that appears to build a nice looking version of it, and set the ylim manually, which would make the demonstration reproducible.</p>

<p>Naturally I'm holding out for something more elegant than my workarounds.  Hoping this isn't too pedestrian a problem, since I imagine it's not uncommon with simulations in R.  Any ideas?</p>
",1
"<p>I have some data, </p>

<pre><code>calvarbyruno.1&lt;-structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250), Run = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c(""""1"""", """"2"""", """"3""""), class = """"factor""""), 
    PAR = c(1.25000000000000e-05, 0.000960333333333333, 0.00205833333333334, 
    0.00423333333333333, 0.0322333333333334, 0.614433333333334, 
    1.24333333333333, 1.86333333333333), PredLin = c(-0.0119152187070942, 
    0.00375925114245899, 0.0272709559167888, 0.0586198956158952, 
    0.215364594111427, 0.372109292606959, 1.15583278508462, 1.93955627756228
    ), PredQuad = c(-0.0615895732702735, -0.0501563307416599, 
    -0.0330831368244257, -0.0104619953693943, 0.100190275883806, 
    0.20675348710041, 0.6782336426345, 1.04748729725370)), .Names = c(""""Nominal"""", 
""""Run"""", """"PAR"""", """"PredLin"""", """"PredQuad""""), row.names = c(NA, 8L), class = """"data.frame"""")
calweight &lt;- -2
</code></pre>

<p>for which I've created both a linear and a quadratic lm model</p>

<pre><code>callin.1&lt;-lm(PAR~Nominal,data=calvarbyruno.1,weight=Nominal^calweight)
calquad.1&lt;-lm(PAR~Nominal+I(Nominal^2),data=calvarbyruno.1,weight=Nominal^calweight)
</code></pre>

<p>I can then plot my data values using ggplot2</p>

<pre><code>qplot(PAR,Nominal,data=calvarbyruno.1)
</code></pre>

<p>But can't work out how to overlay a line representing the two lm objects... Any ideas ?</p>
",1
"<p>I have some data in a dataframe calvarbyruno.1 with variables Nominal and PAR that represent the Peak Area Ratio (PAR) found from analysis of a set of standards using a particular analytical technique, and two lm models of that data (linear and quadratic) for the relationship PAR ~ Nominal.  I'm trying to use the predict.lm function to back calculate Nominal values, given my PAR values, but both predict.lm and fitted seem to only give me PAR values.  I'm slowly loosing my mojo, can anyone help ?</p>

<p>calvarbyruno.1 dataframe</p>

<pre><code>structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250), Run = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c(""""1"""", """"2"""", """"3""""), class = """"factor""""), 
    PAR = c(1.25000000000000e-05, 0.000960333333333333, 0.00205833333333334, 
    0.00423333333333333, 0.0322333333333334, 0.614433333333334, 
    1.24333333333333, 1.86333333333333), PredLin = c(-0.0119152187070942, 
    0.00375925114245899, 0.0272709559167888, 0.0586198956158952, 
    0.215364594111427, 0.372109292606959, 1.15583278508462, 1.93955627756228
    ), PredQuad = c(-0.0615895732702735, -0.0501563307416599, 
    -0.0330831368244257, -0.0104619953693943, 0.100190275883806, 
    0.20675348710041, 0.6782336426345, 1.04748729725370)), .Names = c(""""Nominal"""", 
""""Run"""", """"PAR"""", """"PredLin"""", """"PredQuad""""), row.names = c(NA, 8L), class = """"data.frame"""")
</code></pre>

<p>Linear Model</p>

<pre><code>summary(callin.1)

Call:
lm(formula = PAR ~ Nominal, data = calvarbyruno.1, weights = Nominal^calweight)

Residuals:
       Min         1Q     Median         3Q        Max 
-0.0041172 -0.0037785 -0.0003605  0.0024465  0.0071815 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) -0.007083   0.005037  -1.406   0.2093  
Nominal      0.005249   0.001910   2.748   0.0334 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.004517 on 6 degrees of freedom
Multiple R-squared: 0.5572,     Adjusted R-squared: 0.4835 
F-statistic: 7.551 on 1 and 6 DF,  p-value: 0.03338 
</code></pre>

<p>Quadratic Model</p>

<pre><code>&gt; summary(calquad.1)

Call:
lm(formula = PAR ~ Nominal + I(Nominal^2), data = calvarbyruno.1)

Residuals:
        1         2         3         4         5         6         7         8 
 0.053366  0.033186  0.002766 -0.036756 -0.211640  0.177012 -0.021801  0.003867 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)  -6.395e-02  6.578e-02  -0.972  0.37560   
Nominal       1.061e-02  2.205e-03   4.812  0.00483 **
I(Nominal^2) -1.167e-05  9.000e-06  -1.297  0.25138   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.128 on 5 degrees of freedom
Multiple R-squared: 0.9774,     Adjusted R-squared: 0.9684 
F-statistic: 108.2 on 2 and 5 DF,  p-value: 7.658e-05
</code></pre>

<p>But Predict gives me these values, which both seem wrong (although I can't work out what it's doing that's different for the second set ?</p>

<pre><code>&gt; predict(callin.1)
           1            2            3            4            5            6 
-0.001834123  0.008663451  0.024409812  0.045404959  0.150380698  0.255356437 
           7            8 
 0.780235132  1.305113826 
&gt; predict(callin.1,type=""""terms"""")
      Nominal
1 -0.32280040
2 -0.31230282
3 -0.29655646
4 -0.27556131
5 -0.17058558
6 -0.06560984
7  0.45926886
8  0.98414755
attr(,""""constant"""")
[1] 0.3209663
</code></pre>

<p>EDIT: As has been pointed out, I've not been very clear on what I'm trying to achieve, so I'll try to exaplian myself better.</p>

<p>The data is from analysis of a set of standards of known concentrations (Nominal) which gives a particular set of responses, or peak area ratio's (PAR).  I want to show which model best fits this data to use to then analyse unknown samples to find their concentration.</p>

<p>I'm trying to follow someone else working for this, which involves;<br>
a) Find the appropriate weight to use, by finding the within run variance of PAR and fitting that to a model of log(Variance(PAR))=a+b<em>log(Nominal), where B will be the weight to use (rounded to nearest integer)<br>
  b) Fit the data for each run to a linear model (PAR = a+b</em>Nominal) and a Quadratic Model (PAR = a+B<em>Nominal+c</em>Nominal^2)<br>
  c) Back calculate the found concentration for each standard and compare to the Nominal conentration to give the bias<br>
  d) Assess bias across the calibration range and pick the model based on the bias  </p>

<p>This question is trying to do c).  Posts to the R mailing list suggest it's not appropriate to just do the regression with the terms reversed, I can manually do the calculation for the linear model, but am struggling with the quadratic model.  It seems from searcing the R mailing list that others want to do the same thing.</p>
",1
"<p>Suppose I have the following</p>

<pre><code>y &lt;- rnorm(10)
b &lt;- as.factor(sample(1:4,10,replace=T))
qplot(1:10, y, shape=b)
</code></pre>

<p>How do I change the shapes that are used using <code>ggplot2</code>?</p>
",1
"<p>What is the fastest way in R to compute a recursive sequence defined as </p>

<pre><code>x[1] &lt;- x1 
x[n] &lt;- f(x[n-1])
</code></pre>

<p>I am assuming that the vector x of proper length is preallocated. Is there a smarter way than just looping?</p>

<p>Variant: extend this to vectors:</p>

<pre><code> x[,1] &lt;- x1 
 x[,n] &lt;- f(x[,n-1])
</code></pre>
",1
"<p>Using <a href=""""http://oreilly.com/catalog/9780596804770/"""" rel=""""noreferrer"""">O'Reilly's Data Mashups in R</a> as inspiration, I'm trying to plot a handful of addresses on a shapefile of Salt Lake County, Utah found <a href=""""http://gis.utah.gov/sgid-vector-download/utah-sgid-vector-gis-data-layer-download-index?fc=CensusTracts2000"""" rel=""""noreferrer"""">here</a>.</p>

<p>I have data frame geoTable:</p>

<pre><code>&gt; geoTable
         address        Y         X EID
1    130 E 300 S 40.76271 -111.8872   1
2    875 E 900 S 40.74992 -111.8660   2
3   2200 S 700 E 40.72298 -111.8714   3
4    702 E 100 S 40.76705 -111.8707   4
5 177 East 200 S 40.76518 -111.8859   5
6    702 3rd ave 40.77264 -111.8683   6
7   2175 S 900 E 40.72372 -111.8652   7
8   803 E 2100 S 40.72556 -111.8680   8
</code></pre>

<p>And I've coerced it into an eventData object:</p>

<pre><code>&gt; addressEvents&lt;-as.EventData(geoTable,projection=NA)
&gt; addressEvents
         address        Y         X EID
1    130 E 300 S 40.76271 -111.8872   1
2    875 E 900 S 40.74992 -111.8660   2
3   2200 S 700 E 40.72298 -111.8714   3
4    702 E 100 S 40.76705 -111.8707   4
5 177 East 200 S 40.76518 -111.8859   5
6    702 3rd ave 40.77264 -111.8683   6
7   2175 S 900 E 40.72372 -111.8652   7
8   803 E 2100 S 40.72556 -111.8680   8
</code></pre>

<p>So it looks like I've got everything I need to plot-but its not working.  When I load the shapefile and plot using</p>

<pre><code>addPoints(addressEvents,col=""""red"""",cex=.5)
</code></pre>

<p>I'm left looking at an empty shapefile.  Additionally, when I try and run findPolys against my eventData object, it returns NULL.</p>

<pre><code>&gt; findPolys(addressEvents,myShapeFile)
NULL
</code></pre>

<p>How can I make this work?  I was able to complete the O'Reilly tutorial without any problems and am having difficulty figuring out where I'm going wrong here.  I dont know if its the shapefile, my data frame, or whateverelse.  </p>

<p>Here are the commands I use to import my data and shapefile</p>

<pre><code>slc&lt;-read.table('~/utah.txt',sep=',',header=TRUE,strip.white=TRUE,stringsAsFactors=FALSE)

myShapeFile&lt;-importShapefile(""""/Users/neil/Downloads/SGID93_DEMOGRAPHIC_CensusTracts2000/SGID93_DEMOGRAPHIC_CensusTracts2000"""",readDBF=TRUE)
</code></pre>
",1
"<p>I've a problem concerning construction of log y-axis in a graphic. </p>

<p>How can I manage that the units/numbers of my log y-axis aren't shown in </p>

<pre><code>1e+03, 1e+04, 1e+05 etc....
</code></pre>

<p>But only in regular Arabic numbers (1000, 10000, 100000)?</p>
",1
"<p>Say you have the following dataset:</p>

<pre><code>trt &amp;lt;- ifelse(runif(100)&amp;lt;0.5,""""drug"""",""""placebo"""")
inj.site &amp;lt;- ifelse(runif(100)&amp;lt;0.5,""""ankle"""",""""wrist"""")
relief &amp;lt;- 20 + 0.5*(inj.site==""""ankle"""") + 0.5*(trt==""""drug"""") + rnorm(100)
to.analyze &amp;lt;- data.frame(trt,inj.site,relief)
</code></pre>

<p>Now, the idea is to make a boxplot with injury site on the x-axis and boxes by treatment side-by-side:</p>

<pre><code>bplot &amp;lt;- ggplot(to.analyze,aes(inj.site,relief,fill=trt)) + geom_boxplot(position=""""dodge"""")
</code></pre>

<p>Easy enough. But now I want to add raw data points on top of the boxes. If I didn't have boxes with <code>position=""""dodge""""</code>, this would be easy:</p>

<pre><code>bplot + geom_point(aes(colour=trt))
</code></pre>

<p>However, this draws points in between the boxes, and adding a <code>position=""""dodge""""</code>to this geometry does not seem to work. How do I adjust this so that points are drawn over the boxes?</p>

<p>Bonus: same situation with using <code>stat_summary(blah,y.fun=mean,shape=""""+"""")</code> to overplot the means, which has the same issue.</p>
",1
"<p>I'm running the following script: </p>

<pre><code>cause = c(1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2); 
time =  c(1, 1, 2, 3, 3, 2, 2, 1, 1, 2, 2); 
table(cause, time)
</code></pre>

<p>And I get the following:</p>

<pre><code>    time
cause 1 2 3
    1 2 2 2
    2 2 3 0
</code></pre>

<p>What I want is this:</p>

<pre><code>      time
cause     1 2 3
Maltreat  2 2 2
Non-Maltr 2 3 0
</code></pre>

<p>So, my question is: how do you rename the rows of a table in R?</p>

<p>In the same vein, how would you rename the columns of that table?</p>
",1
"<p>There is <a href=""""http://mars.wiwi.hu-berlin.de/mediawiki/sk/index.php/R_Extension_for_MediaWiki"""" rel=""""noreferrer"""">a very nice Mediawiki plugin for R</a> which allows you to embed R code in any wiki page.  It takes a little effort to configure, but it's really useful once you have it in place.</p>

<p>Does anyone know of an equivalent for embedding R in a blog post?  The only thing I could find was <a href=""""http://lixiaoxu.lxxm.com/RwebFriend/"""" rel=""""noreferrer"""">this wordpress plugin called RWebFriend</a>, but it only allows you to send code to <a href=""""http://bayes.math.montana.edu/Rweb/"""" rel=""""noreferrer"""">Rweb</a>.  I'm envisioning something where you can embed your code between two tags and it is executed and returned.</p>
",1
"<h3>I'm looking for an elegant way to change multiple vectors' datatypes in R.</h3>

<p>I'm working with an educational dataset: 426 students' answers to eight multiple choice questions (<code>1</code> = correct, <code>0</code> = incorrect), plus a column indicating which instructor (<code>1, 2, or 3</code>) taught their course.</p>

<p>As it stands, my data is sitting pretty in <code>data.df</code>, like this:</p>

<p><pre><code>    str(data.df)
    'data.frame': 426 obs. of  9 variables:
    $ ques01: int  1 1 1 1 1 1 0 0 0 1 ...
    $ ques02: int  0 0 1 1 1 1 1 1 1 1 ...
    $ ques03: int  0 0 1 1 0 0 1 1 0 1 ...
    $ ques04: int  1 0 1 1 1 1 1 1 1 1 ...
    $ ques05: int  0 0 0 0 1 0 0 0 0 0 ...
    $ ques06: int  1 0 1 1 0 1 1 1 1 1 ...
    $ ques07: int  0 0 1 1 0 1 1 0 0 1 ...
    $ ques08: int  0 0 1 1 1 0 1 1 0 1 ...
    $ inst  : num  1 1 1 1 1 1 1 1 1 1 ...
</code></pre></p></p>

<p>But those <code>ques0x</code> values aren't <strong>really</strong> integers. Rather, I think it's better to have R treat them as experimental factors. Same goes for the """"inst"""" values.</p>

<h3>I'd love to turn all those <code>int</code>s and <code>num</code>s into <code>factors</code>
</h3>

<p>
Ideally, an elegant solution should produce a dataframe&mdash;I call it <code>factorData.df</code>&mdash;that looks like this:
</p>

<pre><code>    str(factorData.df)
    'data.frame': 426 obs. of  9 variables:
    $ ques01: Factor w/ 2 levels """"0"""",""""1"""": 2 2 2 2 2 2 1 1 1 2 ...
    $ ques02: Factor w/ 2 levels """"0"""",""""1"""": 1 1 2 2 2 2 2 2 2 2 ...
    $ ques03: Factor w/ 2 levels """"0"""",""""1"""": 1 1 2 2 1 1 2 2 1 2 ...
    $ ques04: Factor w/ 2 levels """"0"""",""""1"""": 2 1 2 2 2 2 2 2 2 2 ...
    $ ques05: Factor w/ 2 levels """"0"""",""""1"""": 1 1 1 1 2 1 1 1 1 1 ...
    $ ques06: Factor w/ 2 levels """"0"""",""""1"""": 2 1 2 2 1 2 2 2 2 2 ...
    $ ques07: Factor w/ 2 levels """"0"""",""""1"""": 1 1 2 2 1 2 2 1 1 2 ...
    $ ques08: Factor w/ 2 levels """"0"""",""""1"""": 1 1 2 2 2 1 2 2 1 2 ...
    $ inst  : Factor w/ 3 levels """"1"""",""""2"""",""""3"""": 1 1 1 1 1 1 1 1 1 1 ...
</code></pre>

<p><p>I'm fairly certain that whatever solution you folks come up with, it ought to be easy to generalize to any n number of variables that'd need to get reclassified, and would work across most common conversions (<code>int -> factor</code> and <code>num -> int</code>, for example).</p>

<h3> No matter what solution you folks generate, it's <strong>bound</strong> to be more elegant than mine</h3>

<p><p>Because my current clunky code is just 9 separate <code>factor()</code> statements, one for each variable, like this</p>

<pre>    factorData.df$ques01 </pre>

<p>
I'm brand-new to R, programming, and stackoverflow. Please be gentle, and thanks in advance for your help!
</p>
",1
"<p>I have a dataframe with Address, City, State, Zip entities.  From there, I'm trying to use the Yahoo APIs to Geocode each address.</p>

<p>I'm basing this off the code in O'Reilly's Data Mashups using R Tutorial.  The original example takes a vector of street addresses and uses a hard-coded city.  I'm trying to make a dynamic example that supports multiple cities.</p>

<p>The abbreviated version of the code is:</p>

<pre><code>    geocodeAddresses&lt;-function(myStreets)
    }
  appid&lt;-'&lt;put your appid here&gt;'
          baseURL&lt;-""""http://local.yahooapis.com/MapsService/V1/geocode?appid=""""
          myGeoTable&lt;-data.frame(address=character(),lat=numeric(),long=numeric(),EID=numeric())
          for (myStreet in myStreets){  
            requestUrl&lt;-paste(baseURL, appid, """"&amp;street="""", URLencode(myStreet$address),""""&amp;city="""",URLencode(myStreet$city),""""&amp;state="""",URLencode(myStreet$state),sep="""""""")
            xmlResult&lt;-xmlTreeParse(requestUrl,isURL=TRUE,addAttributeNamespaces=TRUE)
            geoResult&lt;-xmlResult$doc$children$ResultSet$children$Result
            lat&lt;-xmlValue(geoResult[['Latitude']])
            long&lt;-xmlValue(geoResult[['Longitude']])
            myGeoTable&lt;-rbind(myGeoTable,data.frame(address=myStreet,Y=lat,X=long,EID=NA))
          }
    }
</code></pre>

<p>When I try and reference myStreet$City and myStreet$Address, I receive error</p>

<pre><code>$ operator is invalid for atomic vectors
</code></pre>

<p>Other than looping through data frame myStreets, I don't know how I can make the call to the Yahoo API only once for each row and store both the long/lat for each member.</p>
",1
"<p>I have a DNA sequence like: <code>cgtcgctgtttgtcaaagtcg....</code></p>

<p>that is possibly 1000+ letters long.  </p>

<p>However, I only want to look at letters 5 to 200, for example, and to define this subset of the string as a new object.</p>

<p>I tried looking at the <code>nchar</code> function, but haven't found something that would do this.</p>
",1
"<p>I'm trying to round an output from a simple <code>by()</code> function in <code>R</code>. This is what I have:</p>

<pre><code>&gt; by(glaciers[,1:3],glaciers$activity.level,mean)

glaciers$activity.level: Active
       aspect  sun.duration      latitude 
-9.444444e+00  1.771778e+03  3.247643e+09 
-------------------------------------------
glaciers$activity.level: Inactive
      aspect sun.duration     latitude 
1.041667e+01 2.067583e+03 4.048301e+09 
-------------------------------------------
glaciers$activity.level: Relict
      aspect sun.duration     latitude 
1.766667e+01 2.168000e+03 2.759283e+09 
</code></pre>

<p>How can I get my output to round to say 5 decimal places, and still keep the factors?</p>

<p>I've tried: <code>round(by(glaciers[,1:3],glaciers$activity.level,mean),5)</code> but get an error: <code>Non-numeric argument to mathematical function</code>.</p>
",1
"<p>I have a logical vector, for which I wish to insert new elements at particular indexes. I've come up with a clumsy solution below, but is there a neater way?</p>

<pre><code>probes &lt;- rep(TRUE, 15)
ind &lt;- c(5, 10)
probes.2 &lt;- logical(length(probes)+length(ind))
probes.ind &lt;- ind + 1:length(ind)
probes.original &lt;- (1:length(probes.2))[-probes.ind]
probes.2[probes.ind] &lt;- FALSE
probes.2[probes.original] &lt;- probes

print(probes)
</code></pre>

<p>gives</p>

<pre><code>[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
</code></pre>

<p>and</p>

<pre><code>print(probes.2)
</code></pre>

<p>gives</p>

<pre><code>[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE
[13]  TRUE  TRUE  TRUE  TRUE  TRUE
</code></pre>

<p>So it works but is ugly looking - any suggestions?</p>
",1
"<p>In R, I have a 1-row table. How do I convert that to a vector?</p>

<p>Specifically, the table is this:</p>

<pre><code> 0  1  2  3  4 
21 35 46 62 36 
</code></pre>

<p>I've tried bracket notation but to no avail!</p>
",1
"<p>I have a function to calculate the inverse of a quadratic equation.  By default it gives the two possible solutions:</p>

<pre><code>invquad&lt;-function(a,b,c,y,roots=""""both"""")
{
    #Calculate the inverse of a quadratic function y=ax^2+bx+c (i.e. find x when given y.)
    #Gives NaN with non real solutions.
    root1&lt;-sqrt((y-(c-b^2/(4*a)))/a)-(b/(2*a))
    root2&lt;--sqrt((y-(c-b^2/(4*a)))/a)-(b/(2*a))
    if (roots==""""both"""")
        result&lt;-c(root1,root2)
    if (roots==""""min"""")
        result&lt;-min(root1,root2)
    if (roots==""""max"""")
        result&lt;-max(root1,root2)
    result
}
</code></pre>

<p>This works fine if given a single value of y, but if I give it a list or a column from a dataframe, then the min and max elements give me the minimum value of the whole list. I want it to return just the minimum result for that element.  I'm assuming iterating over the list is possible, but it is not very efficient.</p>

<p>Any ideas ?</p>
",1
"<p>Is there a function in R that fits a curve to a histogram?</p>

<p>Let's say you had the following histogram</p>

<pre><code>hist(c(rep(65, times=5), rep(25, times=5), rep(35, times=10), rep(45, times=4)))
</code></pre>

<p>It looks normal, but it's skewed. I want to fit a normal curve that is skewed to wrap around this histogram.</p>

<p>This question is rather basic, but I can't seem to find the answer for R on the internet.</p>
",1
"<p>In R, what would be the most efficient/simplest way to count runs of identical elements in a sequence?</p>

<p>For example, how to count the numbers of consecutive zeros in a sequence of non-negative integers:</p>

<pre><code>x &lt;- c(1,0,0,0,1,0,0,0,0,0,2,0,0) # should give 3,5,2
</code></pre>
",1
"<p>This I am sure is really basic stuff. I am just beginning using gvim and latex-suite. However I would like latex-suite to load when I edit a sweavefile with.Rnw extension.</p>

<p>my .vimrc looks like this</p>

<pre><code>"""" These settings are needed for latex-suite
filetype indent on
filetype plugin on
filetype on
let g:tex_flavor='latex'
set grepprg=grep\ -nH\ $*
""""let g:Tex_Folding=0 """"I don't like folding.
set iskeyword+=:
</code></pre>

<p>and I guess there is some option I can set here that makes vim treat Rnw as .tex?</p>
",1
"<p>I'm not sure if this is possible, but does anyone know if I can pipe ESS commands (i.e. evaluate region) to a R process running outside of Emacs? The Emacs terminal hangs up a bit (more often than Apple's terminal) and I'd like to just ditch it, while still using ESS commands. Currently I am doing the less efficient copy and paste technique :-)</p>

<p>Vince</p>
",1
"<p>...if that is possible</p>

<p>My task is to find the longest streak of continuous days a user participated in a game.</p>

<p>Instead of writing an sql function, I chose to use the R's rle function, to get the longest streaks and then update my db table with the results.</p>

<p>The (attached) dataframe is something like this:</p>

<pre><code>    day      user_id
2008/11/01    2001
2008/11/01    2002
2008/11/01    2003
2008/11/01    2004
2008/11/01    2005
2008/11/02    2001
2008/11/02    2005
2008/11/03    2001
2008/11/03    2003
2008/11/03    2004
2008/11/03    2005
2008/11/04    2001
2008/11/04    2003
2008/11/04    2004
2008/11/04    2005
</code></pre>

<p>I tried the following to get per user longest streak</p>

<pre><code># turn it to a contingency table
my_table &lt;- table(user_id, day)

# get the streaks
rle_table &lt;- apply(my_table,1,rle)

# verify the longest streak of """"1""""s for user 2001
# as.vector(tapply(rle_table$'2001'$lengths, rle_table$'2001'$values, max)[""""1""""])

# loop to get the results
# initiate results matrix
res&lt;-matrix(nrow=dim(my_table)[1], ncol=2)

for (i in 1:dim(my_table)[1]) {
string &lt;- paste(""""as.vector(tapply(rle_table$'"""", rownames(my_table)[i], """"'$lengths, rle_table$'"""", rownames(my_table)[i], """"'$values, max)['1'])"""", sep="""""""")
res[i,]&lt;-c(as.integer(rownames(my_table)[i]) , eval(parse(text=string)))
}
</code></pre>

<p>Unfortunately this for loop takes too long and I' wondering if there is a way to produce the res matrix using a function from the """"apply"""" family.</p>

<p>Thank you in advance </p>
",1
"<p>I've got data being read into a data frame R, by column.  Some of the columns will increase in value; for those columns only, I want to replace each value (n) with its difference from the previous value in that column.  For example, looking at an individual column, I want</p>

<pre><code>c(1,2,5,7,8)
</code></pre>

<p>to be replaced by</p>

<pre><code>c(1,3,2,1)
</code></pre>

<p>which are the differences between successive elements</p>

<p>However, it's getting really late in the day, and I think my brain has just stopped working.  Here's my code at present</p>

<pre><code>col1 &lt;- c(1,2,3,4,NA,2,3,1) # This column rises and falls, so we want to ignore it
col2 &lt;- c(1,2,3,5,NA,5,6,7) # Note: this column always rises in value, so we want to replace it with deltas
col3 &lt;- c(5,4,6,7,NA,9,3,5) # This column rises and falls, so we want to ignore it
d &lt;- cbind(col1, col2, col3)
d
fix_data &lt;- function(data) {
    # Iterate through each column...
    for (column in data[,1:dim(data)[2]]) {
        lastvalue &lt;- 0
        # Now walk through each value in the column, 
        # checking to see if the column consistently rises in value
        for (value in column) {
            if (is.na(value) == FALSE) { # Need to ignore NAs
                if (value &gt;= lastvalue) {
                    alwaysIncrementing &lt;- TRUE
                } else {
                    alwaysIncrementing &lt;- FALSE
                    break
                }
            }
        }

        if (alwaysIncrementing) {
            print(paste(""""Column"""", column, """"always increments""""))
        }

        # If a column is always incrementing, alwaysIncrementing will now be TRUE
        # In this case, I want to replace each element in the column with the delta between successive
        # elements.  The size of the column shrinks by 1 in doing this, so just prepend a copy of
        # the 1st element to the start of the list to ensure the column length remains the same
        if (alwaysIncrementing) {
            print(paste(""""This is an incrementing column:"""", colnames(column)))
            column &lt;- c(column[1], diff(column, lag=1))
        }
    }
    data
}

fix_data(d)
d
</code></pre>

<p>If you copy/paste this code into RGui, you'll see that it doesn't do anything to the supplied data frame.</p>

<p>Besides losing my mind, what am I doing wrong??</p>

<p>Thanks in advance</p>
",1
"<p>I have a dataframe, and I want to produce a table of summary statistics including number of valid numeric values, mean and sd by group for each of three columns.  I can't seem to find any function to count the number of numeric values in R.  I can use length() which tells me how many values there are, and I can use colSums(is.na(x)) to count the number of NA values, but colSums(is.numeric(x)) doesn't work the same way.</p>

<p>I could use tapply with { length - number of NA values - number of blank values - number of text values } but surely there's an easier way.</p>

<p>My data (I want to group by Nominal, and produce summary stats on Actual, LinPred and QualPred)</p>

<pre><code>structure(list(Nominal = c(1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250, 1, 
3, 6, 10, 30, 50, 150, 250, 1, 3, 6, 10, 30, 50, 150, 250), Actual = c(NA, 
0.422, 0.782, 1.25, 3.85, 6.94, 18.8, 31.2, 0.118, 0.361, 0.747, 
1.18, 3.58, 5.82, 16.7, 29, 0.113, 0.382, 0.692, 1.12, 3.51, 
5.43, 17.1, 28.7, 0.134, 0.402, 0.718, 1.25, 3.65, 6.52, NA, 
28.8, 0.123, 0.396, 0.664, 1.12, 3.83, 5.6, NA, 28.1, 0.112, 
0.341, 0.7, 1.08, 3.25, 5.97, NA, 27.1, 0.106, 0.35, 0.674, 1.14, 
3.28, 5.5, 17.3, 30, 0.122, 0.321, 0.673, 1.22, 3.41, 5.85, 17.6, 
28.1, 0.129, 0.351, 0.737, 1.06, 3.39, 5.53, 15.9, 28.5), LinPred = c(NA, 
3.49519490135683, 6.4706724568458, 10.3387932789814, 31.8283534019573, 
57.3678690865708, 155.393324109068, 257.881995464799, 0.982569410055046, 
2.99101676001009, 6.18138991672881, 9.76022819874748, 29.5967452353405, 
48.1108278028274, 138.036371702049, 239.698521514589, 0.941243332895477, 
3.16458628408028, 5.72680306797355, 9.26431527283265, 29.0181801551066, 
44.887393784381, 141.342457874815, 237.218956885015, 1.07941778099747, 
3.36900393602722, 6.0686652233011, 10.6136646056736, 31.1174212178803, 
55.6364968333108, NA, 245.979704049963, 0.98544222985819, 3.3177445444967, 
5.60733069952645, 9.50304445584572, 32.6552029637958, 47.7767234652982, 
NA, 239.999441704736, 0.89146667871891, 2.8478667888003, 5.91488704870955, 
9.1613151789756, 27.7001284491792, 50.9377192763467, NA, 231.456209782983, 
0.887738051402174, 3.04188235451485, 5.9023034783202, 10.0163659588551, 
28.9092709123842, 48.5084526866061, 152.684283738776, 264.805729023739, 
1.02899341554071, 2.78585700701375, 5.89347501806154, 10.7226427795477, 
30.0569707460098, 51.5984137771366, 155.332821816374, 248.031654532288, 
1.09079263735132, 3.05071081477351, 6.45849647461568, 9.31008913816238, 
29.8804015408367, 48.7733064943658, 140.324439376654, 251.563038635751
), QuadPred = c(NA, 3.46077095737974, 6.38659713413108, 10.1956079501556, 
31.4700369979564, 57.0089799611706, 157.775316006369, 268.303966059862, 
0.99289436409299, 2.96536517477853, 6.10198249392715, 9.62549220297933, 
29.2517496204359, 47.7196128593832, 139.600469198163, 248.272682787657, 
0.95232583127381, 3.13590297331348, 5.65480031033985, 9.13693141349813, 
28.6769820181676, 44.4936547741659, 143.050878627236, 245.555818447238, 
1.08417831830729, 3.33895371044810, 6.00044125019758, 10.4882228621509, 
30.8451526869812, 55.4331759085967, NA, 256.446833964951, 0.991679220421247, 
3.28844923081897, 5.54540949253351, 9.3907657095483, 32.3793538902883, 
47.5218142460371, NA, 249.828516445647, 0.899183876120787, 2.82554368740693, 
5.84875388286628, 9.05319326862309, 27.4395572248486, 50.7001828907023, 
NA, 240.411024762687, 0.884412915928806, 3.05257006009469, 5.93046554432476, 
10.0673979669, 29.0311859234644, 48.645035648271, 151.914544909710, 
261.273991566153, 1.02660962824666, 2.79491765184684, 5.92158513760114, 
10.7773327827008, 30.1813919027873, 51.7318741314584, 154.518856412401, 
245.027488125567, 1.08881969774848, 3.06145444119556, 6.48990638077339, 
9.35738460692028, 30.0044505131336, 48.9096796323938, 139.747394069421, 
248.451100154569)), .Names = c(""""Nominal"""", """"Actual"""", """"LinPred"""", 
""""QuadPred""""), row.names = c(NA, -72L), class = """"data.frame"""")
</code></pre>
",1
"<p>I am attempting to find the elements that are not common across multiple vectors. That is, I want to know exactly the elements (not just their position, etc.) that are not shared across all vectors.</p>

<p>The best implementation I could come up with uses a nested-loop, which I realize is probably the least efficient, most notably because the execution is still running as I write this.  Here is what I came up with. (each *.id is a vector of Supreme Court case ID's stored as strings).</p>

<pre><code>check.cases&lt;-TRUE

if(check.cases) {
    all.cases&lt;-c(AMKennedy.id,AScalia.id,CThomas.id,DHSouter.id,JGRoberts.id,JPStevens.id,RBGinsburg.id,SAAlito.id,SGBreyer.id)
    bad.cases&lt;-c()
    for(b in all.cases) {
        for(t in all.cases) {
            m&lt;-match(t,b)
            bad&lt;-t[which(is.na(m))]
            bad.cases&lt;-append(bad.cases,bad)
        }
    }
    bad.cases&lt;-unique(bad.cases)
}

print(bad.cases)
</code></pre>

<p>There must be a more efficient way of doing this?</p>
",1
"<p>Given the following ggplot2 chart:</p>

<pre><code>ggplot(my_data, aes(colour=my_factor) +   
                geom_point(aes(x=prior, y=current)) +   
                facet_grid(gender ~ age)
</code></pre>

<p>I would like to make the size of the points be proportional to the count of my_factor for that prior/current combination.</p>

<pre><code>ggplot(my_data, aes(colour=my_factor, 
                size=&lt;something-here&gt;(my_factor)) +   
                geom_point(aes(x=prior, y=current)) + 
                facet_grid(gender ~ age)
</code></pre>

<p>Any ideas?</p>

<p>== Edit ==</p>

<p>Here's a very trivial example based on mpg dataset. Let's define """"great_hwy"""" as hwy > 35, and """"great_cty"""" as cty > 25:</p>

<pre><code>mpg$great_hwy[mpg$hwy &gt; 35]  &lt;-1
mpg$great_hwy[mpg$hwy &lt;= 35] &lt;-0
mpg$great_hwy &lt;- factor(mpg$great_hwy)

mpg$great_cty[mpg$cty &gt; 25]  &lt;- 1
mpg$great_cty[mpg$cty &lt;= 25] &lt;- 0
mpg$great_cty &lt;- factor(mpg$great_cty)
</code></pre>

<p>If we plot great_hwy vs. great_cty, it won't tell us much:</p>

<pre><code>ggplot(mpg) + geom_point(aes(x=great_cty, y=great_hwy))
</code></pre>

<p>How could I make the data points bigger in size depending on the number of x/y points? Hope this clears it up, but let me know otherwise.</p>
",1
"<p>I'd like to write a function that takes a filename and produces a .pdf file on a *nix platform and a .wmf on a windows platform with that filename and width of 6 inches height 4.</p>

<pre><code>graph &lt;- function(filename){
setwd(""""graphics"""")
ext &lt;- ifelse(.Platform$OS.type == """"unix"""", """"pdf"""", """"wmf"""")
name &lt;- paste(filename, ext, sep=""""."""")
ifelse(.Platform$OS.type == """"unix"""", pdf(name, width=6, height=4), wmf(name, width=6, height=4))
}
</code></pre>

<p>That's my attempt but I'm getting this error</p>

<p>Error in ans[test &amp; !nas] &lt;- rep(yes, length.out = length(ans))[test &amp;  : 
  replacement has length zero</p>

<p>any ideas? I feel like I'm overlooking something.</p>
",1
"<p>Take the following code:</p>

<pre><code>foo &lt;- list()
foo[[1]] &lt;- list(a=1, b=2)
foo[[2]] &lt;- list(a=11, b=22)
foo[[3]] &lt;- list(a=111, b=222)
result &lt;- do.call(rbind, foo)
result[,'a']
</code></pre>

<p>In this case, <code>result[,'a']</code> shows a list.  Is there a more elegant way such that <code>result</code> is a """"regular"""" matrix of vectors?  I imagine there are manual ways of going about this, but I was wondering if there was an obvious step that I was missing.</p>
",1
"<p>My current dataset <code>data.df</code> comes from about 420 students who took an 8-question survey under one of 3 instructors. <code>escore</code> is my outcome variable of interest.
</p></p>

<pre><code>
    'data.frame':   426 obs. of  10 variables:
     $ ques01: int  1 1 1 1 1 1 0 0 0 1 ...
     $ ques02: int  0 0 1 1 1 1 1 1 1 1 ...
     $ ques03: int  0 0 1 1 0 0 1 1 0 1 ...
     $ ques04: int  1 0 1 1 1 1 1 1 1 1 ...
     $ ques05: int  0 0 0 0 1 0 0 0 0 0 ...
     $ ques06: int  1 0 1 1 0 1 1 1 1 1 ...
     $ ques07: int  0 0 1 1 0 1 1 0 0 1 ...
     $ ques08: int  0 0 1 1 1 0 1 1 0 1 ...
     $ inst  : Factor w/ 3 levels """"1"""",""""2"""",""""3"""": 1 1 1 1 1 1 1 1 1 1 ...
     $ escore: int  3 1 5 5 3 3 4 4 2 5 ...
     </code></pre>

<p>
I'm wondering how I can generate <code>escore</code> histograms that are conditionally separated based upon the value of <code>inst</code> for a given observation. In my head, the pseudo-code might look like this:</p>

<p>
<pre><code>
    par(mfrow=c(1,3)) 
    hist(escore, data.df$inst = 1)
    hist(escore, data.df$inst = 2)
    hist(escore, data.df$inst = 3)
</code></pre>
</p>

<p>but of course that won't work :-(</p>

<p>Ideally, my histograms would look like this:</p>

<p><a href=""""http://terpconnect.umd.edu/~briandk/escoreHistogramsbyInstructor-1.png"""" rel=""""nofollow noreferrer"""">3 separate histograms of ~140 observations each, grouped according to their &quot;inst&quot; value http://terpconnect.umd.edu/~briandk/escoreHistogramsbyInstructor-1.png</a></p>

<p>As usual, I sense there's got to be an easy way to do this. In whatever """"conditional/grouping"""" sense I can extract these graphs from my data, I assume it's <strong>got</strong> to be generalizable for all sorts of plots you'd want to make based on certain conditions.</p>

<p>Also, I'm really sorry if this question has been answered before. My primary difficulty is in figuring out how to ask it in a way that makes sense.</p>

<p>Thanks in advance for your help!</p></p>
",1
"<p>I have a csv file where some of the numerical values are expressed as strings with commas as thousand separator, e.g. <code>""""1,513""""</code> instead of <code>1513</code>. What is the simplest way to read the data into R?</p>

<p>I can use <code>read.csv(..., colClasses=""""character"""")</code>, but then I have to strip out the commas from the relevant elements before converting those columns to numeric, and I can't find a neat way to do that.</p>
",1
"<p>I have three data sets of different lengths and I would like to plot density functions of all three on the same plot. This is straight forward with base graphics:</p>

<pre><code>n &lt;- c(rnorm(10000), rnorm(10000))
a &lt;- c(rnorm(10001), rnorm(10001, 0, 2))
p &lt;- c(rnorm(10002), rnorm(10002, 2, .5))

plot(density(n))
lines(density(a))
lines(density(p))
</code></pre>

<p>Which gives me something like this:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/10/density.png"""" rel=""""nofollow noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/10/density.png</a></p>

<p>But I really want to do this with GGPLOT2 because I want to add other features that are only available with GGPLOT2. It seems that GGPLOT really wants to take my empirical data and calculate the density for me. And it gives me a bunch of lip because my data sets are of different lengths. So how do I get these three densities to plot in GGPLOT2?</p>
",1
"<p>I'm working on a script that creates a package in the current directory (using pdInfoBuilder from BioConductor), and I'd like to install it while the script is running. <code>install.packages()</code> with repo=NULL seems like an obvious choice, but this seems to only except package directories tarballed and gzipped. Is there a way I can override this, since the <code>create.pkg()</code> function doesn't create a *.tar.gz? Currently I am using:</p>

<pre><code>R CMD INSTALL package.name
</code></pre>

<p>Thanks,
Vince</p>
",1
"<p>Could anybody explain to me why</p>

<pre><code>simulatedCase &lt;- rbinom(100,1,0.5)
simDf &lt;- data.frame(CASE = simulatedCase)
posterior_m0 &lt;&lt;- MCMClogit(CASE ~ 1, data = simDf, b0 = 0, B0 = 1)
</code></pre>

<p>always results in a MCMC acceptance ratio of 0? Any explanation would be greatly appreciated!</p>
",1
"<p>Is there a more """"R-minded"""" way to dichotomise efficiently? Thanks.</p>

<pre><code>y&lt;-c(0,3,2,1,0,0,2,5,0,1,0,0);b&lt;-vector()

for (k in 1:length(y)) {
    if (y[k] == 0) b[k] = 0
    else
        b[k] = 1
}
y;b
</code></pre>
",1
"<p>I used the package languageR for mixed effect models with the syntax at the end of this posting. I can use pvals.fnc to get p-values for model 1 and 3 (hd_lmer1 and hd_lmer2). Using this with model two gives the following error message:</p>

<blockquote>
  <p>p2 = pvals.fnc(hd_lmer2)
  Error in pvals.fnc(hd_lmer2) : 
    MCMC sampling is not yet implemented in lme4_0.999375
    for models with random correlation parameters</p>
</blockquote>

<p>I'd be grateful if any one could help me out on how to get p-values for such models.</p>

<p>Models:</p>

<pre><code> hd_lmer1 &lt;- lmer(rot~ time + group + sex + gen + (1 | subject) + (1|rot.pre), data = data_long,REML = TRUE)
 hd_lmer2 &lt;- lmer(rot~ time + group + sex + gen + (time | subject) + (1|rot.pre), data = data_long,REML = TRUE)
 hd_lmer3 &lt;- lmer(rot~ time*group + sex + gen + (1 | subject) + (1|rot.pre), data = data_long,REML = TRUE)
</code></pre>
",1
"<p>I've got a nice facet_wrap density plot that I have created with ggplo2. I would like for each panel to have x and y axis labels instead of only having the y axis labels along the left side and the x labels along the bottom. What I have right now looks like this:</p>

<pre><code>library(ggplot2)
myGroups &lt;- sample(c(""""Mo"""", """"Larry"""", """"Curly""""), 100, replace=T)
myValues &lt;- rnorm(300)
df &lt;- data.frame(myGroups, myValues)


p &lt;- ggplot(df)  + 
  geom_density(aes(myValues), fill = alpha(""""#335785"""", .6)) + 
  facet_wrap(~ myGroups)
p
</code></pre>

<p>Which returns:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/10/3stooges.png"""" rel=""""nofollow noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/10/3stooges.png</a></p>

<p>It seems like this should be simple, but my Google Fu has been too poor to find an answer. </p>
",1
"<p>Hi we're trying to get R with the standard gui loaded onto CentOS 4, and under certain users R will not render certain graphics.  When logged in as root the graphics render, but under the restricted user they don't.  The graphics don't render with the error:</p>

<pre><code>&gt; testdata &lt;- rbind(c(1,2,3,4,5,6),c(3,4,5,4,6,2),c(3,6,7,2,2,1),c(5,4,9,8,9,1))
&gt; pairs(testdata)
Error in text.default(x, y, txt, cex = cex, font = font) : 
 X11 font -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 1 at size 16 could not be loaded
</code></pre>

<p>Anyone come across this one or have any ideas?</p>

<p>Thanks</p>
",1
"<p>When in auctex and noweb-mode (using Sweave in emacs), I find it distracting when the screen recenters itself as I use next-line, previous-line, etc. (C-n, C-p, and mouse-1). Does anyone know how to turn it off? Thanks much!</p>
",1
"<p>I have an aggregated table:</p>

<pre><code>&gt; aggdata[1:4,]
  Group.1 Group.2         x
1       4    0.05 0.9214660
2       6    0.05 0.9315789
3       8    0.05 0.9526316
4      10    0.05 0.9684211
</code></pre>

<p>How can I select the x value when I have values for Group.1 and Group.2?</p>

<p>I tried:</p>

<pre><code>aggdata[aggdata[,""""Group.1""""]==l &amp;&amp; aggdata[,""""Group.2""""]==lamda,""""x""""]
</code></pre>

<p>but that replies all x's.</p>

<p>More info:
I want to use this like this:</p>

<pre><code>table = data.frame();
for(l in unique(aggdata[,""""Group.1""""])) {
    for(lambda in unique(aggdata[,""""Group.2""""])) {
        table[l,lambda] = aggdata[aggdata[,""""Group.1""""]==l &amp; aggdata[,""""Group.2""""]==lambda,""""x""""]
    }
}
</code></pre>

<p>Any suggestions that are even easier and giving this result I appreciate!</p>
",1
"<p>I'm thinking there's got to be a better way to do this.</p>

<p>I'm trying to reorder the columns in a dataframe. I have a list, <code>ordered.colnames</code>, representing the new ordering -- but <em>some of the columns don't exist</em> in <code>dataset</code>. To avoid the Error """"<code>undefined columns selected</code>"""", I've wrapped the relevant slicing in a <code>try()</code> function.</p>

<p>The following method works, but is there a better way to do this?</p>

<pre><code>&gt; ordered.colnames[1:5]
[1] """"lady_22102""""         """"attentions_83249""""   """"perseverance_17864""""
[4] """"cecil_84477""""        """"cecilia_133476""""

dataset.reordered = c() 
for (i in 1:length(ordered.colnames)) {
    col = NA
    col = try(cbind(dataset[,ordered.colnames[i]]),silent=TRUE)
    if (!inherits(col,""""try-error"""")) {
        colnames(col) = ordered.colnames[i]
        dataset.reordered = cbind(dataset.reordered, col) 
    }
}
</code></pre>
",1
"<p>I am trying to find a way to stop accidental overwriting of files when using the save() and save.image() function in R. </p>
",1
"<p>I have the following variables in a data frame:</p>

<pre><code>[1] """"Type""""   """"I.alt""""  """"idx06""""  """"idx07""""  """"idx08"""" """"farve1"""" """"farve2""""
</code></pre>

<p>If I do:</p>

<pre><code>dm &lt;- melt(d, id=c(""""Type"""",""""I.alt""""))
</code></pre>

<p>I get these variables:</p>

<pre><code>""""Type""""     """"I.alt""""    """"variable"""" """"value""""   
</code></pre>

<p>Where """"idx06"""", """"idx07"""",  """"idx08"""", """"farve1"""", """"farve2"""" are represented in """"variable"""".</p>

<p>But what I really want is something like this:</p>

<pre><code>""""Type""""     """"I.alt""""    """"variable"""" """"value"""" """"variable2"""" """"value2""""
</code></pre>

<p>Where """"farve1"""" and """"farve2"""" are represented in variable2 and value2.</p>

<p>The reason I want to do this, is that I'd like something where the line color is green if the value is falling and red if rising.
<strong>EDIT: Shane has shown how to reshape the data via two melts merged. But my strategy seams to be ill conceived from the beginning - WRONG in one word. See my comment to Shane's solution.</strong></p>

<pre><code>ggplot(dm, aes(x=variable,y=value,group=Type,col=variable2, label=Type,size=I.alt))+
geom_line()+
geom_text(data=subset(dm, variable==""""idx08""""),hjust=-0.2, size=2.5)+
theme_bw()+
scale_x_discrete(expand=c(0,1))+
opts(legend.position=""""none"""")
</code></pre>

<p>I assume I need to cast the molten frame - but I can't figure it out.
The data:</p>

<pre><code>d &lt;- structure(list(Type = structure(c(8L, 21L, 23L, 20L, 6L, 14L, 
3L, 24L, 2L, 28L, 32L, 22L, 15L, 29L, 1L, 17L, 18L, 33L, 25L, 
13L, 30L, 11L, 26L, 9L, 12L, 4L, 5L, 27L, 16L, 19L, 10L, 31L, 
7L), .Label = c(""""Alvorligere vold"""", """"Andre strafferetlige særlove"""", 
""""Andre tyverier"""", """"Bedrageri"""", """"Brandstiftelse"""", """"Butikstyverier m.v."""", 
""""Dokumentfalsk"""", """"Færdselslovovertræd. i øvrigt"""", """"Færdselsuheld med spiritus"""", 
""""Falsk forklaring i øvrigt"""", """"Forbr. mod off. myndighed m.v."""", 
""""Freds- og ærekrænkelser"""", """"Hæleri"""", """"Hærværk"""", """"Indbrud i bank, forretn. m.v."""", 
""""Indbrud i fritidshuse, garager mv"""", """"Indbrud i villaer, lejligheder mv"""", 
""""Love vedr. forsvaret og lign."""", """"Love vedr. spil, bev., næring"""", 
""""Lov om euforiserende stoffer"""", """"Mangler ved køretøj"""", """"Røveri"""", 
""""Simpel vold"""", """"Spiritus- og promillekørsel"""", """"Trusler"""", """"Tyv./brugstyv. af andet"""", 
""""Tyv./brugstyv. af cykel"""", """"Tyv./brugstyv. af indr. køretøj"""", 
""""Tyv/brugstyv. af knallert"""", """"Tyveri fra bil, båd m.v."""", """"Ulovlig omgang med hittegods"""", 
""""Våbenloven"""", """"Vold o.l. mod off. myndighed""""), class = """"factor""""), 
I.alt = c(16137L, 9519L, 5930L, 5502L, 4887L, 3582L, 3101L, 
1738L, 1660L, 1649L, 1551L, 1412L, 1338L, 1164L, 1154L, 1057L, 
931L, 907L, 857L, 724L, 681L, 644L, 641L, 505L, 450L, 419L, 
405L, 328L, 324L, 324L, 320L, 281L, 262L), idx06 = c(1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), idx07 = c(0.972675591417568, 
0.766866371450899, 0.931743805516597, 0.813047711781889, 
0.88728323699422, 0.96420233463035, 0.855743544078362, 1.03710247349823, 
0.751470588235294, 0.90443686006826, 0.808403361344538, 0.902834008097166, 
0.718181818181818, 0.904555314533623, 1.02717391304348, 0.68957345971564, 
1.10324483775811, 0.93030303030303, 0.805309734513274, 0.843003412969283, 
0.74914089347079, 0.824786324786325, 1.04060913705584, 1.09150326797386, 
0.977941176470588, 0.892405063291139, 0.966666666666667, 
0.828125, 0.696, 0.813559322033898, 0.697841726618705, 0.88235294117647, 
0.62280701754386), idx08 = c(0.986612873647533, 0.712685595207085, 
0.840579710144927, 0.865628042843233, 0.93757225433526, 0.823346303501945, 
0.905609973285841, 1.03356890459364, 0.689705882352941, 0.909556313993174, 
0.798319327731092, 0.955465587044534, 0.714545454545455, 
0.620390455531453, 1.10869565217391, 0.815165876777251, 0.64306784660767, 
0.818181818181818, 0.722713864306785, 0.627986348122867, 
0.59106529209622, 0.927350427350427, 1.21319796954315, 1.20915032679739, 
1.33088235294118, 0.759493670886076, 1.40833333333333, 0.734375, 
0.896, 0.932203389830508, 0.60431654676259, 0.872549019607843, 
0.675438596491228), farve1 = c(""""green"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"green"""", """"red"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"red"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"green"""", 
""""green"""", """"green""""), farve2 = c(""""red"""", """"green"""", """"green"""", """"red"""", 
""""red"""", """"green"""", """"red"""", """"green"""", """"green"""", """"red"""", """"green"""", 
""""red"""", """"green"""", """"green"""", """"red"""", """"red"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"red"""", """"red"""", """"red"""", """"red"""", """"green"""", 
""""red"""", """"green"""", """"red"""", """"red"""", """"green"""", """"green"""", """"red"""")), .Names = c(""""Type"""", 
""""I.alt"""", """"idx06"""", """"idx07"""", """"idx08"""", """"farve1"""", """"farve2""""), class = """"data.frame"""", row.names = c(NA, -33L))
</code></pre>
",1
"<p>I have two sets of data points that both relate to the same primary axis, but who differ in secondary axis. Is there some way to plot them on top of each other in R using ggplot2? </p>

<p>What I am looking for is basically something that looks like this:</p>

<pre>
4+           |
 | x       . + 220
3+     . .   |
 |   x       |
2+   .       + 210
 |     x     |
1+ .     x x |
 |           + 200
0+-+-+-+-+-+-+
     time   

   . temperatur
   x car sale
</pre>

<p>(This is just a example of possible data)</p>
",1
"<p>As per Shanes excellent <a href=""""https://stackoverflow.com/questions/1544907/melt-to-two-variable-columns"""" title=""""excellent solution"""">solution</a> of another question, I now realise that I do not know how to do this.</p>

<p>My original approach was to use melt the data (thanks again shane):</p>

<pre><code>dm1 &lt;- melt(d[,c(""""Type"""",""""I.alt"""",""""idx06"""",""""idx07"""",""""idx08"""")], id=c(""""Type"""",""""I.alt""""))
dm2 &lt;- melt(d[,c(""""Type"""",""""I.alt"""",""""farve1"""",""""farve2"""")], id=c(""""Type"""",""""I.alt""""))
colnames(dm2) &lt;- c(""""Type"""", """"I.alt"""", """"variable2"""", """"value2"""")
dm &lt;- merge(dm1, dm2)
</code></pre>

<p>And then make the plot:</p>

<pre><code>ggplot(dm, aes(x=variable,y=value,group=Type,label=Type,size=I.alt))+
  geom_line(aes(col=value2))+
  geom_text(data=subset(dm, variable==""""idx08""""),hjust=-0.2, size=2.5)+
  theme_bw()+
  scale_x_discrete(expand=c(0,1))+
  opts(legend.position=""""none"""")+
  scale_colour_manual(values=c(""""green"""",""""red""""))
</code></pre>

<p>But it's not working (all the individual line pieces going """"up"""" should be red, all going """"down"""" should be green):</p>

<p><a href=""""http://wana.dk/wp-content/uploads/2009/10/damn.png"""" rel=""""nofollow noreferrer"""">BTW:does the png device insist on geom_point? http://wana.dk/wp-content/uploads/2009/10/damn.png</a></p>

<p>(bonus question 1: how can I use expand to only expand to the right? (where my labels ' at.))</p>

<p>(bonus question 2: Both png and pdf device shows up like above - i.e. with geom_points - this does not happen on my screen)</p>

<p>This is my data:</p>

<pre><code>d &lt;- structure(list(Type = structure(c(8L, 21L, 23L, 20L, 6L, 14L, 
3L, 24L, 2L, 28L, 32L, 22L, 15L, 29L, 1L, 17L, 18L, 33L, 25L, 
13L, 30L, 11L, 26L, 9L, 12L, 4L, 5L, 27L, 16L, 19L, 10L, 31L, 
7L), .Label = c(""""Alvorligere vold"""", """"Andre strafferetlige særlove"""", 
""""Andre tyverier"""", """"Bedrageri"""", """"Brandstiftelse"""", """"Butikstyverier m.v."""", 
""""Dokumentfalsk"""", """"Færdselslovovertræd. i øvrigt"""", """"Færdselsuheld med spiritus"""", 
""""Falsk forklaring i øvrigt"""", """"Forbr. mod off. myndighed m.v."""", 
""""Freds- og ærekrænkelser"""", """"Hæleri"""", """"Hærværk"""", """"Indbrud i bank, forretn. m.v."""", 
""""Indbrud i fritidshuse, garager mv"""", """"Indbrud i villaer, lejligheder mv"""", 
""""Love vedr. forsvaret og lign."""", """"Love vedr. spil, bev., næring"""", 
""""Lov om euforiserende stoffer"""", """"Mangler ved køretøj"""", """"Røveri"""", 
""""Simpel vold"""", """"Spiritus- og promillekørsel"""", """"Trusler"""", """"Tyv./brugstyv. af andet"""", 
""""Tyv./brugstyv. af cykel"""", """"Tyv./brugstyv. af indr. køretøj"""", 
""""Tyv/brugstyv. af knallert"""", """"Tyveri fra bil, båd m.v."""", """"Ulovlig omgang med hittegods"""", 
""""Våbenloven"""", """"Vold o.l. mod off. myndighed""""), class = """"factor""""), 
I.alt = c(16137L, 9519L, 5930L, 5502L, 4887L, 3582L, 3101L, 
1738L, 1660L, 1649L, 1551L, 1412L, 1338L, 1164L, 1154L, 1057L, 
931L, 907L, 857L, 724L, 681L, 644L, 641L, 505L, 450L, 419L, 
405L, 328L, 324L, 324L, 320L, 281L, 262L), idx06 = c(1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), idx07 = c(0.972675591417568, 
0.766866371450899, 0.931743805516597, 0.813047711781889, 
0.88728323699422, 0.96420233463035, 0.855743544078362, 1.03710247349823, 
0.751470588235294, 0.90443686006826, 0.808403361344538, 0.902834008097166, 
0.718181818181818, 0.904555314533623, 1.02717391304348, 0.68957345971564, 
1.10324483775811, 0.93030303030303, 0.805309734513274, 0.843003412969283, 
0.74914089347079, 0.824786324786325, 1.04060913705584, 1.09150326797386, 
0.977941176470588, 0.892405063291139, 0.966666666666667, 
0.828125, 0.696, 0.813559322033898, 0.697841726618705, 0.88235294117647, 
0.62280701754386), idx08 = c(0.986612873647533, 0.712685595207085, 
0.840579710144927, 0.865628042843233, 0.93757225433526, 0.823346303501945, 
0.905609973285841, 1.03356890459364, 0.689705882352941, 0.909556313993174, 
0.798319327731092, 0.955465587044534, 0.714545454545455, 
0.620390455531453, 1.10869565217391, 0.815165876777251, 0.64306784660767, 
0.818181818181818, 0.722713864306785, 0.627986348122867, 
0.59106529209622, 0.927350427350427, 1.21319796954315, 1.20915032679739, 
1.33088235294118, 0.759493670886076, 1.40833333333333, 0.734375, 
0.896, 0.932203389830508, 0.60431654676259, 0.872549019607843, 
0.675438596491228), farve1 = c(""""green"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"green"""", """"red"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"red"""", """"red"""", 
""""green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"green"""", """"green"""", 
""""green"""", """"green""""), farve2 = c(""""red"""", """"green"""", """"green"""", """"red"""", 
""""red"""", """"green"""", """"red"""", """"green"""", """"green"""", """"red"""", """"green"""", 
""""red"""", """"green"""", """"green"""", """"red"""", """"red"""", """"green"""", """"green"""", 
""""green"""", """"green"""", """"green"""", """"red"""", """"red"""", """"red"""", """"red"""", """"green"""", 
""""red"""", """"green"""", """"red"""", """"red"""", """"green"""", """"green"""", """"red"""")), .Names = c(""""Type"""", 
""""I.alt"""", """"idx06"""", """"idx07"""", """"idx08"""", """"farve1"""", """"farve2""""), class = """"data.frame"""", row.names = c(NA, -33L))
</code></pre>
",1
"<p>I am tracking my body weight in a spread sheet but I want to improve the experience by using R. I was trying to find some information about time series analysis in R but I was not succesful.</p>

<p>The data I have here is in the following format:</p>

<p>date -> weight  -> body-fat-percentage  -> water-percentage</p>

<p>e.g.
10/08/09 -> 84.30 -> 18.20 -> 55.3</p>

<p>What I want to do</p>

<p>plot weight and exponential moving average against time</p>

<p>How can I achieve that?</p>
",1
"<p>I am fitting a simple regression in R on gas usage per capita. The regression formulas looks like:</p>

<pre><code>gas_b &lt;- lm(log(gasq_pop) ~ log(gasp) + log(pcincome) + log(pn) +
            log(pd) + log(ps) + log(years), 
            data=gas)
summary(gas_b)
</code></pre>

<p>I want to include a linear constraint that the beta coefficients of <code>log(pn)+log(pd)+log(ps)=1</code> (sum to one).  Is there a simple way of implementing this (possibly in the <code>lm</code> function) in R without having to use <code>constrOptim()</code> function?</p>
",1
"<p>I've been mostly working in SAS of late, but not wanting to lose what familiarity with R I have, I'd like to replicate something basic I've done. You'll forgive me if my SAS code isn't perfect, I'm doing this from memory since I don't have SAS at home.</p>

<p>In SAS I have a dataset that roughly is like the following example (. is equivalent of NA in SAS)</p>

<pre><code>A  B
1  1
1  3
0  .
0  1
1  0
0  0
</code></pre>

<p>If the dataset above was work.foo then I could do something like the following.</p>

<pre><code>/* create work.bar from dataset work.foo */
data work.bar;
set work.foo;

/* generate a third variable and add it to work.bar */
if a = 0 and b ge 1 then c = 1;
if a = 0 and b = 0  then c = 2;
if a = 1 and b ge 1 then c = 3;
if a = 1 and b = 0  then c = 4;
run;
</code></pre>

<p>and I'd get something like</p>

<pre><code>A  B  C
1  1  3
1  3  3
0  .  .
0  1  1
1  0  4
0  0  2
</code></pre>

<p>And I could then proc sort by C and then perform various operations using C to create 4 subgroups.  For example I could get the means of each group with</p>

<pre><code>proc means noprint data =work.bar; 
by c;
var a b;
output out = work.means mean(a b) = a b;
run;
</code></pre>

<p>and I'd get a data of variables by groups called work.means
something like:</p>

<pre><code>C  A  B
1  0  1
2  0  0
3  2  2
4  1  0
</code></pre>

<p>I think I may also get a . row, but I don't care about that for my purposes.  </p>

<p>Now in R. I have the same data set that's been read in properly, but I have no idea how to add a variable to the end (like CC) or how to do an operation on a subgroup (like the by cc command in proc means).  Also, I should note that my variables aren't named in any sort of order, but according to what they represent.</p>

<p>I figure if somebody can show me how to do the above, I can generalize it to what I need to do.</p>
",1
"<p>I am using ggplot2 to do some plotting of genomic data, so the basic format is that there is a chromosome and a position along it.  I convert the positions to be on a continuous scale, then put the breaks at the boundaries of the chromosomes with:</p>

<p><code>scale_x_continuous(""""Genome Position"""", breaks = c(0, cumsum(chromosome_length)))</code></p>

<p>That looks great, as far as the actual plotting is concerned, but the labels are then put at the start and end of the chromosomes.  I would like them to be centered along each chromosome, at the position where the minor break is drawn by default.</p>

<p>Is this possible?</p>
",1
"<p>How do you properly write a double <code>for</code> loop in R?</p>

<p>For example, in C I would do</p>

<pre><code>int i, j;
for (i = 1; i &lt; 6; i++) {
    for (j=i; j &lt;= 3; j++) {
        printf(""""%i,%i\n"""",i,j);
    }
    // Do more operations for i &gt; 3...
}
</code></pre>

<p>which would generate the (artificial) sequence:</p>

<pre><code>1,1
1,2
1,3
2,2
2,3
3,3
</code></pre>

<p>In R you do not get the same behaviour when you write</p>

<pre><code>for (i in 1:6) {
    for (j in i:3) {
        print(paste(i,j,sep="""",""""))
    }
}
</code></pre>

<p>so I've been reduced to doing something like</p>

<pre><code>for (i in 1:6) {
    j &lt;- i
    while (j &lt;= 3) {
        print(paste(i,j,sep="""",""""))
        j &lt;- j+1
    }
}       
</code></pre>

<p>Is there a better way?</p>

<p>As Shane mentioned, maybe I should make this clear: I am particularly interested in the code-style matching the mathematics to make it easier for students to understand. It seems that students are the most comfortable with <code>for</code> loops.</p>

<p>In particular, I want my students to simulate a <a href=""""http://en.wikipedia.org/wiki/LIBOR_market_model"""" rel=""""nofollow noreferrer"""">LIBOR market model</a>. The dynamics of the forward rate are to be simulated under the same probability measure. As such, for each time step and each 
 forward rate, the appropriate drift correction \mu_i needs to be calculated and added.</p>
",1
"<p>I was wondering whether it is possible to use the lapply() function to alter the value of the input, similar to:</p>

<pre><code>a1&lt;-runif(100)
a2&lt;-function(i){
a1[i]&lt;-a1[i-1]*a1[i];a1[i]
}
a3&lt;-lapply(2:100,a2)
</code></pre>

<p>I'm looking for something akin to a for() loop, but using the lapply() infrastructure. I haven't been able to get rapply() to do this.</p>

<p>The reason is that the """"real"""" a2 function is a difficult function that only needs to be evaluated if the value of a1[i-1] meets some criteria.</p>

<p>re-phrasing: so i'm trying to replace the for() in the code below by a lapply()-type thing:</p>

<pre><code>    a1&lt;-runif(100)
    a2&lt;-function(i, a1){
        a1[i]&lt;-a1[i-1]*2
        a1[i]
    }
    a3&lt;-as.numeric(lapply(2:100, a2, a1=a1))
#compare the output of a3 with that of a1 after the recursive loop
    a2&lt;-a1 #saved for comparison
    for(i in 2:length(a1)){
        a1[i]&lt;-a1[i-1]*2
    }
cbind(a1[2:100],a3)
#actually this is would be like writting a lapply() version of the cumprod() function
cbind(a1,cumprod(a2))
</code></pre>

<p>The R mailing list has advised looking unto the Reduce() function....as in:</p>

<pre><code>a1&lt;-runif(100)
cadd&lt;-function(x) Reduce(""""*"""", x, accumulate = TRUE)
cadd(a1)
</code></pre>

<p>which gives the same result as cumprod(a1)...but is even slower than the loop:</p>

<pre><code>a1&lt;-runif(100000)
cadd&lt;-function(x) Reduce(""""*"""", x, accumulate = TRUE)
looop&lt;-function(a1){
j&lt;-length(a1)
    for(i in 2:j){
        a1[i]&lt;-a1[i-1]*a1[i]
    }
a1
}

&gt; system.time(cadd(a1))
   user  system elapsed 
  1.344   0.004   1.353 
&gt; system.time(cumprod(a1))
   user  system elapsed 
  0.004   0.000   0.002 
&gt; system.time(loop(a1))
   user  system elapsed 
  0.772   0.000   0.775 
&gt; 
</code></pre>

<p>Any idea ? </p>
",1
"<p>R is <a href=""""http://en.wikipedia.org/wiki/Functional_programming"""" rel=""""nofollow noreferrer"""">a functional programming language</a>, and one of it's primary benefits is it's ability to create open and transparent functions.</p>

<p>As John Chambers says <a href=""""http://books.google.com/books?id=UXneuOIvhEAC&amp;printsec=frontcover"""" rel=""""nofollow noreferrer"""">in his excellent book """"Software for Data Analysis: Programming with R""""</a>:</p>

<blockquote>
  <p>Computations are organized around functions, which can encapsulate specific, meaningful computational results, with implementations that can be examined for correctness.</p>
</blockquote>

<p>Notions such as """"reproducible research"""" and """"trustworthy software"""" are at the heart of R development.  In general, it is easy to examine a function just by typing its name without parenthesis.  For instance:</p>

<pre><code>&gt; which
function (x, arr.ind = FALSE) 
{
    if (!is.logical(x)) 
        stop(""""argument to 'which' is not logical"""")
    wh &lt;- seq_along(x)[x &amp; !is.na(x)]
    dl &lt;- dim(x)
...
</code></pre>

<p>My question is: how do you example the contents of functions such as <code>for()</code> or <code>if()</code> without downloading the R source code?</p>

<p><i>Edit:</i> Incidentally, I understand that this won't help viewing compiled code (such as C, C++, or Java) that may be called from R.  I'm really wondering if there is an R function which output's R functions.</p>
",1
"<p>I'd like to merge a bunch of data frames together (because it seems many operations are easier if you're only dealing w/ one, but correct me if I'm wrong).</p>

<p>Currently I have one data frame like this:</p>

<pre><code>ID, var1, var2
A,  2,    2
B,  4,    5
.
.
Z,  3,    2
</code></pre>

<p>Each ID is on a single row w/ several single measurements</p>

<p>I also have a csv file w/ repeated measurement for each ID, like:</p>

<p>filename = ID_B.csv</p>

<pre><code>time, var4, var5
0,    1,    2
1,    4,    5
2,    1,    6
...
</code></pre>

<p>What I'd like is:</p>

<pre><code>ID, time, va1, var2, var4, var5
...
B,  0,    4,   5,    1,    2,
B,  1,    4,   5,    4,    5,
B,  2,    4,   5,    1,    6,
...
</code></pre>

<p>I don't really care about the column order.  The only solution I can think of is to add the ID column to each csv file then loop through them calling <code>merge()</code> several times.  Is there a more elegant approach?</p>
",1
"<p>I have a dataset showing the exchange rate of the Australian Dollar versus the US dollar once a day over a period of about 20 years.  I have the data in a data frame, with the first column being the date, and the second column being the exchange rate.   Here's a sample from the data:</p>

<pre><code>&gt;data
             V1     V2
1    12/12/1983 0.9175
2    13/12/1983 0.9010
3    14/12/1983 0.9000
4    15/12/1983 0.8978
5    16/12/1983 0.8928
6    19/12/1983 0.8770
7    20/12/1983 0.8795
8    21/12/1983 0.8905
9    22/12/1983 0.9005
10   23/12/1983 0.9005
</code></pre>

<p>How would I go about displaying the top n% of these records?  E.g. say I want to see the days and exchange rates for those days where the exchange rate falls in the top 5% of all exchange rates in the dataset?</p>
",1
"<p>Say I have a bunch of functions, each with something like<code>MyFunction.1</code>, etc.  I want to pass these functions into another function, which prints out a small report.  Ideally I'd like to be able to label sections of a report by which function is being used to generate the results.  </p>

<p>So are there any nice ways of getting the name of a predefined function as a string?</p>
",1
"<p>I have a vector x, that I would like to sort based on the order of values in vector y. The two vectors are not of the same length.</p>

<pre><code>x &lt;- c(2, 2, 3, 4, 1, 4, 4, 3, 3)
y &lt;- c(4, 2, 1, 3)
</code></pre>

<p>The expected result would be:</p>

<pre><code>[1] 4 4 4 2 2 1 3 3 3
</code></pre>
",1
"<p>I'd like to create a zip archive from within R, and need maximal cross-platform compatibility, so I would prefer not to use a <code>system(""""zip"""")</code> command.</p>

<p>Within utils there's <code>zip.file.extract</code> (aka unzip), which uses [a lot of] c code, derived from zlib 1.1.3 within a file called dounzip.c I couldn't find any similar capabilities for creating zip files.</p>

<p>It's also tricky to construct a specific google query for """"cran create zip"""" or equivalent!</p>

<p>Also, a tar will not suffice, I need to creating zip's to use as input for another set of non-R tools.</p>

<p>I'd appreciate any pointers?</p>

<p>cheers,
mark</p>
",1
"<p>This may be a naive question, but I was wondering if there's a better way than using <code>text()</code> to adding text to a plot.  Note, I'm also using <code>layout()</code> as well.  Specifically, I have a section of a plot where I would like to add some text with headings followed by regular text. </p>

<p><code>text()</code> is fine it seems for simple annotations, but to get the spacing right for several lines of text seems to require a lot of manual manipulation of the <code>x</code> and <code>y</code> and <code>cex</code> parameters.  Any suggestions?</p>
",1
"<p>I have some data for which, at one level of a factor, there is a significant correlation.  At the other level, there is none.  Plotting these side-by-side is simple.  Adding a line to both of them with stat_smooth, also straightforward.  However, I do not want the line or its fill displayed in one of the two facets.  Is there a simple way to do this?  Perhaps specifying a blank color for the fill and colour of one of the lines somehow? </p>
",1
"<p>I have a large dataset (202k points).  I know that there are 8 values over 0.5.  I want to subset on those rows.</p>

<p>How do I find/return a list the row numbers where the values are > 0.5?</p>
",1
"<p>What are the better options to convert a non-decreasing seq of occurrence times to a 0-1 seq? Thanks.</p>

<pre><code>d&lt;-c(3,5,9,12,15);
c(rep(0,d[1]-1),1,unlist(rbind(mapply(rep,0,diff(d)-1),1)))
</code></pre>
",1
"<p>I want to output a dataframe using R2HTML, and remove scientific notation. Ideas?</p>
",1
"<p>I'm outputting a dataframe to html via <code>xtable</code>. I want to add commas to numbers in a couple columns of the table. I figured before I did my own paste hack I'd check if there is a built in way to do this.</p>
",1
"<p>OK, so I'm trying to use S4 classes to build a very complex object, with slots including a half-dozen matrices, a few lists, and probably a kitchen sink or two in there. The object is initialized by referring to and unpacking a configuration object which I've already defined. It's easy enough to define the class with setClass(), but I'm having difficulty figuring out an elegant way of setting the slots in the setMethod(""""initialize""""). </p>

<p>The problem is that I need to set particular elements of those half-dozen matrices based on parts of that configuration object. For each element of the configuration object, I may have to set specific elements of several of the matrices. Note that the matrices are in the scope/environment of the initialize function. I then have nested functions within the initialize function that do the actual assignment to the matrices, or that's the idea anyway. Those functions can of course <em>see</em> the matrices, but they can't <em>modify</em> them because the &lt;- operator creates a new matrix if the original variable was not defined in the current environment. R is pass-by-value, and means it. This is even true for slots of the .Object I'm trying to initialize. So I can't use nested functions to do the initialization.</p>

<p>Unfortunately, these nested functions have to modify several of the matrices, so returning values and doing the assignment in the main initialize function is not practical or elegant. (But it is possible, if I stuffed copies of the matrices into returned lists and then combined them in the main initialize function. Ugly though, and would require a lot of extra code.)</p>

<p>And iteration (which would prevent this scoping issue) is not very practical either because of the hierarchical nature of the configuration object, which really wants to be traversed with recursive calls.</p>

<p>The last option I can think of would be to use the assign() function with the envir option to force the assignment to apply to the nonlocal variable. But using environments like that seems icky, like a goto statement... </p>

<p>So, what is the most piratical approach? Stick with pure functional programming and build ugly data structures just to inefficiently pass around redundant matrices? Try to find an iterative solution that avoids functions altogether? Use deep magic by playing with environments?</p>
",1
"<p>In R, what's the best way to simulate an arbitrary univariate random variate if only its probability density function is available?</p>
",1
"<p>I have installed <a href=""""http://biostat.mc.vanderbilt.edu/rapache/"""" rel=""""nofollow noreferrer"""">rapache</a> and i am trying to fit a linear model inside the R script file. I have configured the RFileHandler in the http.conf. When i am trying to invoke the summary(model) it is giving me a segment fault error ( i see this in the apache log file). I am guessing that it is trying to print to the console and that is why it is failing. </p>

<p>Has any one encountered a similar problem with R and rapache? I am relatively new to R and summary is doing a lot of things that are not directly exposed as functions so i am hoping i could get it to work</p>

<p>Here is my r script</p>

<pre><code>mydata&lt;- read.table(""""/home/user/test.csv"""",header=TRUE,sep="""","""")
fit&lt;- lm(y~x1+x2+x3,data=mydata)
setContentType(""""text/html"""")
cat('&lt;HTML&gt;&lt;BODY&gt;')
cat(summary(fit)$adj.r.squared)
cat('&lt;/BODY&gt;&lt;/HTML&gt;\n')
DONE
</code></pre>

<p>if i replace </p>

<pre><code>    cat(summary(fit)$adj.r.squared)
</code></pre>

<p>with this</p>

<pre><code>    cat(coef(fit))
</code></pre>

<p>it is working!</p>

<p>Thanks
Bharani</p>
",1
"<p>How does one """"throw"""" an error in R?  I have a function that takes a data frame and some column names and does stuff with them.  If the columns don't exist, I want the function to stop and to stop all functions depending on it. </p>

<p>I have looked at <code>recover</code> and <code>browse</code> and <code>traceback</code> but, well, they seemed to be close but not what I am looking for.</p>
",1
"<p>Is there a way to have an <code>R</code> Device (postscript would be great) write the output into a variable instead of a file?</p>

<p>For example I know this:</p>

<pre><code>postscript(file=""""|cat"""")
plot(1:10)
dev.off()
</code></pre>

<p>Will send the postscript text to <code>STDOUT</code>.  How can I get that text into a variable within <code>R</code>?</p>
",1
"<p>I've been using <code>debug()</code> more often now, but sometimes I wonder which functions have been flagged for debugging.  I know that you can use <code>isdebugged()</code> to find out if a particular function is flagged.  But is there a way for R to list all the functions that are being debugged?</p>
",1
"<p>The systems I work with have GCC 4.5 (experimental) in /usr/local/bin/gcc which has proven to be problematic for some R packages. I would like to instead use system GCC in /usr/bin/gcc.</p>

<p>I have tried setting CC and CXX in the Bash configuration files (.bashrc, .bash_profile etc.) as well as on the command line, but although Bash recognizes the change, R does not.</p>

<p>How can I get R to use the version of GCC in /usr/bin instead of the one in /usr/local/bin/? </p>
",1
"<p>I have a vector of integers between 0 and 5.  I want to compute a histogram of counts.  For example:</p>

<pre><code>y &lt;- c(0, 0, 1, 3, 4, 4)
table(y)
# y
# 0 1 3 4 
# 2 1 1 2 
</code></pre>

<p>However, I also want the results to include the fact that there are zero 2's and zero 5's, ie. I want the returned vector to have length 6. Can I use <code>table()</code> for this?</p>

<p>Desired result:</p>

<pre><code># y
# 0 1 2 3 4 5 
# 2 1 0 1 2 0
</code></pre>
",1
"<p>I am using the <code>R's stats</code> package and would like to loop through <code>column[x]</code> in <code>all the rows of a dataframe</code>, operate on the data in <code>each cell</code> in the column with a function and pass the result to a new column (with the <code>calculated result</code> in the <code>new column</code> aligned with the data in <code>column[x]</code>)</p>

<p>I've got two problems:  </p>

<ol>
<li>I can't get it to work </li>
<li>looping seems to be discouraged in the <code>R articles</code> I've read.  Is there an alternative approach and if not, does anyone have an example of how to carry out the loop?</li>
</ol>
",1
"<p>I have a simple question: 
given p points (non-collinear) in R^p i find the hyperplane passing by these points (to help clarify i type everything in R):</p>

<pre><code>p&lt;-2
x&lt;-matrix(rnorm(p^2),p,p)
b&lt;-solve(crossprod(cbind(1,x[,-2])))%*%crossprod(cbind(1,x[,-2]),x[,2])
</code></pre>

<p>then, given a p+1^th points not collinear with first p points, i find the direction perpendicular to b:</p>

<pre><code>x2&lt;-matrix(rnorm(p),p,1)
b2&lt;-solve(c(-b[-1],1)%*%t(c(-b[-1],1))+x2%*%t(x2))%*%x2
</code></pre>

<p>That is, b2 defines a p dimensional hyperplane perpendicular to b and passing by x2.
Now, my questions are:</p>

<p>The formula comes from <a href=""""http://en.wikipedia.org/wiki/Surface_normal"""" rel=""""nofollow noreferrer"""">my interpretation of this wikipedia entry</a> (""""solve(A)"""" is the R command for A^-1). Why this doesn't work for p>2 ? What am i doing wrong ?</p>

<p>PS: I have seen this post (on stakeoverflow edit:sorry cannot post more than one link) but somehow it doesn't help me.</p>

<p>Thanks in advance,</p>

<p>i have a problem implementation/understanding of Liu's solution when p>2:</p>

<p>shouldn't the dot product between the qr decomposition of the sweeped matrix and the direction of the hyperplane be 0 ? (i.e. if the qr vectors are perpendicular to the hyperplane)</p>

<p>i.e, when p=2 this </p>

<pre><code>c(-b[2:p],1)%*%c(a1)
</code></pre>

<p>gives 0. When p>2 it does not. </p>

<hr>

<p>Here is my attempt to implement Victor Liu's solution.</p>

<p>a) given p linearly independent observations in R^p:</p>

<pre><code>p&lt;-2;x&lt;-matrix(rnorm(p^2),p,p);x
      [,1]       [,2]
[1,] -0.4634923 -0.2978151
[2,]  1.0284040 -0.3165424
</code></pre>

<p>b) stake them in a matrix and subtract the first row:</p>

<pre><code>a0&lt;-sweep(x,2,x[1,],FUN=""""-"""");a0
        [,1]        [,2]
[1,] 0.000000  0.00000000
[2,] 1.491896 -0.01872726
</code></pre>

<p>c) perform a QR decomposition of the matrix a0. The vector in the nullspace is the direction im looking for:</p>

<pre><code>qr(a0)
          [,1]       [,2]
[1,] -1.491896 0.01872726
[2,]  1.000000 0.00000000
</code></pre>

<p>Indeed; this direction is the same as the one given by application of the formula from wikipedia (using x2=(0.4965321,0.6373157)): </p>

<pre><code>       [,1]
[1,]  2.04694853
[2,] -0.02569464
</code></pre>

<p>...with the advantage that it works in higher dimensions.</p>

<p>I have one last question: what is the meaning of the other p-1 (i.e. (1,0) here) QR vector when p>2 ?
-thanks in advance, </p>
",1
"<p>How do I debug <code>Rscripts</code> that are run from the command line? </p>

<p>I am currently using the <code>getopt</code> package to pass command line options, nut when there's a bug, it is hard for me to: </p>

<ol>
<li>see what exactly went wrong; </li>
<li>debug interactively in <code>R</code> (since the script expects command line options.)</li>
</ol>

<p>Does anyone have example code and willing to share? </p>
",1
"<p>I have two vectors of integers, and for each element of the second vector I want to find the minumum distance to any element of the first vector - for example</p>

<pre><code>obj1 &lt;- seq(0, 1000, length.out=11)
obj2 &lt;- 30:50
min_diff &lt;- sapply(obj2, function(x) min(abs(obj1-x)))
min_diff
</code></pre>

<p>returns</p>

<pre><code>[1] 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
</code></pre>

<p>Is there a more efficient way? I want to scale this up to thousands (millions?) of both obj1 &amp; obj2.</p>

<p>Thanks, 
Aaron</p>
",1
"<p>I'm working in an R script that uses a long SQL string, and I would like to keep the query relatively free of other markup so as to allow copying and pasting between editors and applications. I'd also like the ability to split the query across lines for better readability. </p>

<p>In the RODBC documentation, the <code>paste</code> function is used to build the query out of separate chunks, but I'd prefer something less kludgy and with fewer quotes and commas. Thanks for your help.</p>
",1
"<p>I have a large dataframe (14552 rows by 15 columns) containing billing data from 2001 to 2007. I have used sqlFetch to get 2008 data. In order to append the 2008 data to the data of the preceding 7 years one would do as follows</p>

<p><code>alltime &lt;-rbind(alltime,all2008)</code></p>

<p>Unfortunately that generates</p>

<blockquote>
  <p>Warning message:
  In <code>[&lt;-.factor</code>(<code>*tmp*</code>, ri, value = c(NA, NA, NA, NA, NA, NA, NA,  :
    invalid factor level, NAs generated</p>
</blockquote>

<p>My guess is that there are some new patients whose names were not in the previous dataframe and therefore it would not know what level to give it. Another column is for the name of the referring doctor. A new referring doctor would cause the same problem.</p>

<p>The way R imports data and automatically works out what is numeric and what is not (and thereby makes it a factor) is wonderful - untill you have to manipulate it further and then it becomes a pain. How do I overcome my problem elegantly?</p>
",1
"<p>I would like to save a whole bunch of relatively large data frames while minimizing the space that the files take up. When opening the files, I need to be able to control what names they are given in the workspace. </p>

<p>Basically I'm looking for the symantics of dput and dget but with binary files.</p>

<p>Example:</p>

<pre><code>n&lt;-10000

for(i in 1:100){
    dat&lt;-data.frame(a=rep(c(""""Item 1"""",""""Item 2""""),n/2),b=rnorm(n),
        c=rnorm(n),d=rnorm(n),e=rnorm(n))
    dput(dat,paste(""""data"""",i,sep=""""""""))
}


##much later


##extract 3 random data sets and bind them
for(i in 1:10){
    nums&lt;-sample(1:100,3)
    comb&lt;-rbind(dget(paste(""""data"""",nums[1],sep="""""""")),
            dget(paste(""""data"""",nums[2],sep="""""""")),
            dget(paste(""""data"""",nums[3],sep="""""""")))
    ##do stuff here
}
</code></pre>
",1
"<p>I ran <code>JAGS</code> with <code>runjags</code> in <code>R</code> and I got a giant list back (named results for this example). </p>

<p>Whenever I access <code>results$density</code>, two <code>lattice plots</code> (one for each parameter) pop up in the default quartz device. </p>

<p>I need to combine these with <code>par(mfrow=c(2, 1))</code> or with a similar approach, and send them to the <code>pdf device</code>. </p>

<p>Nothing I tried is working. Any ideas?</p>

<p>I've tried <code>dev.print</code>, <code>pdf()</code> with <code>dev.off()</code>, etc. with no luck.</p>
",1
"<p>I have a list of hclust objects resulting from slight variations in one variable (for calculating the distance matrix)</p>

<ul>
<li>now I would like to make a consensus tree from this list.</li>
</ul>

<p>Is there a generic package to do this? I am hacking my way through
some code from maanova and it seems to work - but it's ugly and it
needs a lot of hacking since I am not doing """"normal"""" bootstrapping (it's
chemical data).</p>

<p>/Palle Villesen, Denmark</p>

<pre><code>c1_list &lt;- seq(10,100,by=10)
c2 &lt;- 30
e&lt;- 1
mboot &lt;- list()
for (i in 1: length(c1_list) ) {
   c1 &lt;- c1_list[i]
   cat(""""Doing C1="""",c1,""""..."""")
   x &lt;- hclust(custom_euclidean(t(log2(data[, all]+1)), c1,c2,e), method='average')
   cat(""""..done\n"""")
   mboot[[i]] &lt;- x # To get hclust object back use mbot[[i]] to get i'th object
}

#### Now extract the robust groups from mboot...
</code></pre>
",1
"<p>I've been using F# for a while now to model algorithms before coding them in C++, and also using it afterwards to check the results of the C++ code, and also against real-world recorded data.</p>

<p>For the modeling side of things, it's very handy, but for the 'data mashup' kind of stuff, pulling in data from CSV and other sources, generating statistics, drawing charts etc., my colleague teases me no end (""""why are you coding that yourself? It's built in to MatLab"""").</p>

<p>And I have another colleague who swears by R, which also has charting stuff 'built-in'.</p>

<p>I know that MatLab, R and F# are not strictly comparable, so I'm not asking for a 'feature comparison shoot out'. I just wondered what other people are using for these kind of pre- and post-analysis scenarios, and how happy they are with it. </p>

<p>(If there's anyone out there working on wrapping Microsoft Charts into something F#-friendly, let me know, I'd be happy to participate...)</p>

<p><em>(Note: answers to this question will be subjective, but based on experience, please)</em></p>
",1
"<p>I'm using ggplot2 to create panels of histograms, and I'd like to be able to add a vertical line at the mean of each group.  But geom_vline() uses the same intercept for each panel (i.e. the global mean):</p>

<pre><code>require(""""ggplot2"""")
# setup some sample data
N &lt;- 1000
cat1 &lt;- sample(c(""""a"""",""""b"""",""""c""""), N, replace=T)
cat2 &lt;- sample(c(""""x"""",""""y"""",""""z""""), N, replace=T)
val &lt;- rnorm(N) + as.numeric(factor(cat1)) + as.numeric(factor(cat2))
df &lt;- data.frame(cat1, cat2, val)

# draws a single histogram with vline at mean
qplot(val, data=df, geom=""""histogram"""", binwidth=0.2) + 
  geom_vline(xintercept=mean(val), color=""""red"""")

# draws panel of histograms with vlines at global mean
qplot(val, data=df, geom=""""histogram"""", binwidth=0.2, facets=cat1~cat2) + 
  geom_vline(xintercept=mean(val), color=""""red"""")
</code></pre>

<p>How can I get it to use each panel's group mean as the x-intercept?  (Bonus points if you can also add a text label by the line with the value of the mean.)</p>
",1
"<p>I've got a data frame with 2 character columns. I'd like to find the rows which one column contains the other, however grepl is being strange. Any ideas?</p>

<pre><code>&gt; ( df &lt;- data.frame(letter=c('a','b'),food = c('apple','pear','bun','beets')) )
  letter  food
1      a apple
2      b  pear
3      a   bun
4      b beets 

&gt; grepl(df$letter,df$food)

[1]  TRUE  TRUE FALSE FALSE
</code></pre>

<p>but i want T F F T</p>

<p>Thanks.</p>
",1
"<p>After installing RPy2 from </p>

<p><a href=""""http://rpy.sourceforge.net/rpy2.html"""" rel=""""nofollow noreferrer"""">http://rpy.sourceforge.net/rpy2.html</a></p>

<p>I'm trying to use it in Python 2.6 IDLE but I'm getting this error:</p>

<pre><code>&gt;&gt;&gt; import rpy2.robjects as robjects
&gt;&gt;&gt; robjects.r['pi']

&lt;RVector - Python:0x0121D8F0 / R:0x022A1760&gt;
</code></pre>

<p>What I'm doing wrong?</p>
",1
"<p>I have a list of lists that looks like this: <code>x[[state]][[year]]</code>. Each element of this is a data frame, and accessing them individually is not a problem. </p>

<p>However, I'd like to rbind data frames across multiple lists. More specifically, I'd like to have as output as many dataframes as I have years, that is rbind all the state data frames within each year. In other words, I'd like to combine all my state data, year by year, into separate data frames.</p>

<p>I know that I can combine a single list into a data frame with <code>do.call(""""rbind"""",list)</code>. But I don't know how I can do so across lists of lists.</p>
",1
"<p>I am trying to compute the median vector of a data set <code>s</code> with column <code>A1</code> and <code>B1</code>. The median vector is the median for each  observation from both columns. </p>

<p>I tried to do this and it did not work. </p>

<pre><code>median(s[c(""""A1"""",""""B1"""")])
</code></pre>

<p>Is there another way to do it? </p>
",1
"<p>Suppose we have the contents of tables x and y in two dataframes in R. Which is the suggested way to perform an operation like the following in sql:</p>

<pre><code>Select x.X1, x.X2, y.X3
into z
from x inner join y on x.X1 = y.X1
</code></pre>

<p>I tried the following in R. Is there a better way? 
Thank you</p>

<pre><code>x&lt;-data.frame(cbind('X1'=c(5,9,7,6,4,8,3,1,10,2),'X2'=c(5,9,7,6,4,8,3,1,10,2)^2))
y&lt;-data.frame(cbind('X1'=c(9,5,8,2),'X3'=c('nine','five','eight','two')))

z&lt;-cbind(x[which(x$X1 %in% (y$X1)), c(1:2)][order(x[which(x$X1 %in% (y$X1)), c(1:2)]$X1),],y[order(y$X1),2])
</code></pre>
",1
"<p>Is there a way in R to build a new dataset consisting of a given set of vectors -- median1, median2, median3, median4 -- which are median vectors from a previous dataset s? </p>

<pre><code>median1 = apply(s[,c(""""A1"""",""""B1"""",""""C1"""",""""D1"""",""""E1"""",""""F1"""",""""G1"""",""""H1"""",""""I1"""")],1,median)
median2 = apply(s[,c(""""A2"""",""""B2"""",""""C2"""",""""D2"""",""""E2"""",""""F2"""",""""G2"""",""""H2"""",""""I2"""")],1,median)
median3 = apply(s[,c(""""A3"""",""""B3"""",""""C3"""",""""D3"""",""""E3"""",""""F3"""",""""G3"""",""""H3"""",""""I3"""")],1,median)
median4 = apply(s[,c(""""A4"""",""""B4"""",""""C4"""",""""D4"""",""""E4"""",""""F4"""",""""G4"""",""""H4"""",""""I4"""")],1,median)

plot(median1,median2, pch = """"."""")
</code></pre>
",1
"<p>Is there a variant of lag somewhere that keeps NAs in position? I want to compute returns of price data where data could be missing.</p>

<p>Col 1 is the price data
Col 2 is the lag of price
Col 3 shows p - lag(p) - the return from 99 to 104 is effectively missed, so the path length of the computed returns will differ from the true.
Col 4 shows the lag with NA position preserved
Col 5 shows the new difference - now the return of 5 for 2009-11-07 is available</p>

<p>Cheers, Dave</p>

<pre><code>x &lt;- xts(c(100, 101, 97, 95, 99, NA, 104, 103, 103, 100), as.Date(""""2009-11-01"""") + 0:9)

# fake the lag I want, with NA kept in position
x.pos.lag &lt;- lag.xts(x.pos)
x.pos.lag &lt;- lag.xts(x.pos)
x.pos.lag['2009-11-07']=99
x.pos.lag['2009-11-06']=NA

cbind(x, lag.xts(x), x - lag.xts(x), x.pos.lag, x-x.pos.lag)
           ..1 ..2 ..3 ..4 ..5
2009-11-01 100  NA  NA  NA  NA
2009-11-02 101 100   1 100   1
2009-11-03  97 101  -4 101  -4
2009-11-04  95  97  -2  97  -2
2009-11-05  99  95   4  95   4
2009-11-06  NA  99  NA  NA  NA
2009-11-07 104  NA  NA  99   5
2009-11-08 103 104  -1 104  -1
2009-11-09 103 103   0 103   0
2009-11-10 100 103  -3 103  -3
</code></pre>
",1
"<p>I'm trying to add a title at the top of the page scatterplots, however whenever I use the command <em>title</em> it doesn't add the title at the top of page and overwrites my plots. Is there a way to fix this ?</p>

<pre><code>plot(median, pch = """"."""")
title(main = """"Scatterplot of the median vectors """",line = 0,font=2)
</code></pre>
",1
"<p>How does one go about drawing an hyperplane (given the equation) in 3D in R ?
(i.e. 3d equivalent to """"abline"""")</p>

<p>Thanks in advance, </p>
",1
"<p>Let's say I have two columns of data. The first contains categories such as """"First"""", """"Second"""", """"Third"""", etc. The second has numbers which represent the number of times I saw """"First"""".</p>

<p>For example:</p>

<pre><code>Category     Frequency
First        10
First        15
First        5
Second       2
Third        14
Third        20
Second       3
</code></pre>

<p>I want to sort the data by Category and sum the Frequencies:</p>

<pre><code>Category     Frequency
First        30
Second       5
Third        34
</code></pre>

<p>How would I do this in R?</p>
",1
"<p>I regularly make figures (the exploratory data analysis type) in R. I also program in Python and was wondering if there are features or concepts in matplotlib that would be worth learning. For instance, I am quite happy with R - but its image() function will produce large files with pixelated output, whereas Matlab's equivalent figure (I also program regularly in Matlab) seems to be manageable in file size and also 'smoothed' - does matplotlib also provide such reductions...? But more generally, I wonder what other advantages matplotlib might confer. I don't mean this to be a trolling question. Thanks.</p>
",1
"<p>When programming in Stata I often find myself using the loop index in the programming. For example, I'll loop over a list of the variables nominalprice and realprice:  </p>

<pre><code>local list = """"nominalprice realprice""""
foreach i of local list {
  summarize `i'
  twoway (scatter `i' time)
  graph export """"C:\TimePlot-`i'.png""""
}
</code></pre>

<p>This will plot the time series of nominal and real prices and export one graph called TimePlot-nominalprice.png and another called TimePlot-realprice.png.  </p>

<p>In R the method I've come up with to do the same thing would be:  </p>

<pre><code>clist &lt;- c(""""nominalprice"""", """"realprice"""")
for (i in clist) {
  e &lt;- paste(""""png(\""""c:/TimePlot-"""",i,"""".png\"""")"""", sep="""""""")
  eval(parse(text=e))
  plot(time, eval(parse(text=i)))
  dev.off() 
}
</code></pre>

<p>This R code looks unintuitive and messy to me and I haven't found a good way to do this sort of thing in R yet. Maybe I'm just not thinking about the problem the right way? Can you suggest a better way to loop using strings? </p>
",1
"<p>I have a data set of comic book unit sales by volume (ex. Naruto v10) that I need to reduce to sales by series (so all Naruto volume unit sales would be added together into a single observation).  I have a variable """"series"""" that identifies the series of each observation.  The equivalent code in Stata would be: </p>

<pre><code>by series, sort:replace unitssales=sum(unitssales);
by series, sort:keep if _n==_N
</code></pre>

<p>But I'm trying to figure out how to do this in R.  Any help would be much appreciated!  Thanks in advance!</p>
",1
"<pre><code>data &lt;-c(88, 84, 85, 85, 84, 85, 83, 85, 88, 89, 91, 99, 104, 112, 126, 138, 146,151,   150, 148, 147, 149, 143, 132, 131, 139, 147, 150, 148, 145, 140, 134, 131, 131, 129, 126, 126, 132, 137, 140, 142, 150, 159, 167, 170, 171, 172, 172, 174, 175, 172, 172, 174, 174, 169, 165, 156, 142, 131, 121, 112, 104, 102, 99, 99, 95, 88, 84, 84, 87, 89, 88, 85, 86, 89, 91, 91, 94, 101, 110, 121, 135, 145, 149, 156, 165, 171, 175, 177, 182, 193, 204, 208, 210, 215, 222, 228, 226, 222, 220)
</code></pre>

<p>Why do the ARMA models acting on the first differences of the data differ from the corresponding ARIMA models?</p>

<pre><code>for (p in 0:5)
{
for (q in 0:5)
{
#data.arma = arima(diff(data), order = c(p, 0, q));cat(""""p ="""", p, """", q ="""", q, """"AIC ="""",  data.arma$aic, """"\n"""");
data.arma = arima(data, order = c(p, 1, q));cat(""""p ="""", p, """", q ="""", q, """"AIC ="""", data.arma$aic, """"\n"""");
}
}
</code></pre>

<p>Same with <code>Arima(data,c(5,1,4))</code> and <code>Arima(diff(data),c(5,0,4))</code> in the forecast package. I can get the desired consistency with</p>

<pre><code>auto.arima(diff(data),max.p=5,max.q=5,d=0,approximation=FALSE, stepwise=FALSE, ic =""""aic"""", trace=TRUE);
auto.arima(data,max.p=5,max.q=5,d=1,approximation=FALSE, stepwise=FALSE, ic =""""aic"""", trace=TRUE);
</code></pre>

<p>but it seems the holder of the minimum AIC estimate for these data has not been considered by the algorithm behind auto.arima; hence the suboptimal choice of ARMA(3,0) instead of ARMA(5,4) acting on the first differences. A related question is how much the two AIC estimates should differ before one considers one model better than the other has little to do wuth programming - the smallest AIC holder should at least be considered/reported, even though 9 coefficients may be a bit too much for a forecast from 100 observations.</p>

<p>My R questions are:</p>

<p>1) Vectorised version of the double loop so it is faster?</p>

<p>2) Why does <code>arima(5,1,4)</code> acting on the data differ from <code>arma(5,4)</code> acting on the first differences of the data? Which one is to be reported?</p>

<p>3) How do I sort the AICs output so that the smaller come first?</p>

<p>Thanks.</p>
",1
"<p>When I try to calculate Gest in spatstat I get the error:</p>

<blockquote>
  <p>bootstrap output matrix missing.</p>
</blockquote>

<p>Does anyone know what am I doing wrong?</p>
",1
"<p>I have a network loaded into an igraph object <code>G</code> that has 198 vertices and 214 edges.  If I run:</p>

<pre><code>eig&lt;-evcent(G)$vector
</code></pre>

<p>The resulting <code>eig</code> is a vector with 2172 elements, rather than 198 elements.   <a href=""""http://igraph.sourceforge.net/doc/R/evcent.html"""" rel=""""nofollow noreferrer"""">The documentation on the package</a> claims it returns the """"centralities of positions <code>v</code>.""""  Any ideas on how to get the eigenvalue centralities for each vertex?</p>
",1
"<p>I have the following vector:</p>

<pre><code>tmp3 &lt;- c(""""1500 2"""", """"1500 1"""", """"1510 2"""", """"1510 1"""", """"1520 2"""", """"1520 1"""", """"1530 2"""", 
""""1530 1"""", """"1540 2"""", """"1540 1"""")
</code></pre>

<p>I would like to just retain the second number in each of the atoms of this vector, so it would read:  </p>

<pre><code>c(2,1,2,1,2,1,2,1,2,1)
</code></pre>
",1
"<p>I am trying to find out whether the <a href=""""http://en.wikipedia.org/wiki/R_(programming_language)"""" rel=""""nofollow noreferrer"""">R programming language</a> is interpreted or compiled.  Can't seem to find this info.</p>

<hr>

<p><strong>Edit</strong>
I should have said interpreted or compiled to begin with.  Commenters are absolutely right - static or dynamic has nothing to do with whether the language is interpreted or dynamic.</p>
",1
"<p>I'm thinking to start learning <strong>R</strong>, but I want to know one thing, Is it embeddable(Windows CE, Palm OS)?</p>
",1
"<p>I have written a very basic package in R. In fact, I followed <a href=""""http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf"""" rel=""""nofollow noreferrer"""">this tutorial</a> for creating a basic package.</p>

<p>My package works just fine in linux. eg:</p>

<pre>
> install.packages(""""linmod"""", repos=NULL)
Warning in install.packages(""""linmod"""", repos = NULL) :
  argument 'lib' is missing: using '/home/jpgoel/R/i486-pc-linux-gnu-library/2.9'
* Installing *source* package ‘linmod’ ...
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
 >>> Building/Updating help pages for package 'linmod'
     Formats: text html latex example 
** building package indices ...
* DONE (linmod)
> library(linmod)
> data(mod1)
> mod1
Call:
linmod.default(x = x, y = y)

Coefficients:
     Const        Bwt 
-0.3566624  4.0340627 

</pre>

<p>Now, I took my """"linmod"""" folder, copied it to Windows XP, and tried the following:</p>

<pre>
> install.packages(""""C:\\Documents\ and\ Settings\\foo\\Desktop\\linmod"""",repos=NULL)
Error in gzfile(file, """"r"""") : cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In gzfile(file, """"r"""") :
  cannot open compressed file 'linmod/DESCRIPTION', probable reason 'No such file or directory'
> 
</pre>

<p>Okay. So then I took that folder and placed it into a .zip file. Then I went to Packages -> Install package(s) from local zip files... and selected my package.</p>

<pre>
> utils:::menuInstallLocal()
updating HTML package descriptions

> library(linmod)
Error in library(linmod) : 'linmod' is not a valid installed package

</pre>

<p>I'm stumped. My package doesn't have any native code (eg, no extensions written in C.)</p>

<p>Feel free to download the .zip <a href=""""http://www.2shared.com/file/8966494/44855d78/linmod.html"""" rel=""""nofollow noreferrer"""">from here</a> (the link to download is all the way at the bottom, """"Save file to your PC"""")</p>
",1
"<p>let's suppose that I have data frame like</p>

<pre><code>   expr_value     cell_type
1    5.345618 bj fibroblast
2    5.195871 bj fibroblast
3    5.247274 bj fibroblast
4    5.929771          hesc
5    5.873096          hesc
6    5.665857          hesc
7    6.791656          hips
8    7.133673          hips
9    7.574058          hips
10   7.208041          hips
11   7.402100          hips
12   7.167792          hips
13   7.156971          hips
14   7.197543          hips
15   7.035404          hips
16   7.269474          hips
17   6.715059          hips
18   7.434339          hips
19   6.997586          hips
20   7.619770          hips
21   7.490749          hips
</code></pre>

<p>What I want to is to get a new data frame which looks the same but only has the data for one cell_type. E.g.</p>

<pre><code>   expr_value     cell_type
1    5.929771          hesc
2    5.873096          hesc
3    5.665857          hesc
</code></pre>

<p>or for two classes like</p>

<pre><code>   expr_value     cell_type
1    5.345618 bj fibroblast
2    5.195871 bj fibroblast
3    5.247274 bj fibroblast
4    5.929771          hesc
5    5.873096          hesc
6    5.665857          hesc
</code></pre>

<p>Is there any easy way to do this?</p>

<p>What I've tried already is something like</p>

<pre><code>&gt; expr[expr[2] == 'hesc']
[1] """"5.929771"""" """"5.873096"""" """"5.665857"""" """"hesc""""     """"hesc""""     """"hesc""""    
&gt;
</code></pre>

<p>if the original data frame is called expr but it gives the results in wrong format as you can see.</p>
",1
"<p>I'm plotting a group of curves, using facet in ggplot2. I'd like to have a smoother applied to plots where there are enough points to smooth, but not on plots with very few points. In particular I'd like to stop the plot failing when one of the panels only has 1 or 2 points.</p>

<p>Example:</p>

<pre><code>a &lt;- data.frame( x=1:100, y=sin(seq(0.1,10,0.1) )) 
b &lt;- data.frame( x=1:5, y=sin(seq(0.1,0.2,0.1) )) 
l &lt;- melt(list(a=a,b=b),id.vars=""""x"""") 
qplot( x, value, data=l ) + geom_smooth() + facet_wrap( ~ L1 )
</code></pre>
",1
"<p>This question came today in the manipulatr mailing list.</p>

<pre><code>http://groups.google.com/group/manipulatr/browse_thread/thread/fbab76945f7cba3f
</code></pre>

<p>I am rephrasing.</p>

<p>Given a distance matrix (calculated with <code>dist</code>) apply a function to the rows of the distance matrix.</p>

<p>Code:</p>

<pre><code>library(plyr)
N &lt;- 100
a &lt;- data.frame(b=1:N,c=runif(N))
d &lt;- dist(a,diag=T,upper=T)
sumd &lt;- adply(as.matrix(d),1,sum)
</code></pre>

<p>The problem is that to apply the function by row you have to store the whole matrix (instead of just the lower triangular part. So it uses too much memory for large matrices. It fails in my computer for matrices of dimensions ~ 10000.</p>

<p>Any ideas?</p>
",1
"<p>I have a dataframe, and for each row in that dataframe I have to do some complicated lookups and append some data to a file.</p>

<p>The dataFrame contains scientific results for selected wells from 96 well plates used in biological research so I want to do something like:</p>

<pre><code>for (well in dataFrame) {
  wellName &lt;- well$name    # string like """"H1""""
  plateName &lt;- well$plate  # string like """"plate67""""
  wellID &lt;- getWellID(wellName, plateName)
  cat(paste(wellID, well$value1, well$value2, sep="""",""""), file=outputFile)
}
</code></pre>

<p>In my procedural world, I'd do something like:</p>

<pre><code>for (row in dataFrame) {
    #look up stuff using data from the row
    #write stuff to the file
}
</code></pre>

<p>What is the """"R way"""" to do this?</p>
",1
"<p>Is there an open source and/or free statistics package or library for <a href=""""http://en.wikipedia.org/wiki/Delphi_programming_language"""" rel=""""nofollow noreferrer"""">Delphi</a>? I'm looking for something that can compile directly into the executable, so no DLL's. It needs to be compatible with Delphi 2009 and later (the Unicode versions).</p>

<p>Hopefully there is something comprehensive available out there. By comparison, I am used to the amazing features of <a href=""""http://www.sas.com/technologies/analytics/statistics/stat/index.html"""" rel=""""nofollow noreferrer"""">SAS</a> and <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a>.  </p>

<p>I'm looking for distribution functions (normal, binomial, chi square, <a href=""""http://en.wikipedia.org/wiki/Logit"""" rel=""""nofollow noreferrer"""">logit</a>) and regression (linear, non-linear, multinomial) and if possible predictors (e.g. <a href=""""http://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average"""" rel=""""nofollow noreferrer"""">ARIMA</a>).</p>
",1
"<p>How do you debug a generic function (using debug, or mtrace in the debug package)?</p>

<p>As an example, I want to debug cenreg in the NADA package, specifically the method that takes a formula input.</p>

<p>You can retrieve the method details like this:</p>

<pre><code>library(NADA)
getMethod(""""cenreg"""", c(""""formula"""", """"missing"""", """"missing""""))

function (obs, censored, groups, ...) 
{
    .local &lt;- function (obs, censored, groups, dist, conf.int = 0.95, 
        ...) 
    {
        dist = ifelse(missing(dist), """"lognormal"""", dist)

...
}
</code></pre>

<p>The problem is that cenreg itself looks like this:</p>

<pre><code>body(cenreg)
# standardGeneric(""""cenreg"""")
</code></pre>

<p>I don't know how to step through the underlying method, rather than the generic wrapper.</p>
",1
"<p>Sorry for the non-descriptive title but I don't know whether there's a word for what I'm trying to achieve.</p>

<p>Let's assume that I have a list of names of different classes like</p>

<pre><code>c( '1', '2', '3', '4')
</code></pre>

<p>I'd like to generate all possible permutation pairs out of this so that there are no reverse-duplicates. So what I'd like to have is something like</p>

<pre><code>'1' '2'
'1' '3'
'1' '4'
'2' '3'
'2' '4'
'3' '4'
</code></pre>

<p>Note that I don't have e.g. <code>'2' '1'</code> because I already have <code>'1' '2'</code>. Is there an easy way to achieve this in R?</p>
",1
"<p>I'm running R 2.9 on a large EC2 Ubuntu instance, loaded with RAM, but without a terminal.  When I load a library that has display dependencies, such as the sqldf package, I receive the following error:</p>

<pre><code>library(sqldf)
...
Loading required package: tcltk
Loading Tcl/Tk interface ... Error in fun(...) : couldn't connect to display """"localhost:11.0""""
Error : .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package 'tcltk' could not be loaded
</code></pre>

<p>This seems to be a general problem, and I'm wondering how others have solved it.  Installing an X11 server is not a desirable solution.</p>
",1
"<p>I'm getting a weird error when training a glmnet regression.</p>

<pre><code>invalid class """"dgCMatrix"""" object: length(Dimnames[[2]])' must match Dim[2] 
</code></pre>

<p>It only happens occasionally, and perhaps only under larger datasets.</p>

<p>I'm not sure whether it's consistent it happens given a certain dataset.</p>

<p>Any clues?</p>
",1
"<p>I want do fit some sort of multi-variate time series model using R. </p>

<p>Here is a sample of my data:</p>

<pre><code>   u     cci     bci     cpi     gdp    dum1 dum2 dum3    dx  
 16.50   14.00   53.00   45.70   80.63  0   0    1     6.39 
 17.45   16.00   64.00   46.30   80.90  0   0    0     6.00 
 18.40   12.00   51.00   47.30   82.40  1   0    0     6.57 
 19.35   7.00    42.00   48.40   83.38  0   1    0     5.84 
 20.30   9.00    34.00   49.50   84.38  0   0    1     6.36 
 20.72   10.00   42.00   50.60   85.17  0   0    0     5.78 
 21.14   6.00    45.00   51.90   85.60  1   0    0     5.16 
 21.56   9.00    38.00   52.60   86.14  0   1    0     5.62 
 21.98   2.00    32.00   53.50   86.23  0   0    1     4.94 
 22.78   8.00    29.00   53.80   86.24  0   0    0     6.25 
</code></pre>

<p>The data is quarterly, the dummy variables are for seasonality.</p>

<p>What I would like to do is to predict dx with reference to some of the others, while (possibly) allowing for seasonality. For argument's sake, lets say I want to use """"u"""", """"cci"""" and """"gdp"""".</p>

<p>How would I go about doing this?</p>
",1
"<p>I am trying to export biometric data from an analysis using the ROCR package.  Here is the code that I've done so far:</p>

<pre><code>pred = performance(Matching.Score,Distribution)
perf = prediction(pred,""""fnr"""", """"fpr"""")

An object of class “performance”

Slot """"x.name"""":

[1] """"False positive rate""""

Slot """"y.name"""":

[1] """"False negative rate""""

Slot """"alpha.name"""":

[1] """"Cutoff""""

Slot """"x.values"""":

[[1]]

[1] 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000
[15] 0.00000 0.00000 0.00000 0.00000 0.00000 0.00000
  ......

Slot """"y.values"""":

[[1]]

[1] 1.00000 0.99999 0.99998 0.99997 0.99996 0.99995
[15] 0.99986 0.99985 0.99984 0.99983 0.99982 0.99981
    ......

Slot """"alpha.values"""":

[[1]]

[1]  Inf      1.0427800 1.0221150 1.0056240 1.0032630 0.9999599
[12] 0.9644779 0.9633058 0.9628996 0.9626501 0.9607665 0.9605930
    .......
</code></pre>

<p>This results in several Slots.  I would like to export the resulting values into a text file for Excel modification using: </p>

<p><code>write(pred, """"filename"""")</code></p>

<p>However, when I try to write the file, I get an error stating:</p>

<pre><code>Error in cat(list(...), file, sep, fill, labels, append) : 
  argument 1 (type 'S4') cannot be handled by 'cat'
</code></pre>

<p>Is there any way around this?</p>

<p>I'd appreciate any advice.  Thank you! </p>

<p>Matt Peterson</p>
",1
"<p>Is there an R timer or stopwatch function similar to MATLAB's <a href=""""http://www.mathworks.com/access/helpdesk/help/techdoc/ref/tic.html"""" rel=""""noreferrer"""">tic/toc</a>?</p>
",1
"<p>I have a data frame showing four classes for each year, along with their respective shares of the total for that year. </p>

<pre><code>&gt; head(df)
      class year share
1    class1 1975 0.806
2    class2 1975 0.131
3    class3 1975 0.018
4    class4 1975 0.045
5    class1 1976 0.788
6    class2 1976 0.151
</code></pre>

<p>When I run <code>ggplot</code> with no <code>fill</code> specified, I get a uniform gray box, as expected.</p>

<pre><code>&gt; ggplot(df, aes(x=year, y=share, group=class)) + geom_area() + scale_fill_brewer()
</code></pre>

<p>So I try to add <code>fill=class</code>, and it doesn't work.</p>

<pre><code>&gt; ggplot(df, aes(x=year, y=share, group=class, fill=class)) + geom_area() + scale_fill_brewer()

Error in inherits(x, """"factor"""") : object """"base_size"""" not found
In addition: Warning message:
In inherits(x, """"factor"""") : restarting interrupted promise evaluation
&gt; 
</code></pre>

<p>What can I do to the <code>class</code> factor to get it working properly with <code>scale_fill_brewer()</code>? The idea, obviously, is to shade each area of the graph according to its class.</p>

<p>Thanks.</p>
",1
"<p>I understand how outer() works in R:</p>

<pre><code>&gt; outer(c(1,2,4),c(8,16,32), """"*"""")

     [,1] [,2] [,3]
[1,]    8   16   32
[2,]   16   32   64
[3,]   32   64  128
</code></pre>

<p>It basically takes 2 vectors, finds the crossproduct of those vectors, and then applies the function to each pair in the crossproduct.</p>

<p>I don't have two vectors, however. I have two lists of matrices:</p>

<p>M = list();</p>

<pre><code>M[[1]] = matrix(...)
M[[2]] = matrix(...)
M[[3]] = matrix(...)
</code></pre>

<p>And I want to do an operation on my list of matricies. I want to do:</p>

<pre><code>outer(M, M, """"*"""")
</code></pre>

<p>In this case, I want to take the dot product of each combination of matrices I have.</p>

<p>Actually, I am trying to generate a kernel matrix (and I have written a kernel function), so I want to do:</p>

<pre><code>outer(M, M, kernelFunction)
</code></pre>

<p>where <code>kernelFunction</code> calculates a distance between my two matrices.</p>

<p>The problem is that outer() only takes """"vector"""" arguments, rather than """"list""""s etc. Is there a function that does the equivalent of outer() for non-vector entities?</p>

<p>Alternately, I could use a for-loop to do this:</p>

<pre><code>M = list() # Each element in M is a matrix

for (i in 1:numElements)
{
   for (j in 1:numElements)
   {
      k = kernelFunction(M[[i]], M[[j]])
      kernelMatrix[i,j] = k;
   }
} 
</code></pre>

<p>but I am trying to avoid this in favor of an R construct (which might be more efficient). (Yes I know I can modify the for-loop to compute the diagonal matrix and save 50% of the computations. But that's not the code that I'm trying to optimize!)</p>

<p>Is this possible? Any thoughts/suggestions?</p>
",1
"<p>I have a dataframe <code>df.all</code> and I'm plotting it in a bar plot with ggplot2 using the code below. I'd like to make it so that the order of the dodged bars is flipped. That is, so that the bars labeled """"Singular"""" come before the bars labeled """"Plural"""".</p>

<pre><code>ggplot(df.all, aes(gram, V1, fill=number)) + 
    geom_bar(stat=""""identity"""", position=""""dodge"""") + 
    scale_x_discrete(labels=c(""""Grammatical"""",""""Ungrammatical"""")) +
    scale_y_continuous(formatter=""""percent"""", limits=c(0,1)) +
    facet_grid(. ~ experiment) + 
    scale_fill_hue(""""Attractor"""", breaks=c(""""S"""",""""P""""), labels=c(""""Singular"""",""""Plural""""))
</code></pre>

<p>I've tried doing <code>levels(df.all$number) = c(""""S"""", """"P"""")</code> thinking that maybe ggplot uses the order of the levels to decide plotting order, but that didn't work. I'm not sure what else to try. Any ideas?</p>

<p>The contents of <code>df.all</code>, in case it's useful:</p>

<pre><code>&gt; df.all
  number gram     experiment        V1
1      S    G BERIMBAU_AGR_A 0.8133333
2      S    G BERIMBAU_AGR_B 0.8658537
3      S    U BERIMBAU_AGR_A 0.5436242
4      S    U BERIMBAU_AGR_B 0.4597701
5      P    G BERIMBAU_AGR_A 0.8580645
6      P    G BERIMBAU_AGR_B 0.8536585
7      P    U BERIMBAU_AGR_A 0.3087248
8      P    U BERIMBAU_AGR_B 0.3975904

&gt; str(df.all)
'data.frame':   8 obs. of  4 variables:
 $ number    : Factor w/ 2 levels """"S"""",""""P"""": 2 2 2 2 1 1 1 1
  ..- attr(*, """"scores"""")= num [1:2(1d)] 0 -1
  .. ..- attr(*, """"dimnames"""")=List of 1
  .. .. ..$ : chr  """"P"""" """"S""""
 $ gram      : Factor w/ 2 levels """"G"""",""""U"""": 1 1 2 2 1 1 2 2
 $ experiment: Factor w/ 4 levels """"BERIMBAU_AGR_A"""",..: 1 4 1 4 1 4 1 4
 $ V1        : num  0.813 0.866 0.544 0.46 0.858 ...
</code></pre>
",1
"<p>I'm trying to generate GOFrame objects to generate a gene ontology mapping in R for unsupported organisms (see <a href=""""http://www.bioconductor.org/packages/release/bioc/vignettes/GOstats/inst/doc/GOstatsForUnsupportedOrganisms.pdf"""" rel=""""nofollow noreferrer"""">http://www.bioconductor.org/packages/release/bioc/vignettes/GOstats/inst/doc/GOstatsForUnsupportedOrganisms.pdf</a>).</p>

<p>However, following the instructions literally doesn't help me.
Here's the code I execute (R 2.9.2 on ubuntu koala 64 bit)</p>

<pre><code>library(""""AnnotationDbi"""")
library(""""org.Hs.eg.db"""")
frame = toTable(org.Hs.egGO)
goframeData = data.frame(frame$go_id, frame$Evidence, frame$gene_id)
goFrame = GOFrame(goframeData, organism = """"Homo sapiens"""")
</code></pre>

<p>However, when i try to map my dataframe into a goFrame object, I get this mistake</p>

<pre><code>Error: could not find function """"GOFrame""""
</code></pre>

<p>I'm pretty sure the GOFrame wrapper is in the AnnotationDBI library, so I'm puzzled.
Any help is extra appreciated :-)</p>
",1
"<p>What is the best way to make use of a C++ library in R, hopefully preserving the C++ data structures.  I'm not at all a C++ user, so I'm not clear on the relative merits of the available approaches.  The R-ext manual seems to suggest wrapping every C++ function in C.   However, at least four or five other means of incorporating C++ exist.</p>

<p>Two ways are packages w/ similar lineage, the Rcpp (maintained by the prolific overflower Dirk Eddelbuettel) and RcppTemplate packages (both on CRAN), what are the differences between the two?  </p>

<p>Another package, rcppbind available, on R forge that claims to take a different approach to binding C++ and R (I'm not knowledgeable to tell).</p>

<p>The package inline available on CRAN, claims to allow inline C/C++ I'm not sure this differs from the built in functionality, aside for allowing the code to be inline w/R.  </p>

<p>And, finally RSwig which appears to be <a href=""""http://www.swig.org/Doc1.3/R.html"""" rel=""""noreferrer"""">in the wild</a> but it is unclear how supported it is, as the <a href=""""http://www.omegahat.org/RSWIG/GettingStarted.html"""" rel=""""noreferrer"""">author's page</a> hasn't been updated for years.</p>

<p>My question is, what are the relative merits of these different approaches.  Which are the most portable and robust, which are the easiest to implement.  If you were planning to distribute a package on CRAN which of the methods would you use?</p>
",1
"<p>I am trying to load an hdf5 into R and running into some problems.  Here are the steps I took to configure my environment:</p>

<ul>
<li>R 2.10.0 (x64) on Mac OS X 10.6</li>
<li>hdf5 1.8.3 installed via macports</li>
<li>hdf5_1.6.9.tar.gz from CRAN</li>
</ul>

<p>I suspect the problem I am having relates to incompatibilities in my version of HDF5 and the one the R module expects.  For completeness here is how I installed the R module:</p>

<blockquote>
  <p>R CMD INSTALL --configure-vars='CPPFLAGS=-I/opt/local/include' --configure-args='--with-hdf5=/opt/local' hdf5_1.6.9.tar.gz</p>
</blockquote>

<p>This builds fine.  The library seems to load without issue, but no data is returned when I try to load a file:</p>

<blockquote>
  <p>library(hdf5)</p>
  
  <p>hdf5load(""""test.h5"""")</p>
  
  <p>NULL</p>
</blockquote>

<p>Yet,</p>

<blockquote>
  <p>osx:data scott$ h5dump test.h5 
  HDF5 """"test.h5"""" {
  GROUP """"/"""" {
     DATASET """"dset"""" {
        DATATYPE  H5T_STD_I32LE
        DATASPACE  SIMPLE { ( 31 ) / ( 31 ) }
        DATA {
        (0): 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192,
        (14): 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152,
        (22): 4194304, 8388608, 16777216, 33554432, 67108864, 134217728,
        (28): 268435456, 536870912, 1073741824
        }
     }
  }
  }</p>
</blockquote>

<p>Any thoughts?</p>

<p>Thanks in advance.</p>
",1
"<p>I have very large tables (30 million rows) that I would like to load as a dataframes in R.  <code>read.table()</code> has a lot of convenient features, but it seems like there is a lot of logic in the implementation that would slow things down.  In my case, I am assuming I know the types of the columns ahead of time, the table does not contain any column headers or row names, and does not have any pathological characters that I have to worry about.</p>

<p>I know that reading in a table as a list using <code>scan()</code> can be quite fast, e.g.:</p>

<pre><code>datalist &lt;- scan('myfile',sep='\t',list(url='',popularity=0,mintime=0,maxtime=0)))
</code></pre>

<p>But some of my attempts to convert this to a dataframe appear to decrease the performance of the above by a factor of 6:</p>

<pre><code>df &lt;- as.data.frame(scan('myfile',sep='\t',list(url='',popularity=0,mintime=0,maxtime=0))))
</code></pre>

<p>Is there a better way of doing this?  Or quite possibly completely different approach to the problem?</p>
",1
"<p>I am trying to run an analysis by invoking R through the command line as follows: </p>

<pre><code>R --no-save &lt; SampleProgram.R &gt; SampleProgram.opt
</code></pre>

<p>For example, consider the simple R program below: </p>

<pre><code>mydata = read.csv(""""test.txt"""", header=T)
attach(mydata)
summary(Variable1)
q()
</code></pre>

<p>The output is displayed in SampleProgram.opt (only partially shown): </p>

<pre><code>&gt; mydata = read.csv(""""test.txt"""", header=T)
&gt; attach(mydata)
&gt; summary(Variable1)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   1.00    1.00    2.00    2.47    3.00    4.00
&gt; q()
</code></pre>

<p>This simple R program is going to be executed by a script that needs to use the summary statistics displayed for Variable1. </p>

<p>The question is this: Is there any way in R to capture the output of summary(Variable1) and write the results into an output file? In other words, I need R to run the summary statistics for Variable1, capture the """"Min"""", """"Median"""" and """"Max"""" values and write those alone to an output text file. In this example, the output file should contain only one line with the values """"1.00, 2.00, 4.00"""" (i.e. the """"Min"""", """"Median"""" and """"Max"""" values). </p>

<p>The example above talks about the summary function. But, I need to do that with other commands as well (such as glm)</p>

<p>I am fairly new to R and was wondering if there was a way in R that I could do this? </p>

<p>Thanks for the help.  </p>
",1
"<p>I have been struggling with how to make a <a href=""""http://en.wikipedia.org/wiki/Pareto_chart"""" rel=""""noreferrer"""">Pareto Chart</a> in R using the ggplot2 package. In many cases when making a bar chart or histogram we want items sorted by the X axis. In a Pareto Chart we want the items ordered descending by the value in the Y axis. Is there a way to get ggplot to plot items ordered by the value in the Y axis? I tried sorting the data frame first but it seems ggplot reorders them. </p>

<p>Example:</p>

<pre><code>val &lt;- read.csv(""""http://www.cerebralmastication.com/wp-content/uploads/2009/11/val.txt"""")
val&lt;-with(val, val[order(-Value), ])
p &lt;- ggplot(val)
p + geom_bar(aes(State, Value, fill=variable), stat = """"identity"""", position=""""dodge"""") + scale_fill_brewer(palette = """"Set1"""")
</code></pre>

<p>the data frame val is sorted but the output looks like this:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp.png"""" rel=""""noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp.png</a></p>

<p>Hadley correctly pointed out that this produces a much better graphic for showing actuals vs. predicted:</p>

<pre><code>ggplot(val, aes(State, Value)) + geom_bar(stat = """"identity"""", subset = .(variable == """"estimate""""), fill = """"grey70"""") + geom_crossbar(aes(ymin = Value, ymax = Value), subset = .(variable == """"actual""""))
</code></pre>

<p>which returns:</p>

<p><a href=""""http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp1.png"""" rel=""""noreferrer"""">alt text http://www.cerebralmastication.com/wp-content/uploads/2009/11/exp1.png</a></p>

<p>But it's still not a Pareto Chart. Any tips?</p>
",1
"<p>Spaces are redundant when reporting a binary sequence. This code</p>

<pre><code>x &lt;- '1 0 0 0 0 0 1 1 0 1 0 1 1 0 '
y&lt;-gsub(' +', '', x)
</code></pre>

<p>does the job so I can copy and paste from R. How do I do the same for 0-1 sequences (and other one-digit data) in others formats, e.g.,</p>

<pre><code>x &lt;- c(1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0)
</code></pre>

<p>or</p>

<pre><code>toString(x)
</code></pre>

<p>or whatever (for the sake of learning various options)? Thanks.</p>
",1
"<p>What are differences in the assignment operators '=' and '&lt;-' in R? I know that operators are slightly different as this example shows</p>

<pre><code>x &lt;- y &lt;- 5
x = y = 5
x = y &lt;- 5
x &lt;- y = 5
# Error in (x &lt;- y) = 5 : could not find function """"&lt;-&lt;-""""
</code></pre>

<p>But is this the only difference? </p>
",1
"<p>I'm curious to know if R can use its <code>eval()</code> function to perform calculations provided by e.g. a string.</p>

<p>This is a common case:</p>

<pre><code>eval(""""5+5"""")
</code></pre>

<p>However, instead of 10 I get:</p>

<pre><code>[1] """"5+5""""
</code></pre>

<p>Any solution?</p>
",1
"<p>I am writing an R function, and I want to make sure that the argument of my R function is of a certain class (eg, """"matrix"""").</p>

<p>What is the best way to do this?</p>

<p>Say I have a function """"foo"""" which computes the inverse of a matrix:</p>

<pre><code>foo &lt;- function(x)
{
   # I want to make sure x is of type """"matrix""""
   solve(x)
}
</code></pre>

<p>How can I say - as you might in C - <code>function(matrix x)</code> to denote that """"<code>x</code> must be of type <code>matrix</code>, and if it isn't, then return an error""""?</p>
",1
"<p>I am writing R code to create a square matrix. So my approach is:</p>

<ol>
<li>Allocate a matrix of the correct size</li>
<li>Loop through each element of my matrix and fill it with an appropriate value</li>
</ol>

<p>My question is really simple: what is the best way to pre-allocate this matrix? Thus far, I have two ways:</p>

<pre><code>&gt; x &lt;- matrix(data=NA,nrow=3,ncol=3)
&gt; x
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]   NA   NA   NA
[3,]   NA   NA   NA
</code></pre>

<p>or</p>

<pre><code>&gt; x &lt;- list()
&gt; length(x) &lt;- 3^2
&gt; dim(x) &lt;- c(3,3)
&gt; x
     [,1] [,2] [,3]
[1,] NULL NULL NULL
[2,] NULL NULL NULL
[3,] NULL NULL NULL
</code></pre>

<p>As far as I can see, the former is a more concise method than the latter. Also, the former fills the matrix with NAs, whereas the latter is filled with NULLs.</p>

<p>Which is the """"better"""" way to do this? In this case, I'm defining """"better"""" as """"better performance"""", because this is statistical computing and this operation will be taking place with large datasets.</p>

<p>While the former is more concise, it isn't breathtakingly easier to understand, so I feel like this could go either way.</p>

<p>Also, what is the difference between NA and NULL in R? ?NA and ?NULL tell me that """"NA"""" has a length of """"1"""" whereas NULL has a length of """"0"""" - but is there more here? Or a best practice? This will affect which method I use to create my matrix.</p>
",1
"<p>since the latest Ubuntu release (karmic koala), I noticed that the internal R package advertises on start-up the <a href=""""http://www.revolution-computing.com/"""" rel=""""nofollow noreferrer"""">REvolution</a> package.
It seems to be a library collection for high-performance matrix calculations. And it seems to really work, apparently. For example on a matrix transposition with REvolution:</p>

<pre><code>&gt; system.time(t(matrix(rnorm(10000000),ncol=1000)))
   user  system elapsed 
  1.280   0.150   1.556 
</code></pre>

<p>And without REvolution:</p>

<pre><code>&gt; system.time(t(matrix(rnorm(10000000),ncol=1000)))
   user  system elapsed 
  1.320   0.170   1.725 
</code></pre>

<p>Is anyone using it? Is it really working? Which specific types of calculation is it improving and how? Any drawback?</p>

<p>Thanks :-)</p>
",1
"<p>Suppose you're trying to create a data frame within a function.  I would like to be able to define the column names ahead of time as one of the parameters of the function.  Take the following code:</p>

<pre><code>  foo &lt;- function(a) {
    answer &lt;- data.frame(a=1:5)
    return(answer)
    }
</code></pre>

<p>In the above example, I would like to be able to specify the value of the column name in the function <code>foo()</code>, e.g. <code>foo('my.name')</code> so that answer has the column name <code>my.name</code> instead of <code>a</code>.  I imagine you could code this up within the function using <code>colnames()</code>, but I was interested in an alternative approach.</p>
",1
"<p>I am trying to use the <code>kernlab</code> R package to do Support Vector Machines (SVM). For my very simple example, I have two pieces of training data. A and B.</p>

<p>(A and B are of type <code>matrix</code> - they are adjacency matrices for graphs.)</p>

<p>So I wrote a function which takes A+B and generates a kernel matrix.</p>

<pre><code>&gt; km
         [,1]     [,2]
[1,] 14.33333 18.47368
[2,] 18.47368 38.96053
</code></pre>

<p>Now I use <code>kernlab</code>'s <code>ksvm</code> function to generate my predictive model. Right now, I'm just trying to get the darn thing to work - I'm not worried about training error, etc.</p>

<p>So, <strong>Question 1</strong>: Am I generating my model correctly? Reasonably?</p>

<pre><code># y are my classes. In this case, A is in class """"1"""" and B is in class """"-1""""
&gt; y
[1]  1 -1

&gt; model2 =  ksvm(km, y, type=""""C-svc"""", kernel = """"matrix"""");
&gt; model2
Support Vector Machine object of class """"ksvm"""" 

SV type: C-svc  (classification) 
 parameter : cost C = 1 

[1] """" Kernel matrix used as input.""""

Number of Support Vectors : 2 

Objective Function Value : -0.1224 
Training error : 0 
</code></pre>

<p>So far so good. We created our custom kernel matrix, and then we created a ksvm model using that matrix. We have our training data labeled as """"1"""" and """"-1"""".</p>

<p>Now to predict:</p>

<pre><code>&gt; A
     [,1] [,2] [,3]
[1,]    0    1    1
[2,]    1    0    1
[3,]    0    0    0

&gt; predict(model2, A)
Error in as.matrix(Z) : object 'Z' not found
</code></pre>

<p>Uh-oh. This is okay. Kind of expected, really. """"Predict"""" wants some sort of vector, not a matrix.</p>

<p>So lets try some things:</p>

<pre><code>&gt; predict(model2, c(1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, c(1,1,1,1))
Error in as.matrix(Z) : object 'Z' not found
&gt; predict(model2, km)
Error in as.matrix(Z) : object 'Z' not found
</code></pre>

<p>Some of the above tests are nonsensical, but that is my point: no matter what I do, I just can't get predict() to look at my data and do a prediction. Scalars don't work, vectors don't work. A 2x2 matrix doesn't work, nor does a 3x3 matrix.</p>

<p><strong>What am I doing wrong here?</strong></p>

<p>(Once I figure out what ksvm <em>wants</em>, then I can make sure that my test data can conform to that format in a sane/reasonable/mathematically sound way.)</p>
",1
"<p>I am probably being unreasonable asking for help debugging a program, but I have spent a day and a half on this pretty simple bit of code and have run out of ideas. I am trying to optimise a function called """"log.pr.data"""" with respect to its first argument. </p>

<p>Because the function optimise requires you to set bounds on the argument I decided to use nlm which only requires a starting point. I have checked with simple exampels that nlm is indeed able to pass functions as arguments. My problem is that I am unable to pass a function as an argument in this particular case. </p>

<p>So here is the objective function (with two print diagnostics). I want to maximise it with respect to the argument lambda.s. (As a matter of interest, I am not maximising a likelihood here. I am trying to optimise an importance sampler.)</p>

<pre><code>log.pr.data&lt;-function(lambda.s,n1,n0,lambda.star,psi0,tobs,g=T.chan){
           print(""""Function log.pr.data"""")
           print(g)
          psi.s&lt;-boundary(lambda.s,g,psi0,tobs,n1,n0)
         -my.dbinom(n0*lambda.s,n0,lambda.star,log=TRUE)
}
</code></pre>

<p>I have no problems with the command:</p>

<pre><code>nlm(log.pr.data,p=0.6,n1=n1,n0=n0,lambda.star=lambda.star,psi0=psi0,tobs=tobs)
</code></pre>

<p>It works fine. But I want to be able to chance the function g=T.chan. So I redefined the function leaving g unspecified in log.pr.data. In other words, I just removed the """"=T.chan"""" in the argument list. I checked that the function works OK. For instance with the command</p>

<pre><code> log.pr.data(l,n1,n0,lambda.star,psi0,tobs,T.chan)
</code></pre>

<p>for a range of values of """"l"""" and it works fine and gives the same values as the previous function where g=T.chan is specified in the argument list. So the function T.chan is being passed properly it appears.</p>

<p>I then try to optimise</p>

<pre><code>nlm(log.pr.data,p=0.6,n1=n1,n0=n0,lambda.star=lambda.star,psi0=psi0,tobs=tobs,g=T.chan)
</code></pre>

<p>and I get the error</p>

<blockquote>
  <p>Error in nlm(function(x) f(x, ...), p,
  hessian, typsize, fscale, msg,  : 
          invalid NA value in parameter</p>
</blockquote>

<p>It is also interesting that there does not seem to be a single call to log.pr.data because """"Function log.pr.data"""" is not printed. In earlier attempts to trouble shoot this problem, I realised that I was using the symbol """"f"""" for the function being passed and that this might cause problems because nlm called its obejctive function """"f"""". So I changed it to """"g"""" throughout.</p>
",1
"<p>This is a really really simple question to which I seem to be entirely unable to get a solution. I would like to do a scatter plot of an observed time series in R, and over this I want to plot the fitted model.</p>

<p>So I try something like:</p>

<pre><code>model &lt;- lm(x~y+z)
plot(x)
lines(fitted(model))
</code></pre>

<p>But this just plots x with lines.</p>

<p>Thanks</p>
",1
"<p>Is there a simple way to check if <code>R functions</code> and <code>packages</code> have <code>demo()</code> and <code>example()</code> methods?</p>

<p>When building a package, does the package need to have the necessary objects so that <code>demo()</code> and <code>example()</code> can be called on it?</p>

<p><strong>Edit:</strong> In trying to answer this, I checked the source code of <code>demo()</code></p>

<pre><code>demo(package = .packages(all.available = TRUE)) # check which packages have demo
</code></pre>
",1
"<p>I am trying to add a line to a plot of points, and I can't figure it out.  My y values are numbers from 0 to Inf, while my x values are from an ordered factor.</p>

<p>Here is the plotting code, which only displays points:</p>

<pre><code>g = ggplot() +
  layer(data = ratesdf, mapping = aes(x = age, y = rates), geom = """"point"""", stat=""""identity"""") +
  layer(data = ratesdf, mapping = aes(x = age, y = rates), geom = """"smooth"""", stat = """"smooth"""", method = loess)
print(g)
</code></pre>

<p>Here is the dataframe:</p>

<pre><code>          rates      age
[0,5)    0.00000000    [0,5)
[5,10)   0.00000000   [5,10)
[10,15)  0.00000000  [10,15)
[15,20)  0.02017059  [15,20)
[20,25)  0.32707402  [20,25)
[25,30)  0.54013169  [25,30)
[30,35)  0.71698958  [30,35)
[35,40)  0.81120944  [35,40)
[40,45)  0.87283637  [40,45)
[45,50)  0.91411649  [45,50)
[50,55)  0.91273334  [50,55)
[55,60)  0.95627322  [55,60)
[60,65)  0.92879819  [60,65)
[65,70)  0.98088779  [65,70)
[70,75)  0.90406674  [70,75)
[75,80)  1.00000000  [75,80)
[80,85)  1.00000000  [80,85)
[85,Inf] 1.00000000 [85,Inf]
</code></pre>

<p>Thanks to everyone in advance!</p>

<p>(Hadley, I promise to buy your book as soon as I get my annual birthday giftcards :)  )</p>
",1
"<p>I've fitted a VECM model in R, and converted in to a VAR representation. I would like to use this model to predict the future value of a response variable based on different scenarios for the explanatory variables.</p>

<p>Here is the code for the model:</p>

<pre><code>library(urca)
library(vars)

input &lt;-read.csv(""""data.csv"""")
ts &lt;- ts(input[16:52,],c(2000,1),frequency=4)
dat1 &lt;- cbind(ts[,""""dx""""], ts[,""""u""""], ts[,""""cci""""],ts[,""""bci""""],ts[,""""cpi""""],ts[,""""gdp""""])

args('ca.jo')
vecm &lt;- ca.jo(dat1, type = 'trace', K = 2, season = NULL,spec=""""longrun"""",dumvar=NULL)
vecm.var &lt;- vec2var(vecm,r=2)    
</code></pre>

<p>Now what I would like do is to predict """"dx"""" into the future by varying the others. I am not sure if something like """"predict dx if u=30,cpi=15,bci=50,gdp=..."""" in the next period would work. So what I have in mind is something along the lines of: increase """"u"""" by 15% in the next period (which would obviously impact on all the other variables as well, including """"dx"""") and predict the impact into the future.</p>

<p>Also, I am not sure if the """"vec2var"""" step is necessary, so please ignore it if you think it is redundant.</p>

<p>Thanks<br>
Karl</p>
",1
"<p>Data I'm importing describes numeric measurements taken at various locations for more or less evenly spread timestamps.  sometimes this """"evenly spread"""" is not really true and I have to discard some of the values, it's not that important which one, as long as I have one value for each timestamp for each location.  </p>

<p>what I do with the data?  I add it to a <code>result</code> data.frame.  There I have a <code>timestamp</code> column and the values in the timestamp column, they are definitely evenly spaced according to the <code>step</code>.</p>

<pre><code>timestamps &lt;- ceiling(as.numeric((timestamps-epoch)*24*60/step))*step*60 + epoch
result[result$timestamp %in% timestamps, columnName] &lt;- values
</code></pre>

<hr>

<p>This does NOT work when I have timestamps that fall in the same time step.  This is an example:</p>

<pre><code>&gt; data.frame(ts=timestamps, v=values)
                   ts         v
1 2009-09-30 10:00:00 -2.081609
2 2009-09-30 10:04:18 -2.079778
3 2009-09-30 10:07:47 -2.113531
4 2009-09-30 10:09:01 -2.124716
5 2009-09-30 10:15:00 -2.102117
6 2009-09-30 10:27:56 -2.093542
7 2009-09-30 10:30:00 -2.092626
8 2009-09-30 10:45:00 -2.086339
9 2009-09-30 11:00:00 -2.080144
&gt; data.frame(ts=ceiling(as.numeric((timestamps-epoch)*24*60/step))*step*60+epoch,
+ v=values)
                   ts         v
1 2009-09-30 10:00:00 -2.081609
2 2009-09-30 10:15:00 -2.079778
3 2009-09-30 10:15:00 -2.113531
4 2009-09-30 10:15:00 -2.124716
5 2009-09-30 10:15:00 -2.102117
6 2009-09-30 10:30:00 -2.093542
7 2009-09-30 10:30:00 -2.092626
8 2009-09-30 10:45:00 -2.086339
9 2009-09-30 11:00:00 -2.080144
</code></pre>

<p>in Python I would (mis)use a dictionary to achieve what I need:</p>

<pre><code>dict(zip(timestamps, values)).items()
</code></pre>

<p>returns a list of pairs where the first coordinate is unique.</p>

<p>in R I don't know how to do it in a compact and efficient way.</p>
",1
"<p>I would like to know how I can access the individual fields contained in an R object. Or, more precisely, how to get R to tell me how.</p>

<p>For example, if I run the following code:</p>

<pre><code>dx.ct &lt;- ur.df(dat1[,'dx'], lags=3, type='trend')
summary(dx.ct)
</code></pre>

<p>then I get this output:</p>

<pre><code>############################################### 
# Augmented Dickey-Fuller Test Unit Root Test # 
############################################### 

Test regression trend 


Call:
lm(formula = z.diff ~ z.lag.1 + 1 + tt + z.diff.lag)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.46876 -0.24506  0.02420  0.15752  0.66688 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)  1.099231   0.561377   1.958   0.0606 .
z.lag.1     -0.239438   0.141093  -1.697   0.1012  
tt          -0.019831   0.007799  -2.543   0.0170 *
z.diff.lag1 -0.306326   0.193001  -1.587   0.1241  
z.diff.lag2 -0.214229   0.186135  -1.151   0.2599  
z.diff.lag3 -0.223433   0.179040  -1.248   0.2228  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

Residual standard error: 0.3131 on 27 degrees of freedom
Multiple R-squared: 0.3326,     Adjusted R-squared: 0.209 
F-statistic: 2.691 on 5 and 27 DF,  p-value: 0.04244 


Value of test-statistic is: -1.697 2.4118 3.2358 

Critical values for test statistics: 
      1pct  5pct 10pct
tau3 -4.15 -3.50 -3.18
phi2  7.02  5.13  4.31
phi3  9.31  6.73  5.61
</code></pre>

<p>So, I know that I should be able to access all of the values above individually, I don't know how to point to them. Is there some way to ask R to show me how they are stored?</p>

<p>I am thinking along the lines of:</p>

<pre><code>showobjects(summary(dx.ct))
</code></pre>

<p>And then it outputs</p>

<pre><code>$formula
$residuals
$coefficients
etc.
</code></pre>

<p>and then I can do</p>

<pre><code>showobjects(summary(dx.ct)$residuals)
</code></pre>

<p>which then outputs</p>

<pre><code>$min
$1Q
$median
etc.
</code></pre>

<p>Thanks<br>
Karl</p>
",1
"<p>What is the problem with initializing a matrix object to <code>NULL</code> and then growing it with <code>cbind()</code> and <code>rbind()</code>?
In case the number of rows and columns are not known a priori, is it not necessary to grow from <code>NULL</code>?</p>

<p>Edit: My question was prompted by the need to understand memory efficient ways of writing R code. The matrix context is more general and I'm probably looking for suggestions about efficient ways to handle other data objects as well.
Apologize for being too abstract/generic, but I did not really have a specific problem in mind.</p>
",1
"<p>Consider the following code.  When you don't explicitly test for <code>NA</code> in your condition, that code will fail at some later date then your data changes.</p>

<pre><code>&gt;   # A toy example
&gt;   a &lt;- as.data.frame(cbind(col1=c(1,2,3,4),col2=c(2,NA,2,3),col3=c(1,2,3,4),col4=c(4,3,2,1)))
&gt;   a
  col1 col2 col3 col4
1    1    2    1    4
2    2   NA    2    3
3    3    2    3    2
4    4    3    4    1
&gt;   
&gt;   # Bummer, there's an NA in my condition
&gt;   a$col2==2
[1]  TRUE    NA  TRUE FALSE
&gt; 
&gt;   # Why is this a good thing to do?
&gt;   # It NA'd the whole row, and kept it
&gt;   a[a$col2==2,]
   col1 col2 col3 col4
1     1    2    1    4
NA   NA   NA   NA   NA
3     3    2    3    2
&gt;   
&gt;   # Yes, this is the right way to do it
&gt;   a[!is.na(a$col2) &amp; a$col2==2,]
  col1 col2 col3 col4
1    1    2    1    4
3    3    2    3    2
&gt;     
&gt;   # Subset seems designed to avoid this problem
&gt;   subset(a, col2 == 2)
  col1 col2 col3 col4
1    1    2    1    4
3    3    2    3    2
</code></pre>

<p>Can someone explain why the behavior you get without the <code>is.na</code> check would ever be good or useful?</p>
",1
"<p>I had Eclipse 3.4 working nicely with the R Console over rJava. I want to get Sweave working in Eclipse, but need Eclipse 3.5 / statet 0.8 to do it.</p>

<p>When I try to start the rJava Console the JVM starts, but no feedback comes back to the console in Eclipse.</p>

<p>JVM process below - any help gratefully received.</p>

<p>Thanks, Dave</p>

<pre><code>dave     23183 22325  0 Nov20 pts/0    00:00:52 /home/dave/dev/app/jdk1.6.0_18/bin/java -Djava.security.policy=jar:file:/home/dave/dev/app/eclipse-3.5/plugins/de.walware.statet.r.core_0.8.0.b200909221530sw.jar!/localhost.policy -Djava.rmi.server.hostname=127.0.0.1 -Djava.rmi.server.codebase=file:///home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.server_0.3.0.b200909221530sw.jar -Xss8192k -Dfile.encoding=UTF-8 -classpath /home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.server_0.3.0.b200909221530sw.jar:/home/dave/dev/app/eclipse-3.5/plugins/de.walware.rj.data_0.3.0.b200909221530sw.jar:/home/dave/dev/app/eclipse-3.5/plugins/org.eclipse.swt_3.5.1.v3555a.jar:/home/dave/dev/app/eclipse-3.5/plugins/org.eclipse.swt.gtk.linux.x86_3.5.1.v3555a.jar de.walware.rj.server.RMIServerControl start ///rjs-local-1258679148742 -auth=none -plugins=awt,
</code></pre>
",1
"<p>I asked this on Super User, but someone suggested that I take it here because there are many more R experts.</p>

The question:

<p>I have to keep navigating to my directory when I go to File > Change dir..., which is particularly annoying.</p>

<p>Does anyone know how to make R remember the previously used directory?</p>
",1
"<p>Let's say I have an R source file comprised of some functions, doesn't matter what they are, e.g.,</p>

<pre><code>fnx = function(x){(x - mean(x))/sd(x)}
</code></pre>

<p>I would like to be able to access them in my current R session (without typing them in obviously). It would be nice if library(""""/path/to/file/my_fn_lib1.r"""") worked, as """"import"""" works in Python, but it doesn't. One obvious solution is to create an R Package, but i want to avoid that overhead just to import a few functions.</p>
",1
"<p>Im trying to do principal component analysis in R . There is 2 ways of doing it , I believe. 
One is doing  principal component analysis right away the other way is  standardizing the matrix first  using s = scale(m)and then apply principal component analysis.<br>
How  do I tell what result is better ? What values in particular should i look at . I already managed to find the eigenvalues and eigenvectors , the proportion of  variance for each eigenvector using both methods. </p>

<p>I noticed that the proportion of the variance for the first  pca without standardizing had a larger  value . Is there a meaning to it ? Isnt this always the case?</p>

<p>At last , if I am  supposed to predict a variable ie weight should I drop the variable ie weight from my data matrix when I do principal component analysis ?</p>
",1
"<p>Basically I want to know why <code>as.Date(200322,format=""""%Y%W"""")</code> gives me <code>NA</code>. While we are at it, I would appreciate any advice on a data structure for repeated cross-section (aka pseudo-panel) in R.
I did get <code>aggregate()</code> to (sort of) work, but it is not flexible enough - it misses data on columns when I omit the missed values, for example.
Specifically, I have a survey that is repeated weekly for a couple of years with a bunch of similar questions answers to which I would like to combine, average, condition and plot in both dimensions. Getting the date conversion right should presumably help me towards my goal with zoo package or something similar.</p>

<p>Any input is appreciated.</p>

<p>Update: thanks for string suggestion, but as you can see in your own example, <code>%W</code> part doesn't work - it only identifies the year while setting the current day while I need to set a specific week (and leave the day blank).</p>
",1
"<p>I'm learning R and I'm curious...  I need a function that does this:</p>

<pre><code>&gt; fillInTheBlanks(c(1, NA, NA, 2, 3, NA, 4))
[1] 1 1 1 2 3 3 4
&gt; fillInTheBlanks(c(1, 2, 3, 4))
[1] 1 2 3 4
</code></pre>

<p>and I produced this one...  but I suspect there's a more R way to do this.</p>

<pre><code>fillInTheBlanks &lt;- function(v) {
  ## replace each NA with the latest preceding available value

  orig &lt;- v
  result &lt;- v
  for(i in 1:length(v)) {
    value &lt;- v[i]
    if (!is.na(value))
      result[i:length(v)] &lt;- value
  }
  return(result)
}
</code></pre>
",1
"<p>I'm a developer up in Portland, OR. I'm wondering if anyone can assist:</p>

<p>I'm working on Loess fit models using R, once I have the fit
accomplished, I'm looking to back-out the equation of the
fitted non-linear curve, wondering if there is a way to
determine this equation in R? I've been looking but can't find
any literature. For me, the graph of the function is great, but
without the equation of the graph, I'm kinda dead in the water.</p>
",1
"<p>I am currently using <code>cast</code> on a melted table to calculate the total of each value at the combination of ID variables ID1 (row names) and ID2 (column headers), along with grand totals for each row using <code>margins=""""grand_col""""</code>. </p>

<p><code>c &lt;- cast(m, ID1 ~ ID2, sum, margins=""""grand_col"""")</code></p>

<pre><code>  ID1      ID2a  ID2b     ID2c     ID2d   ID2e    (all)
1  ID1a  6459695  885473  648019  453613 1777308 10224108
2  ID1b  7263529 1411355  587785  612730 2458672 12334071
3  ID1c  7740364 1253524  682977  886897 3559283 14123045
</code></pre>

<p>So far, so R-like.</p>

<p>Then I divide each cell by its row total to get a percentage of the total. </p>

<pre><code>c[,2:6]&lt;-c[,2:6] / c[,7]
</code></pre>

<p>This looks kludgy. Is there something I should be doing in <code>cast</code> or maybe in <code>plyr</code> to handle the percent of margin calculation in the first command? </p>

<p>Thanks,
Matt</p>
",1
"<p>I would like to know how to quickly find the specific function called by a generic function for a specific object. Example :</p>

<pre><code>library(spatial)
data(redwood)
K &lt;- Kest(redwood)
plot(K)
</code></pre>

<p>This is not an usual plot, it's a plot build for a <code>Kest()</code> object. So to investigate in order to find the function used, I do :</p>

<pre><code>class(K)
</code></pre>

<p>I get </p>

<blockquote>
  <p>""""fv""""         """"data.frame""""</p>
</blockquote>

<p>I guess it is plot.fv</p>

<pre><code>?plot.fv
</code></pre>

<p>Yey ! But I'm sure there a more efficient way than guessing. Anyone ?</p>
",1
"<p>I have some survey data that I want to describe by political party and state. </p>

<p>I'm having some trouble with the by() aggregation command. It works with lots of functions, but just not length(). Eg:</p>

<pre><code>by(x, list(party=nn$info$party,state=nn$info$st),mean)
</code></pre>

<p>works fine but not</p>

<pre><code>by(x, list(party=nn$info$party,state=nn$info$st),length)
</code></pre>

<p>Which returns an array filled not with the count of the data I'm looking for, but just a series of 1's. This is what it looks like for Alabama:</p>

<pre><code>party: D
state: AL
[1] 1
--------------------------------------------------------------------------- 
party: I
state: AL
[1] 1
--------------------------------------------------------------------------- 
party: R
state: AL
[1] 1
--------------------------------------------------------------------------- 
</code></pre>

<p>Very mystifying. Any ideas?</p>
",1
"<p>I'm having a little trouble with getting ggplot2 to work as I want. Basically, I'd like to compare actual observations vs. approximated by putting them in one single plot. For example,</p>

<pre><code>&gt; library(ggplot2)
&gt; df.actual &lt;- data.frame(x = 1:100, y = (1:100) * 2)
&gt; df.approx &lt;- data.frame(x = 1:150, y = (1:150) * 2 + 5  + rnorm(150, mean = 3) )
&gt; ggplot() + geom_point(aes(x, y), data = df.actual) + geom_line(aes(x,y), data = df.approx)
</code></pre>

<p>My problem is that I can't display a legend. I read somewhere that ggplot2's legend is not very flexible(?). Ideally, a legend with </p>

<ul>
<li>title = 'Type'</li>
<li>key: a black filled point, and a black line</li>
<li>key label: 'Actual', 'Approximate'</li>
<li>legend.position = 'topright'</li>
</ul>

<p>Thanks.</p>
",1
"<p>Is there an easy way to view the source of an R package (or a method in a package), from within the interactive environment?</p>
",1
"<p>I'm trying to normalize a big amount of Affymetrix CEL files using R. However, some of them appear to be truncated, so when reading them i get the error</p>

<pre><code>Cel file xxx does not seem to have the correct dimensions
</code></pre>

<p>And the normalization stops. Manually removing the corrupted files and restart every time will take very long. Do you know if there is a fast way (in R or with a tool) to detect corrupted files?</p>

<p>PS I'm 99.99% sure I'm normalizing together CELs from the same platform, it's really just truncated files :-)</p>
",1
"<p><a href=""""http://www.omegahat.org/RGoogleDocs/"""" rel=""""nofollow noreferrer"""">RGoogleDocs</a> is fantastic. It allows one to store data on Google and read it in in real time to R. I tried to install it on a computer the other day and lo and behold all I could find was RGoogleData in RForge. What is the relationship between the two packages? I tried to google search RGoogleData and RGoogleDocs in the same search and found nothing. Duncan Temple Lang wrote RGoogleDocs and it appears that Adrian A. Dragulescu wrote RGoogleData. </p>

<p>I could have sworn that a windows binary of RGoogleDocs had been posted in omegahat by Duncan Temple Lang but alas in the past couple of months I no longer see omegahat on the select repository option list from RGUI. Instead RForge is now on that list. What is the relationship between omegahat and RForge?</p>
",1
"<p>I'm using R to loop through the columns of a data frame and make a graph of the resulting analysis. I don't get any errors when the script runs, but it generates a pdf that cannot be opened.</p>

<p>If I run the content of the script, it works fine. I wondered if there is a problem with how quickly it is looping through, so I tried to force it to pause. This did not seem to make a difference. I'm interested in any suggestions that people have, and I'm also quite new to R so suggestions as to how I can improve the approach are welcome too. Thanks.</p>

<pre><code>for (i in 2:22) {

  # Organise data
  pop_den_z = subset(pop_den, pop_den[i] != """"0"""")  # Remove zeros
  y = pop_den_z[,i]        # Get y col
  x = pop_den_z[,1]        # get x col
  y = log(y)               # Log transform

  # Regression
  lm.0 = lm(formula = y ~ x)                # make linear model
  inter = summary(lm.0)$coefficients[1,1]   # Get intercept
  slop = summary(lm.0)$coefficients[2,1]    # Get slope

  # Write to File
  a = c(i, inter, slop)
  write(a, file = """"C:/pop_den_coef.txt"""", ncolumns = 3, append = TRUE, sep = """","""")

  ## Setup pdf
  string = paste(""""C:/LEED/results/Images/R_graphs/Pop_den"""", paste(i-2), """"City.pdf"""")
  pdf(string, height = 6, width = 9)

  p &lt;- qplot(
    x, y,
    xlab = """"Radius [km]"""",
    ylab = """"Population Density [log(people/km)]"""",
    xlim = x_range,
    main = """"Analysis of Cities""""
  )

  # geom_abline(intercept,slope)
  p + geom_abline(intercept = inter, slope = slop, colour = """"red"""", size = 1)

  Sys.sleep(5)

  ### close the PDF file
  dev.off()
}
</code></pre>
",1
"<p>Whenever I run this code , the first plot would simply overwrite the previous one. Isnt there a way in R to separate to get two plots ? </p>

<pre><code>plot(pc)
title(main='abc',xlab='xx',ylab='yy')

plot(pcs)
title(main='sdf',xlab='sdf',ylab='xcv')
</code></pre>
",1
"<p>I was wondering if there is a way to include error terms for a linear regression model like </p>

<p>r = lm(y ~ x1+x2) ? </p>
",1
"<p>I'm reading a table and it contains strings that describe timestamps.  I just want to convert from string to a built-in datetime type...</p>

<pre><code>R&gt; Q &lt;- read.table(textConnection('
               tsstring
1 """"2009-09-30 10:00:00""""
2 """"2009-09-30 10:15:00""""
3 """"2009-09-30 10:35:00""""
4 """"2009-09-30 10:45:00""""
5 """"2009-09-30 11:00:00""""
'), as.is=TRUE, header=TRUE)
R&gt; ts &lt;- strptime(Q$tsstring, """"%Y-%m-%d %H:%M:%S"""", tz=""""UTC"""")
</code></pre>

<p>if I try to store the datetime column into the data.frame, I get a curious error:</p>

<pre><code>R&gt; Q$ts &lt;- ts
Error in `$&lt;-.data.frame`(`*tmp*`, """"ts"""", value = list(sec = c(0, 0, 0,  : 
  replacement has 9 rows, data has 5
</code></pre>

<p>but if I go through a numeric representation held in the data.frame, it works...</p>

<pre><code>R&gt; EPOCH &lt;- strptime(""""1970-01-01 00:00:00"""", """"%Y-%m-%d %H:%M:%S"""", tz=""""UTC"""")
R&gt; Q$minutes &lt;- as.numeric(difftime(ts, EPOCH, tz=""""UTC""""), units=""""mins"""")
R&gt; Q$ts &lt;- EPOCH + 60*Q$minutes
</code></pre>

<p>any help in understanding the situation?</p>
",1
"<p>Let's say I have a data matrix d </p>

<pre><code>pc = prcomp(d)

# pc1 and pc2 are the principal components  
pc1 = pc$rotation[,1] 
pc2 = pc$rotation[,2]
</code></pre>

<p>Then this should fit the linear regression model right? </p>

<pre><code>r = lm(y ~ pc1+pc2)
</code></pre>

<p>But then I get this error : </p>

<pre><code>Errormodel.frame.default(formula = y ~ pc1+pc2, drop.unused.levels = TRUE) : 
   unequal dimensions('pc1')
</code></pre>

<p>I guess there a packages out there who do this automatically, but this should work too? </p>
",1
"<p>Is there an equivalent of dir function (python) in R?</p>

<p>When I load a library in R like -</p>

<blockquote>
  <p>library(vrtest)</p>
</blockquote>

<p>I want to know all the functions that are in that library.</p>

<p>In Python, dir(vrtest) would be a list of all attributes of vrtest.</p>

<p>I guess in general, I am looking for the best way to get help on R while running it in ESS on linux. I see all these man pages for the packages I have installed, but I am not sure how I can access them.</p>

<p>Thanks</p>
",1
"<p>First I will have to apologise for my ignorance as I'm sure this is a very simple question but I am very new to R. My question is that I have a data frame that looks like this;</p>

<pre><code>countrydes       Insured

USA               4500
CANADA            4500 
USA               7500
CANADA            7600
</code></pre>

<p>All I want to do is aggregate the sum of the insured value by country and produce a bar graph e.g.</p>

<pre><code>countrydes        Insured 

USA                12000       
Canada             12100
</code></pre>

<p>Many thanks.</p>
",1
"<p>I want to construct a new centrality measure using <code>igraph</code>, preferably in <code>R</code>. </p>

<p>How would I begin this? </p>

<p>For example, would I be better adding to the <code>igraph C library</code> or the <code>R interface</code>?</p>
",1
"<p>For a linear model with 2 variables </p>

<pre><code>r = lm(y ~ x1+x2)
</code></pre>

<p>When I run  <code>plot(r)</code> , I get a bunch of plots such as residuals vs fitted values and so on , but I can only look at one of them at a time . </p>

<p>Isn't there a way to separate them ? </p>
",1
"<p>I'm trying to get a better understanding on FA, hope you can take a look at this, my biggest problem is how to interpret FA model in R.</p>

<p>My results look like this:
What values in my results should I be looking at and what is a good indication of FA analysis?</p>

<pre><code>Call:
factanal(x = m2, factors = 2)

Uniquenesses:
v1 v2 v3 v4 v5 v6 v7 v8 v9 v10 v11 v12
0.005 0.324 0.344 0.092 0.084 0.128 0.271 0.272 0.398 0.384 0.540 0.472

Loadings:
Factor1 Factor2
v1 0.847 0.527
v2 0.818
v3 0.733 0.344
v4 0.938 0.169
v5 0.949 0.125
v6 0.825 0.437
v7 0.701 0.488
v8 0.646 0.557
v9 0.467 0.619
v10 0.665 0.417
v11 0.525 0.429
v12 0.581 0.436

Factor1 Factor2
SS loadings 5.905 2.780
Proportion Var 0.492 0.232
Cumulative Var 0.492 0.724

Test of the hypothesis that 2 factors are sufficient.
The chi square statistic is 410.82 on 43 degrees of freedom.
The p-value is 1.59e-61
</code></pre>
",1
"<p>Often in R, there are a dozen functions scattered across as many packages--all of which have the same purpose but of course differ in accuracy, performance, documentation, theoretical rigor, and so on.</p>

<p>How do you locate these--from within R and even from among the CRAN Packages which you have not installed?</p>

<p>So for instance: the generic <strong><em>plot</em></strong> function. Setting secondary ticks is much easier using a function <strong>outside</strong> of the base package:</p>

<pre><code>minor.tick(nx=n, ny=n, tick.ratio=n)
</code></pre>

<p>Of course <em>plot</em> is in R core, but <em>minor.tick</em> is not, it's actually in <em>Hmisc</em>. </p>

<p>Of course, that doesn't show up in the documentation for <em>plot</em>, nor should you expect it to. </p>

<p>Another example: data-input arguments to <em>plot</em> can be supplied by an object returned from the function <em>hexbin</em>, again, this function is from a library <em>outside</em> of R core.</p>

<p>What would be great obviously is a programmatic way to gather these function arguments from the various libraries and put them in a single namespace?</p>

<p>*edit: (trying to re-state my example just above more clearly:) the arguments to <em>plot</em> supplied in R core, e.g., setting the axis tick frequency are xaxp/yaxp; however, one can also set a/t/f via a function outside of the base package, again, as in the minor.tick function from the Hmisc package--but you wouldn't know that just from looking at the plot method signature. Is there a meta function in R for this?*</p>

<p>So far, as i come across them, i've been manually gathering them, each set gathered in a single <em>TextMate</em> <em>snippet</em> (along with the attendant library imports).  This isn't that difficult or time consuming, but i can only update my snippet as i find out about these additional arguments/parameters. Is there a canonical R way to do this, or at least an easier way?</p>

<p>Just in case that wasn't clear, i am not talking about the case where multiple packages provide functions directed to the same statistic or view (e.g., 'boxplot' in the base package; 'boxplot.matrix' in gplots; and 'bplots' in Rlab).  What i am talking is the case in which the function name is the same across two or more packages.</p>
",1
"<p>I'm looking to get a count for the following data frame:</p>

<pre><code>&gt; Santa
   Believe Age Gender Presents Behaviour
1    FALSE   9   male       25   naughty
2     TRUE   5   male       20      nice
3     TRUE   4 female       30      nice
4     TRUE   4   male       34   naughty
</code></pre>

<p>of the number of children who believe. What command would I use to get this?</p>

<p>(The actual data frame is much bigger. I've just given you the first four rows...)</p>

<p>Thanks!</p>
",1
"<p>I noticed something in R, say <code>pc</code> is the result of applying PCA to a data matrix and 
<code>pc$x</code> is my sample principal component matrix . </p>

<p>When try <code>plot(pc$x)</code>, it will only plot the first principal component (<code>pc1</code>) against the second (<code>pc2</code>), but I actually have more than 2 principal components. How do I show all of them? </p>
",1
"<p>I have a script called <code>foo.R</code> that includes another script <code>other.R</code>, which is in the same directory:</p>

<pre><code>#!/usr/bin/env Rscript
print(""""Hello"""")
source(""""other.R"""")
</code></pre>

<p>But I want <code>R</code> to find that <code>other.R</code> no matter what the current working directory. </p>

<p>In other words, <code>foo.R</code> needs to know its own path. How can I do that?</p>
",1
"<p>I don't think I need to explain exactly what the code does. The point is that while performing the chisq.test outside the loop, I get a result like this (expected):</p>

<pre><code>        Chi-squared test for given probabilities

data:  observed 
X-squared = 185912, df = 5, p-value &lt; 2.2e-16
</code></pre>

<p>but when I try to do the test in a loop, the expected result does not appear </p>

<pre><code>total &lt;- dim(crs$dataset_init)[1]
expected.fr &lt;- cl.popul / total

for (i in 1:dim(cl.vs.Onerall)[1] ) {
        if (cl.vs.Onerall[i,1] &gt; 0) {
             observed &lt;- cl.vs.Onerall[i,2:(clust_no + 1)]

             print(rownames(cl.vs.Onerall)[i])
             chisq.test(observed, p=expected.fr)
             print(""""------------------------------"""")
    }
}
</code></pre>

<p>Any ideas would be greatly appreciated!</p>
",1
"<p>In <code>Emacs Speaks Statistics</code> for <code>R</code>, how can the auto replacement of <code>_</code> with <code>&lt;-</code> be turned off?</p>
",1
"<p>I'm using R to loop through a data frame, perform a calculation and to make a plot.</p>

<pre><code>for(i in 2 : 15){
# get data
dataframe[,i]  

# do analysis

# make plot
a &lt;- plot()
}
</code></pre>

<p>Is there a way that I can make the plot object name 'a', using the value of 'i'? For example, a + """"i"""" &lt;- plot(). Then I want to add that to a vector so I have a series of plots that I can then use at a later stage when I want to make a pdf. Or perhaps there is another way of storing this.</p>

<p>I'm familiar with the paste() function but I haven't figured out how to define an object using it.</p>
",1
"<p>I'm trying to use ggplot2 to create and label a scatterplot. The variables that I am plotting are both scaled such that the horizontal and the vertical axis are plotted in units of standard deviation (1,2,3,4,...ect from the mean). What I would like to be able to do is label ONLY those elements that are beyond a certain limit of standard deviations from the mean. Ideally, this labeling would be based off of another column of data. </p>

<p>Is there a way to do this? </p>

<p>I've looked through the online manual, but I haven't been able to find anything about defining labels for plotted data. </p>

<p>Help is appreciated! </p>

<p>Thanks!</p>

<p>BEB</p>
",1
"<p>I have data nested in to levels:</p>

<pre><code>L1 L2   x1 x2 x3 x4
A  This 20 14 12 15
A  That 11 NA 8  16
A  Bat  Na 22 13  9
B  This 10  9 11  6
B  That 3   3  1 NA
B  Bat  4  10  2  8
</code></pre>

<p>Now I want something simply - and I feel I have been able to do this just last month. But something has gone missing in my head: I want percentages (ignoring NA), summing to 100 for each variable in L1</p>

<pre><code>L1 L2   x1  x2   x3   x4
A  This 65% 39%  36%  38%
A  That 35%  0%  24%  40%
A  Bat   0% 61%  40%  22%
</code></pre>

<p>I can get the totals I need with</p>

<pre><code>cast(L1~variable, data=melt(d, na.rm=T),sum)
</code></pre>

<p>But I guess it should be possible to cook up a function that gives me what I want?
I tried various approaches with cast and plyr... But it seams xmas has already brought to many beers to my frail brain.</p>

<p>Any help will be appreciated - as will any refrain from a downvote.</p>

<p>Thanx</p>

<p>this is my data:</p>

<pre><code>d &lt;- structure(list(level1 = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 
6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 10L, 10L, 10L, 10L, 
11L, 11L, 11L, 11L, 11L, 11L, 9L, 9L, 9L, 9L, 9L, 12L, 12L, 12L, 
12L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 14L, 14L, 
15L, 15L, 15L, 15L, 15L, 16L, 16L, 16L, 16L, 16L, 16L, 17L, 17L, 
17L, 17L, 17L, 18L, 18L, 18L, 18L, 18L, 18L, 19L, 19L, 19L, 19L, 
19L, 19L), .Label = c(""""a"""", """"b"""", """"c"""", """"d"""", """"e"""", """"f"""", """"g"""", """"h"""", 
""""i"""", """"j"""", """"k"""", """"l"""", """"m"""", """"n"""", """"o"""", """"p"""", """"q"""", """"r"""", """"s""""), class = """"factor""""), 
level2 = structure(c(6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 
6L, 1L, 3L, 5L, 6L, 5L, 6L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 
5L, 6L, 1L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 6L, 
2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 1L, 3L, 5L, 6L, 
2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 
5L, 6L, 2L, 1L, 3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 6L, 2L, 1L, 
3L, 5L, 4L, 6L, 2L, 1L, 3L, 5L, 4L), .Label = c(""""This"""", """"That"""", 
""""Phat"""", """"Bat"""", """"Man"""", """"Hat""""), class = """"factor""""), X2002 = c(28L, 
9L, 17L, 8L, 95L, 18L, NA, NA, 36L, 40L, 15L, 10L, 71L, NA, 
14L, 25L, 18L, NA, 56L, 5L, 29L, 5L, 13L, 8L, 65L, 23L, 8L, 
34L, NA, 14L, 5L, 5L, NA, 51L, 18L, NA, 5L, 56L, 30L, 8L, 
9L, 11L, 77L, 5L, 53L, 12L, 16L, 13L, 114L, 30L, 8L, NA, 
52L, 38L, NA, 12L, 5L, 87L, 5L, 35L, NA, 10L, 6L, 92L, 10L, 
41L, NA, 22L, 8L, 115L, 27L, 6L, 9L, NA, 47L, 9L, 29L, 6L, 
11L, NA, 56L, 38L, 7L, 10L, NA, 93L, 6L, 22L, 9L, 9L, NA, 
59L, 5L), X2003 = c(32L, NA, 16L, 9L, 76L, 10L, NA, 5L, 24L, 
22L, 12L, 9L, 63L, 12L, 9L, 36L, 9L, 6L, 83L, 5L, 35L, NA, 
12L, 8L, 82L, 19L, 5L, 53L, 5L, 10L, NA, 7L, NA, 35L, 15L, 
6L, 6L, 40L, 30L, NA, 10L, 8L, 85L, 9L, 46L, NA, 14L, 9L, 
106L, 24L, 6L, 7L, 56L, 33L, NA, 12L, 9L, 106L, NA, 37L, 
7L, 11L, 8L, 79L, 5L, 54L, 5L, 10L, 6L, 100L, 25L, 9L, 5L, 
6L, 49L, NA, 31L, NA, 13L, 10L, 79L, 46L, NA, 14L, NA, 82L, 
5L, 21L, 7L, 11L, NA, 69L, NA), X2004 = c(35L, 6L, 13L, 8L, 
82L, 12L, 5L, NA, 35L, 34L, 5L, 6L, 75L, 9L, 9L, 40L, 13L, 
9L, 70L, NA, 41L, NA, 17L, 10L, 83L, 10L, 6L, 40L, NA, 18L, 
NA, 6L, NA, 34L, 10L, NA, NA, 45L, 38L, 6L, 11L, NA, 74L, 
NA, 45L, 5L, 12L, 9L, 131L, 34L, NA, NA, 64L, 28L, 5L, NA, 
NA, 93L, NA, 32L, NA, 9L, 11L, 99L, NA, 40L, NA, 18L, 8L, 
104L, 14L, NA, 13L, 6L, 67L, NA, 23L, NA, 6L, 8L, 85L, 49L, 
NA, 19L, 7L, 102L, NA, 28L, 5L, 7L, 7L, 74L, NA), X2005 = c(36L, 
NA, 20L, 10L, 93L, 22L, NA, NA, 35L, 38L, 13L, 9L, 99L, NA, 
14L, 48L, 17L, 7L, 70L, NA, 35L, NA, 13L, 9L, 103L, 16L, 
5L, 49L, NA, 12L, NA, 5L, 8L, 51L, 15L, 7L, 5L, 45L, 40L, 
NA, 12L, 5L, 102L, NA, 40L, NA, 21L, 16L, 141L, 25L, 9L, 
10L, 70L, 41L, NA, 10L, NA, 111L, NA, 37L, NA, 10L, 9L, 124L, 
NA, 37L, NA, 12L, 12L, 124L, 32L, NA, 16L, 6L, 45L, NA, 33L, 
NA, 8L, NA, 101L, 51L, NA, 19L, 5L, 117L, NA, 17L, NA, 11L, 
5L, 73L, NA), X2006 = c(38L, NA, 22L, 13L, 103L, 15L, NA, 
7L, 44L, 39L, 11L, 6L, 95L, NA, 15L, 53L, 16L, 9L, 89L, NA, 
41L, NA, 12L, 13L, 87L, 30L, 6L, 43L, NA, 14L, NA, 6L, 5L, 
50L, 19L, 5L, NA, 63L, 23L, NA, 6L, NA, 75L, NA, 38L, NA, 
12L, 19L, 142L, 32L, 7L, 7L, 64L, 49L, NA, 13L, 12L, 114L, 
NA, 48L, NA, 23L, 5L, 136L, NA, 52L, NA, 15L, 16L, 127L, 
24L, NA, 6L, NA, 57L, NA, 32L, NA, NA, 13L, 96L, 20L, NA, 
10L, 21L, 102L, NA, 31L, NA, 5L, 12L, 93L, NA)), .Names = c(""""level1"""", 
""""level2"""", """"X2002"""", """"X2003"""", """"X2004"""", """"X2005"""", """"X2006""""), row.names = c(NA, 
-93L), class = """"data.frame"""")
</code></pre>
",1
"<p>HI all,</p>

<p>I was trying to load a certain amount of Affymetrix CEL files, with the standard BioConductor command (R 2.8.1 on 64 bit linux, 72 GB of RAM)</p>

<pre><code>abatch&lt;-ReadAffy()
</code></pre>

<p>But I keep getting this message:</p>

<pre><code>Error in read.affybatch(filenames = l$filenames, phenoData = l$phenoData,  : 
  allocMatrix: too many elements specified
</code></pre>

<p>What's the general meaning of this allocMatrix error? Is there some way to increase its maximum size?</p>

<p>Thank you</p>
",1
"<p>I asked <a href=""""https://stackoverflow.com/questions/1816480/generating-names-iteratively-in-r-for-storing-plots"""">this</a> question yesterday about storing a plot within an object. I tried implementing the first approach (aware that I did not specify that I was using <code>qplot()</code> in my original question) and noticed that it did not work as expected.</p>

<pre><code>library(ggplot2)               # add ggplot2

string = """"C:/example.pdf""""      # Setup pdf
pdf(string,height=6,width=9)

x_range &lt;- range(1,50)         # Specify Range

# Create a list to hold the plot objects.
pltList &lt;- list()
pltList[]

for(i in 1 : 16){

# Organise data 
y = (1:50) * i * 1000                       # Get y col
x = (1:50)                                  # get x col
y = log(y)                                  # Use natural log

# Regression
lm.0 = lm(formula = y ~ x)                  # make linear model
inter = summary(lm.0)$coefficients[1,1]     # Get intercept
slop = summary(lm.0)$coefficients[2,1]      # Get slope

# Make plot name
pltName &lt;- paste( 'a', i, sep = '' )

# make plot object    
p &lt;- qplot(
    x, y,   
    xlab = """"Radius [km]"""", 
    ylab = """"Services [log]"""",
    xlim = x_range,
    main = paste(""""Sample"""",i)
) + geom_abline(intercept = inter, slope = slop, colour = """"red"""", size = 1)        

print(p)     

pltList[[pltName]] = p       
}

# close the PDF file
dev.off() 
</code></pre>

<p>I have used sample numbers in this case so the code runs if it is just copied. I did spend a few hours puzzling over this but I cannot figure out what is going wrong. It writes the first set of pdfs without problem, so I have 16 pdfs with the correct plots.</p>

<p>Then when I use this piece of code:</p>

<pre><code>string = """"C:/test_tabloid.pdf""""
pdf(string, height = 11, width = 17)

grid.newpage()
pushViewport( viewport( layout = grid.layout(3, 3) ) )

vplayout &lt;- function(x, y){viewport(layout.pos.row = x, layout.pos.col = y)}

counter = 1

# Page 1
for (i in 1:3){    
    for (j in 1:3){     
         pltName &lt;- paste( 'a', counter, sep = '' )   
         print( pltList[[pltName]], vp = vplayout(i,j) )
         counter = counter + 1
     }
 }

 dev.off()
</code></pre>

<p>the result I get is the last linear model line (<code>abline</code>) on every graph, but the data does not change. When I check my list of plots, it seems that all of them become overwritten by the most recent plot (with the exception of the <code>abline</code> object).</p>

<p>A less important secondary question was how to generate a muli-page pdf with several plots on each page, but the main goal of my code was to store the plots in a list that I could access at a later date.</p>
",1
"<p>I am trying to write a function that uses Newton's method <code>(coefficients+(inverse hessian)*gradient)</code> to iteratively find the coefficients for a loglinear model. </p>

<p>I am using the following code:</p>

<pre><code> ##reading in the data
    dat&lt;-read.csv('hw8.csv')
    summary(dat)
    # data file containing yi and xi
    attach(dat)
    ##Creating column of x's
    x&lt;-cbind(1,xi)

    mle&lt;-function(c){
     gi&lt;- 1-yi*exp(c[1]+c[2]*xi)
     hi&lt;- gi-1
     H&lt;- -1*(t(x)%*%hi%*%x)
     g&lt;-t(x)%*%gi
     c&lt;-c+solve(H)%*%g
      return(c)
    }

    optim(c(0,1),mle,hessian=TRUE)
</code></pre>

<p>When I run the code, I get the following error:</p>

<pre><code>Error in t(x) %*% hi %*% x : non-conformable arguments
RMate stopped at line 29
</code></pre>

<p>Given that the formula is drawn from Bill Greene's problem set, I don't think it is a formula problem. I think I am doing something wrong in passing my function.</p>

<p>How can I fix this?<br>
Any help with this function would be much appreciated.</p>
",1
"<p>Still trying to get into the R logic...  what is the """"best"""" way to unpack (on LHS) the results from a function returning multiple values?</p>

<p>I can't do this apparently:</p>

<pre><code>R&gt; functionReturningTwoValues &lt;- function() { return(c(1, 2)) }
R&gt; functionReturningTwoValues()
[1] 1 2
R&gt; a, b &lt;- functionReturningTwoValues()
Error: unexpected ',' in """"a,""""
R&gt; c(a, b) &lt;- functionReturningTwoValues()
Error in c(a, b) &lt;- functionReturningTwoValues() : object 'a' not found
</code></pre>

<p>must I really do the following?</p>

<pre><code>R&gt; r &lt;- functionReturningTwoValues()
R&gt; a &lt;- r[1]; b &lt;- r[2]
</code></pre>

<p>or would the R programmer write something more like this:</p>

<pre><code>R&gt; functionReturningTwoValues &lt;- function() {return(list(first=1, second=2))}
R&gt; r &lt;- functionReturningTwoValues()
R&gt; r$first
[1] 1
R&gt; r$second
[1] 2
</code></pre>

<p>--- edited to answer Shane's questions ---</p>

<p>I don't really need giving names to the result value parts.  I am applying one aggregate function to the first component and an other to the second component (<code>min</code> and <code>max</code>.  if it was the same function for both components I would not need splitting them).  </p>
",1
"<p>In R, how do I make a (bar)plot's y axis labels parallel to the X axis instead of parallel to the Y axis?</p>
",1
"<p>Is there a function to get an index (row number and column number) for a matrix?  </p>

<p>Suppose that I have a simple matrix:</p>

<pre><code>a &lt;- matrix(1:50, nrow=5)
</code></pre>

<p>Is there an easy way to get back something like c(3, 5) for the number """"23"""", for instance?  In this case, saying <code>which(a==23)</code> just returns 23.  </p>

<p>This seems to work but I'm sure that there's a better way:</p>

<pre><code>matrix.index &lt;- function(a, value) {
  idx &lt;- which(data.frame(a)==value)
  col.num &lt;- ceiling(idx/nrow(a))
  row.num &lt;- idx - (col.num-1) * nrow(a)
  return(c(row.num, col.num))
}
&gt; matrix.index(a, 23)
[1] 3 5
&gt; matrix.index(a, 50)
[1]  5 10
</code></pre>
",1
"<p>I have the following setup:</p>

<pre><code>emp &lt;- structure(list(s = structure(c(1L, 2L, 2L, 2L, 7L, 7L, 3L, 4L, 4L, 4L, 4L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 5L, 5L, 6L), .Label = c(""""8"""", """"24"""", """"31"""", """"78"""", """"135"""", """"142"""", """"30"""", """"98"""", """"117"""", """"123""""), class = """"factor"""", scores = structure(c(1, 2, 14, 3, 5, 17, 18, 20, 11, 13), .Dim = 10L, .Dimnames = list(c(""""8"""", """"24"""", """"30"""", """"31"""", """"78"""", """"98"""", """"117"""", """"123"""", """"135"""", """"142"""")))), t = structure(c(6L, 1L, 2L, 4L, 7L, 9L, 3L, 1L,  2L, 4L, 5L, 8L, 9L, 10L, 7L, 8L, 9L, 11L, 9L, 1L, 4L, 1L), .Label = c(""""8"""", """"24"""", """"40"""", """"78"""", """"135"""", """"142"""", """"30"""", """"98"""", """"117"""", """"119"""", """"123"""" ), class = """"factor"""", scores = structure(c(1, 2, 14, 4, 5, 17, 18, 19, 20, 11, 13), .Dim = 11L, .Dimnames = list(c(""""8"""", """"24"""", """"30"""", """"40"""", """"78"""", """"98"""", """"117"""", """"119"""", """"123"""", """"135"""", """"142"""")))), V1 = c(3L, 1L, 9L, 4L, 1L, 107L, 2L, 5L, 3L, 1L, 2L, 1L,  6L, 14L, 20L, 1L, 4L, 1L, 2L, 3L, 2L, 2L)), .Names = c(""""s"""", """"t"""", """"V1""""), row.names = c(NA, -22L), class = """"data.frame"""")
o &lt;- c(8L, 24L, 31L, 40L, 78L, 80L, 85L, 94L, 104L, 113L, 135L, 136L, 142L, 30L, 54L, 91L, 98L, 117L, 119L, 123L, 9L, 34L, 97L, 126L,  140L, 13L, 75L, 92L, 134L, 138L, 141L, 6L, 12L, 22L, 44L, 48L, 51L, 57L, 64L, 79L, 84L, 88L, 93L, 100L, 115L, 124L, 129L, 132L,  143L, 144L, 2L, 10L, 14L, 15L, 16L, 17L, 19L, 35L, 39L, 41L, 50L, 52L, 53L, 58L, 61L, 66L, 67L, 68L, 71L, 72L, 73L, 76L, 96L, 99L, 101L, 106L, 109L, 114L, 121L, 127L, 128L, 131L, 137L, 145L, 146L, 148L, 150L, 4L, 18L, 23L, 28L, 29L, 32L, 37L, 38L, 65L, 82L, 90L, 102L, 105L, 107L, 111L, 122L, 130L, 133L, 139L, 147L, 3L, 5L, 7L, 11L, 21L, 27L, 33L, 43L, 45L, 46L, 47L, 49L, 55L, 56L, 59L, 60L, 62L, 63L, 69L, 70L, 77L, 83L, 87L, 89L, 103L, 108L, 112L, 116L, 118L, 120L, 125L, 149L, 151L, 1L, 20L, 25L, 26L, 36L, 42L, 74L, 81L, 86L, 95L, 110L)

emp$s &lt;- reorder(factor(emp$s),match(emp$s,o))
emp$t &lt;- reorder(factor(emp$t),match(emp$t,o))
qq &lt;- ggplot(emp,aes(x=s,y=t))
qq + geom_tile(aes(fill=log(V1)))+theme_bw()+
scale_fill_gradient(low=""""white"""",high=""""black"""")+
opts(axis.text.x=theme_text(angle=-90, hjust=0, size=5),
     axis.text.y=theme_text(vjust=0, size=5),
     panel.grid.minor = theme_blank(),
     panel.grid.major = theme_blank())
</code></pre>

<p>This produces the following:</p>

<p><a href=""""http://i46.tinypic.com/292n3ao.png"""" rel=""""nofollow noreferrer"""">alt text http://i46.tinypic.com/292n3ao.png</a></p>

<p>I would like to include a vertical line just after 142 and before 30.  (Note, I need to keep these values as a factor.) I've been considering two options: </p>

<ul>
<li>vline: I only am able to put the line on 142 and on 30, but not between them.</li>
<li>grid stuff: I feel like the ideal solution is to introduce a grid.major or something.</li>
</ul>

<p>Any ideas?</p>
",1
"<p>let's say, I have this xml file:</p>

<pre><code>&lt;?xml version=""""1.0"""" encoding=""""UTF-8"""" ?&gt;
&lt;TimeSeries&gt;
  &lt;timeZone&gt;1.0&lt;/timeZone&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:00:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:15:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:30:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:45:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""11:00:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""11:15:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
  &lt;/series&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""""2009-09-30"""" time=""""08:00:00"""" value=""""1.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""08:15:00"""" value=""""2.6"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""09:00:00"""" value=""""6.3"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""09:15:00"""" value=""""4.4"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""09:30:00"""" value=""""3.9"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""09:45:00"""" value=""""2.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:00:00"""" value=""""1.7"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:15:00"""" value=""""2.3"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:30:00"""" value=""""2.0"""" flag=""""2""""&gt;&lt;/event&gt;
  &lt;/series&gt;
  &lt;series&gt;
    &lt;header/&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:00:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:15:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:30:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""10:45:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
    &lt;event date=""""2009-09-30"""" time=""""11:00:00"""" value=""""0.0"""" flag=""""2""""&gt;&lt;/event&gt;
  &lt;/series&gt;
&lt;/TimeSeries&gt;
</code></pre>

<p>and let's say I want to do something with its series elements and that I would like to put in practice the advice 'vectorize the vectorizable'...  I import the XML library and do the following:</p>

<pre><code>R&gt; library(""""XML"""")
R&gt; doc &lt;- xmlTreeParse('/home/mario/Desktop/sample.xml')
R&gt; TimeSeriesNode &lt;- xmlRoot(doc)
R&gt; seriesNodes &lt;- xmlElementsByTagName(TimeSeriesNode, """"series"""")
R&gt; length(seriesNodes)
[1] 3
R&gt; (function(x){length(xmlElementsByTagName(x[['series']], 'event'))}
+ )(seriesNodes)
[1] 6
R&gt; 
</code></pre>

<p>and I don't understand why I should only get the result of applying the function to the first element: I had expected three values, just as the length of seriesNodes, something like this:</p>

<pre><code>R&gt; mapply(length, seriesNodes)
series series series 
     7     10      6 
</code></pre>

<p>oops!  I already came with the answer: """"use <code>mapply</code>"""":</p>

<pre><code>R&gt; mapply(function(x){length(xmlElementsByTagName(x, 'event'))}, seriesNodes)
series series series 
     6      9      5 
</code></pre>

<p>but then I see the following problem: the R-inferno tells me that I'm """"loop-hiding"""", not """"vectorizing""""!  can I avoid looping at all?  ...</p>
",1
"<p>I <a href=""""https://stackoverflow.com/questions/1295955/what-is-the-most-useful-r-trick/1826778#1826778"""">recently discovered</a> that you can conditionally assign a value with an if-else block.</p>

<pre><code>y &lt;- if(condition) 1 else 2
</code></pre>

<p>I realise that the use case for this is limited: if you have vectorised code, you would use the <code>ifelse</code> function instead.  There is a performance benefit: <code>if-else</code> runs about 35x faster than <code>ifelse</code> in the scalar case on my machine (though you need to call it millions of times to notice much of a difference).</p>

<p>What is bugging me is that I can't work out why this code works&mdash;I was amazed that it doesn't just throw an error.</p>

<p>Another example suggests that if blocks behave like functions&mdash;they automatically return the last value in the block (though you can't use a <code>return</code> statement in them).</p>

<pre><code>y &lt;- if(TRUE) 
{
   y &lt;- 3
   4
}    # y is 4
</code></pre>

<p>Based on this, I guessed that maybe another environment was created when you entered an if block, but this doesn't seem to be the case.</p>

<pre><code>if(TRUE) sys.frames()    # NULL
</code></pre>

<p>Can anyone tell me what is happening under the hood, please?</p>
",1
"<p>I am trying to use a <code>Java package</code> from <code>R</code>.  </p>

<p><code>RJava</code> provides a way to call <code>Java</code> from <code>R</code>, but wrapping all the methods is impractical. </p>

<p>Does anyone know of a script that generates wrappers for a package (say, by processing the relevant javadoc)?</p>
",1
"<p>In matlab there is a way to find the values in one vector but not in the other.</p>

<p>for example:</p>

<pre><code>x &lt;- c(1,2,3,4)
y &lt;- c(2,3,4)
</code></pre>

<p>is there any function that would tell me that the value in <code>x</code> that's not in <code>y</code> is 1?</p>
",1
"<p>the function I am writing specifies the behaviour of a physical switch: it should be turned ON if a value goes above an upper threshold and can go again OFF if it goes under the lower threshold.  a similar logic would describe a normal thermostat in a household oven.  obviously I want it to work on vectors, that's the whole point!</p>

<p>so if I have the data</p>

<pre><code>S &lt;- c(50, 100, 150, 180, 210, 200, 190, 182, 175, 185, 195, 205)
</code></pre>

<p>my function tells if the oven temperature is all right.  the logical inverse of """"switch the oven on"""".</p>

<pre><code>R&gt; thresholdOnOff(S, 180, 200)
 [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE
</code></pre>

<p>the question is about programming style: I first tried to write it with an 'apply' function in it but I had forgotten to take environments into account...  so I wrote a working version with a 'for' loop - which I didn't like, then remembered about the environments and I'm not sure about the two versions:</p>

<pre><code>thresholdOnOff &lt;- local( {
  ## following the R inferno
  f &lt;- function(series, lower, upper, initialValue=FALSE) {
    status &lt;&lt;- initialValue

    switchOnOff &lt;- function(x) {
      if(x &gt; upper)
        status &lt;&lt;- TRUE
      if(x &lt; lower)
        status &lt;&lt;- FALSE
      return(status)
    }

    sapply(series, switchOnOff)
  }
} )


thresholdOnOff &lt;- function(series, lower, upper, initialValue=FALSE) {
  ## just guessing and reading from the documentation
  status &lt;- initialValue

  switchOnOff &lt;- function(x) {
    if(x &gt; upper)
      assign('status', TRUE, inherits=TRUE)
    if(x &lt; lower)
      assign('status', FALSE, inherits=TRUE)
    return(status)
  }

  sapply(series, switchOnOff)
}
</code></pre>
",1
"<p>Take for example the following ftable</p>

<pre><code>height &lt;- c(rep('short', 7), rep('tall', 3))
girth &lt;- c(rep('narrow', 4), rep('wide', 6))
measurement &lt;- rnorm(10)
foo &lt;- data.frame(height=height, girth=girth, measurement=measurement)
ftable.result &lt;- ftable(foo$height, foo$girth)
</code></pre>

<p>I'd like to convert the above <code>ftable.result</code> into a matrix with row names and column names.  Is there an efficient way of doing this?  <code>as.matrix()</code> doesn't exactly work, since it won't attach the row names and column names for you.</p>

<p>You could do the following</p>

<pre><code>ftable.matrix &lt;- ftable.result
class(ftable.matrix) &lt;- 'matrix'

rownames(ftable.matrix) &lt;- unlist(attr(ftable.result, 'row.vars'))
colnames(ftable.matrix) &lt;- unlist(attr(ftable.result, 'col.vars'))
</code></pre>

<p>However, it seems a bit heavy-handed.   Is there a more efficient way of doing this?</p>
",1
"<p>I'd like to read the contents of a URL (e.q., <a href=""""http://www.haaretz.com/"""" rel=""""noreferrer"""">http://www.haaretz.com/</a>) in R. I am wondering how I can do it</p>
",1
"<p>I've used RODBC for some time to import Excel spreadsheets with mostly good results. However I have had no luck writing to an Excel spreadsheet. Also are there favorable differences using the xlsx format with Excel2007? </p>
",1
"<p>Is there a way of overlaying a mathematical function on top of data using ggplot?</p>

<pre><code>## add ggplot2
library(ggplot2)

# function
eq = function(x){x*x}

# Data                     
x = (1:50)     
y = eq(x)                                                               

# Make plot object    
p = qplot(    
x, y,   
xlab = """"X-axis"""", 
ylab = """"Y-axis"""",
) 

# Plot Equation     
c = curve(eq)  

# Combine data and function
p + c #?
</code></pre>

<p>In this case my data is generated using the function, but I want to understand how to use <code>curve()</code> with ggplot.</p>
",1
"<p>I have a situation in which I have to give a formula as input to the <code>nls()</code> function.
I have data which is between time and variance. For example:</p>

<pre><code>Time Variance
1     0.15
2     0.23
3     0.67
4     0.85
</code></pre>

<p>Now I am using the formula <em>Vt = ((1-e^kt)/kt)) (q^2)/2k</em>, where <em>Vt</em> is the variance at time <em>t</em>. I have the two variables <em>(k,q)</em> in the above equation. I have to determine <em>k(hat)</em> and <em>q(hat)</em>. Can I define the above formula as a user-defined formula and give it as an argument to the <code>nls()</code> function?</p>
",1
"<p>I have a table where there are """"NA""""s littered all over the place in one column in particular. I want to replace every instance of """"NA"""" with something else -- say, the number 1. </p>

<p>How should I do that?</p>
",1
"<p>I am trying to reshape a data frame in R and it seems to have problems using the recommended ways of doing so. The data frame has the following structure:</p>

<pre><code>ID                     DATE1             DATE2            VALTYPE        VALUE
'abcd1233'         2009-11-12        2009-12-23           'TYPE1'        123.45
...
</code></pre>

<p><code>VALTYPE</code> is a string and is a factor with only 2 values (say <code>TYPE1</code> and <code>TYPE2</code>). I need to transform it into the following data frame (""""wide"""" transpose) based on common ID and DATEs:</p>

<pre><code>ID                     DATE1             DATE2            VALUE.TYPE1  VALUE.TYPE2
'abcd1233'             2009-11-12        2009-12-23       123.45           NA
...
</code></pre>

<p>The data frame has more than 4,500,000 observations (although about 70% of <code>VALUE</code>s are <code>NA</code>). The machine is an Intel-based Linux workstation with 4Gb of RAM. Loading the data (from a compressed Rdata file) into a fresh R process makes it grow to about 250Mb which clearly leaves a lot of space for reshaping.</p>

<p>These are my experiences so far:</p>

<ul>
<li><p>Using vanilla <code>reshape()</code> method:</p>

<p>tbl2 &lt;- reshape(tbl, direction = """"wide"""", idvar = c(""""ID"""", """"DATE1"""", """"DATE2""""), 
                timevar = """"VALTYPE"""");</p></li>
</ul>

<p>RESULT: <code>Error: cannot allocate vector of size 4.8 Gb</code></p>

<ul>
<li><p>Using <code>cast()</code> method of <code>reshape</code> package:</p>

<p>tbl2 &lt;- cast(tbl, ID + DATE1 + DATE2 ~ VALTYPE);</p></li>
</ul>

<p>RESULT: R process consumes all RAM with no end in sight. Had to kill the process eventually.</p>

<ul>
<li><p>Using <code>by()</code> and <code>merge()</code>:</p>

<p>sp &lt;- by(tbl[c(1,2,3,5)], tbl$VALTYPE, function(x) x);
tbl &lt;- merge(sp[[""""TYPE1""""]], sp[[""""TYPE2""""]], 
       by = c(""""ID"""", """"DATE1"""", """"DATE2""""), all = TRUE, sort = TRUE);</p></li>
</ul>

<p>RESULT: works fine, although this is not very elegant and foolproof (i.e. it will break if more types are added).</p>

<p>To add insult to injury, the operation in question can be trivially achieved in about 3 lines of AWK or Perl (and with hardly any RAM used). So the question is: what is a better way to do this operation in R using recommended methods without consuming all available RAM?</p>
",1
"<p>a function I wrote extracts timestamps from a XML document.  Timestamps are coupled to events, which are repeated elements of the series element.</p>

<p>series elements have a variable amount of events, so my function returns a data.frame (if the series have the same length).  in general it returns a more generic list and I want it to work with matrices as well.  I was pointed out (Thanks Eduardo) that 'list' is the generic type, but I still have trouble with functions that work on generic lists but not with more specific types, like data.frame or matrix.</p>

<p>what I need to do with the data at the moment is to see what is the most common distance between timestamps (I expect it to appear (much) more often than 50% of the times), I have written and rewritten a function doing this:</p>

<pre><code>R&gt; mostCommonStep( list(a=cumsum(c(1,3,3,2,3,3,4,3,2,3,3)), b=cumsum(c(2,3,2,3))) )
[1] 3
R&gt; mostCommonStep( data.frame(a=c(2,4,6,8,12,14,18), b=c(12,14,16,18,22,24,28)) )
[1] 2
R&gt; mostCommonStep( matrix(c(2,4,6,8,12,14,18, 12,14,16,18,22,24,28), 7, 2) )
[1] 2
</code></pre>

<p>but I would like to see a more """"R"""" conformant version</p>
",1
"<p>We are currently using <code>R</code> to automatically generate various kinds of <code>boxplots</code>. </p>

<p>The problem we have is that the length of our labels varies considerably between different plots and classes in one plot.</p>

<p>Is there a way to automatically adjust the plot so that all the labels will fit it nicely? </p>

<p>Specifying a worst case <code>mar</code> isn't feasible because in some plots the labels are considerably shorter than in others.</p>
",1
"<p>I'm reading a text file like this in R 2.10.0</p>

<pre><code>248585_at   250887_at   245638_s_at AFFX-BioC-5_at
248585_at   250887_at   264488_s_at 245638_s_at AFFX-BioC-5_at  AFFX-BioC-3_at  AFFX-BioDn-5_at
248585_at   250887_at
</code></pre>

<p>Using the command
    clusters&lt;-read.delim(""""test"""",sep=""""\t"""",fill=TRUE,header=FALSE)</p>

<p>Now, I must pass every row in this file to a BioConductor function that takes only character vectors as input.
MY problem is that using """"as.character"""" on this """"clusters"""" object turns everything into numeric strings.</p>

<pre><code>&gt; clusters[1,]
         V1        V2          V3             V4 V5 V6 V7
1 248585_at 250887_at 245638_s_at AFFX-BioC-5_at         
</code></pre>

<p>But </p>

<pre><code>&gt; as.character(clusters[1,])
[1] """"1"""" """"1"""" """"2"""" """"3"""" """"1"""" """"1"""" """"1""""
</code></pre>

<p>Is there any way to keep the original names and put them into a character vector?</p>

<p>Maybe it helps: my """"clusters"""" object given by the """"read.delim"""" file belongs to the """"list"""" type.</p>

<p>Thanks a lot :-)</p>

<p>Federico</p>
",1
"<p>I have a df and I want to do multiple transform on it with plyr:</p>

<pre><code>idplot / idtree / species /  condition / dbh_cm / h_m / hblc_m


CalcG &lt;- function (df) transform(df, g_m2 = pi * (dbh_cm^2)/40000)

CalcHD &lt;- function (df) transform(df, hd = h_m / dbh_cm)
</code></pre>

<p>...</p>

<p>Can be done in one function?
Many thanks.</p>
",1
"<p>I have a vector: <code>c(1,2,3)</code></p>

<p>Calling <code>print()</code> on this value gives <code>[1] 1 2 3</code></p>

<p>Is there a function that takes a vector and gives the string <code>c(1,2,3)</code>?</p>
",1
"<p>I'm trying to read a text file with different row lengths:</p>

<pre><code>1
1   2
1   2   3
1   2   3   4
1   2   3   4   5
1   2   3   4   5   6
1   2   3   4   5   6   7
1   2   3   4   5   6   7   8
</code></pre>

<p>To overcome this problem, I'm using the argument fill=TRUE in read.table, so:</p>

<pre><code>data&lt;-read.table(""""test"""",sep=""""\t"""",fill=TRUE)
</code></pre>

<p>Unfortunately, to assess the maximum row length, read.table reads only the first 5 lines of the file, and generates an object looking like this:</p>

<pre><code>data
   V1 V2 V3 V4 V5
1   1 NA NA NA NA
2   1  2 NA NA NA
3   1  2  3 NA NA
4   1  2  3  4 NA
5   1  2  3  4  5
6   1  2  3  4  5
7   6 NA NA NA NA
8   1  2  3  4  5
9   6  7 NA NA NA
10  1  2  3  4  5
11  6  7  8 NA NA
</code></pre>

<p>Is there a way to force read.table to scroll over the whole file to assess the maximum row length?
I know a possible solution would be to provide the column number, like:</p>

<pre><code>data&lt;-read.table(""""test"""",sep=""""\t"""",fill=TRUE,col.names=c(1:8))
</code></pre>

<p>But since I have a lot of files, I wanted to assess this automatically within R. Any suggestion? :-)</p>

<hr>

<p>EDIT: the original file doesn't contain progressive numbers, so this is not a solution:</p>

<pre><code>data1&lt;-read.table(""""test"""",sep=""""\t"""",fill=TRUE)
data2&lt;-read.table(""""test"""",sep=""""\t"""",fill=TRUE,col.names=c(1:max(data1))
</code></pre>
",1
"<p>I have multiple sets of xy pairs that I want to plot.  I want each set of xy pairs to be connected by a line.  In other words the goal is to have multiple experimental instances each approximated by a line plotted on one plot.  Also how would I colour the lines differently?</p>

<p>The plot function does what I want, but takes on one set of xy pairs:
<code>plot(x, y, ...)</code></p>

<p>Can this function be made to take multiple sets or is there another function for that?</p>
",1
"<p>I'm working with a large data frame, and have run up against RAM limits. At this point, I probably need to work with a serialized version on the disk. There are <a href=""""http://cran.r-project.org/web/views/HighPerformanceComputing.html"""" rel=""""nofollow noreferrer"""">a few packages</a> to support out-of-memory operations, but I'm not sure which one will suit my needs. I'd prefer to keep everything in data frames, so the <code>ff</code> package looks encouraging, but there are still compatibility problems that I can't work around.</p>

<p>What's the first tool to reach for when you realize that your data has reached out-of-memory scale?</p>
",1
"<p>I have a dataframe that I want to reshape; my reshape code:</p>

<pre><code>matchedlong &lt;- reshape(matched, direction = 'long',
                       varying = c(29:33, 36:3943),
                       v.names = c(""""Math34"""", """"TFCIn""""),
                       times = 2006:2009, idvar = """"schoolnum"""")
</code></pre>

<p>in <code>matched</code> columns 36 to 39 are logical (<code>TRUE</code> <code>FALSE</code>) but in <code>matchedlong</code> they have turned into numbers somehow .... No clear pattern to the numbers. </p>

<p>what is causing this?</p>

<p>Sample data:</p>

<pre><code>example.data &lt;- structure(list(Grade_Range_2008 = structure(c(14L, 14L, 40L,
40L, 36L, 13L), .Label = c(""""3-5, UE"""", """"4-5, UE"""", """"4-8, UE, US"""",
""""5-10, UE, US"""", """"5-8, 10, UE, US"""", """"5-8, UE, US"""", """"5-9, UE, US"""",
""""6-11, US"""", """"6-12, UE, US"""", """"6-7, UE, US"""", """"6-8, 10, UE, US"""",
""""6-8, UE"""", """"6-8, UE, US"""", """"6-9, UE, US"""", """"6, UE"""", """"7-10, US"""",
""""7-8, US"""", """"8-Jun"""", """"8-May"""", """"K-3"""", """"K-3, UE"""", """"K-4, UE"""", """"K-5"""",
""""K-5, UE"""", """"K-6, UE"""", """"K-8"""", """"K-8, UE"""", """"K-8, UE, US"""", """"K, 2-5, UE"""",
""""N/A"""", """"PK-3, UE"""", """"PK-4, UE"""", """"PK-5, 10, UE"""", """"PK-5, 7-9, UE, US"""",
""""PK-5, 8, UE"""", """"PK-5, UE"""", """"PK-6, 10, UE"""", """"PK-6, UE"""", """"PK-8, UE"""",
""""PK-8, UE, US""""), class = """"factor""""), X__of_Yrs_in_school = c(0L,
0L, 0L, 0L, 0L, 0L), Total_Enrollment_2008 = c(348L, 444L, 636L,
495L, 319L, 410L), Free_Lunch_pct_2008 = c(75L, 89L, 94L, 89L,
89L, 91L), Reduced_Lunch_pct_2008 = c(6L, 6L, 3L, 4L, 5L, 4L),
    Stability_pct_2008 = c(89L, 93L, 100L, 98L, 92L, 81L),
Limited_Eng__Prof__pct_2008 = c(8L,
    20L, 8L, 10L, 19L, 19L), Am__Ind_pct_2008 = c(1L, 2L, 0L,
    2L, 0L, 2L), Black_pct_2008 = c(41L, 39L, 28L, 33L, 32L,
    38L), Hispanic_pct_2008 = c(55L, 59L, 70L, 61L, 65L, 57L),
    Asian_pct_2008 = c(2L, 1L, 0L, 2L, 1L, 1L), White_pct_2008 = c(2L,
    0L, 1L, 2L, 1L, 2L), Multi_pct_2008 = c(0L, 0L, 0L, 0L, 0L,
    0L), w_o_Valid_Cert__N_2008 = c(4L, 0L, 1L, 0L, 1L, 1L),
    w_o_Valid_Cert__pct_2008 = c(11L, 0L, 2L, 0L, 3L, 5L),
Teaching_Out_of_Certification_N_ = c(7L,
    7L, 2L, 13L, 3L, 4L), Teaching_Out_of_Certification_pc = c(20L,
    15L, 4L, 25L, 9L, 18L), X_3_yrs__Exp_N_2008 = c(12L, 13L,
    5L, 12L, 5L, 5L), X_3_yrs__Exp_pct_2008 = c(34L, 28L, 11L,
    24L, 15L, 23L), Masters_Plus_N_2008 = c(6L, 11L, 15L, 10L,
    16L, 8L), Masters_Plus___2008 = c(17L, 23L, 32L, 20L, 47L,
    36L), Core_Classes_N_2008 = c(78L, 142L, 49L, 91L, 22L, 49L
    ), Core_Not_Taught_by_HQ_Teachers_p = c(23L, 6L, 2L, 24L,
    9L, 20L), Number_of_Classes_N_2008 = c(93L, 193L, 56L, 119L,
    33L, 68L), Clases_Not_taught_by_App__Cert__ = c(18L, 18L,
    2L, 37L, 3L, 13L), Clases_Not_taught_by_App__Cert_0 = c(19L,
    9L, 4L, 31L, 9L, 19L), Turnover_Rate_of_Teachers_with__ = c(31L,
    56L, 20L, 32L, 0L, 50L), Turnover_Rate_all_Teachers_pct_2 = c(42L,
    29L, 17L, 30L, 14L, 49L), Math_Level_3_4_pct_2006 = c(5.1,
    16.4, 58.2, 34.4, 48.9, 12.4), Math_Level_3_4_pct_2007 = c(15.2,
    22.1, 65.7, 29.9, 70.5, 22.6), Math_Level_3_4_pct_2008 = c(29.9,
    43.2, 69.8, 41.2, 78.9, 38.5), Math_Level_3_4_pct_2009 = c(50.7,
    49.7, 80.7, 47.1, 83.9, 51.6), Att__pct_2005 = c(0.83, 0.86,
    0.89, 0.9, 0.89, 0.87), Susp__pct_2005 = c(6L, 15L, 1L, 4L,
    0L, 3L), schoolnum = c(4013, 4045, 4096, 4101, 4102, 4117
    ), In_2006 = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE),
    In_2007 = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE), In_2008 = c(FALSE,
    FALSE, FALSE, FALSE, FALSE, FALSE), In_2009 = c(FALSE, FALSE,
    FALSE, FALSE, FALSE, FALSE), weights = c(1, 1, 1, 1, 1, 1
    )), .Names = c(""""Grade_Range_2008"""", """"X__of_Yrs_in_school"""",
""""Total_Enrollment_2008"""", """"Free_Lunch_pct_2008"""", """"Reduced_Lunch_pct_2008"""",
""""Stability_pct_2008"""", """"Limited_Eng__Prof__pct_2008"""", """"Am__Ind_pct_2008"""",
""""Black_pct_2008"""", """"Hispanic_pct_2008"""", """"Asian_pct_2008"""", """"White_pct_2008"""",
""""Multi_pct_2008"""", """"w_o_Valid_Cert__N_2008"""", """"w_o_Valid_Cert__pct_2008"""",
""""Teaching_Out_of_Certification_N_"""", """"Teaching_Out_of_Certification_pc"""",
""""X_3_yrs__Exp_N_2008"""", """"X_3_yrs__Exp_pct_2008"""", """"Masters_Plus_N_2008"""",
""""Masters_Plus___2008"""", """"Core_Classes_N_2008"""",
""""Core_Not_Taught_by_HQ_Teachers_p"""",
""""Number_of_Classes_N_2008"""", """"Clases_Not_taught_by_App__Cert__"""",
""""Clases_Not_taught_by_App__Cert_0"""", """"Turnover_Rate_of_Teachers_with__"""",
""""Turnover_Rate_all_Teachers_pct_2"""", """"Math_Level_3_4_pct_2006"""",
""""Math_Level_3_4_pct_2007"""", """"Math_Level_3_4_pct_2008"""",
""""Math_Level_3_4_pct_2009"""",
""""Att__pct_2005"""", """"Susp__pct_2005"""", """"schoolnum"""", """"In_2006"""", """"In_2007"""",
""""In_2008"""", """"In_2009"""", """"weights""""), row.names = c(1L, 4L, 7L, 8L,
11L, 12L), class = """"data.frame"""")
</code></pre>
",1
"<p>so I decided I would put my few R functions into a package and I'm reading/learning <a href=""""http://cran.r-project.org/doc/manuals/R-exts.pdf"""" rel=""""nofollow noreferrer"""">Writing R Extension</a>.</p>

<p>it obviously complains about an amount of things I'm not doing right.</p>

<p>after enough googling, I'm firing a few questions here, this one is about testing style: I am using <a href=""""http://cran.r-project.org/web/packages/RUnit/vignettes/RUnit.pdf"""" rel=""""nofollow noreferrer"""">RUnit</a> and I like having tests as close possible to the code being tested.  this way I won't forget about the tests and I use the tests as part of the technical documentation.  </p>

<p>for example:</p>

<pre><code>fillInTheBlanks &lt;- function(S) {
  ## NA in S are replaced with observed values

  ## accepts a vector possibly holding NA values and returns a vector
  ## where all observed values are carried forward and the first is
  ## carried backward.  cfr na.locf from zoo library.
  L &lt;- !is.na(S)
  c(S[L][1], S[L])[1 + cumsum(L)]
}

test.fillInTheBlanks &lt;- function() {
  checkEquals(fillInTheBlanks(c(1, NA, NA, 2, 3, NA, 4)), c(1, 1, 1, 2, 3, 3, 4))
  checkEquals(fillInTheBlanks(c(1, 2, 3, 4)), c(1, 2, 3, 4))
  checkEquals(fillInTheBlanks(c(NA, NA, 2, 3, NA, 4)), c(2, 2, 2, 3, 3, 4))
}
</code></pre>

<p>but <code>R CMD check</code> issues NOTE lines, like this one:</p>

<pre><code>test.fillInTheBlanks: no visible global function definition for
  ‘checkEquals’
</code></pre>

<p>and it complains about me not documenting the test functions.</p>

<p>I don't really want to add documentation for the test functions and I definitely would prefer not having to add a dependency to the RUnit package.</p>

<p>how do you think I should look at this issue?</p>
",1
"<p>this sounds like a silly problem: I'm putting my R code into a package and <code>R CMD check src</code> complains about the .Rd~ backup files being produced by Emacs.  </p>

<pre><code>* checking package subdirectories ... WARNING
Subdirectory 'man' contains invalid file names:
  read.PI.Rd~ write.PI.Rd~
</code></pre>

<p>the documentation says: »In addition [...] files [...]  with base names [...] ending in ‘~’, ‘.bak’ or ‘.swp’, are excluded by default.« (page 18).  but then why the warning?</p>
",1
"<p>I'm trying to make a visualization that looks like this <a href=""""http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG"""" rel=""""nofollow noreferrer"""">http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG http://www.gradient-da.com/img/temperature%20surface%20plot%20470x406.JPG</a>.</p>

<p>The idea is to have a 3D surface plot overlapping a 2d representation of a surface.</p>

<p>I can build arbitrary surfaces/polygon shapes (as in <a href=""""http://addictedtor.free.fr/graphiques/graphcode.php?graph=135"""" rel=""""nofollow noreferrer"""">http://addictedtor.free.fr/graphiques/graphcode.php?graph=135</a> ) and I can make the respective 2D plot. What I don't seem to be able to figure out is the way to put them together in a nice way (like the one shown in the jpg above).</p>

<p>I've tried googling for the answer, but I wasn't able to find anything similar done in R.
Any help would be greatly appreciated!</p>

<p>EDIT: The 2D portion is not a projection of the 2D one. I chose this specific picture to illustrate this. For example</p>

<ol>
<li>Here the 2D portion is the image of the circuit and on the 3D portion is the temperature).</li>
<li>In 2D you can have the map of a city and in 3D the traffic</li>
<li>etc...</li>
</ol>

<p>Best,</p>

<p>Bruno</p>
",1
"<p>I have decided to learn R. I am trying to get a sense of how to write """"R style"""" functions and to avoid looping. Here is a sample situation:</p>

<p>Given a vector <code>a</code>, I would like to compute a vector <code>b</code> whose elements <code>b[i]</code> (the vector index begins at 1) are defined as follows:</p>

<pre><code>1 &lt;= i &lt;= 4:
b[i] = NaN

5 &lt;= i &lt;= length(a):
b[i] = mean(a[i-4] to a[i])
</code></pre>

<p>Essentially, if we pretend 'a' is a list of speeds where the first entry is at time = 0, the second at time = 1 second, the third at time = 2 seconds... I would like to obtain a corresponding vector describing the average speed over the past 5 seconds.</p>

<p>E.g.:
If <code>a is (1,1,1,1,1,4,6,3,6,8,9)</code> then <code>b</code> should be <code>(NaN, NaN, NaN, NaN, 1, 1.6, 2.6, 3, 4, 5.4, 6.4)</code></p>

<p>I could do this using a loop, but I feel that doing so would not be in """"R style"""".</p>

<p>Thank you,</p>

<p>Tungata</p>
",1
"<p>I'm putting this thing in my source(s)...  (right, for now it's just one, plus the test scripts).</p>

<pre><code>REVISION = (function(x) substring(x, first=7, last=nchar(x)-2))(""""$Rev: 8727 $"""")
</code></pre>

<p>but how do """"real"""" R programmers do?  </p>
",1
"<p>I am making my first attempts to write a R package. I am loading one csv file from hard drive and I am hoping to bundle up my R codes and my csv files into one package later.</p>

<p>My question is how can I load my csv file when my pakage is generated, I mean right now my file address is something like c:\R\mydirectory....\myfile.csv but after I sent it to someone else how can I have a relative address to that file?</p>

<p>Feel free to correct this question if it is not clear to others!</p>
",1
"<p>I have the following dataset</p>

<pre><code>1890 mar 0.4
1890 apr 0.8
1890 may 1.0
...
1989 jan 0.2
1989 feb 0.4
1989 mar 0.5
</code></pre>

<p>How can I make a line plot in <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a> with on the x-axis the year, displayed every 5 years?</p>

<p>My problem is not so much making the plot, but getting to display only the years I want, and place them on the beginning of that year. So I don't want a tick on April but on January.</p>
",1
"<p>I have the character vector below</p>

<pre><code>a = c(""""2009-07-31 18:00:33"""", """"2009-07-31 18:00:38"""", """"2009-07-31 18:00:43"""",  """"2009-07-31 18:00:49"""", """"2009-08-01 01:58:49"""", """"2009-08-01 01:53:16"""",  """"2009-08-01 08:04:13"""", """"2009-08-01 16:16:13"""")
</code></pre>

<p>I want to convert this to time objects so I do this:</p>

<pre><code>b = strptime(a, """"%Y-%m-%d %H:%M:%S"""")
</code></pre>

<p>Why do a and b have different lengths?</p>

<pre><code>&gt; length(a)
[1] 8
&gt; length(b)
[1] 9
</code></pre>
",1
"<p>a question following  <a href=""""https://stackoverflow.com/questions/1886571"""">making-the-subversion-revision-number-visible-in-my-r-scripts</a></p>

<p><code>R CMD build PKG</code> creates a file named as Package_Version.tar.gz according to the fields in <code>DESCRIPTION</code>.  </p>

<p>not only isn't the strictly sequential numbering coming from svn very practical here, but its <code>$REV: number $</code> format does not respect the <code>number.number-number</code> structure expected after <code>Version:</code>.  </p>

<p>I think I would want to use the subversion revision number as the third """"coordinate"""" of the package version.  the first and second coordinates would be raised by hand at major changes.</p>

<p>but how do you """"normally"""" do?</p>

<hr>

<p>One could write a bash/grep/awk script that gets the highest Rev out of the sources, that wouldn't a problem.  But, is <code>configure</code> run before <code>R CMD build</code>?  In this case one could build the DESCRIPTION file (kept out of source control) from a template file and this highest Rev number.</p>

<p>My question is about common practice.</p>

<hr>

<p>the """"optimal"""" answer would allow me to place a package on r-forge and have the automated scripts run there update the third coordinate of the <code>Version:</code> field from the latest files committed in the <code>R</code> subdir.</p>

<p>a """"good enough"""" answer would work locally and I have it already, but am not using it any more because I otherwise get used to things that are generally unavailable.</p>

<p>since it's about practices, I'll add my current practice as possible answer.  it is not automated but I find it clear and (almost) acceptable.</p>
",1
"<p>I'm a newbie to both R and LaTeX and have just recently found how to plot a standard time series graph using R and save it as a png image. What I'm worried about is that saving it as an image and then embedding it into LaTeX is going to scale it and make it look ugly.</p>

<p>Is there a way to make R's <code>plot()</code> function output a vector graphic and embed that into LaTeX? I'm a total beginner in both so please be gentle :) Code snippets are highly appreciated!</p>
",1
"<p>I am using the <a href=""""http://cran.r-project.org/web/packages/EMD/EMD.pdf"""" rel=""""nofollow noreferrer"""">EMD</a> package for R. This package has a spectrogram function for displaying a Hilbert Spectrum (calculated with hilbertspec). The output however, is really vague and black-white.</p>

<p>This function does not seem to have an option for outputting color images. How can I get the spectrum displayed clearly and if possible in color.</p>
",1
"<p>A few years back I used UCINET for some social network analysis. Theese days I'd like to use SNA again - but this time I prefer a unified analysis framework - which for me is R.</p>

<p>I have looked at the sna and statnet documentation but am a bit overwhelmed.</p>

<p>What I'd like to do: First: Load an bipartite/incidence matrix pulled directly from e.g. a websurvey (often valued). Convert this matrix to two adjacency matrix' (affiliatoin by affiliation and cases by cases). It could also be a directed, valued cases by cases matrix.</p>

<p>Second: Load a file (also from e.g. websurvey data) of vertice attributes.</p>

<p>Third: Then plot the graph with e.g. vertice size according to some centrality measure, colored and labeled by some vertice attributes, with only edges with value over a certain threshold being drawn.</p>

<p>This is a mini incidence matrix: </p>

<pre><code>data &lt;- structure(list(this = c(0, 1, 0, 1, 1, 2, 0, 1, 3), 
 that = c(1, 1, 3, 0, 0, 0, 2, 1, 0), 
 phat = c(0, 0, 2, 1, 0, 0, 1, 2, 0)), 
 .Names = c(""""this"""", """"that"""", """"phat""""), 
 row.names = c(""""a"""", """"b"""", """"c"""", """"d"""", """"e"""", """"f"""", """"g"""", """"h"""", """"i""""), 
 class = """"data.frame"""")
</code></pre>

<p>with som attribute data:</p>

<pre><code>att &lt;-structure(list(sex = structure(c(1L, 1L, 2L, 2L, 1L, 2L, 1L, 
1L, 1L), .Label = c(""""F"""", """"M""""), class = """"factor""""), agegr = c(1L, 
1L, 3L, 1L, 3L, 1L, 1L, 3L, 1L), place = structure(c(1L, 2L, 
1L, 1L, 1L, 1L, 2L, 2L, 1L), .Label = c(""""Lower"""", """"Upper""""), 
class = """"factor"""")), .Names  = c(""""sex"""", 
""""agegr"""", """"place""""), row.names = c(NA, -9L), class = """"data.frame"""")
</code></pre>

<p>p.s. maybe SNA would be a good tag for this post? I just don't have the nescassary SO goodwill :-)</p>
",1
"<p>I have a 3-tuple data set (X,Y,Z points) that I want to plot using R.</p>

<p>I want to create a surface plot from the data, and superimpose a contour map on the surface plot, so as to create the impression of the contour map being the """"shadow"""" or projection from the surface plot. The contour map is to appear below the surface plot.</p>

<p>My data set looks somewhat like this:</p>

<pre><code>Axis  |  Data Type
-------------------
X     |  Date value
Y     |  Float value
Z     |  Float value
</code></pre>

<p>How can I achieve this?</p>
",1
"<p>What the most efficient way in the programming language <a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a> to calculate the angle between two vectors?</p>
",1
"<p>I am using ggplot2 library and am working with the qplot command
I know I can save my output as an anti-aliased image file by using the following command after my qplot </p>

<pre><code>ggsave(file=""""filename.png"""")
</code></pre>

<p>But how about my LCD display? is there any way to see a plot on the monitor as anti-aliased grpah? </p>
",1
"<p>I want to rbind.zoo two zoo object together.  When I was testing I came across the following issue(?)...</p>

<p>Note:  The below is an example, there is clearly no point to it apart from being illustrative.
I have an zoo object, call it, 'X'.  I want to break it into two parts and then rbind.zoo them together.  When I compare it to the original object then all.equal gives differences.</p>

<p>It appears that the '$class' attribute differs, but I can't see how or why.  Is I make these xts objects then the all.equal works as expected.</p>

<p>i.e. .....</p>

<pre><code>X.date &lt;- as.POSIXct(paste(""""2003-"""", rep(1:4, 4:1), 
                     """"-"""", sample(1:28, 10, replace = TRUE), sep = """"""""))

X &lt;- zoo(matrix(rnorm(24), ncol = 2), X.date)

a &lt;- X[c(1:3), ]      # first 3 elements

b &lt;- X[c(4:6), ]      # second 3 elements

c &lt;- rbind.zoo(a, b)  # rbind into an object of 6 elements

d &lt;- X[c(1:6), ]      # all 6 elements

all.equal(c, d)       # are they equal?
</code></pre>

<p>~~~~</p>

<p>all.equal gives me the following difference:</p>

<p>""""Attributes: &lt; Component 3: Attributes: &lt; Length mismatch: comparison on first 1 components > >""""</p>
",1
"<p>Using <code>kernlab</code> I've trained a model with code like the following:</p>

<pre><code>my.model &lt;- ksvm(result ~ f1+f2+f3, data=gold, kernel=""""vanilladot"""")
</code></pre>

<p>Since it's a linear model, I prefer at run-time to compute the scores as a simple weighted sum of the feature values rather than using the full SVM machinery.  How can I convert the model to something like this (some made-up weights here):</p>

<pre><code>&gt; c(.bias=-2.7, f1=0.35, f2=-0.24, f3=2.31)
.bias    f1    f2    f3 
-2.70  0.35 -0.24  2.31 
</code></pre>

<p>where <code>.bias</code> is the bias term and the rest are feature weights?</p>

<p>EDIT:</p>

<p>Here's some example data.</p>

<pre><code>gold &lt;- structure(list(result = c(-1, -1, -1, -1, -1, -1, -1, -1, -1, 
-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), f1 = c(0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 
1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1), f2 = c(13.4138113499447, 
13.2216999857095, 12.964145772169, 13.1975227965938, 13.1031520152764, 
13.59351759447, 13.1031520152764, 13.2700658838026, 12.964145772169, 
13.1975227965938, 12.964145772169, 13.59351759447, 13.59351759447, 
13.0897162110721, 13.364151238365, 12.9483051847806, 12.964145772169, 
12.964145772169, 12.964145772169, 12.9483051847806, 13.0937231331592, 
13.5362700880482, 13.3654209223623, 13.4356400945176, 13.59351759447, 
13.2659406408724, 13.4228886221088, 13.5103065354936, 13.5642812689161, 
13.3224757352068, 13.1779418771704, 13.5601730479315, 13.5457299603578, 
13.3729010596517, 13.4823595997866, 13.0965264603473, 13.2710281801434, 
13.4489887206797, 13.5132372154748, 13.5196188787197), f3 = c(0, 
1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 
0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0)), .Names = c(""""result"""", 
""""f1"""", """"f2"""", """"f3""""), class = """"data.frame"""", row.names = c(NA, 40L
))
</code></pre>
",1
"<p>I have a stationary time series to which I want to fit a linear model with an autoregressive term to correct for serial correlation, i.e. using the formula At = c1*Bt + c2*Ct + ut, where ut = r*ut-1 + et</p>

<p>(ut is an AR(1) term to correct for serial correlation in the error terms)</p>

<p>Does anyone know what to use in R to model this?</p>

<p>Thanks
Karl</p>
",1
"<p>I'm new to R and having a hard time piecing together information from various sources online related to what is considered a """"good"""" practice with writing R code.  I've read basic guides but I've been having a hard time finding information that is definitely up to date.</p>

<ol>
<li>What are some examples of well written/documented S3 classes?</li>
<li>How about corresponding S4 classes?</li>
<li>What conventions do you use when commenting .R classes/functions?  Do you put all of your comments in both .Rd files and .R files?  Is synchronization of these files tiresome?</li>
</ol>
",1
"<p>I am following the hints to <a href=""""https://stackoverflow.com/questions/1879843/distributing-r-package-containing-unit-tests"""">this question</a>, but I'm impatient and I would like to run my tests more quickly, without having to wait for the 30+ checks that <code>R CMD check src</code> invokes  before <code>checking tests</code>.  </p>

<p>what I thought I could do was to add a <code>--standalone</code> option to the <code>doRUnit.R</code> suggested in <a href=""""http://wiki.r-project.org/rwiki/doku.php?id=developers:runit"""" rel=""""nofollow noreferrer"""">that R-wiki page</a> so that I could run the unit tests independently of <code>R CMD</code>.</p>

<p>I added these lines to the script:</p>

<pre><code>  opt &lt;- list(standalone=NULL)
  if(require(""""getopt"""", quietly=TRUE)) {
    ## path to unit tests may be given on command line, in which case
    ## we also want to move the cwd to this script
    opt &lt;- getopt(matrix(c('standalone', 's', 0, """"logical""""),
                         ncol=4, byrow=TRUE))
    if(!is.null(opt$standalone)) {
      ## switch the cwd to the dir of this script
      args &lt;- commandArgs()
      script.name &lt;- substring(args[substring(args, 1, 7)==""""--file=""""], 8, 1000)
      if(!is.null(script.name))
        setwd(dirname(script.name))
    }
  }
</code></pre>

<p>with this change, the script finds the <code>test.*\.R</code> files, independently from the directory from which I invoke the script.</p>

<p>the remaining problem now is that the <code>doRUnit.R</code> script loads the <strong>installed</strong> library, it does not <code>source()</code> the files that compose the library.</p>

<p>assuming that I want to load each and every file in the <code>R</code> directory, how would I do that?</p>

<p>assuming you have a better testing schema (satisfying the requirements """"quick"""", """"uninstalled""""), what is it?</p>
",1
"<p>In packages like marray and <a href=""""http://bioinf.wehi.edu.au/limma/"""" rel=""""noreferrer"""">limma</a>, when complex objects are loaded, they contain """"members variables"""" that are accessed using the @ symbol. What does this mean and how does it differ from the $ symbol?</p>
",1
"<p>I'm working on a big Sweave document/script on a Mac OS X system, R version 2.9.2. Under some circumstances, it appears as if Sweave is redirecting stdout, so that <code>x &lt;- 1; print(x)</code> gives nothing at all. (The console is still running, as <code>plot(x)</code> pops up a plot as normal.) So, two questions:</p>

<ol>
<li>How do I force stdout to go back to the console, and,</li>
<li>Why does Sweave do this, and how?</li>
</ol>
",1
"<p>In R (statistical computing environment) I would like on a generic plot, with time on the x-axis, highlight some specific years.</p>

<p>How can I bestly do this? My idea is for example a light yellow bar for the highlighted years, behind the plot of course.</p>

<p>The plot code I have now:</p>

<pre><code>pdf(""""temperature_imfs_big_interm5.pdf"""", width=6, height=8);
par(mfrow=c(temperature$bigEmdIm5$nimf+1,1), mar=c(2,1,2,1))
for(i in 1:temperature$bigEmdIm5$nimf) {
    plot(timeline$big, temperature$bigEmdIm5$imf[,i], type=""""l"""", xlab="""""""", ylab="""""""", ylim=range(temperature$bigEmdIm5$imf[,i]), axes=FALSE, main=paste(i, """"-th IMF"""", sep=""""""""))#; abline(h=0)
  axis.POSIXct(side=1, at=tickpos$big)
}
plot(timeline$big, temperature$bigEmdIm5$residue, xlab="""""""", ylab="""""""", axes=FALSE, main=""""residue"""", type=""""l"""")
axis.POSIXct(side=1, at=tickpos$big)
dev.off();
</code></pre>

<p>Where temperature$bigEmdIm5 is the output of emperical mode decompostion. The data is in months, so I would like to higlight 01/1950 until 12/1950 for example.</p>
",1
"<p>I have a vector of numbers:</p>

<pre><code>numbers &lt;- c(4,23,4,23,5,43,54,56,657,67,67,435,
         453,435,324,34,456,56,567,65,34,435)
</code></pre>

<p>How can I have R count the number of times a value <em>x</em> appears in the vector?</p>
",1
"<p>this seems to be an easy task really, but being completely new to the world of programming, I have problems with the following task:
I have a huge file which has the following format:</p>

<pre><code>track type= wiggle name09
variableStep chrom=chr1
34 5 
36 7 
54 8 
variableStep chrom=chr2 
33 4 
35 2 
78 7 
this is text with the word random in it# this we need to remove
82 4 
88 6 
variableStep chrom=chr3 
78 5 
89 4 
56 7
</code></pre>

<p>now what I would like as an out put is just</p>

<p>one file called 1 
and containing only</p>

<pre><code>34 5
36 7
54 8

a second file called 2

33 4
35 2
78 7
82 4 
88 6

a third file

78 5
89 4
56 7
</code></pre>

<p>It would be great to get some help on this...
If any knows how to do it in R... that would be even better</p>
",1
"<p>I have a data frame with two columns (data will not always be identical). </p>

<pre><code>1 1 
2 2 
3 3 
0 0 
-1 -1 
-2 -2 
-3 -3
</code></pre>

<p>What I would like to do is create another column for the top 10% of the column and the bottom 10% of the column to be used as labels for a scatter plot. </p>

<pre><code>1 1 
2 2 
3 3 1
0 0 
-1 -1  
-2 -2 
-3 -3 2
</code></pre>

<p>In addition, it needs to be able to select and label from either column the top/bottom 10% </p>

<p>Any ideas?</p>
",1
"<p>Here is a question for R-users. I am interested in drawing a histogram with points stacked up, instead of a bar. For example if the data is (1,1,2,1,2,3,3,3,4,4), then I would like to see three points stacked up at 1, 2 points stacked up at 2 and so on. What is the best way to do this in R?</p>
",1
"<p>Is it possible to reposition the labels such that in sector (-x,y) the label is on the left and sector (+x,y) the label is on the right?</p>
",1
"<p>I am trying to output about 250 plots from an r-script and I'm receiving a """"too many open devices"""" error. Is there some setting that I can adjust to avoid this problem?</p>

<p>Here is an example of how I am creating the plots: </p>

<pre><code>for(x in 250) { 

plots &lt;- ggplot(data=dat, aes(x,y,lab=labels))
jpeg(a_paste_function)
print(plots)

} 
</code></pre>

<p>One thing I notice is that when I <code>write.table</code>, the files are ready right away, whereas I always have to close R for the jpegs to be """"printed"""". Perhaps that is the real problem, the method in which I'm dumping the plots?</p>
",1
"<p>I have a time series of data in TSV like so:</p>

<pre><code>ID \t Date \t Value
-------------------------------
1234567 \t 2009-01-01T00:00:00.000Z \t 121
12131 \t 2009-06-01T00:00:00.000Z \t 151
12131 \t 2009-07-01T00:00:00.000Z \t 15153
...
</code></pre>

<p>It easily fits in RAM, but is too big for Excel.</p>

<p>There is one value per month per ID, but not all IDs have entries for all 12 months.</p>

<p>The data spans 12 months, but not all IDs have all 12 months.  I want to go through the data for each ID, and if there is an entry for the previous month, take the current month minus the previous month and store it in a new column to get a delta.  If there is no entry for the previous month, then return 0.  Then, for each month, I want the top 100 positive and negative of those deltas, along with the ID.</p>

<p>I'd like to do this in R, because it's hard in Excel and it keeps crashing.  I have R, Rattle, etc. installed and I've worked through basic examples, but ... the learning curve is steep.  I would really appreciate some help :)</p>
",1
"<p>On one of my PCs, when I build any R package I get the following fatal error</p>

<pre><code>* checking for file 'forecast/DESCRIPTION' ... OK
* preparing 'forecast':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building binary distribution
WARNING: some HTML links may not be found
Error in setwd(owd) : cannot change working directory
 ERROR
* installation failed
</code></pre>

<p>But the same packages compile fine on my other PC. I'm at a loss as to what's causing this. Has anyone else seen something similar?</p>

<p>Using Windows XP, R2.10.1, Rtools 2.10.</p>
",1
"<p>Question:  how can you create a pdf where the output is vertically
justified, with for example, a one inch margin on top using <code>pdf()</code>.</p>

<p>For example in</p>

<pre><code>pdf(file='test.pdf', paper='letter', pagecentre=F)
### code for plot here ###
dev.off()
</code></pre>

<p>is there an option where it generate output that starts from the top of the
page rather than printing from the bottom of the page (which is what happens when <code>pagecentre=F</code>).  Or will this require
some adjustment of settings in <code>par()</code>?</p>
",1
"<p>I'm now reading some books of <strong><a href=""""http://www.r-project.org/"""" rel=""""nofollow noreferrer"""">R</a></strong>, but I want to know if I can use this language as I use Perl or Ruby. Things like:</p>

<ul>
<li>Image Processing</li>
<li>File Compression</li>
<li>Use APIs</li>
<li>Interact With Internet</li>
</ul>

<p>But it's usual and simple(as in Perl or Ruby) to do things like this?</p>

<p>PS: I liked this language very much, because of this I want to use it on my personal projects and spread it for my friends and at the internet.</p>
",1
"<p>I have a data.frame, like this:</p>

<pre><code>nums&lt;-c(5,7,8,9,10,3,2,1)
text&lt;-c(""""a"""",""""b"""",""""c"""",""""d"""",""""a 09"""",""""b 09"""",""""c 09"""",""""d 09"""")
this &lt;- data.frame()
this &lt;- cbind(text,nums)

""""a""""   5 
""""b""""   7
""""c""""   8
""""d""""   9
""""a 09"""" 10
""""b 09"""" 3
""""c 09"""" 2
""""d 09"""" 1
</code></pre>

<p>a:d = data from 2010, a 09:d:09 = data from 2009. 
I'd like it to be sorted first by the numeric column from greatest to least and then by the string column. The only catch is that the string column has to show the 09' data underneath the 2010 data, like this: </p>

<pre><code>""""d""""   9
""""d 09"""" 1
""""c""""   8
""""c 09"""" 2
""""b""""   7
""""b 09"""" 3
""""a""""   5 
""""a 09"""" 10
</code></pre>
",1
"<p>I want to import an XML file from polarpersonaltrainer.com that stores heartrate data into a R data.frame.
Is there a package that makes importing XML easy or do I have to write my own parser?</p>
",1
"<p>I'm learning <strong><a href=""""http://r-project.org"""" rel=""""nofollow noreferrer"""">R</a></strong> and like the language very much because of its flexibility, but I want to know:</p>

<ul>
<li>Are there any ports of <strong><a href=""""http://r-project.org"""" rel=""""nofollow noreferrer"""">R</a></strong> for mobile devices?</li>
<li>Where can I get them?</li>
</ul>
",1
"<p>Is there a faster way in R to turn a list of characters like <code>c(""""12313"""",""""21323"""")</code> into an integer list like <code>c(12313, 21323)</code> other than writing a for loop myself?</p>
",1
"<p>I have multiple lists of measurements. In each list have the timestramp formated as a string (""""2009-12-24 21:00:07.0"""") and I know that each measurement in the list is separated by 5 seconds.
I want to combine all data into a huge data.frame in R. Afterwards I want to be able to easily access the time difference of two measurements so I probably should convert data into something different than characters.</p>

<p>Which format should I use to store the times? Is there some time format in some package that I should use?</p>
",1
"<p>I have come across a number of situations where I want to plot more points than I really ought to be -- the main holdup is that when I share my plots with people or embed them in papers, they occupy too much space.  It's very straightforward to randomly sample rows in a dataframe.</p>

<p>if I want a truly random sample for a point plot, it's easy to say:</p>

<pre><code>ggplot(x,y,data=myDf[sample(1:nrow(myDf),1000),])
</code></pre>

<p>However, I was wondering if there were more effective (ideally canned) ways to specify the number of plot points such that your actual data is accurately reflected in the plot.  So here is an example. 
Suppose I am plotting something like the CCDF of a heavy tailed distribution, e.g.</p>

<pre><code>ccdf &lt;- function(myList,density=FALSE)
{
  # generates the CCDF of a list or vector
  freqs = table(myList)
  X = rev(as.numeric(names(freqs)))
  Y =cumsum(rev(as.list(freqs)));
  data.frame(x=X,count=Y)
}
qplot(x,count,data=ccdf(rlnorm(10000,3,2.4)),log='xy')
</code></pre>

<p>This will produce a plot where the x &amp; y axis become increasingly dense. Here it would be ideal to have fewer samples plotted for large x or y values.</p>

<p>Does anybody have any tips or suggestions for dealing with similar issues?</p>

<p>Thanks,
-e</p>
",1
"<p>Is there a command to easily add a grid onto an R plot?</p>
",1
"<p>I'm wondering if there's any documentation about the efficiency of operations in <code>R</code>, specifically those related to data manipulation. </p>

<p>For example:</p>

<ul>
<li>I imagine it's efficient to add columns to a data frame, because I'm guessing you're just adding an element to a linked list. </li>
<li>I imagine adding rows is slower because vectors are held in arrays at the <code>C level</code> and you have to allocate a new array of length <code>n+1</code> and copy all the elements over.</li>
</ul>

<p>The developers probably don't want to tie themselves to a particular implementation, but it would be nice to have something more solid than guesses to go on.</p>

<p>Also, I know the main <code>R</code> performance hint is to use vectored operations whenever possible as opposed to <code>loops</code>. </p>

<ul>
<li>what about the various flavors of <code>apply</code>? </li>
<li>are those just <code>hidden loops</code>? </li>
<li>what about <code>matrices</code> vs. <code>data frames</code>?</li>
</ul>
",1
"<p>I am a new R user.  I have a time series cross sectional dataset and, although I have found ways to lag time series data in R, I have not found a way to create lagged time-series cross sectional variables so that I can use them in my analysis. </p>
",1
"<p>I am new to R language. I have successfully loaded a query's resultset into a variable. Now I want to access the resultset data by column name and row number. And I need to verify if it is Null (it is shown as &lt; NA > in result) then send a mail by bat file with PHP. My sample code is below.</p>

<pre><code>library(RODBC)
newconn = odbcConnect(""""db"""", uid=""""uid"""", pwd=""""pwd"""") 
new &lt;- sqlQuery(newconn,""""SELECT COL1, COL2 FROM TABLE1;"""", errors = TRUE, 1)
if(new$COL1[3] == """"&lt;NA&gt;""""){
system(""""sendmail.bat"""")
}else{
print (""""failed"""")
}
</code></pre>

<p>Also I would like to compare a string result like below.</p>

<pre><code>if(new$COL2[10] == 'MYSTRING'){
print(""""success"""")
}
</code></pre>

<p>But I think I am using wrong syntax. Please help as I am not able to get the correct syntax for doing these comparisons. </p>
",1
"<p>I was wondering if there is any way to get the foreach package in R to use a pre-allocated structure to put results. basically it involves lots of small linalg operations on very big data sets.</p>

<p>My non-foreach original code is something like</p>

<pre><code>results &lt;- rep(NA,m*l*[big.number])
dim(results) &lt;- c(m,l,[big.number])
for (i in 1:m){
    for (j in 1:l){
        results[i,j,] &lt;- function(j,i,data)
    }
}
</code></pre>

<p>I'd like to use foreach and doMC to parallelize this but test runs are really really slow and I think it's the continual data moving that rbind and c do.</p>
",1
"<p>I have a function that at the moment programmed in a functional model and either want to speed it up and maybe solve the problem more in the spirit of R.
I have a data.frame and want to add a column based on information that's where every entry depends on two rows.
At the moment it looks like the following:</p>

<pre><code>faultFinging &lt;- function(heartData){
    if(heartData$Pulse[[1]] == 0){
        Group &lt;- 0
    }
    else{
        Group &lt;- 1
    }
    for(i in seq(2, length(heartData$Pulse), 1)){
        if(heartData$Pulse[[i-1]] != 0 
            &amp;&amp; heartData$Pulse[[i]] != 0
            &amp;&amp; abs(heartData$Pulse[[i-1]] - heartData$Pulse[[i]])&lt;20){
            Group[[i]] &lt;- 1
        }
        else{
            if(heartData$Pulse[[i-1]] == 0 &amp;&amp; heartData$Pulse[[i]] != 0){
                Group[[i]] &lt;- 1
            }
            else{
                Group[[i]] &lt;- 0
            }
        }
    }
    Pulse&lt;-heartData$Pulse
    Time&lt;-heartData$Time
    return(data.frame(Time,Pulse,Group))
}
</code></pre>
",1
"<p>I'm writing some R code that calls other code that may fail. If it does, I want to print a stack trace (to track down what went wrong), then carry on regardless. However, the traceback() function only provides information about uncaught exceptions. I can get the result I want via a rather complex, natty construction involving tryCatch and dump.frames, but is there not an easier way of doing this?</p>
",1
"<p>I will make a analysis about some information of my company.</p>

<p>I thought making a <strong>ca</strong> to representate the association between two variables. I have 3 variables: Category, Tag, Valoration. My idea is to make 2 analysis, one to view the association between Category - Valorarion and a second analysis between Tag - Valoration.</p>

<p>But I think that this representation is possible with a mca.</p>

<p>What do you recomment me?</p>

<p>Thank You</p>
",1
"<p>I have a dataset that looks like this: </p>

<pre><code>a &lt;- data.frame(rep(1,5),1:5,1:5)
b &lt;- data.frame(rep(2,5),1:5,1:5)
colnames(a) &lt;- c(1,2,3)
colnames(b) &lt;- c(1,2,3)
c &lt;- rbind(a,b)

   1 2 3
1  1 1 1
2  1 2 2
3  1 3 3
4  1 4 4
5  1 5 5
6  2 1 1
7  2 2 2
8  2 3 3
9  2 4 4
10 2 5 5
</code></pre>

<p>but I want it to be restructured to this: </p>

<pre><code>    2_1 2_2 3_1 3_2
   1  1   1   1   1
   2  2   2   2   2 
   3  3   3   3   4
   4  4   4   4   4 
   5  5   5   5   5
</code></pre>
",1
"<p>I am trying to manually calculate the standard error of the constant in an ARIMA model, if it is included. I have referred to Box and Jenkins (1994) text, specially Section 7.2, but my understanding is that the methods mentioned here calculates the variance-covariance matrix for the ARIMA parameters only, not the constant. Tried searching on the Internet, but couldn't find any theory. Software like Minitab, R etc. calculate this, so I was wondering what is the way? Can someone provide any pointer(s) on this topic?
Thanks. </p>
",1
"<p>Is there a standard/common method/formula to calculate the number of months between two dates in R?</p>

<p>I am looking for something that is similar to <a href=""""http://www.mathworks.com/access/helpdesk/help/toolbox/finance/months.html"""" rel=""""noreferrer"""">MathWorks months function</a></p>
",1
"<p>I try this command :</p>

<pre><code>Rscript """"/Users/test/Scripts/arg_test.R"""" """"path_in=/Users/test/GR/web-app/Rproject/Inputs/Rmerge/Description.csv"""" path_in2=""""/Users/test/IdeaProjects/Rproject/Inputs/Rmerge/Template_Auto.csv""""
</code></pre>

<p>but I have this error :
Error in parse(text = args[[i]]) : unexpected '/' in """"path_in=/""""</p>

<p>Part of Rscript :</p>

<pre><code>args=(commandArgs(TRUE))

if(length(args)==0){
    print(""""No arguments supplied."""")
}else{
    for(i in 1:length(args)){
         eval(parse(text=args[[i]]))
    }
}


path_out = """"/Users/test/Rproject/Results/""""

annotation = read.csv(paste(path_in, sep=""""""""))

modules = read.csv(paste(path_in2, sep=""""""""))

merge_output = merge(annotation, modules, by = """"Module"""")
</code></pre>

<p>How can I define path_in as argument(args) ?</p>

<p>Thank you.</p>
",1
"<p>I would like to know what kind of information does an object of class Spatialpolygons has versus an object of class Polygons. </p>
",1
"<p>R question: Looking for the fastest way to NUMERICALLY solve a bunch of arbitrary cubics known to have real coeffs and three real roots. The polyroot function in R is reported to use Jenkins-Traub's algorithm 419 for complex polynomials, but for real polynomials the authors refer to their earlier work. What are the faster options for a real cubic, or more generally for a real polynomial? </p>
",1
"<p>In <a href=""""http://en.wikipedia.org/wiki/R_language"""" rel=""""noreferrer"""">R</a>, how can I import the contents of a multiline text file (containing SQL) to a single string? </p>

<p>The sql.txt file looks like this:</p>

<pre><code>SELECT TOP 100 
 setpoint, 
 tph 
FROM rates
</code></pre>

<p>I need to import that text file into an R string such that it looks like this:</p>

<pre><code>&gt; sqlString
[1] """"SELECT TOP 100 setpoint, tph FROM rates""""
</code></pre>

<p>That's so that I can feed it to the RODBC like this</p>

<pre><code>&gt; library(RODBC)
&gt; myconn&lt;-odbcConnect(""""RPM"""")
&gt; results&lt;-sqlQuery(myconn,sqlString)
</code></pre>

<p>I've tried the readLines command as follows but it doesn't give the string format that RODBC needs.</p>

<pre><code>&gt; filecon&lt;-file(""""sql.txt"""",""""r"""")
&gt; sqlString&lt;-readLines(filecon, warn=FALSE)
&gt; sqlString
[1] """"SELECT TOP 100 """"                              """"\t[Reclaim Setpoint Mean (tph)] as setpoint, """"
[3] """"\t[Reclaim Rate Mean (tph)] as tphmean """"       """"FROM [Dampier_RC1P].[dbo].[Rates]""""           
&gt; 
</code></pre>
",1
"<p>The <code>cast()</code> function is great at calculating margins for aggregate values:</p>

<p><code>cast(df, IDx1+IDx2~IDy1, margins=c('IDx1','IDx2','grand_row'),c(min, mean, max))</code></p>

<p>The problem is that I need to weight my means using a second vector and a custom function. </p>

<p>Of course, <code>ddply()</code> lets me apply custom aggregation functions to my grouped records:</p>

<pre><code>ddply(d, IDx1+IDx2~IDy1 , function(x) 
c(
min(x$value),
MyFancyWeightedHarmonicMeanFunction(x$value,x$weight),
max(x$value)
)
)
</code></pre>

<p>...and this is awesome.</p>

<p>But what would really save the day is the ability to do both things at once, whether by calling the two-vector function in <code>cast()</code> or by faking somehow the <code>margins=()</code> variable in <code>ddply().</code></p>

<p>Is this possible?</p>
",1
"<p>Does anyone have any suggestions for a good way to call R from S-Plus?  Ideally I would like to just pass code to R and get data back without having to write anything too elaborate to integrate them.  </p>

<p>I should add that I'm familiar with the <a href=""""http://www.omegahat.org/RinS/"""" rel=""""nofollow noreferrer"""">RinS</a> package on Omegahat, but I haven't used it.  I was under the impression that Insightful had made an effort to integrate the environments before Tibco took over.</p>

<p><em>Edit:</em> It turns out that RinS doesn't work on Windows.  I found that the easiest solution was to just use Rscript.  I can call this from S-Plus with the <code>system()</code> command.  For example, here's a simple script:</p>

<pre><code>#! Rscript --vanilla --default-packages=utils
args &lt;- commandArgs(TRUE)
print(args)
print(1:100)
Sys.sleep(2)
res &lt;- """"hello world""""
class(res) &lt;- """"try-error""""
if(inherits(res, """"try-error"""")) q(status=1) else q()
</code></pre>

<p>And calling it from S-Plus:</p>

<pre><code>system(""""rscript c://test.rscript 'some text'"""")
</code></pre>

<p>Then I just store the results into a text file and import it into S-Plus after the script is run.  </p>
",1
"<p>I'm looking for a function to dump variables and objects, with human readable explanations of their data types.  For instance, in php <code>var_dump</code> does this.</p>

<pre><code>$foo = array();
$foo[] = 1;
$foo['moo'] = 2;

var_dump($foo);
</code></pre>

<p>Yields:</p>

<pre><code>array(2) {
  [0]=&gt;
  int(1)
  [""""moo""""]=&gt;
  int(2)
}
</code></pre>
",1
"<p>Is it possible to determine - from within the script - whether the script is running in the R-GUI (specifically R.app on OS X) or whether it has been called from Terminal/command line (i.e. <code>R --vanilla -f script.R</code>)? If so, how is this possible?</p>

<p>I'm asking because I have a script that can run parallelized (using the <code>doMC</code> library), which should not be used from the GUI. Sometimes I need to further process the data calculated in the script, so I'd like to call the script from the GUI on these occasions.</p>
",1
"<p>I have asked this question before and received a solution, but my problem is somewhat varied from the original explanation </p>

<p>I have a data frame, like this: </p>

<pre><code>nums&lt;-c(5,7,8,9,10,3,2,1)
text&lt;-c(""""Company a"""",""""Company b"""",""""Company c"""",""""Company d"""",""""Company a 09"""",""""Company b 09"""",""""Company c 09"""",""""Company d 09"""")
this &lt;- data.frame()
this &lt;- cbind(text,nums)
</code></pre>

<p>""""Company a:d"""" = data from 2010, """"Company a 09:d:09"""" = data from 2009. I'd like it to be sorted first by the numeric column from greatest to least and then by the string column. The only catch is that the string column has to show the 09' data underneath the 2010 data, like this: </p>

<pre><code>""""Company d""""   9
""""Company d 09"""" 1
""""Company c""""   8
""""Company c 09"""" 2
""""Company b""""   7
""""Company b 09"""" 3
""""Company a""""   5 
""""Company a 09"""" 10
</code></pre>

<p>There's been a few suggestions from <a href=""""https://stackoverflow.com/questions/1956337/inner-sort-with-r-once-by-numeric-then-by-alpha"""">this question</a>, but I can't replicate it for this, somewhat more complicated example. </p>

<p>I've uploaded some <a href=""""http://www.bertelsen.ca/R/testdata.csv"""" rel=""""nofollow noreferrer"""">test data</a>.</p>
",1
"Explanation
Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27",0
"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)",0
"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.",0
"""""
More
I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of """"""""types of accidents""""""""  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.

There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  """"",0
"You, sir, are my hero. Any chance you remember what page that's on?",0
"""""

Congratulations from me as well, use the tools well.  · talk """"",0
COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK,0
"Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.",0
"Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169",0
alignment on this subject and which are contrary to those of DuLithgow,0
"""""
Fair use rationale for Image:Wonju.jpg

Thanks for uploading Image:Wonju.jpg. I notice the image page specifies that the image is being used under fair use but there is no explanation or rationale as to why its use in Wikipedia articles constitutes fair use. In addition to the boilerplate fair use template, you must also write out on the image description page a specific explanation or rationale for why using this image in each article is consistent with fair use.

Please go to the image description page and edit it to include a fair use rationale.

If you have uploaded other fair use media, consider checking that you have specified the fair use rationale on those pages too. You can find a list of 'image' pages you have edited by clicking on the """"""""my contributions"""""""" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting """"""""Image"""""""" from the dropdown box. Note that any fair use images uploaded after 4 May, 2006, and lacking such an explanation will be deleted one week after they have been uploaded, as described on criteria for speedy deletion. If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • ) 
Unspecified source for Image:Wonju.jpg

Thanks for uploading Image:Wonju.jpg. I noticed that the file's description page currently doesn't specify who created the content, so the copyright status is unclear. If you did not create this file yourself, then you will need to specify the owner of the copyright. If you obtained it from a website, then a link to the website from which it was taken, together with a restatement of that website's terms of use of its content, is usually sufficient information. However, if the copyright holder is different from the website's publisher, then their copyright should also be acknowledged.

As well as adding the source, please add a proper copyright licensing tag if the file doesn't have one already. If you created/took the picture, audio, or video then the  tag can be used to release it under the GFDL. If you believe the media meets the criteria at Wikipedia:Fair use, use a tag such as  or one of the other tags listed at Wikipedia:Image copyright tags#Fair use. See Wikipedia:Image copyright tags for the full list of copyright tags that you can use.

If you have uploaded other files, consider checking that you have specified their source and tagged them, too. You can find a list of files you have uploaded by following [ this link]. Unsourced and untagged images may be deleted one week after they have been tagged, as described on criteria for speedy deletion. If the image is copyrighted under a non-free license (per Wikipedia:Fair use) then the image will be deleted 48 hours after . If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • ) """"",0
"bbq 

be a man and lets discuss it-maybe over the phone?",0
"Hey... what is it..
@ | talk .
What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?

Ask Sityush to clean up his behavior than issue me nonsensical warnings...",0
"Before you start throwing accusations and warnings at me, lets review the edit itself-making ad hominem attacks isn't going to strengthen your argument, it will merely make it look like you are abusing your power as an admin. 
Now, the edit itself is relevant-this is probably the single most talked about event int he news as of late. His absence is notable, since he is the only living ex-president who did not attend. That's certainly more notable than his dedicating an aircracft carrier. 
I intend to revert this edit, in hopes of attracting the attention of an admin that is willing to look at the issue itself, and not throw accusations around quite so liberally. Perhaps, if you achieve a level of civility where you can do this, we can have a rational discussion on the topic and resolve the matter peacefully.",0
"Oh, and the girl above started her arguments with me. She stuck her nose where it doesn't belong. I believe the argument was between me and Yvesnimmo. But like I said, the situation was settled and I apologized. Thanks,",0
"""""

Juelz Santanas Age

In 2002, Juelz Santana was 18 years old, then came February 18th, which makes Juelz turn 19 making songs with The Diplomats. The third neff to be signed to Cam's label under Roc A Fella. In 2003, he was 20 years old coming out with his own singles """"""""Santana's Town"""""""" and """"""""Down"""""""". So yes, he is born in 1983. He really is, how could he be older then Lloyd Banks? And how could he be 22 when his birthday passed? The homie neff is 23 years old. 1983 - 2006 (Juelz death, god forbid if your thinking about that) equals 23. Go to your caculator and stop changing his year of birth. My god.""""",0
"Bye! 

Don't look, come or think of comming back! Tosser.",0
REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski,0
The Mitsurugi point made no sense - why not argue to include Hindi on Ryo Sakazaki's page to include more information?,0
"Don't mean to bother you 

I see that you're writing something regarding removing anything posted here and if you do oh well but if not and you can acctually discuss this with me then even better.

I'd like to ask you to take a closer look at the Premature wrestling deaths catagory and the men listed in it, surely these men belong together in some catagory. Is there anything that you think we can do with the catagory besides delting it?",0
"""""

 Regarding your recent edits 

Once again, please read WP:FILMPLOT before editing any more film articles.  Your edits are simply not good, with entirely too many unnecessary details and very bad writing.  Please stop before you do further damage. -''''''The '45 """"",0
"""""
Good to know. About me, yeah, I'm studying now.(Deepu) """"",0
"""""

 Snowflakes are NOT always symmetrical! 

Under Geometry it is stated that """"""""A snowflake always has six symmetric arms."""""""" This assertion is simply not true! According to Kenneth Libbrecht, """"""""The rather unattractive irregular crystals are by far the most common variety."""""""" http://www.its.caltech.edu/~atomic/snowcrystals/myths/myths.htm#perfection Someone really need to take a look at his site and get FACTS off of it because I still see a decent number of falsities on this page. (forgive me Im new at this and dont want to edit anything)""""",0
"""""

 The Signpost: 24 September 2012 

 Read this Signpost in full
 Single-page
 Unsubscribe
   
""""",0
"""""

Re-considering 1st paragraph edit?
I don't understand the reasons for 's recent edit of this article  not that I'm sure that the data are necessarily """"""""wrong.""""""""  Rather, I'm persuaded that the strategy of introducing academic honors in the first paragraph is an unhelpful approach to this specific subject.  I note that articles about other sitting Justices have been similarly """"""""enhanced;"""""""" and I also believe those changes are no improvement.  

In support of my view that this edit should be reverted, I would invite anyone to re-visit articles written about the following pairs of jurists.
 A1. Benjamin Cardozo
 A2. Learned Hand

 B1. John Marshall Harlan
 B2. John Marshall Harlan II

The question becomes: Would the current version of the Wikipedia article about any one of them  or either pair  be improved by academic credentials in the introductory paragraph?  I think not.

Perhaps it helps to repeat a wry argument Kathleen Sullivan of Stanford Law makes when she suggests that some on the Harvard Law faculty wonder how Antonin Scalia avoided learning what others have managed to grasp about the processes of judging?  I would hope this anecdote gently illustrates the point. 

Less humorous, but an even stronger argument is the one Clarence Thomas makes when he mentions wanting to return his law degree to Yale.

At a minimum, I'm questioning this edit?  It deserves to be reconsidered.   """"",0
"Radial symmetry 

Several now extinct lineages included in the Echinodermata were bilateral such as Homostelea, or even asymmetrical such as Cothurnocystis (Stylophora).

-",0
"There's no need to apologize. A Wikipedia article is made for reconciling knowledge about a subject from different sources, and you've done history studies and not archaeology studies, I guess. I could scan the page, e-mail it to you, and then you could ask someone to translate the page.",0
"Yes, because the mother of the child in the case against Michael Jackson was studied in here motives and reasonings and judged upon her character just as harshly as Wacko Jacko himself.  Don't tell me to ignore it and incriminate myself.  I am going to continue refuting the bullshit that Jayjg keeps throwing at me.   18:01, 16 Jun 2005 (UTC)",0
"""""
Ok. But it will take a bit of work but I can't quite picture it. Do you have an example I can base it on?  the Duck """"",0
"""""== A barnstar for you! ==

  The Real Life Barnstar lets us be the stars
   """"",0
"How could I post before the block expires?  The funny thing is, you think I'm being uncivil!",0
Not sure about a heading of 'Fight for Freedom' what will it contain?,0
"Praise 

looked at this article about 6 months ago -much improved. ]",0
"I was able to post the above list so quickly because I already had it in a text file in my hard drive  I've been meaning to get around to updating the sound list for some time now. 
As far as generating interest  I've spent four years trying to drum up more interest in freely licensed full length classical music. Unfortunately, my attempts failed - I'm still effectively the only one who does it. The classical music wikiproject was not interested, (Wikipedia_talk:WikiProject_Classical_music/Archive_5#Need_help.21Wikipedia_talk:WikiProject_Music/Archive_3#I_could_use_some_helpWikipedia_talk:WikiProject_Music/Archive_2#Raulbot.2C_and_the_music_list) So I really had given up trying to interest others.  
The sound list was featured on digg a while back - http://digg.com/music/Wikipedia_has_free_classical_music_downloads . It got 1600 diggs, which is IMO very impressive.",0
"""""
Well, not """"""""before the process"""""""" but """"""""before how we do things with subpages"""""""" His RfA is listed on NoSeptember's page and you can find it if you look. September 2004 I think. I have my differences with El_C to be sure, but was surprised to see a block, so I left a note. ++: t/c """"",0
"""""

Not at all, you are making a straw man argument here. I never claimed O'Donohue had that position, rather that practitioners and researchers in the field ignored the DSM position, which is exactly what the quote says and also something O'Donohue agrees with. 

Again, I was combating the notion that it was a """"""""absurd part"""""""" to claim that pedophilia is a sexual orientation. Since many researchers hold this position, it would be unfair to call it absurd. The disorder part is divided in the field, some argue that it is not a disorder at all, some do. At the end of the day, it is a value judgment (as Cantor pointed out earlier in the thread), not a scientific judgement. If we choose to make this value judgment in the article, it should be stated clearly and not pretend to have a scientific basis.   """"",0
"""""

 """"""""Mainland Asia"""""""" includes """"""""the lower basin of China's Yangtze River"""""""" as well as """"""""Korea"""""""".  But being specific is fine too.  I just found a citation for a more comprehensive DNA study by Hammer below, rather than our generarizations and speculation so far. 

 Citation for """"""""Yayoi culture was brought to Japan by migrants from Korea, who in turn trace their roots to southeast Asia/south China."""""""" 

 2005 DNA study by Hammer
 Describes the Yayoi migration from Korea based on the O-SRY(465) genes and other genes with close lineage (haplogroups O-M122 and O-M95).
Reiterates that """"""""the entire O haplogroup has been proposed to have a Southeast Asian origin.""""""""  (Their definition of Southeast Asia includes southern China).  Then hypothesizes that """"""""the dispersals of Neolithic farmers from Southeast Asia also brought haplogroup O lineages to Korea and eventually to Japan.""""""""
 In the concluding paragraph, it states """"""""we propose that the Yayoi Y chromosomes descend from prehistoric farmers that had their origins in southeastern Asia, perhaps going back to the origin of agriculture in this region.""""""""
 Hammer's DNA study is based on a """"""""global sample consisted of > 2,500 males from 39 Asian populations, including six populations sampled from across the Japanese archipelago.""""""""
 """"",0
"pretty much everyone from warren county/surrounding regions was born at glens falls hospital. myself included. however, i'm not sure this qualifies anyone as being a glens falls native. rachel ray is, i believe, actually from the town of lake luzerne.  —The preceding unsigned comment was added by 70.100.229.154  04:28:57, August 19, 2007 (UTC)",0
"Hi Explicit, can you block O Fenian for edit-warring on the Giant's Causeway wp. He has made several edits which can only be described as terrorism.",0
"Notability of Rurika Kasuga
A tag has been placed on Rurika Kasuga, requesting that it be speedily deleted from Wikipedia. This has been done because the article seems to be about a person, group of people, band, club, company, or web content, but it does not indicate how or why the subject is notable, that is, why an article about that subject should be included in Wikipedia. Under the criteria for speedy deletion, articles that do not assert notability may be deleted at any time. Please see the guidelines for what is generally accepted as notable, and if you can indicate why the subject of this article is notable, you may contest the tagging. To do this, add  on the top of the page (below the existing db tag) and leave a note on the article's talk page explaining your position. Please do not remove the speedy deletion tag yourself, but don't hesitate to add information to the article that would confirm its subject's notability under the guidelines.

For guidelines on specific types of articles, you may want to check out our criteria for biographies, for web sites, for bands, or for companies. Feel free to leave a note on my talk page if you have any questions about this.",0
"""""
 Sure, but the lead must briefly summarize Armenia's history. I simply added what I found necessary. If anyone thinks this or that sentence is redundant for the lead, they are welcome to remove make edits.  talk  """"",0
"TFD 

I think we just eced. I think we responded to each other without seeing each others responses. I added something in response to yours, but don't know if you saw mine. (T/C//WP:CHICAGO/WP:FOUR)",0
"You are gay or antisemmitian? 

Archangel WHite Tiger

Meow! Greetingshhh!

Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...

1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!

2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!

3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!

Beware of the Dark Side!",0
"FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!",0
"I'm Sorry 

I'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82",0
"I don't believe the Lisak criticism present there conforms with the NPV rule.  Lisak doesn't have a neutral point of view to begin with.  If an offer to polygraph or even concerned review of polygraph results shocks a complainant into thinking her lies have been uncovered, the recantation is still perfectly valid.  If you know you are telling the truth, you will argue with machine or investigator.  Also part of Kanin's research was a followup of the recanted story where possible to verify if any were false recantations.  In all followups the recanted version of events matched what the accused said happened.

Arguing that Lisak is a respected PHD is baseless if Kanin is a respected PHD.  I agree that my edit wasn't as neutral as possible though, so apologize for that.  Still something must be done here.",0
"You had a point, and it's now ammended with appropriate encyclopedic notability/significance.",0
"In other words, you're too lazy to actually point anything out. Until you change that approach, the tag goes.",0
"""""
As for your claims of """"""""stalking"""""""", that is absolute rubbish and serves only to aggravate the situation. I have assumed good faith (and good intentions) on your part, and have never suggested (or seen reason to suggest) that you might have some ulterior motive in mass-adding links to one specific company's web page. Nor, for that matter, have I ever made any suggestion that this is an """"""""administrative"""""""" matter or even mentioned such a role. (Clearly, as a party to this disagreement, I would not do so at any rate as it would be a conflict of interest.) I would ask that you thus extend the same good faith toward me, rather than making spurious and unfounded accusations. ''''''chatspy 

""""",0
"""""::::Jmabel; in regards to predominant scholary consensus who is it that allegedly claims """"""""despite """"""""Third Way"""""""" rhetoric, fascism in power functioned rather consistently as a right-wing force""""""""? As far as I'm aware (owning numerous books on the subject) that is not the scholary consensus at all. The consensus, developed by respected scholars of fascism who write in a manner which is not bias to any interest group such as Roger Griffin, Hamish McDonald, Roger Eatwell and Zeev Sternhell all recongise fascism as a """"""""Third Way"""""""" as the references show.

The only dissenters I'm aware of who seem to think fascism has absoutely no leftist connections and is merely a radical right system are street level socialists who want to put as much distance between the movements as possible. This of course does not come from educated people in a position to write books. For example, even the foremost scholary expert on Fascism, and a former member of both the Communist Party and then Socialist Party of Italy, Renzo De Felice doesn't try to """"""""cover up"""""""" its socialistic origins and third way status. This is a man who has wrote a definitive seven volume piece on Mussolini. -   

""""",0
"""""

BI, you said you wanted to talk

At the bottom of the lead section you have written:

""""""""Its promoter speculated in 1994 that the skyhook concept could be cost competitive with what is realistically thought to be achievable using a space elevator, but the skyhook is not competitive with other rotating tether concepts. In addition, the rotating skyhook is in fact deemed """"""""not engineeringly feasible using presently available materials"""""""".""""""""

Regarding:  In addition, the rotating skyhook is in fact deemed """"""""not engineeringly feasible using presently available materials""""""""

That statement appears to come from Ref [3] on page 10.  The full quote is

""""""""If the mass of the tether alone started to exceed 200 times the mass of the payload,
then that was an indication the particular scenario being considered was not engineeringly
feasible using presently available materials, although the application might become feasible in
the near future as better materials become available with higher tensile strengths at higher
operational temperatures.""""""""

It then goes on to say

""""""""As we shall see, presently available commercial materials will suffice to make the HASTOL
tethers needed. The primary message we want to leave with the Reader is:
“We don't need magic materials like ‘Buckminster-Fuller-carbon-nanotubes’ to make
the space tether facility for a HASTOL system. Existing materials will do.”""""""""

So it would appear that you misread your reference.  The tether mass of 200 times mass of the payload mass is the upper limit to the problem.  Systems where the tether mass is less than 200 times the payload mass can be built with """"""""presently available commercial materials.""""""""

To further reinforce this the Conclusion to the report states

""""""""The fundamental conclusion of the Phase I HASTOL study effort is that the concept is
technically feasible. We have evaluated a number of alternate system configurations that will
allow hypersonic air-breathing vehicle technologies to be combined with orbiting, spinning space
tether technologies to provide a method of moving payloads from the surface of the Earth into
Earth orbit. For more than one HASTOL architecture concept, we have developed a design
solution using existing, or near-term technologies. We expect that a number of the other
HASTOL architecture concepts will prove similarly technically feasible when subjected to
detailed design studies. The systems are completely reusable and have the potential of drastically
reducing the cost of Earth-to-orbit space access.""""""""

Regarding: """"""""but the skyhook is not competitive with other rotating tether concepts."""""""" and 

""""""""A 2000 Boeing report on the possibillity of combining skyhooks with hypersonic planes concluded that """"""""In general, the non-spinning tether HyperSkyhook concept does not look competitive with the spinning tether concepts."""""""".""""""""

The full quote is:

""""""""HyperSkyhook

In 1995 Zubrin proposed the “Hypersonic Skyhook” as a solution to the mismatch between
the attainable atmospheric speeds of a hypersonic airplane and the orbital speeds of space tethers.
Since the orbital speed of the space tether decreases with increasing altitu",0
GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!,0
Are you threatening me for disputing neutrality? I know in your country it's quite common to bully your way through a discussion and push outcomes you want. But this is not Russia.,0
"Thanks! Undeletion was more than I'd hoped for. I'm researching the status of Texas government (including local government) copyright status, but it's slow going. Apparently works of the Florida government are usually public domain, but we don't have a similar article on Texas, so I guess I'll have to research the old-fashioned, non-lazy, actually reliable way. Or ask the copyright help desk, like you suggested. In the meantime, I'm using the fair use rationale, since it's valid while the image is used in an article. Thanks again! -",0
Awesome! Then I'll simply disregard your notice. Thanks!,0
Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!,0
=Tony Sidaway is obviously a fistfuckee. He loves an arm up his ass.,0
"""""

 GA Review II 

I'm sorry to say this, but I have to fail this article's GAN. The several major problems that  brought up in this article's previous GA assessment have not been issued. As s/he has said before me, """"""""he article's WP:LEAD should be longer. The History, Media attention, Academics, Student Government, Demographics, Trivia, and Additional Information section are very deficient in citiations. Also, Triva and Additional information should be integrated into the rest of the article."""""""" Again, please look over WP:WIAGA and fix these problem, then renominate it for GA-class. However, I have re-assessed this article as B-class, as it does meet B-class criteria. My regards,   """"",0
"My Band Page's deletion. You thought I was gone. 

Deleting the comment I posted on your 'talk page' does not delete my feelings for your hasty decision to delete my page. You, sir, are still a cock-sucking douche fuck. Sit back for a second and think about what your life has become. ............ Done? That didn't take long did it? Nope. Because, as I am most certainly aware, your life is a shitstorm of sitting in front of the computer masturbating to fictional creatures. Your attempts to get rid of me are mediocre at best. You are constantly sucking the dick of failure. You don't want a personal attack, huh? Well, too bad, Fuckcock McDickerson. You've got one. From me. You can go ahead and delete my profile from wikipedia. I'll just make another one and come right back to 'Syrthiss's talk page and insult the dick off of you. How could you shatter the dreams of an innocent eighteen year old college freshman trying to make a name for his band. Does that make you happy? Fucking with people because you're an overweight, single, old man in a dead-end job. Did you spot that perhaps someone else was going to follow his dreams and you were trying to hold him back so somebody else could suffer like you? Yes you did. I don't make empty threats, so I won't be saying anything along the lines of 'i'll hurt you' or 'i'll eat the children from within your sister's womb', but I will say that you are a asshole, son-of-a-bitch, mother fucking cock sucker. So, go eat some more food and drown your sorrows you premature ejaculating, bald headed fuck.

You should do something nice for yourself, maybe go grab a couple of Horny Goat Weeds from your local convenience store and jack off for a little longer than three minutes tonight.

Sincerely,
An Asshole That's Better Than You In Every Way.",0
"Why can't you believe how fat Artie is? Did you see him on his recent appearence on the Tonight Show with Jay Leno? He looks absolutely AWFUL! If I had to put money on it, I'd say that Artie Lange is a can't miss candidate for the 2007 Dead pool!   

  
Kindly keep your malicious fingers off of my above comment, . Everytime you remove it, I will repost it!!!",0
"Locking this page would also violate WP:NEWBIES.  Whether you like it or not, conservatives are Wikipedians too.",0
"A Bisexual, like a homosexual or a heterosexual, is not defined by sexual activity. (Much like a 15 year old boy who is attracted to a girl sexually but has never had sex is still straight). A person who is actually sexually attracted/aroused by the same sex as well as the opposite sex is bisexual.",0
REDIRECT Talk:Frank Herbert Mason,0
"""""

""""""""Christian arabs""""""""
Hi. Could you please stop enforcing the category """"""""Christian arabs"""""""" on non arabic Christians living in the middle east? This is wrong. We middle-eastern Christians, though not arabs, have gone through Arabization, and that needs to stop. We are not arabs. We have our own ethnicity, and we shouldn't be forced to be called """"""""Christian arabs"""""""". If a Christian European is born in the middle east, should he be called a """"""""Christian arab"""""""" because of that reason alone? Please understand, they are Syriac Christians (i.e. of Assyrian ancestry), and most of them speak Aramaic, though a lot of them are forgetting it. As someone who speaks Aramaic, you should respect this fact, and not appease muslims who want to call everyone arabs just because they're in the middle east. We are not closely related to the arabs from Saudiarabia. We have our own ethnicity, please stop forcing upon us some alien arab ethnicity. That's oppression. |Talk 12:17 26 Jun, 2007 (UTC)""""",0
"""""

 DH 
Dude, ABC officially says THIS is the name for that episode. I do know there is already an episode with that name, but ABC says it's """"""""Everybody's Says Don't"""""""".   """"",0
"All of my edits are good.  Cunts like you who revert good edits because you're too stupid to understand how to write well , and then revert other edits just because you've decided to bear a playground grudge, are the problem.  Maybe one day you'll realise the damage you did to a noble project.  201.215.187.159",0
"""""
 - NeilN's bang on - You aren't being harassed at all, If you don't edit disruptively  you don't get reverted. –Talk """"",0
"I went there around the same time he did, and that certainly was not the case at the time. Later on they stopped taking children from such a young age.",0
There must be some chemical imbalance in your brains. Are you ok? The gibberish you guys are writing really makes me feel sorry for you. Don't ever go to law school. You would do the legal profession bad.,0
"""""

Parzival418, you are trying to scare ThAtSo. How can you say that the comments of ThAtSo are """"""""insulting""""""""? ThAtSo is trying to suggest that there should be no original research in the Wikipedia. And, he is right. """"",0
"""""

Oppose – As the article stands, it does not properly reference under the WP:REFERENCE guidelines. If this issue is resolved, I don't any issues with it being moved to the mainspace. 「」¤ • ¢  """"",0
"I would appreciate an apology from both of you but I can see that is unlikely.
If not Please don't waste my time any longer with attempts at trying justify either your or Plasma Physics transgressions toward me or bother me any longer about this issue and I SHALL LEAVE YOU ALONE and seek others here who deserve my considerate attention.",0
"They are NOT original research, they are pointed in the episodes.",0
"""""
 Ambiguous ? 
So Mabuska Irish can mean more than one thing ? I will qoute you on that .Thanks .  — Preceding unsigned comment added by 109.77.58.139   
Of course it can. The word """"""""Irish"""""""" wasn't invented on the establishment of the Irish Free State. Talk 

Quote me all you want, it depends on the context of the term when its being used as to whether its applicable or not. Note how i said citizenship and ethnicity - i never mentioned nationality which is the real key meaning. The nationality meaning of the term is the predominantly used form on Wikipedia. In nationality terms it refers to the Republic of Ireland. But you already know that i'm sure.  (talk) 

""""""""In nationality terms it refers to the Republic of Ireland"""""""" no such country . so nationality terms it refers to Ireland .  — Preceding unsigned comment added by 109.76.191.188   

Oh wow, Ireland as in Ireland the state (whose official description is the Republic of Ireland). Whats the point in this inane conversation.  (talk) 

Ireland whose official name is Ireland .  — Preceding unsigned comment added by 109.76.191.188   
http://www.constitution.ie/reports/ConstitutionofIreland.pdf reading for you . Also , I see http://www.constitution.ie/reports/mbunreachtnaheireann.pdf , as you speak both .  — Preceding unsigned comment added by 109.78.224.50   """"",0
"""""
While the magazine's masthead says """"""""TIME"""""""" the corporate name is Time Inc.  You can easily look this up.  On the other hand, ABN AMRO is always the corporate name.  You can look this up as well.   """"",0
Take your belated and piffling prevarications elsewhere. Too late for here.,0
"That's what I'm looking through, it looks like he was just being an all around dick on talk pages though. It's nothing too bad though, looks more like an inability to express himself properly. Thank you for your concern also, Cheers!! -",0
"In the same direction, is it really necessary to name all the US states who recognize it? Why not give just the number of states? This is not an American encyclopedia, but an universal one, I don't see why every single US states which recognize it should be named.  (ix)",0
", 20 December 2006 (UTC)

You must not play Metal Gear Solid 2 that often. GW is the Arsenal Gear A.I. that went haywire after Solid Snake uploaded Emma's virus.  19:32",0
"Hi! I am back again!
Last warning!
Stop undoing my edits or die!",0
"""""

Minimization of textile effluent

A proposed deletion template has been added to the article Minimization of textile effluent, suggesting that it be deleted according to the proposed deletion process. All contributions are appreciated, but this article may not satisfy Wikipedia's criteria for inclusion, and the deletion notice should explain why (see also """"""""What Wikipedia is not"""""""" and Wikipedia's deletion policy).  You may prevent the proposed deletion by removing the  notice, but please explain why you disagree with the proposed deletion in your edit summary or on its talk page. Also, please consider improving the article to address the issues raised. Even though removing the deletion notice will prevent deletion through the proposed deletion process, the article may still be deleted if it matches any of the speedy deletion criteria or it can be sent to Articles for Deletion, where it may be deleted if consensus to delete is reached. If you agree with the deletion of the article, and you are the only person who has made substantial edits to the page, please add  to the top of Minimization of textile effluent.    """"",0
"""""

Is it scientific to attribute an event A, to cause B, where cause B was deliberate designed, with some sort of intelligent intent? Don't answer the questions beyond that
Well, the problem with not answering beyond that is that your example is completely rigged. There are several major fundamental problems here.  

First, you completely fail to mention the fact that the intelligence behind ID is quite literally not of this earth. Natural science might look at a honeycomb, see it is built by bees, and then find an odd looking fossilized honeycomb, and theorize that it was made by odd looking bees. That is fundamentally different than saying it was made by something not of this earth. ID has at its core the notion that something OUTSIDE the system we can observe is at cause here. This is not science in any sense of the word, it is mythology. When Paul Bunyan was having a wrestling match with babe his blue ox, they kicked up so much dirt they created the great lakes. No evidence of paul and his ox remain. i mean, really.  

Second, natural science takes an approach to knowledge that nothing is known scientific law unless it is irrefutable. Theories must have heavy supporting empirical data to back it up. ID turns this on its head and does an end run around knowledge and plays games with """"""""probabilities"""""""". If no one can say how flagella on bacteria could have formed naturally, how in the hell can ID proponents come up with any sort of mathematically accurate PROBABILITY of flagella naturally forming on bacteria? If you don't understand it, you can't do statistics on it. ID jumps right over that hurdle and takes anything that doesn't have a complete, detailed, natural explanation and jams in their own statistics that say """"""""well, it's so improbable for this to happen, that someone MUST have designed it"""""""". This is such a perversion of science. You can assign probabilities to something you don't understand. ID is just making up their numbers.  

Finally, your example has A->B, where B was deliberate design. that's all well and good for a rigged example, except that with respect to life on earth, """"""""B"""""""" is unknown. Your A->B example might qualify as forensic science, if """"""""A"""""""" were a dead body and """"""""B"""""""" were a bullet in the heart. You see a bunch of dead bodies with bullets through the heart, the next time you see a body with a bullet through the  heart, you can probably figure that's what killed him. You don't have that with life on earth. You have ONE scenario, """"""""A"""""""", and you have no other cases to observe or test. So, in that sense, A->B is not scientific if you've never actually observed """"""""B"""""""". (btw, B is teh intelligent designer, which has NEVER been observed). So, in that sense, no, it isn't science.  """"",0
"Screwjob 

   Hey i noticed your comments on the Montreal Screwjob discussion page. I decided since nobody except someone with no account objected to what you said. I would atleast change the page a little to make it fair. I just wanted to tell you because I thought you would like to know. I only changed a few words at the top of the first paragraph and added something to the second one. If your not bothered thats fine but I thought since you were fighting for and nothing was even said, I might aswell tell you.",0
"April 2006
Thank you for experimenting with the page Andy Griffith on Wikipedia. Your test worked, and has been reverted or removed. Please use the sandbox for any other tests you want to do. Take a look at the welcome page if you would like to learn more about contributing to our encyclopedia.",0
"""""

Christ. """"""""IQ is selected for therefore every population has the same IQ."""""""" Never ceases to amaze me.   

""""",0
Can you prove it isn't ? If you had a better knowledge of the English language it would have been obvious to you.,0
"Would you both shut up, you don't run wikipedia, especially a stupid kid.",0
"Oh, it's me vandalising?xD See here. Greetings,",0
"Website 

Hey all,
I was thinking of getting myself a website to display my pictures and this was the cheapest thing I could find. I don't know about others, but Fir and Diliff, you guys have websites, do you think it is legit? Could you provide any better alternatives? Help from any other guild member is also appreciated. Thanks (talk)",0
Thanks reading there now !,0
"Personal attacks in Fruit Brute VfD 

My apologies if I'm being to critical, but I feel that many of the comments made in the Fruit Brute VfD debate were far from reasonable.  There had to be a more diplomatic way to disagree with 's assertion on the initial sentence than don't lie, it makes you look even more juvenile.... Learn to face up to when you've goofed, it will go a long way in your life  The attacks do to his age certainly border on a personal attack.  Were Bart133 forty, sixty, or eighty, would you have included the comment on how 'juvenile' he is?

I don't expect you to apologise to anyone, but I want to make it clear that I consider your comments in this VfD debate inappropriate, and I think their are many members of the community who would agree with me.   talk 06:46, 2005 Feb 7 (UTC)",0
"Transliteration of Russian place names
In writing about Moscow Metro for the Malayalam Wikipedia, we are finding it difficult to correctly transliterate the Russian place names. For example, do we pronounce Park Kultury as PAARK KALTTARI or PAARK KALCHCHARI (or perhaps something completely different)? Can somebody please help by transliterating the list given in https://ml.wikipedia.org/wiki/സംവാദം:മോസ്കോ_മെട്രോ. (I am not putting the list here as I don't want to clutter up this page.) Thanks",0
"""""
Almost got me too; I had to look it up to see if it was real. ...  talk """"",0
How can one defame someone who thinks the Fort Hood Shooting is justified by God's law?,0
"LACK OF BALANCE

This article is seriously out of balance.  It would benefit greatly from the introduction of additional information about the negative aspects of the T-34.  Just for the record, this sort of balance problem is not uncommon when there is an over dependence on the works of a particular author.  For example, testing and evaluation of a T-34 by the US Army Ordnance Dept. exposed some very serious problems with the tank.  This type of information should be included in the article to bring it back into balance.",0
"""""

Thanks. I can see that violating clearly stated Wikipedia policy is no problem with some people, as is now being reviewed elsewhere. Finishing up one other wiki project todsy and then spending the rest of the day on an important personal blog entry.  Then I'll go find other discussions of James Petras' fascinating discussion of the use of the term """"""""Jewish Lobby"""""""" so that I don't have to put back up the deleted Dissident Voice article right away per Talk:Jewish_lobby#WP:V_-_comparing_Jewish_Virtual_Library_and_Dissident_Voice.
Carol Moore  talk""""",0
"""""
Hi
Thanks for our kind words. See you around ) Talk """"",0
"Collusion in poker 

This is regarded as most heinous form of cheating in poker, perhaps some mention of this (or example) is warranted?",0
"Thanks much - however, if it's been resolved, why is it that today, when I didn't write anything in edit summary, CAMERA put its ad in my edit summary box?1equalvoice1 (talk)",0
"You can do all you're doing right now but if you get a username you'll be able to do more and have more impact is what I'm saying. And you seem to be very familiar with everything so you probably have a username? Just get one, it takes 10 seconds.  (talk•contribs)",0
"However, the Moonlite edit noted by golden daph was me (on optus ...)  Wake up wikkis.  So funny",0
"Check the following websites:

http://www.iranchamber.com/personalities/farabi/farabi.php
http://www.islam.org.br/%C2%A0al_farabi.htm
http://www.superbeyin.com/sohbet/sohbet.htm",0
i can't believe no one has already put up this page Dilbert's Desktop Games so I did,0
"""""

Well, after I asked you to provide the diffs within one hour of your next edit here, you made an edit to your talk page here and then did not provide the diffs I requested within one hour of that edit. I then sanctioned you for failing to provide the requested diffs in a timely manner (which, after more than a week, you have still not done). Consequently, your request to lift the sanction is denied.  """"",0
"What page shoudld there be for important characters that DON'T reoccur?
Void, Black Doom, Mephiles, etc",0
A pair of jew-hating weiner nazi schmucks.,0
"I tend to think that when the list is longer than the rest of the article, there's a problem.  Either the history and characteristics should be expanded, of the list should be culled.  I personally like the consensus that was reached in the Tripel article between  and others...myself included.  We decided that the country of origin should be highlighted with the most examples.  There we did Trappist, Abbey, and Foreign.  Foreign includes all non-Belgium examples.  This way the article is an article in an encyclopedia, not a list.  People can find lists anywhere, and the article should reference this.  Also, the style statistics are bad.  When you say style statistics, it sounds like a prescription, not a description.  An encyclopedia should follow the latter, and if the former is used, a citation should follow...And you'll not find a valid one for this style in it's country of origin.",0
"""""

 What's up with this? 
""""""""If you are a religiously or politically motivated to push this or that issue, please refrain from talking on my page. I am not interested. Otherwise, feel free to talk about relevant edits here or science. Deleet (talk) 

I would prefer if the following users never post here:
Maunus ·ʍaunus·snunɐw
WeijiBaikeBianji""""""""

This guy is a published psychology researcher right? Perhaps he doesn't know you have access to libraries and the best sources. You should point that out more often. It doesn't come across as mind-bendingly condescending. Also I suspect that editor is a racist. See you on the wiki. 121.134.219.36  """"",0
"I'm not vandalizing  

I'm just having fun man, you have no sense of humor if you think I'm vandalizing stuff. lemonparty.org=this site now",0
"Welcome to Wikipedia ! [bla] Discover Ekopedia, the practical encyclopedia about alternative life techniques. 

 
[bla] Discover Ekopedia, the practical encyclopedia about alternative life techniques.",0
Including some appropriate mention of the Solomon article is not without some level of support .,0
"""""

Comment. I could not verify the claim.  (talk) """"",0
"""""
 Czech Republic is in Central Europe. The state of this article is part of the reason why people are making such confusions. Especially more ridiculous is that they you would replace the mention of North Caucasus in favor of """"""""north slope of Caucasus Mountains"""""""" which isnt even a geographical area other than denoting the mountains in that region. Countries are located within continents, yet for some reason you refuse to allow this article to be denoted a continent. This single factor alone would have made a massive difference for readers. I'm tired of arguing with people who are essentially wiki-squatters refusing to nudge on a given article. 24.90.230.216  """"",0
"Thanks, Josette. I enjoyed meeting you, too. I was shocked by the decision, which does not begin to reflect consensus. Does just one Grand Poobah make it alone? Serves me right for stealing time from more pressing real-world duties to indulge in a fun hobby. I've learned my lesson and won't waste time like that again. I'll stick to fixing the little things I run across as I read articles for my own information.",0
"Paleontologists agree that organic remains must be buried quickly so they can be preserved long enough to be come fossilized.  However, the term fossilized is not a very precise term.  There are several factors and metamorphic mineral processes which occur to organic remains that result in what is typically called a fossil.  One major factor concerns what kind of organisms are to be fossilized  vertebrate, invertebrates, radiolarians, sponges, plants, pollen, foot prints, etc.  And multiple processes may include permineralization, recrystalization, carbonization, replacement, dissolving, diagenesis, etc.  Talking about fossilization is a complex issue, however quick burial is not questioned.

The major question is, how long does it take for these processes to work on organic reamins in the environment they are found in?  Experimental taphonomy has resulted in an assortment of remains becoming fossilized by various processes in the lab, which of course implies that given the right conditions, vast ages are not an issue.  The metamorphic processes are ongoing until an equilibrium is met between the chemical enviroument of the burial site and the minerals of the organic remains.  Flood catastrophic geologists do not expect that organic remains buried during the flood were completely fossilized within the one year period of the flood, but rather that there has been some 4000 years for the processes to have been working.  Much more work needs to be done on the taphonomy of organic remains.  Yet, how one interprets even those results will depend upon which world view you choose to believe with.",0
Also I think Vegetable Basket needs it's own Wikipedia page.,0
"Bigfoot Reference 

The magazine is better known as just the Engineering and Mining Journal, which you may have a difficult time finding, depending on where you live.  I ran across the article a few years ago while researching something else, and made a copy.  It is clearly derived from press accounts, and treats the incident as a joke.  My whole point in citing it was to show that the incident, whatever it was, was not (entirely) created 40+ years after the fact.  If you leave me your email, I will scan the page and email you a PDF.",0
"Also see this if you cant trust Murkoth Ramunni
http://books.google.com/books?id=HHev0U1GfpEC&pg;=PA51&dq;=Thiyya+matrilineal&hl;=en&sa;=X&ei;=TlpPUd2aH8mWiQLgvIDgBA&ved;=0CDYQ6AEwAQ#v=onepage&q;=Thiyya%20matrilineal&f;=false",0
"""""

 Chart performance of """"""""Single Ladies (Put a Ring on It)"""""""" 

Please take my advice and split up the paragraphs in the section. FAs generally have short paragraphs. It's hard and boring to ingest so much information at once, so splitting the paragraphs will improve the flow. — · [ TALK ]  """"",0
"""""

hahahaha.... good one ......
I have removed it.
 """"",0
"""""

Having said that, I've temporarily removed my requests based on Cyde's advice, pending a """"""""request for consensus"""""""" i've asked for on the talk page. I urge anyone reading this to vote so we all know what the community wants.  """"",0
"Conformity as healthy 

I may have missed it, but this article does not seem to address conformity as just a healthy behaviour. Such as the way that we conform to grammar so that we can be understood, or that we conform to laws because we recognise a need for an orderly society. 194.126.85.214",0
"Hi, I am new to wikipedia. Read up on pandemics today. I am impressed by the quality of information, to my knowledge not easily available elsewhere in the same easily accessible format. Thank you all of you for creating this content and making it accessible.",0
"Should say something about his views as an educationalist and socialist political commentator.

Link to http://www.langandlit.ualberta.ca/Fall2004/SteigelBainbridge.html mentions this a bit - he stood as an election candidate for Respect.",0
"""""==Sandbox==
Don't take the template out of the sandbox. It says """"""""don't remove"""""""" for a reason.  11:36, 10 Jan 2005 (UTC)

""""",0
"heh, it's a bit of a copy of Wikipedia:WikiProject Professional wrestling, but I thought it look a bit tidy and better that way.",0
"Ahh, Hello Witzeman 

203.92.84.161  
Symbols: ~ | ¡ ¿ † ‡ ↔ ↑ ↓ • ¶   # ½ ⅓ ⅔ ¼ ¾ ⅛ ⅜ ⅝ ⅞ ∞   ‘ “ ’ ” «»   ¤ ₳ ฿ ₵ ¢ ₡ ₢ $ ₫ ₯ € ₠ ₣ ƒ ₴ ₭ ₤ ℳ ₥ ₦ № ₧ ₰ £ ៛ ₨ ₪ ৳ ₮ ₩ ¥   ♠ ♣ ♥ ♦   m² m³ 
Characters: Á á Ć ć É é Í í Ĺ ĺ Ń ń Ó ó Ŕ ŕ Ś ś Ú ú Ý ý Ź ź   À à È è Ì ì Ò ò Ù ù   Â â Ĉ ĉ Ê ê Ĝ ĝ Ĥ ĥ Î î Ĵ ĵ Ô ô Ŝ ŝ Û û Ŵ ŵ Ŷ ŷ   Ä ä Ë ë Ï ï Ö ö Ü ü Ÿ ÿ   ß   Ã ã Ẽ ẽ Ĩ ĩ Ñ ñ Õ õ Ũ ũ Ỹ ỹ   Ç ç Ģ ģ Ķ ķ Ļ ļ Ņ ņ Ŗ ŗ Ş ş Ţ ţ   Đ đ   Ů ů   Ǎ ǎ Č č Ď ď Ě ě Ǐ ǐ Ľ ľ Ň ň Ǒ ǒ Ř ř Š š Ť ť Ǔ ǔ Ž ž   Ā ā Ē ē Ī ī Ō ō Ū ū Ȳ ȳ Ǣ ǣ   ǖ ǘ ǚ ǜ Ă ă Ĕ ĕ Ğ ğ Ĭ ĭ Ŏ ŏ Ŭ ŭ   Ċ ċ Ė ė Ġ ġ İ ı Ż ż   Ą ą Ę ę Į į Ǫ ǫ Ų ų   Ḍ ḍ Ḥ ḥ Ḷ ḷ Ḹ ḹ Ṃ ṃ Ṇ ṇ Ṛ ṛ Ṝ ṝ Ṣ ṣ Ṭ ṭ   Ł ł   Ő ő Ű ű   Ŀ ŀ   Ħ ħ   Ð ð Þ þ   Œ œ   Æ æ Ø ø Å å   Ə ə    
Greek: Ά ά Έ έ Ή ή Ί ί Ό ό Ύ ύ Ώ ώ   Α α Β β Γ γ Δ δ   Ε ε Ζ ζ Η η Θ θ   Ι ι Κ κ Λ λ Μ μ   Ν ν Ξ ξ Ο ο Π π   Ρ ρ Σ σ ς Τ τ Υ υ   Φ φ Χ χ Ψ ψ Ω ω    
Cyrillic: А а Б б В в Г г   Ґ ґ Ѓ ѓ Д д Ђ ђ   Е е Ё ё Є є Ж ж   З з Ѕ ѕ И и І і   Ї ї Й й Ј ј К к   Ќ ќ Л л Љ љ М м   Н н Њ њ О о П п   Р р С с Т т Ћ ћ   У у Ў ў Ф ф Х х   Ц ц Ч ч Џ џ Ш ш   Щ щ Ъ ъ Ы ы Ь ь   Э э Ю ю Я я 
IPA: t̪ d̪ ʈ ɖ ɟ ɡ ɢ ʡ ʔ   ɸ ʃ ʒ ɕ ʑ ʂ ʐ ʝ ɣ ʁ ʕ ʜ ʢ ɦ   ɱ ɳ ɲ ŋ ɴ   ʋ ɹ ɻ ɰ   ʙ ʀ ɾ ɽ   ɫ ɬ ɮ ɺ ɭ ʎ ʟ   ɥ ʍ ɧ   ɓ ɗ ʄ ɠ ʛ   ʘ ǀ ǃ ǂ ǁ   ɨ ʉ ɯ   ɪ ʏ ʊ   ɘ ɵ ɤ   ə ɚ   ɛ ɜ ɝ ɞ ʌ ɔ   ɐ ɶ ɑ ɒ   ʰ ʷ ʲ ˠ ˤ ⁿ ˡ   ˈ ˌ ː ˑ ̪   
= My Famous Article ==witze  happiness − wikipedia The Witzeman is a great honour that has been passed down through the generations of many families, regardless of race, age, character or knowledge. The outside world knows little about these elusive characters, and the honour of the Witzeman. For those who have ever been a Witzeman, it has been said to have been a great honour, although the qualities needed for the job have never been disclosed. A person may not now they were a Witzeman for many years, until they are called by former Witzemans via dreams. Associates of the Witzeman are known to be a certain Babe Cool or the much lesser known Witzewoman.

The Present Witzeman is an 11-year-old boy namely Benjamin Woods, who is said to have become a Witzeman after he felt this 'awesome radiance in his top-right bumcheek'. He has not told a great number of people his testimony, but has promised to do so in years to come.

                           History
The present world has only come enlightned with the knowledge of the Witzeman in present years, because former Witzemen have not been so public about the honour, to abide with the formality and conservativism in their time. The term 'Witzeman' is a compound word of the adjective Witze and 'man', witze being an 11th century term for 'a person of extreme humour and radiant intelligence'. Unfortuneatly, Witze is also sometimes associated with bad wind, for unspeakable reasons.

                       Proper History
As early as the 14th century, Witzemen were considered outcasts, and young children were encouraged to poke them with sticks. This led to the 1st Witzeman Rebellion of 1555 when the current Witzeman and his followers attempted a coup to take over the local Council chess team. This rebellion further disgraced the Witzeman, as he and his followers were embarassingly pronounced 'gaga' at a Government meeting that year. The period from here to the early 1900s was a dark time in the Witzemans history. However good times were to come for the Witzeman. Many normal people took part in mass demonstrations and protests for the Witzeman in the 1980s, building up to a great moment in the history...the Great Rebellion of 1988. This was when several Witzeman sprinted round the Visitors Gallery of the House of Commons, wearing clown masks, but otherwise completely naked. This was thought to be an act of circambulation. However many people who witnessed this shocking behaviour, were 'mentally, spiritually, and emotionallly scarred for life'. This group of people included many young children who were forced to go to asylums in a state of mental instability, suffering from trauma. It was at this time that the Government finally took positive action for the Witzeman. In 1990, a bill of rights for the Witzeman was signed, stating all Witzemen were allowed to do as they pleased. Although this was a formal agreement, many journalists viewed it as a letter of submission from the Government to the Witzeman, as the behaviour of the Witzeman and his followers became more and more twisted.",0
"""""

OK: just finished my planned cleanup of the todo page. The entries that were removed were copied to the investigated entries page so we have a record that we looked at them. ——  talk -  """"",0
""""". (On Dec 14, 2006, a NIST scientist said """"""""...the collapse of the towers were not of any magnitude that was seismically significant..."""""""". See Dr Wood's """"""""The Scientific Method Applied to the Thermite Hypothesis"""""""" paper on her tripod site for mp3 links.)""""",0
"The statement drawn from Watchtower literature, honestly, not clandescently, not with hypocrisy, is drawn from Watchtower literature via Ray Franz's arguments and literature, and imposed into the Wikipedia article. It's too much of a coincidence that a more or less follower of Ray Franz is going to come up with a reference to Wa. literature on his own, exactly the same connection Ray Franz makes, without having first seen the connection made in Ray Franz literature.    Natural
  Nature",0
"Sorry about that.  I had checked, but had only come up with Dulas Bay.  Somehow I had missed the Dulas disambiguation page completely.  Apologies again, it's not even as if it was getting particularly late at night!  The onset of swine flu perhaps?",0
"TCM 

I can find no evidence that acupressure is a TCM, rather than derived from TCM. If no one objects I'll place a citation note in the article.",0
"Well, it still needs expansion in areas, citations in others, more images (was going to get a pic of the Stanley Cup banner tonight at the Hitmen game, but forgot my camera) and a thorough review/copy edit by someone with a better flair for words than I, but work progresses.  lute",0
"A redirect somewhere couldn't hurt, though I still don't think any o the candidates are ideal. But then if he passes the notability threshold some day the basic material is still there to work with.",0
"Meivazhi
I've had a go at restarting the Meivazhi article in a style that's more standard for Wikipedia articles. Someone would probably have deleted it pretty quickly if it had stayed in the form you posted. I'd be grateful if you could help at Talk:Meivazhi about the accuracy. 

Unfortunately I had to remove your links. The conflict of interest guidelines advise against editors linking to their own sites, and also Wikipedia's attribution policy WP:ATT requires that information should come from third-party published sources rather than personal websites. Do you know of any good newspaper/book accounts of Meivazhi?  

PS What is the salaimanimudi.indlist.com site? A personal site by a member?",0
"Though this is certainly a small article, but it is not so inconsequential as to warrant subsuming it within the Flame Trees article. 

It is a discography article, and should stand alone.

 22 May 2005",0
"Yeah, let's merge the content. (Not sure if Devil's Canyon is the same type of codename.)",0
"""""

 Image:YourTransitAd.jpg 

I think I may be able to get a better photo of this ad. If I'm able to do that, is it okay if I use it to replace this current one? I want to check with you first before doing anything. -→™/?! """"",0
"""""

 A cookie for you! 

  A cookie for you   """"",0
"LMAO, what a n00b. Go and listen to manele!",0
"06, 29 December 2007 (UTC)
Yep. LOL, the [[Reformist Party (Serbia)|Reformist Party] is having another go (the 20th very last on the parliamentary election, winning less votes than notable to actually be mentioned). ) 
By the way, here's something very little people have figured out - the new Constitution of Serbia has been brought to enable Kosovo' secession. The 1990 Constitution barred that as a possibility, and after the Kumanovo Military-Technical Agreement was signed between NATO and FRY the SRS broke its coalition with SPS and the government collapsed, causing new elections - because that was unconstitutional, as an act of highest treason, enough to be tried from maximum sentence (which the Radicals demanded from then to his death, to have a trial in Serbia, and to be tried for treason among other reasons). This constitution releases the authorities from that weight, and they won't have to go to prison if they recognize any form of further loss of sovereignty in Kosovo. ;)   15",0
"New WikiProject Novels initiative
We have begun a new initiative at the WikiProject Novels: an improvement drive. As a member listed here, you are being notified. Please see Wikipedia talk:WikiProject Novels#5-5-5 Improvement Drive and Wikipedia:WikiProject Novels/Collaboration for more details. Also I would like to remind you to keep an eye on the project talk page at Wikipedia talk:WikiProject Novels. Thanks,",0
"""""

Reply
Are you being facetious? if not, you would have relayed the same message to Jza and MRSC as my words were no more stern than theres. If you would like evidence for any of the claims made on the talk, then I will only be too glad to provide. You also failed to provide diffs in your message to me, in regards to which words you're claiming are offesive, perhaps WP:Assume good faith.

The two users constantly harass and follow me to articles making disruptive edits in violation of numerous Wikipedia guidelines (WP:HARASS is just one). For example the removal of third party references from articles which don't suit their POV, without entering an edit summary (considered by Wikipedia guidelines as bad faith and a violation of WP:BLANK). The violation of WP:NEO by adding derogatory neologisms to the articles of organisations who they do not personally agree with, despite being made aware of the policy, despite not having any reference to the said organisation being described with said neologislm and despite the community majority constantly removing the derogatory term.  The same """"""""tag team"""""""" practise can be shown to be used against numerous other editors who edit articles on British culture and trad counties, not just against me. Again, if you would like evidence just ask.

It would seem however, looking at the messages on your talkpage above, especially the lovely intertude under """"""""UK mediation"""""""" section, that Jza messaged you (somebody he seems very familiar with) in violation of WP:CANVAS. Specifically the section on Wikipedia:CANVAS#Campaigning may interest you. If you're going to be an admin, may I suggest you please make yourself familiar with the policies and guidelines I have referenced in this message. Rather than accusing me, a user who is being cyberstalked, of """"""""personal attacks"""""""". Systematic bias is not acceptable, you're here to make sure that our policies are upheld not to chip in for the sake of a friend. Thanks. -   """"",0
"""""P.S. It's not polite to talk to people behind their backs, please remove your comments from Mrph's talk page.

Vaughan
You're right; I went to check your previous edit and found a page on the Marvel site that spelled it """"""""Vaughn"""""""", but now I am finding many more that spell it correctly. Thanks for the edits.   (☎☓) 

""""",0
"The Block

Hi just wondering if it has been confirmed the Darren Jolly will be a contestant on The Block??

Thanks",0
"""""

 Opinion Please Pt II 

As SRQ continues to make personal remarks after she said she wouldn't,  may I assume you will  help me with a WP:RFC/U?  Also, I believe she has violated the 3RR rule today. Edit warring over one accurate word is ridiculous, as is edit warring in general. Let's make it stop!   May I also ask what was wrong with the honest statement I made on talk page and what you mean by hasty refactoring? I appreciate any assistance and welcome any questions. BTW, when do pivotal, accurate, well referenced entries become """"""""peacock""""""""? My understanding is that it refers to unneceessary editorializing, not to precise vital info in the sequence of events? Thanks!   """"",0
"Azari or Azerbaijani? 

Azari-iranian,azerbaijani-turkic nation.",0
"Userbox
Hello. A userbox you are using (Template:User queerrights) has been moved to user space per WP:GUS. The new link is  and leave any questions you may still have on my talk page. Thank you.",0
"""""

If you actually take the time to do a little bit of research Bloodofox, instead of jumping into what you perceive to be an avenue to pursue your vendetta against me, you'd have realised by now as would your colleague Kiyoweap that in all probability the kelpie==water horse==each uisge, just different terms in used in different places for the same entity. Which is why I challenged Kiyoweap to produce something decent on the each uisge, which I guarantee he'll be unable to do.  Corbett """"",0
"From what I've seen with editors other than Eric, the elephant in the room is the issue of baiting/poking the bear/whatever the hell you want to call passive/aggressive baiting. No one wants to touch that one, even though it's uncivil as hell and appears to be the tactic of choice whenever someone wants to get rid of someone or get their way. That's the part that saddens me. darkness",0
"""""

 Socialistm? 

There are two important features of Smith's concept of the """"""""invisible hand"""""""". First, Smith was not advocating a social policy (that people should act in their own self interest), but rather was describing an observed economic reality (that people do act in their own interest). Second, Smith was not claiming that all self-interest has beneficial effects on the community. He did not argue that self-interest is always good; he merely argued against the view that self-interest is necessarily bad. It is worth noting that, upon his death, Smith left much of his personal wealth to charity.

Good!  Let's all make sure we put forth the idea that Adam Smith was a socialist.  That's the wikipedia way!""""",0
"""""

SORRY PUCK BUT NO ONE EVER SAID DICK WAS NUMBER ONE!! But he is clearly listed as being """"""""second only to Batman"""""""" and a """"""""master detective and martial artist"""""""" and been trained in all the mentioned combat discplines. No need to mention in skills/abilities about the battles he's lost and won because thats not what an encylopia is supposed to do. 

Also, what your problem is your going by low end showings and not HIGH end showings where he's proven more than a match for a meta like Slade and pinned Shiva down in one of his earliest appearences.
 """"",0
The Alpha version had multiplayer. The Beta version did not.,0
"""""
PD: I just have seen that apart from the article Coat of arms of the Sahrawi Arab Democratic Republic, there is also a different article named Coat of arms of Western Sahara. That shows clearly that some users here have politically-driven intentions and bad faith, although they claim to be neutral. If they were neutral, logically they would work on the """"""""Coat of arms of Western Sahara"""""""" article, intead of trying to merge the two articles and messing it.  """"",0
")

We are not treating this as a forum. A question arose and was appropriately answered. End of story. ;-",0
"""""

 Military history WikiProject Newsletter - Issue II 

The April 2006 issue of the project newsletter is now out.  You may read this issue or change the format in which future issues will be delivered to you by following the link.  Thanks.  """"",0
. Between the unblock submission and  response there is less that 3 minutes which proves that this administrator did not pay enough attention to this case,0
"""""

  

Your request to be unblocked has been granted for the following reason(s):
Allowing username change to GianLuigiPalermo . Please put this request in at Wikipedia:Changing username as soon as possible to avoid re-blocking.

Request handled by:  

 Unblocking administrator: Please check for active autoblocks on this user after accepting the unblock request.""""",0
"Once again, I responded to MileMoney's reasoning for his edit and I gave my reasoning for my edit.  Yes, it is absolutely relevant to this page.  There are other places for the discussion on income inequality than in the Progressive Tax article.",0
"""""

UNBLOCK ME OR I'LL GET MY LAWYERS ON TO YOU FOR BLOCKING MY CONSTITUTIONAL RIGHT TO FREE SPEECH""""",0
"""""== Attributing and classifying of personalities == 
Invitation. Your input to Culture of Lithuania is welcomed. 
Some problems of defining personalities or attributing them to certain well-known ideological systems may raise here. I propose a quite liberal variant of it, where definition may not be connected with one certain word. Necessity however to follow certain classifying remains. 

My initial ideas on this branch, the ones, concerning period of Lithuanian national Renaissance period: Some artists, writers or other cultural workers of this period are often described as  modernists. This definition is not false, but some more concrete things should be added, some specifics of Lithuania. 
We should distinguish leading ideas of the Nat. Renaissance from later modernism, which is more known for us. Cultural aspirations of the later Nat. Ren. may be defined as  modernism in a cultural context of Lithuania. But they accented also expression of Lithuanian cultural heritage, and their expression may be seen as something simply typically  Lithuanian. I mean, that such authors in as  Čiurlionis is seen as modernist in Lithuanian context, but it also (and even more) is a representative of Lithuanian culture, when in European or World-wide context. A parallel  example may be taken from literature of India. Poet  Tagore, well known Nobel price winner is known for us as a representative of culture of India. Making India more understandable and closer for western people is concerned as main his input to Western culture. But in his own country, he was seen as a modernist too, who was changing traditional cultural forms, especially stagnated ones. This way also Lithuanian cultural leaders of the N. Ren. could be seen as modernists, which were broadening cultural forms and changing stagnated ones, in Lithuanian context. They also can be seen as modernists in a wider context, but more for acquainting Western people with Lithuanian culture than for their direct input into Western culture. Čiurlionis is the best example here. 
In other way, the later Lithuanian modernists (they depended mostly to later  generation, approximately from 4th decade of the 20th century) concerned themselves part of Western modernistic movement and their main purpose (looking generally) was  to introduce Western European ideas into Lithuanian cultural life (see the table below). 
We see two different movements and two different world outlooks here. The problem is, that both movements collaborated, especially their political wings did, and interchange of ideas between them is well seen. So, many researchers don't pay attention to this difference. Especially in the Soviet period, when national ideas were officially forbidden, mixture in description of these movements was allowed. E. g. philosopher Ramūnas Bytautas, who clearly depends to the first generation, is often described as liberal. And it may be understood in a sense of the second generation (as idea of liberalism).
 

 period and generation  artists, writers, philosophers etc in a context of Lithuania in an European context The National Renaissance period, the younger generation, approx 1905 – 1930  painter and composer  Čiurlionis, painter Kazys Šimonis, poet and philosopher Vilius Storastas - Vydūnas, dramatist Sofija Kymantaitė - Čiurlionienė, poets Adomas Jakštas, Motiejus Gustaitis, Liudas Gira, composer Stasys Šimkus, philosopher Ramūnas Bytautas.  reformers and innovators of Lithuanian culture Representatives of Lithuanian culture, almost unknown before them. The period between WWI and WWII and post-war years.   poets V Mykolaitis - Putinas, Kazys Binkis, writer Ignas Šeinius – Jurkūnas, artists: all 'ars' group,  philosopher Juozas Girnius  Modernists, introducing new Western ideas into Lithuanian cultural life  Central European modernism. 
Note: Lists of personalities isn't complete here, nor it's made precisely by prominence. 
 07:51, 2004 Jul 16 (UTC)

""""",0
"""""

Actually, direct quotes that aren't in quotation marks and aren't attributed are generally known as """"""""plagiarism"""""""" and/or """"""""copyright infringement."""""""" But the NYT material isn't the issue, as you well know. The material from the """"""""Jewish Action Taskforce"""""""" is the problem.  """"",0
"""""
Katelyn Faber
Could you weigh in at the bottom of the Talk Page for Katelyn Faber regarding the inclusion of an image of her?   

 Template:User Totalbox 

Thanks for reverting.  

 Esperanza Newsletter, Issue #1 
{| style=""""""""border-spacing:8px;margin:0px -8px"""""""" width=""""""""100%""""""""
|class=""""""""MainPageBG"""""""" style=""""""""width: 55%; border:1px solid #cef2e0; background-color:#f5fffa; vertical-align:top;color:#000""""""""|
 Reach outReach out is a program aimed at allowing users to bring issues that they have had in Wikipedia to a listening, sympathetic and caring audience:
 """"""""No one can know how we feel if we do not say. We cannot expect to get understanding if we do not ask for it. No one will dispute that sometimes life's issues are too much for one person. It is fair to say that sometimes Wikipedia's problems fall under the same heading. This is a place where you can bring the bruises that can sometimes be got on this project for attention."""""""" Stress AlertsThe Stress alerts program aims at identifying users who are stressed, alerting the community of thier stress and works in tandem with the Stressbusters at trying to identify causes of stress and eliminating them. Note from the editorWelcome to this new format of the Esperanza Newsletter, which came about during the last Advisory Council meeting - we hope you like it! The major changes are that each month, right after the Council meeting, this will be sent out and will include two featured programs and a sum up of the meeting. Also, it will be signed by all of the Advisory Council members, not just . Have an Esperanzial end of March, everyone!
|class=""""""""MainPageBG"""""""" style=""""""""width: 45%; border:1px solid #cedff2; background-color:#f5faff; vertical-align:top""""""""|
{| width=""""""""100%"""""""" cellpadding=""""""""2"""""""" cellspacing=""""""""5"""""""" style=""""""""vertical-align:top; background-color:#f5faff""""""""
! The last AC meeting (full log)
|-
|style=""""""""color:#000""""""""|
 Future meetings are to be held monthly, not fortnightly as before.
 Bans and Access level changes (apart from autovoice) in the IRC channel are to be reported at the new log.
 In the IRC channel, there is going to be only one bot at a time.
 The charter requires members to have 150 edits and 2 weeks editing. Why this is the case will be clarified.
 A new Code of Conduct will be drafted by  and proposed to the Esperanza community.
 The NPA reform idea is to be dropped officially.
 Charter ammendments are to be discussed in future, not voted on.
 The Advisory Council is not going to be proposed to be expanded by the Advisory Council themselves, if others want to propose it, they will listen.
|-
!",0
"Fradulent claim 

I am most certainly not a sockpuppet of TheChief, please retract your fradulent claim at once.",0
That is quick if we only limit the discussion for changing the title but considering the previous discussions for months can have a valid reason for the move.,0
"""""

 123 18:38, July 18, 2005 (UTC)

P.S. Feel free to leave a message on my talk page if you need help with anything or simply wish to say hello. )""""",0
"And, of course, Peiser is more than just a social anthropologist.  He's one whose recent research has focused primarily on the social aspects of climate change and is thus at least as qualified to comment on the state of consensus as a historian.  Regarding his study, it hasn't been published in a peer-reviewed journal, but the results have appeared in many reliable sources.  In effect, it should be treated no differently than as if Peiser himself (or any other scientist) had verbally relayed the conclusions directly to a reporter.  Literally tens of thousands of Wiki articles contain such references direct quotes from scientists, which appear in no other source but through the medium of a reputable reporter.",0
"Hi 

Hi, good day.

My deepest apologies that I had made the change.
I had made the change it was because I was there. On the day.
I was there on the day when they are all line up the most straightest one straight line,
the most biggest, the most brightest and highest star in the sky over my head
when the clock strikes 12 exactly at the noon on that day. (The date which I provided).
It was the most beautiful thing I ever see.
I know many thing need prove but I know what I saw that day. It is up to you now
but it was okay if black and white prove to be needed. I don't have any.
My sincere apologies for the trouble I had cause you.

I am from south east Asia.
I'm a Asia and I came from a very traditional Chinese family.

have a pleasant day",0
"You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.",0
"It looks to me like he is violating WP:NPA, but it's pretty minor. I'll point this out to him, and if you two are having a content conflict then you can try the Mediation Cabal. By the way, it's generally easier to sign with ~~~~ than typing out . Have a stop by in the IRC channel if you want further advice, by the way.  |||  Talk",0
"""""

A pat on the head
KC, you are one of the most dedicated Wikipedians I know and I'm madly in love with you. I'd give you a Barnstar but in the end you'd just chew it up and bury it. Instead, let me offer this metaphorical pat on the head: """"""""That'll do Pup, that'll do.""""""""  see you around   )  Tropics """"",0
Note that the Sandbox is the right place to experment.  Thanks!,0
"friesers opinion is simple i guess. kursk was no turning point, german were on retreat before and after. i think hes correct. russians had more personnel before and after they improved their skill ( glantz ) this in combination forced germans to retreat only. the losses were not the problem, after the battle of kursk the tanks and infantry strenghts were more in favor for germans then before... , some weeks after kursk german tank strenghters were higher than before kursk ( zetterling )",0
"Oh, I didn't know, thanks.",0
"Lois Roisman
Your piece on Lois Roisman omitted much of her background and everything to do with her death. I have updated it. Please review if there's anything you want to add. 67.101.255.166",0
"""""know the sex of the foetus""""""""""""",0
I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms,0
"86.29.244.57|86.29.244.57]] 04:21, 14 May 2007",0
"Sorry, the link you gave me is dead. And I formatted in harvnb, so plz help in that matter.",0
"REPLY ABOVE:
That was me, loser. The UN defines Vietnam to be part of Southeast Asia. And far as I know Vietnam is part of ASEAN, and used to be part of French Indochina with Laos and all those shit countries Anyway your culture has always been more influenced by SEA than Han Chinese (as in proper Yangtze Han Chinese, not the fringe indigenous tribes in Guangzhou/Guangxi). 

Just admit that you vietnamese are all a bunch of wannabe crap people. ALL the east asian people I've spoken to thinks of Vietnam as a very integral part of SEA, and we all think you're backward, dirty and speak in a horrible swearing language. Doesn't matter what crap you spout on Wikipedia, won't change the way people in the real world think.",0
"""""

 29 August 2006 
wow. i understand that the sentance I """"""""added"""""""" was not crucial and really does not change the content. But what is this?! has the community not gotten smaller? was it not caused by the automobile? have I not sourced the statement as asked? is it not a fact? is it not information? does it not help inform people as to why foresters falls is not as large as it seemingly once was? is it not the only peice of information in the article that bridges the span of time between 1870 and present? is the usfullness of the edit the only criteria used to determine if it will be reverted or not? if so it should be noted that I simply re-added the information after it was removed. was not the removal frivilous and unwarranted? what is the problem? why insist on the absence of this statement? it is unjustifiable. it is negligible. I am re adding the information as it is: A)factual, B) sourced, and C) informative. I assume that since there is no reason to remove it again (or in the first place) that you and all other Wiki Nazis will relax. If you are concerned with useless edits please see the edit fom the 26th. I know it was carried out by the great infallable Mindmatrix but imho that was the first useless change. """"",0
"you are a stupid fuck 

and your mother's cunt stinks",0
""""") (ETA: John D. Haynes House. SarekOfVulcan (talk) """"",0
"""""== new ==

{{userbox 
 TABTAB| id =  
 TABTAB| id-c = White 
 TABTAB| info = This user is a faggot. 
 TABTAB| info-c = LightBlue 
 TABTAB| border-c = Black 
 TABTAB| usercategory = LGBT Wikipedians 
 TABTAB| nocat =  
 TABTAB}} 
 TABTAB
 TABTAB- ''This template automatically categorizes the user in LGBT""""",0
", 16 December 2005 (UTC)
Mendel doesn't talk about those changes at all.  Mendel was refering to the Conspiracy section that used to be there.  16:53",0
"""""

 Please do not vandalize pages, as you did with this edit to Budweiser (Anheuser-Busch). If you continue to do so, you will be blocked from editing.  - ✰✰ echo """"",0
"Correct, Dead is dead. There are, however, leves of wounds, hence the emphasis when they are serious. This is not a POV adjective.",0
"""""

I fixed the pic, if anyone still feels that it should move it can be done.  - THE VOICES """"",0
"George W. Bush approval rating graph 

http://upload.wikimedia.org/wikipedia/commons/1/10/George_W_Bush_approval_ratings_with_events.svg

The circle for the September 11th attacks looks too far right. Think you could update it?

Why are the data points post 2005 omitted?",0
"""""

Sorry to interrupt but I'm at 1200 edits now... the first 200 were likely just on my own pages and because I was asking for help so much so maybe just 1000... or maybe less... but it still kind of counts. ♥♥Amulet♥♥ """"",0
"Absolutely, use of that word is strongly misleading, even with '-like'. The structure had nothing to do with mastaba - a burial chamber basicly. Mastaba by definition has entran & ceinner space.
This structure was one solid pile of rocks, with no inner space or entrances.
It was ment as a wall fragment.",0
"I just noticed that the neutrality of this article is disputed (not by me). In light of that, I again ask that my post here, and my invitation to discuss how and whether neutrality can be achieved, not be deleted. It is highly relevant, and relatively urgent (bearing in mind the rule that there are no emergencies on Wikipedia, in time convergence on Truth will be achieved.",0
"""""
, editors don't care about your """"""""explanations"""""""" if they're not accompanied by reliable published sources. I could """"""""explain"""""""" why I thought dogs ate cats but I would get the same reception if I didn't provide sources. Stop edit warring and present sources.  talk to me """"",0
"About Mitch moved to Yggdrasill 

I have no idea & it wasn't me on doing that",0
"Sockpuppets and impersonators 

The two above sockpuppet/impersonator accounts, including",0
"Oh, also wouldn't films that are named Three or some variation thereof be listed on the disambig page and not on here? JUST WONDERING BECAUSE IT MAKES MUCH MORE SENSE TO ME  (I apologize in advance for certain individuals who are too sensitive to hear the truth)",0
"Review Request 

Hi,

I'd like to request KLM for a GA-class review. Can anyone do that? It seems to have many similar stuff to other GA's, such as Kenya Airways and Ethiopian Airlines. Cheers. '''BreaksFixes'''",0
"I don't at all propose that it should be transcribed as [meːn] in this or any other article.  If anything at all, just a brief mention of the raising of TRAP and MOUTH in a pre-nasal environment would suffice.  I just thought it was an American thing to raise  before nasals (I do it myself), but I often hear Aussies do it quite a bit as well, and I don't hear English people do it at all.  The only difference is that Americans have a tendency to diphthongize it as well as raising it.  
I'm not really surprised you don't have a broad accent, being a Wikipedian.  I'm not saying it's not possible.
You're right; I was just kind of thinking aloud.",0
"Homosexuals are intent on legitimizing their behavior. Therefore, they will seize any opportunity to suggest that famous persons are gay. In this way, their way of life will be received as being not only harmless, but perfectly normal. As generations of people grow from childhood to maturity and are exposed to this strategy, they increasingly develop a tolerance for homosexuality. In this way, it is now almost universally accepted as a diverse or alternate behavior or way of being, similar to a religion, race,  or nationality. Lestrade",0
"Al Messier 
This article was a non-notable biography according to the criteria set out in WP:BIO. (aeropagitica)",0
"""""

 Link to Sacramento 

I placed a wikipedia-link in this article where the word """"""""Sacramento"""""""" appears.  Another editor, who appears to be stalking me and is reverting everything that I do, claims that I am """"""""overlinking"""""""" by doing this.  I have read the policy, and think I understand it, and I disagree with him.  The word """"""""Sacramento"""""""" was not linked anywhere else in this article before I made the link, and I think that my link provided good context for a reader who did not know Walnut Creek but thought that maybe they knew Sacramento.  Was there anything wrong with my link?  I would like someone objective to give their opinions. 74.234.45.208  """"",0
"Your blatant POV pushing 

Neither of you guys has made any contribution to this Italian history article other than to shove your unhistorical unconstructive modern POV in my face.
This is a HISTORY article. HISTORY.
Have you heard of that?
This is the reason why so many people get pissed off about the pedantry and idiocy and triviality of Wikipedia.
J*sus. Get a f*cking life.",0
"""""
Reliable sources indicate otherwise. Please do not insert your personal analysis into the article.  (talk) """"",0
"I did research thank you very much, and it is not in the relevance of the article. I think you may have to reseacrh WP:EL to amke sure you realise the facts about why these links are being deleted. I am willing to agree with people that only the official sites should be there, therefore I shall delete the game site and the otehrs now.",0
"""""

A """"""""TotallyDisputed"""""""" notice would probably be appropriate, given the depth of disagreement that exists here, but I cannot understand why highlighting statements identified by some as """"""""dubious"""""""" would constitute """"""""disfiguring the article"""""""".  SlimVirgin has also used that wording recently, but I rather think that inaccurate and irrelevant information is more of a """"""""disfigurement"""""""" than is a template notice.

To answer your second question: my """"""""side"""""""" has brought forward a proposal, and the other side has not yet responded.  This is sadly consistent with recent patterns of delay.  (I'll make no comment on whether or not this is a deliberate strategy.)   """"",0
I've abused NOTHING. Your threats are extremely disrespectful to the rules of Wikipedia. All I have ever done is tried to improve the quality of Wikipedia articles and maintain the standards of quality. I should NOT be treated like a vandal who only registered to muck up articles. My account should not be blocked. I should be an administrator. (  ),0
Give me a permanat block raseac....!!! remember me....!!! Muslims dont you worry for these images they are trying to hurt us but they cant look these images are fake and have nothing to do with Islam or our prophet even their article is so lame wikipedia is not an authentic source its an encyclopedia for the kids which has not authenticity anyone can edit or write whatever they think...just like raeasc you can see he does not knows what Islam is and he talks about it so forget about wiki its lame they have no authenticity...i recommend they should add pissed christ in jessus article....they should...,0
"Invite
 

Hi! I still did not have time to write the articles about the fundamentals of the Romani culture and society (that would have permitted a normal presentation, beyond the stereotypes), I hope in the near future I'll manage to do it. From the last discussion I just managed to organize better Category:Romani people by country and Category:Romani people by occupation and create some more articles about Romani persons.",0
"I asked him a question about recall, maybe that would make you less troubled.  account",0
says no consensus was ever reached as he reverted my edits here:,0
I FIND IT DIFFICULT TO CONTROL MY EMOTIONS and I still feel that Mr Logy Wogy was bad.,0
"Fuck you, block me, you faggot pussy!",0
"Attacking another editor. How? I am trying to make a point about how easy it is to edit Wikipedia and his piece on George Orwell's page proved my point. It is common place for Wikipedians to help each other make better and a lot lesser bias edits and that is all i was trying to do. So if you wouldn't mind, please could you remove that warning.",0
"""""

Please see ref 1, 4 , 5 & 6 of this article, mentioned by Wikipedia for Youngest Patent holder of India. Moreover I mentioned about news & latest book about real life heroes, by providing notable & reliable reference. Do not you feel DNA group is reliable & notable reference as Its page exists on Wikipedia. Do you really believe that, what ever or who so ever provide information for this article is having bad intentions. In your words sock/meatpuppets. Did i asked/suggested anything from you to edit or write. I am a free man to send information & You are a free person to analyse it. Are you above Wikipedia? When ref 1, 4 , 5 & 6 of this article, mentioned by Wikipedia for Youngest Patent holder of India for the subject..Why you speak in bad words...Your words verbatim """"""""Any book or review which repeats the """"""""India's youngest patent holder and the youngest disabled patent holder in the world"""""""" claim that Bhati and his supporters are pushing fails as a reliable source.""""""""  How can you discourage people from sending information, which is relevant, reliable & notable122.161.30.232  """"",0
"""""

 Randroide Answers to """"""""Next Step"""""""" 

Guys, I do not see you taking steps to Wikipedia:Requests for mediation.

I can not do this job because I always connect from """"""""filtered"""""""" institutional net-access, and following those steps could result in new, undesired, controversial """"""""truncation"""""""" of words by the software. I do not want that happenning.

Could you please follow the instructions in the link I provided?. Thank you. 

 Randroide answers to New reference by Burgas00 

  At last we agree on something!...of course that the new section is a good idea: The false """"""""suicidal"""""""" terrorists from PRISA will also be included there. 

Come oooooon, boys, start writing that section. I do not want all the kudos for myself: The new proposed article is, by now, an effort made only by me. 

But remember: NPOV and sources, all the sources. Just like me citing """"""""El País"""""""" in the section about the doubts about the genuineness of the 13th bomb. Cheers  

 

Indeed, a good point. And all the remarks in COPE too. And the """"""""moral certitudes"""""""" of Mariano Rajoy published in El Mundo.

  I agree with you 100%, Larean.

  What Randroide omits to mention on the section about the 13th bomb is that he only added balancing references when I insisted that he do so, the original version he created was entirely POV, as is much of the rest of the proposed article. Also, all the sources that he added from El Pais are only available to subscribers - NPOV it is not. 

  You are right, Southofwatford, in your """"""""Randroide omits..."""""""" section.

If you have not subscription to """"""""El País"""""""", I am sorry but that´s your problem. My """"""""institutional"""""""" access also has some advantages, like paid access to """"""""El País"""""""" (and many, many other publications and books). That´s one of the reasons for my exclusive use of """"""""filtered"""""""" Internet accesss: It´s much easier for me to work here due to the easy availability of sources.

Do you see?. The truncation of words is offsett (I think) by better sources.

BTW, if you write under a """"""""Randroide answers"""""""" section you are:
Invading """"""""my"""""""" space. I do not mind, really. But you are doing it.
Risking new truncations on your messages. To avoid this, please write OUTSIDE """"""""Randroide answers"""""""" sections.

If you think that the proposed article is POV, work in it to make it NPOV. The article is not """"""""mine"""""""".

  I'll take the risk of you truncating the reply and put it here, it's very short. The issue is not whether I subscribe to El País, its whether the people who read an article in the English Wikipedia subscribe to it. All sources used should be accessible to all readers of the article, putting in a source that readers will not be able to see just so you can claim the article is NPOV is, to my mind, completely unreasonable.

  

All sources used should be accessible to all readers of the article

Very funny, Southofwatford. 

I am going to follow this joke of yours.

Please propose also the deletion of all books as sources, because, did you know?, there is always someone without this or that book.
Delete all references to TV or radio stations, because that user in Brazil has no TV and no radio at home.
Delete all the references in spanish, because, did you know?, there are users who know no spanish.

It´s a pleasure to read this kind of funny jokes, really. I had a good laugh.

User:Southofwatford  How strange that you should find it so funny, after all most of the sources we are providing should enable users to find out more information about what is being sourced, so to deliberately choose sources that require those users to pay to see the information is not funny, it's simply bizarre. Equally, in the English Wikipedia I would argue that choosing a Spanish or other foreign language source when an equally valid source exists in English does not make sense, except perhaps to those who are too busy laughing - your cynicism is evident in your response.

 08:3",0
"Hence why I removed it, content of that nature is not suitable for wikipedia (proscribed by WP:NOT) but perhaps for one of its sister projects, such as wikia.",0
"Pirating incident 

I've removed this statenment as it doesn't really relate to the episode much, plus it's kinda off topic.",0
And check this out: http://www.cla.purdue.edu/blackmon/102cs2001/critical.html#bio,0
"Kill all niggers. 

I have hard, that others have said this.. should this be included? That racists sometimes say these.",0
"New User 

Hello Gogo Dodo!

I am a new user on wikipedia and just wanted to ask if my new page could be removed from the deletion list.  My new page is Kaburst and i still have a lot i want to do with it.  I think the reason it was considered is because it starts off like it should be in wiktionary.  but yeah just give me some time to make it better.

Thanks!",0
"Regarding edits made during December 11 2006 (UTC) to José Mourinho
Thank you for experimenting with  Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our encyclopedia. If this is an IP address, and it is shared by multiple users, ignore this warning if you did not make any unconstructive edits.",0
"""""
 December 2011 

Hello, and welcome! Although everyone is welcome to contribute, at least one of your recent edits, such as the one you made to Smoke bomb with this edit, did not appear to be constructive, and has been reverted or removed. Thank you! 1992 """"",0
"""""::: You are wrong. Although I was blocked on some occasions, I was never blocked for Sockpuppetry or Vandalism. It was because of disputes on multiple topics with various socks of user:Hkelkar & user:VandalPetrol, both of which are permabanned. I have never used any other account. If you are permitted to edit then you should get other accounts deleted which says you are indeffed.  No-Blast 

""""",0
i only deleted personal attacks,0
"Please, please, continue.  Tell me what you really think.",0
"""""

 An important message 

Block me. I can live with it.

The mess that's being made of Parker v District of Columbia is why Wikipedia can't rise above the level of a sophisticated Blog.

The """"""""Controversy"""""""" section doesn't belong there in the first place, and the fact that you and other non-experts are issuing """"""""warnings"""""""" indicates Wikipedia has become a sandbox for idiots.

Sorry I can't be more polite, but that's the long and short of it.

 

'""""",0
I'm moving this to the talk page.,0
"""""
Very well. I see that consensus has formed to show that they are indeed not POv but bad judgement on my part. Thanks for the comments anyway.Coldplay Expért Let's talk """"",0
http://www.users.bigpond.com/MONTDALE/page8.html  Heritage from village Κρανιώνας in macedonian Дреновени. Sources claim that the village was pure Slavic.,0
"""""
The organization of sub-topics. Culture is thrown way down towards the end, after economy and tourism, which is inappropriate. The information section is unnecessarily loaded with history and detailed geography, which makes it not only uninteresting, but also repetitive. Information is interspersed all through the sub-sections, without regard to whether or not they fit there. Eg, the Geography section starts with the fact that UP is the 5th largest state. That is not strictly geography, and belongs in the introduction. Climate belongs towards the latter part of the page, perhaps before toursim. Regions and cities is not such an interesting combination. In any case, """"""""Cities of Uttar Pradesh"""""""" can be an interesting topic on its own, because, UP has several interesting cities (and regions) each with specialities of its own (like the copperware of Moradabad, ceramics of Khurja and carpets of Bhadohi). In fact I remember there used to be such information in the article before.(  )""""",0
"I don't know the answer to this, but

Legally, how is it possible for a private citizen to violate another private citizen's civil rights?
I don't know if this is the section Nelson was charged under in the federal case, but if anyone could explain this, I would appreciate it.

You can argue whether or not the outcome of the state murder trial was justified, that's really not my concern here, since it's a dead letter.  I'm concerned about whether the subsequent civil rights prosecution was legal.  If the state murder acquittal was a miscarriage of justice, it's not the first time.  Look at Issei Sagawa.  Part of having a mature understanding of this sort of thing is to realize that the criminal justice system isn't perfect, and that it is inevitable that innocent people will be convicted, and that guilty people will be acquited, from time to time.  That's the price you pay for having a legal system; in the end someone has to make the decision, and sometimes they may not necessarily get it right.  I don't think it's going out on a limb to say that the Sagawa case is completely beyond all reasonable belief.",0
"Burn Deck 

If that'd guy's burn deck is like what I think it is than he is in for a blrude awakening!!! Leviathan motherfucker!!!",0
"Decesed group members 

I've seen a few articles where band members have their name, sollowed by (deceased).  Whats wrong witht that?  It's just a little extra information for people who do not already know this.  Surely this is the main reason such the articles exist in the first place, or even why the whole wikipedia site exists!  What's so bad about adding this word after people's names if they are no longer with us?  It is factual, non-opinionative and does not slate them in anyway.",0
"Fatima bint Asad 
I noticed you added a large chunk to this article recently. Could you post your sources (webpages, books, etc.)? It would be really helpful. Thanks.  23:56, July 29, 2005 (UTC)",0
"""""

I added information about Mayor de Blasio's announced decisions about Charter Schools but someone removed the factual information because they said it was not referenced.  It was factual but not referenced. I tired to add the information again with references but was not successful. 

I correctly added the race and sexuality of Chirlane McCray ONCE but someone (the same person who removed the factual information I provided under Charter Schools) was incredibly rude and stated it was """"""""vandalism"""""""" and reported it.  How can this be and why are these descriptions considered negative?? Who decides what is """"""""reverted?"""""""" On Chirlane McCray's own Wikipedia site the word """"""""black"""""""" (I prefer African American) is mentioned SIX times and her sexuality is mentioned over and over again. These are not assertions at all and can be """"""""referenced"""""""" by an approved Wikipedia site and Chirlane McCray's own important writings.  What is the problem?""""",0
"Please stop adding nonsense to Wikipedia. It is considered vandalism. If you would like to experiment, use the sandbox. Thank you.  2000",0
"Well I will use my user page then, don't tell meyour gonna remove it too, because that will piss me off and drive me nuts. Also I am not making a personal ttack on Jimmy wales, I am saying he is a bit to greedy dont you think? He's got 6 million dollars already and now he's asking for more.",0
"I thought I would offer you some advise aswell:
1)No Wikipedia:Edit warring
2)No arguing with Wikipedia:Administrators
3)May I also remind you of the three-revert-rule",0
u r a tw@ fuck off u gay boy.U r smelly.Fuck ur mum poopie,0
"Its also expressly against guidelines to sneak in disallowed links in the discussion section, as Froman has done with his YouTube propaganda link above, but as evidenced throughout this page, the rules don't seem to be applied to Froman. Why don't you just go whole hog and add it to Feith's main page? There are plenty of unencyclopedic sources there now and no admin seems to have a problem with any link, anonymous, left wing, blogs, whatever you care to use seems to be fair game for Froman. 71.100.167.23",0
"""""==Deletion of Account==

Ok Blueboy, """"""""Editing from L31 G0NG L41 has been disabled by Blueboy96 for the following reason(s):

Came back from 31-hour block and picked it right back up again ... and judging by history, not likely to get it""""""""

for this:

""""""""this is to call attention to a topic which was """"""""resolved"""""""" before any of the matters were addressed.

there are moderators deleting Wikipedia History items, and moderator BorgQueen's edit of """"""""Cuisine of Hawaii"""""""" was simply a provocation and nothing more.

I am a reknowned Chef of Pacific Rim Cuisine, and the Cuisine of Hawaii, and the Cuisine of Hawaii is NOT """"""""local plate lunch"""""""" that is like saying the cuisine of Mexico is Frozen Burritos, or that the Cuisine of Canada is Starbucks pastries, or that the Cuisine of America is McDonald's. Its Slanderous, Vicious, and Spiteful.

the main point here is WHY did the admin in question DELETE THE HISTORY???

and no, it is NOT """"""""Resolved"""""""" until that problem is addressed.

and I TRIED discussing it with that user directly and my account was LOCKED

THAT USER IS NOT OPEN FOR DISCUSSION OR DDEBATE, THAT ADMIN SUFFERS THE GOD-COMPLEX, AND LOVCKED ME FROM EVEN EDITING MY OWN PAGE, HENCE THE REASON I HAD TO WAIT TO BE UNBANNED TO POST HERE, AND I AM NOT LEVING HERE TO BACK AND BECOME CORRUPT-ADMIN FODDER BACK AON THE TOPIC PAGE UNTIL THIUS MATTER IS RESOLVED BETWEEN BORGQUEEN AND MYSELF AS i I WILL NOT SUBJEGATE MYSELF TO ANY FURTHER DISCRIMINATION, HAZING, OR PERSONAL VENDETTAS""""""""

Not likely to """"""""get"""""""" it eh buddy?

listen up, You will delete my User page and account from the wiki, grommet, you are not going to """"""""lock """""""" me and keep my name, content or profile.

I am out of this facade which is Wikipedia for good.

delete it all, NOW. grommet

""""",0
|listas = Sabina of Bavaria,0
"Bad Redirect 
Please remove the redirect from the X-24C page, that aircraft was distinctly different in design, builder, mission, etc, and restore that aircrafts unique content to its page.75.67.80.68",0
"more info 
Thanks for entering this article. There are a few errors, which I have corrected. It would have been nice if you had not simply cut and pasted the text from the Clear Lake article.",0
"His name was Troy Tedford, not Troy Telford. I am looking at his orginal Discharge papers right now. I also have his orginal purple heart with 2 olc. The man was a war hero in the biggest World War ever. I myself am a Historian. History degree recieved Dec of 04 from ATU.",0
It is interesting to note that both aircraft landed at the same airfield in Hawaii.,0
Thanks for fixing that! Again an exquisite picture.,0
", and I would like to clamp down on them",0
", and man has also created new words even after modern languages have already been established",0
"""""
It's in the History, or more conveniently in your own contribs. Thank you for the explanation, but that wasn't a big deal. I was more upset by your second post—waving me off with a sneer about growing a thicker skin and a finger-waggle about """"""""profanity""""""""—treating me as an insensate piece of internet polemic rather than a fellow human attempting to give an honest account of herself. An account which Mackensen promptly removed, as you say. Well, I understand that trying to contribute to the workshop was a bad idea in the first place—running full tilt into Tony Sidaway, after managing to avoid him on IRC for a whole month, to the immeasureable improvement of my quality of life. Anyway. I've always seen you as somebody who stands up for the underdog — I remember praising your addition of this edit to the Harassment guideline—and I was sad to see there was no mutuality of respect.  | talk .""""",0
some type and are on a soap box,0
"""""
Yes they are indeed.  I've replaced that second one with a summary of Women's rights  talk """"",0
". Anyone can do an in-text search for [2] and [3] and see the article does not rely mainly on one source (the publisher). In fact, the grand total of two citations referencing the publisher are for pure-facts issues such as the number of items (149,000) that are in the parts library",0
"Gore response 

Can anybody find Gore's response to Bush's malaprop? Why didn't Gore, as the inventor of the darn thing, club him silly after that one?",0
"Pls give a reply, yes or no.",0
"""""

Neither of the two added cites support the assertion: """"""""Misconception: Hyphens and dashes are the same glyphs"""""""".  It remains unsourced, and as near as I can tell there's only one person making this claim, despite all the claims of """"""""consensus"""""""". Unsourced material gets removed.  That's wiki policy, I've given you a month to find a source or reword the entry so that it reflects what the sources actually say.  I'm restoring the citation needed tag, and if there's no source in a day or so the entry will be removed.    """"",0
"""""*a short summary of referencing essentials
FAQs for organizations
I noticed you've also disclosed an association with Frank151 on your userpage; thanks for that! It makes working with you and knowing where you're coming from a lot easier. If you have any questions about my review of your article, do feel free to leave me a message or send me an email. Cheers. sonia♫ 

""""",0
"For your information, you have already been reported.  Fair-minded?  Talk about yourself and your refusal to allow for relevant information, which is factual, from being posted.  You are obviously the biased party, and an inappropriate representative for Wikipedia.",0
Same for File:SeanKilpatrick2014.jpg and File:ConnorBarwinCincy.png,0
Y r we doing this: Pat,0
"""""
Thanks for the copy-edit, OMG it reads so professional. ) I appreciate it a lot. Yeah, I knew that that would be a problem. Okay, here's the """"""""back story"""""""" to it. Danny had body paint while he was a robot during a sketch. During the after party, in which the theme was a black light one, everybody could see that Danny still had paint on him, as it hadn't washed off or something. To be sure, Jack had a black light switch in his apartment, and when Liz came in, he turned it on, which resulted in Liz having the paint all over her, see here. Or if whatever I just said doesn't make sense, read here and here (about the paint still on Danny and the black light attack).
Yeah, I thought maybe if people saw that, the GA note, they won't leave me a message. Though, that didn't work, as a user left me a message regarding an article I reviewed. This has to work in the future. I'm a have to make it better. I still haven't gotten the chance to see it, but I have to see it. I need to know what happened and stuff. Well, after I got the news that he lost, I started watching his DVD and telling myself that I'll never see his wrestling moves again. I didn't cry, I  was just sad. The night on Raw, I lost it and cried. Whatever, I didn't think that was cool. Shawn didn't mind, but I did. Not really, I still don't see that """"""""face"""""""" like quality to him. I think they'll play Randy out like Triple H, you know, good with the crowd, but still have him """"""""heel-ish"""""""". Maybe cause all the new people are heel and they need some faces... who knows. Speaking of Randy, today's his birthday, turned 30. Well, if you remember, his first """"""""punted"""""""" victim was Shawn, so, nice to see that he did that to Cody... all in the storyline, Nici. ) You are welcome for Danielson and Miz, I guess.  (Hit  """"",0
"""""#if:|==  ==|}}
{| width=""""""""100%"""""""" style=""""""""background:transparent""""""""
{| width=""""""""100%"""""""" style=""""""""background-color:#""""""""
|style=""""""""width: 50%; border:1px solid #; background-color:#; vertical-align:top""""""""|
 Hello, Lceliku, and Welcome to Wikipedia!
Please remember to sign your name on talk pages by clicking  or using four tildes (~~~~); this will automatically produce your username and the date. Also, please do your best to always fill in the edit summary field. Below are some useful links to facilitate your involvement.
Happy editing!   
{| width=""""""""100%"""""""" style=""""""""background-color:#""""""""
|style=""""""""width: 50%; border:0; background-color:#; vertical-align:top""""""""|
 Getting started Introduction
 The five pillars of Wikipedia
 How to edit a page
 Intuitive guide to Wikipedia Finding your way around Table of contents
 Department directory Editing articles How to develop an article
 Manual of Style
|style=""""""""width: 50%; border:0; background-color:#; vertical-align:top""""""""|
{| width=""""""""100%"""""""" cellpadding=""""""""2"""""""" style=""""""""vertical-align:top; background-color:#""""""""
! Getting help
|-
|style=""""""""color:#000""""""""|
 Frequently asked questions
 Cheatsheet
 Where to ask a question
 Help pages
 New contributors' help page
 Article Wizard - a Wizard to help you create articles
|-
!",0
"""""

14.07.09 """"""""I don't know how that got to be but i'm a big supporter of the X-files and i've like seen almost every episode and not once did it mention Mulder being the father of Scull'y baby""""""""

Can't have watched very carefully can you? William being Mulder's son is frequently referenced to in the final episode. Just off the top of my head:

Guard: """"""""What are you thinking about?""""""""
Mulder: """"""""My son. His mother.""""""""

Scully: """"""""Our son, Mulder ...I gave him up. Our son. I was so afraid you could never forgive me.""""""""

Not to mention the meaningful looks that Mulder and Scully give each other when the officiator at the hearing asks, """"""""Agent Scully, isn't it true that you and Mulder were lovers, and you got pregnant and had his love child?""""""""""""",0
Citation Rèf.:Saumur v. The City of Quebec [1953] 2 S.C.R. 299.§ Endorsement:Rosemary deCaires,0
"Education 

PLEASE keep the list of colleges in Pittsburgh a list of colleges IN Pittsburgh.  If you are not familar with the area, don't edit this list.  Greensburg, Washington, McCandless, and California are NOT in Pittsburgh.  Please don't be offended when I enforce this.  Also, a Pittsburgh mailing address does not mean that the school is in Pittsburgh.  The address extends far (in some place a 20 minute ride away).

Thanks,",0
. Until you find the way to put the 25 cites that were in the page back I am throught here.,0
We descendants of Otman Baba trough Mehmed Ali Karakoç are Sunni Muslim's and not Alevis...,0
Could you clarify?  Do you want me to start an RFC?  I don't see that one was listed in the page history of Talk:Rasmussen Reports.,0
Atheism is full of bias shit,0
"""""

 You beat me to it. 

Just wanted to say good work for beating me to the revert on the Ned Kelly article, I always enjoy it when I know someone else is on the hunt for vandals. Happy Hunting. Cheers Pro """"",0
"You removed the link to the same references used in the health study which say that a reduced use of the MMR vaccine is why Waldorf kids have fewer allergies from the section on immunizations?  WTF?  

Would data from the whole of California count for you?  The private and public Waldorf schools in California have 'Personal Belief Exemption' rates of 12% to 88% of their kindergarten classes.  Regardless of what the official position is - and I assert here, but would not do so in the article, that the 'official' position was a lie in order for Waldorf education to not appear like a complete cult - Waldorf students are grossly under vaccinated.  That fact should be in the article.",0
"Thanks for that. I'll take a deep breath and have a go at an intro tomorrow. I identified the source of the phrase London over the border, and showed that the boundary is contested in the footnote. I've clarified the diaspora section, and will justify the statements by reference to the Victoria History articles on West Ham and East Ham. Hopefully, I'll struggle to a justification without substantially changing the outcome of the previous discussions. Then move onto to standardising the references, probably section by section.",0
"German Article of the day

Dear Jimbo, German wikipedia is proud to present the article of the day: http://de.wikipedia.org/wiki/Wikipedia:Hauptseite . Really thrilling, really amazing, worth a glimpse: http://de.wikipedia.org/wiki/Fremdk%C3%B6rper_in_Anus_und_Rektum You might improve your German reading it, there's a lot to learn.

Yours sincerly",0
"I agree, like I aready have stated, that this is peripheral to main article. But nevertheless important because I merely underlienes the mythomania propagated by both sides. My only interest here is historical reality. Dab, why don't you actually analyze the situation rather than offerring your usual smart-alec remarks. Lontech's arguements have been shot to pieces summarily, and everytime this happens, he engages in tangential and irrational behaviour. Commonsense will tell you there was no long-lasting state or kingdom in Dardania before Roman times. We can;t just allow the intro paragraph to read like some KLA recruiting web-site",0
"I found one!  Sort of, anyhow.  The web site for JewsForLife.org isn't loading, but I have an article from them in a Catholic source.  I'm going to remove the erroneous sentence now.
In hindsight, it would have been great if this minor content issue could have been resolved with references in the first place.",0
"""""

I have provided plenty of reference materials yet you have provided none. All writings in Chamar section have comes from sources that are verifiable. Yet you have provided none. You are the one with the ECCENTRIC IDIOLOGY. 
You still have not provided ANY VERIFIABLE sources to show that RAMDASIA and CHAMAR are different.
Chamars that took up weaving are known as RAMDASIA's.
A simple google search on """"""""RAMDASIA CHAMAR"""""""" will provide you with countless links.   bal537""""",0
Block evading IP blocked. Guy (),0
I see that it has a number of  citations on PubMed.,0
Hey why you are spreading misconceptions and trying to spread false information to the people.You not even know who won the battle and who lost.you are the cheapest person on the earth.Bloody ignorant fool.Check sources before spreading rumors,0
"I should add here, for any admin considering that I was blocked for 24 hours by user:Sarek of Vulcan weeks ago, so there is more background if thats relevant, and I should have learned my lesson then.  Pax!  ( talk)",0
"Change of Username (Usurpations request) Request Still In Progress  Mb-m → Mmitra 

Hi, I have requested for Change of Username using Usurpations from Mb-m → Mmitra. It's almost 8 days from the date of request but still it shows In progress, i would like to know how much time does it takes to complete the request and how long would it take to complete. Please reply as soon as possible. Thank You !

Link: Mb-m → Mmitra",0
"2005 (UTC)

  15:59, 17 December",0
"Because otherwise is POV, look at Flemish (linguistics) case.",0
"Yes, mainsprings are used in (some) clocks as well. Please feel free to be bold and help improve the article!",0
"""""::::::::""""""""getting normal"""""""" term is used by a German politician by the way. I got it from there

""""",0
"Keep the original title at Xbox, although you can have additional likes like XBOX and X-box that redirect to this article.",0
"""""

And you are? Let me know when you've crawled out of their arses. '''''' Dick Laurent is dead """"",0
"The problem is that people keep trying to state that BSAs policies are this and that.  There is no policy that says homosexual scouts cannot be members.  To state otherwise is a lie and OR.  Just be it is a contraversy page doesn't allow you state lies or add OR, you can list things as misinterpretations of the rules and things like that but it you try to say scouting does this or scouting does that then you need to be sure scouting actually says that.  Even the misinterpretations of the rules need sources.  Just because an editor might misinterprete the rules doesn't mean anyone in mainstream has.  Can you find a source for somewhere where a homosexual youth was removed from the program just for being a openly homosexual youth?  Then insert it.  Unless you have it or an actual policy from BSA that says you can't be an openly homosexual youth member then what is being added is OR.",0
"""""

Level 1 message
Hello, and thank you for experimenting with  Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may wish to do. I encourage you to also take a look at the welcome page to learn more about contributing to our encyclopedia. Thank you for your interest in Wikipedia.   """"",0
I'm focussing on doing science at the moment (leading the revolution!).,0
"Another question, does this style information stripping occur only whenever a shape itself is edited, or for less intrusive edits, such as moving a shape around? If even highlighting and selecting the shape in Inkscape makes it unusable, then I shouldn't even be messing with Inkscape at all.",0
"Article about Ed Morrissey 

Hi. I've just moved our article about Ed Morrissey and Captain's Quarters to Ed Morrissey, and started bringing it up to date. Would you be able to take a look at it and (please!) fix any defects you spot. Thanks, CWC",0
"I can see that you have been running around several TALK pages accusing me and several others of EDIT WARS. Please go on and prove the same or else you will be the first one to be blocked. Moreover, you cannot prove your POV and when defeated, going around making accusations is a good way out. Communist? -",0
"Yes, I received the confirmation e-mail on 2012-09-11 with username (= my e-mail-address) and password. Uuuh, it was 09/11 ...",0
I am currently blocked from editing so I will be unable to add that tag. however I did take that picture.,0
this user is such a worthless goddamn faggot fuck you faggot,0
"It's an unsourced aesthetic opinion, and therefore violates WP:NOR and/or WP:NPOV.",0
"""""

Image:Popclassic.jpg
I have tagged Image:Popclassic.jpg as , because it does not provide a fair use rationale.  If you believe the image to be acceptable for fair use according to Wikipedia policy, please provide a rationale explaining as much, in accordance with the fair use rationale guideline, on the image description page.  Please also consider using  or one of the other tags listed at Wikipedia:Image copyright tags#Fair_use.  Thank you.   Man """"",0
"Fuck off

You are NOT an administrator. You DON'T have the authority to tell me what to do.",0
"""""
How adorably disingenuous. →  ₪ """"",0
"Well you are ridiculous, in fact I suspect that you are Calton, please block me, I dont care....",0
"""""

 Orangemike 

Time to move on to collateral targets.  I suggest User:FisherQueen, the """"""""girl"""""""" who protected him.""""",0
"Windows Phone upgradeability 

Hi Gregory.  I reverted your change on the Windows phone article.  Neither Microsoft nor its partners have made any official statements on whether devices running Windows Phone 7.5 will be upgradeable to Windows Phone 8.  The references given by another user are blogs that are relying on Hearsay.",0
Btw whatever decision an adminstration wish to take. He should remember that this block is too harsh given that it is his first violation since he joined wikipedia. -,0
"I've tried to be as objective as possible, and treat the author in my head as someone who's first tongue is not English.  I think Davies is borderline notable, but the article is not.  I spent an hour googling Davies earlier today and found nothing except that he has translated a lot of stuff.  Well, I have done a lot of stuff in my life.  I'm even borderline notable in a small field, but nothing to warrant an article on me, especially one that precisley nothing links to like this one.  Frankly I hope the author just makes it notable.  I'll respond to him with gentlemanly politesse, but I can;t help him any further.",0
"""""

 Shiny things 

  What a Brilliant Idea Barnstar For actively seeking every possible way to help other users, especially those I honestly didn't think would work but did, I hereby award  (//c) """"",0
Will you make the change to both engineering articles?,0
"Thanks, and I apologize for my comment.  I'd like you to know that I understand your position.   16:33, 7 Nov 2004 (UTC)",0
"Appearance in historical fiction 

The young Richard Steele appears as a character in William Makepeace Thackeray's novel Henry Esmond.  Is this appropriate to mention in the article, do y'all reckon?",0
"CU and Scibaby 
Why are you wasting time CUing Scibaby accounts which are WP:DUCK ? I am just indef blocking them on sight but the CU request makes reference to some politics which I don't know about?  talk",0
"""""

Per WP:AE, you have been blocked indefinitely for persistent disruption to the project, including vandalism, disruptive editing and sock puppetry, as per Wikipedia:Requests for arbitration/Macedonia#Discretionary sanctions. If you believe this block is unjustified, please request one in the normal manner.   (talk) """"",0
"""""

I'm sure if you worked on articles other than Arcayne you'd do fine. You two seem to have a problem with each other, so why do you seek him out and edit where he does? –xenotalk """"",0
"""""

 Fuck you 

  Fuck you award go fuck yourself   """"",0
"Sorry about the edit conflict; I'm glad you were able to salvage my edits. As to your question about structuring, yes I think we will have to think of a way to divide the article into sections and subsections. Also the intro may need some fleshing out before confronting the reader with technical terms like dendrite and axon. I will look at it. Smithfarm 08:24, 14 Apr 2005 (UTC)

Very cool. Happy to hear you are still on the article. I will also do some research to extend it.  talk) contr 08:27, Apr 14, 2005 (UTC)",0
"February 2014 (UTC)
Comment did the proposal change or something? Someone added requested move banner to this section, when it's clearly not one.  70.50.148.248  17:50, 7",0
"Best Clans in Runescape 

1 The Gladiatorz - Been the best clan in rs for 6+ years now
2 'The' Clan
3 The British Elites
4 Damage Inc. - An average clan.",0
I don't even know where to begin on replying to   Talk,0
"""""

 Please do not vandalize pages, as you did with this edit to Hyperopia. If you continue to do so, you will be blocked from editing.   fisto """"",0
"Keep your eye on it, no one cares, OK? People can put what they want on here, and clean it up all you want but no one cares. God, you're so freakin' stupid!   Omnigan",0
the episode list to keep the episode list above the references.,0
over the next ~30 hours or so,0
"""""

66.185.85.80's rant

Presently, we are witnessing  an open war against Croatian Dinaric culture.  Croatian Left often portrays this culture as """"""""primitive"""""""" and """"""""rural"""""""" (even """"""""fashist"""""""") being  in  service of Conservative HDZ party. Croatian writer Predrag Raos, for instance, """"""""performed"""""""" on gusle instrument in Zagreb on several occasions this year (2004) with only one intention - to ridicule the same instrument and its rich poetic tradition.
 
Another """"""""apostle"""""""" of Croatian Left - Miljenko Jergović - refers to his political opponents on the Right as """"""""gusle players"""""""". 

Some even claim the Serbian origin of Croatian Dinaric culture following the line of traditional greater Serbian propagabda (all štokavian people and their culture are Serbian). However, Croatian Dinaric folklore and its rich gusle heritage is primarly Croatian. Dalmatian costal region has been historically associated with this culture. For example, the first written document about the most popular folk hero of traditional gusle music, Marko Kraljević, is associated with Dalmatian island Hvar through Petar Hektorović's book """"""""Ribanje i ribarsko prigovaranje"""""""", 1568). Also, the first historical document which mentioned gusle player and its instrument originated in  Dubrovnik (1547). Even now, a contemporary Croatian writer (born in Dubrovnik) Stijepo Mijović Kočan tells us a story about his uncle (also from Dubrovnik area) who could memorize numerous gusle songs (Stijepo Mijović Kočan: Gusle, Glasnik, May 25, 1992, p. 42). Dubrovnik is also a home of Anica Begin (born Kalafatović, 1816), a daughter of famous gusle player Ante. Although illiterate, she was able to recite by heart an immense number of gusle songs, some of which were recorded in antology of Croatian folk poetry. 
 
Not far from Dubrovnik, another coastal city - Makarska – was  also a bastion of Croatian gusle music. Actually, this region could be considered the Capital of all Croatian gusle players. This Mediterranean area  also gave birth to  Andrija Kačić Miošić (18th century Catholic priest), who is  viewed as the father of all gusle players of Croatia and beyond. To honour Kačić's work, Ivan Meštrović, the most famous Croatian sculptor, built a sculpture in America showing Kačić in his priestly clothes  playing gusle instrument.  

In addition to Kačić, Makarska Littoral produced a great many other followers of Croatian gusle music. According to dr. fra Karlo Jurišić (who quotes the work of Croatian folklorist Stipan Banović), Zaostrog alone  produced a great number of gusle players starting with Stipan Kosović-Kudrić (1771-1818) and culminating with the most known Mate Banović – Trliš (1844-1915).  As for Dalmatian women, they didn't play gusle (it's    considered   a male activity only), yet they were actively involved in spreading  gusle music  by  imitating its sound. 

Olinko Delorko, the researcher of  Dalmatian  folk poetry in the 1960s, states in his book Ljuba Ivanova (1969) that most of his Dalmatian folk poetry collection was obtained by  women, especially the ones from the island of Hvar. 

The Zadar Littoral also witnessed strong gusle tradition. English writer Maude M. Holbach, travelling through Zadar region in the first decade of 20th century  states in her book  """"""""Dalmatia: The Land Where East Meets West"""""""" that the gusle was the national instrument of the region. As for Dinaric dances, which took place at markets and certain festivals, they  are very picturesque and interesting, and worth going a long way to see, being a survival of ancient custom probably unique in Europe (p.54)

This admiration for Dinaric folk music, particularly gusle, was seen in both Dalmatian Litteral and  Hinterland.  Matija Murko, the researcher of this literary/music forms,  had reported   that during his trips  through Dalmatia in the 1930s, he saw a child, barely three years old playing gusle (Eduard Osredečki: “Hrvatske narodne junačke pjesme”, Željezno-Beč, p. 9)

Now, lets  take a look at  the names of some Dalmatian sports clubs and organizations: Hajduk, Junak, Gusar, Alkar, Uskok, sinjska alka, etc. What do they have in common? Of course, their names refer to the heroic gusle tradition of the region. 

Having this in mind, one wonders why this proud Croatian heritage has become almost  extinct.  Why do we have so few gusle players today ? Is it a  result of  unavoidable urbanization  of  modern Croatian society where peasant culture is being considered  inferior to global  rock 'n' roll  culture ? If so, why has tamburitza music of Northern Croatia  gained wide acceptance from the Croatian establishment while its  Dinaric counterpart (gusle music) is looked upon with suspicion and  open hatre",0
The total population(10 millions) does not match with the e sum of the referenced populationsbelow in the infoboxImages in Infobox,0
to a convicted felon,0
MATT HARDY IS SO FUCKY!!!''Italic text[[Media:Example.ogg]]'''''MATT HARDY IS SO FUCKY!!!,0
"lol censorship. You're really disappointed that NPOV is a core policy, aren't you?  (talk ⋅ contribs)",0
"MfD nomination of Wikipedia:Try your best
Wikipedia:Try your best, a page you substantially contributed to, has been nominated for deletion. Your opinions on the matter are welcome; please participate in the discussion by adding your comments at Wikipedia:Miscellany for deletion/Wikipedia:Try your best  and please be sure to sign your comments with four tildes (~~~~).  You are free to edit the content of Wikipedia:Try your best during the discussion but should not remove the miscellany for deletion template from the top of the page; such a removal will not end the deletion discussion.  Thank you. '''' contributions talk",0
REDIRECT Talk:List of South Carolina Stingrays seasons,0
"who cares? if i was blocked on myspace or pulse music board, then i would be more concerned.",0
http://www.theatlantic.com/entertainment/archive/2012/02/linsanity-how-the-internet-made-jeremy-lin-a-star-in-less-than-a-week/252755/ Source explaining why he is a star. 198.151.130.68,0
"God is dead
I don't mean to startle anyone but God is dead. We should not worry about him anymore. Just thought I would let everyone know. Well, goodbye and good luck with your newfound crisis of faith! 24.77.205.229",0
"Hello 

I am back.

Bongwarrior's user page will be attacked in 1 minute.",0
"""""
 I'm always on the """"""""Requests for page protection"""""""" if I detect any missing/errant templates to see if the administrators can correct them.   """"",0
Unsure at this stage its not very clear what wording is actually being discussed.,0
"""""

 Marvin Kitman's """"""""Don't Make Me Laugh"""""""" doesn't appear to exist 

The citation for much of the early history of the laugh track appears not to exist. The publication, """"""""Channels of Communication,"""""""" doesn't exist in the three journal databases I've searched.""""",0
"Have you seen the reference to their claim, you moron''?? This is not a source. It´s their POV. Once I have more time I will reduce your Pashtun nationalist POVs here on Wiki and give order to my uncles and cousins the execution of Pashtuns in the entire northern Afghanistan down to Gardez, Jalalabad, Lashkargah, Logar, Paghman, Laghman, Kunduz, Herat, Farah ... whereever immigrant descandants of violent Kuchis settled and took non-Pashtun lands away and traditional Tajik countries. 84.59.190.210",0
"""""

 RfA question 
Simply curious, what is the question you intended to submit here?  talk """"",0
"When you say irrigiation structure, what exactly do you mean? I live on an irrigated block which uses overhead sprinkers, and I'm not far from the nearest channel. Thye all look the same throughout Sunraysia. I've got a little spare time now to grab some more shots, though I don't think I'll get out as far as Dareton. Got any requests?  \talk",0
THIS WIIL BE MY LAST USE OF THIS ACOUNT PLEASE DELETE IT==,0
"3RR Violation by PatrickFlaherty 
User user:PatrickFlaherty is reverting a sourced post. He is also violating the 3RR for Raila_Odinga",0
"""""

== I wasnt really attacking him/her regarding the Lisa Williams article (Hmpzzz!) Do you know if Lisa can see dead people too? I have psychic powers too you know, i can see the future! Send all these """"""""Lisa Williams"""""""" to Finland and they will all be locked in jails for being scam artists!""""",0
"Yes, there is definite value in documenting the Scientific Instrument Module, but I don't believe it belongs with the Service module sectors subsection.  It is really a payload and not actually part of the spacecraft services, so it interrupts the flow.  I plan to move it to the Apollo Program, Mission types section where I think it really belongs, when I edit the sectors subsection to improve the wording flow a bit.",0
"Thank you 
Hei, it's me, the William Hope fan. Guess what - I am back at a new IP, ready to vandalize everything regarding William Hope, and you can't do sh-t to stop me, maybe delay me, but no stopping me. So lets salute to some more William Hope lunacy by shoving his p-nis in my mouth.",0
"""""
Yes. Quite persistent. I'm about to just create the article myself... Other new users are going to get lost in this discussion!  T/C """"",0
"Fuck you 

-User:The Bohemian Shinobis yeah, that's right, bitch! You are all pieces of shit!",0
"""""
Yes, it looks much better than before. At the top of the page, it says """"""""This article needs additional citations for verification"""""""", may be britannica encyclopedia could help adding citations... I dunno. Cheers,   """"",0
"Okay, I'll give it another whirl via email.  If worst comes to worst, i.e. if I do not get a reply soon, than I can always just use new accounts if I am ignored and that way it will just keep those who have been stalking me tied down/busy chasing me around rather than trying to delete content.  Take care!",0
"North Eastern Region of Jharkhand  

Wiki says North Eastern Region of Jharkhand is Angika region.  However, official language of theses districts of Jharkhand is not Angika but Hindi, Santali.  This is confusing.  So, it needs some clarification as to how come district of Jharkhand where the official language is Hindi, Santali could be Angika region.  Only those districts would be in Angika region where official language is Angika. 

````",0
"""""
The vote was on the Campbell Case but the primary reason was the Russian Treaties:

""""""""Baldwin was careful to emphasise that the Treaties were the substance of his objections. Standfordham wrote to the King, on 7 October, 'I saw Mr Baldwin who, in reply to my question """"""""Do you want to turn the Government out?"""""""" said """"""""Yes, but not on the Campbell issue, but on the Russian Treaties which the country generally condemns."""""""" He sees no alternative to a dissolution; it has always been expected, some wished for it before now, though he is opposed to hastening the Government's fall. ...' ... And it is true that only in the House of Commons were Baldwin's strictures based on the Campbell case – at Newcastle on 2 October he congratulated MacDonald on the agreement, achieved at a conference in London, on the Dawes Plan for reparations, and then spent the rest of the speech alternately pouring scorn on the Labour party's subservience to its extremists, and tearing to pieces the Russian agreement. But the final debate on 8 October was a mean Parliamentary occasion. Two days before, in a meeting which was something of a suave qui puet, the Cabinet decided to take it as a vote of confidence, preferring to go out on the Campbell case to a defeat on the Russian Treaties which might give the left wing too much prominence.—Middlemas and Barnes, p. 273.  """"",0
"Jayjg, stop the Spin (public relations) tactics.",0
"""""
No, I just quoted Bryant that talks about popular and secondary creator.  They are literally in the same paragraph.Talk """"",0
"Future Perfect at Sunrise|☼]] 14:59, 16",0
"""""
In general, the outside sourcing should exceed the inside sourcing. If there's an entire section without any references, you don't have enough. The lede refers to a """"""""dire need""""""""  this would generally be seen as over-the-top. Look at the APO article for ideas on how to speak about your group.   """"",0
"That's a rather feeble premise to argue showing an excessive number of photos prominently showing 24 different women's vaginas, compared to one human male penis 3/4 of the way down the page on the equivalent article for male genitalia. This demonstrates the overwhelming male bias in editorial content on Wikipedia. 86.13.182.103",0
"""""

OKAY, I have now tried to just delete the offensive sentences in the beginning about Mr. Irving being a socalled 'holocaust denier'. He says himself he is not, and acknowledges that many jews were killed during the war, however he does not go along with the 6 million jews killed-figure, as he reckons the number to be lower. And it really comes down to that: """""""" David has the right to question anything relating to history and WW2 is his speciality, and he actually makes a living of questioning and critically examining sources.

I also decided to delete the account about him loosing a court case in 2000. David have launched several libel cases before - in 1996 he won 45000 £ libel-damage against an English Sunday Newspaper. The fact that he this time lost is not something that should figure at the head of his CV. Many people also find it extraordinary that a judge can deside what a person IS or is not, and what beliefs he holds.""""",0
There I've made him bold. Thats better. Lemmey  talk,0
".

After that my father started taken Melfalan.Now it is nearly 1 and half year and his health condition is not good.I am consulting with the Doctors",0
"I'm pretty sure the incident has already been included. And I know how to handle my own at riots, too. 8)",0
I'm afraid that's a broken link for me. -,0
Ok. Maybe you want to comment on the Talk page about that. It's interestig to know.,0
"""""
Oppose I find it hard to believe this requires an RFC, but such is the wikiworld... 連絡 見学/迷惑 """"",0
"History? ==

Can someone provide some information regarding the contracting of the AC service area? AC Transit used to serve most of the cities of the 680 corridor, but the cities basically kicked out AC Transit and now run their own services. Part of the reason was that AC Transit was under-serving the suburbs, while spending their money on underutilized services in the urban areas.  That history should be reflected in this article. '''''' (talk) 

==",0
"""""Please do not create any more elephant nonsense pages.  talk """"",0
""""" , I and   —Preceding undated comment added  

 , I and  (talk ⋅ contribs) We do not care that WIKINEWS even considers Dr. Rafizadeh as an expert and interviewed hin here: https://en.wikinews.org/wiki/Wikinews_interviews_Scott_Lucas,_Eyal_Zisser,_Majid_Rafizadeh_about_risks_of_US_military_intervention_in_Syria

We """"""""simply, do not care. We do not care even if he publishes on CNN or NYT or quoted on CNN and New York Times like here 

http://www.cnn.com/2013/06/16/opinion/iran-rouhani-syria-rafizadeh/index.html
http://globalpublicsquare.blogs.cnn.com/2012/08/07/jobs-key-to-middle-easts-revolutionary-wave/
http://edition.cnn.com/2013/05/08/world/meast/syria-shiites

Does not matter even if BBC World service made bio of him here: http://www.bbc.co.uk/programmes/p01gsjfk

Dos not matter if CNN and France International wrote about him and his family members being killed here  

http://www.france24.com/en/20120831-syria-majid-rafizadeh-kidnap-family-targetted-civil-war-shabiha-opposition-bashar-assad

I and  (talk ⋅ contribs) will never change our opinion.  (talk is always right. 

We also dont care that he published in almost all national and international outlets including scholarly and academic works like here  https://scholar.google.com/scholar?hl=en&q;=majid+rafizadeh+&btnG;=&as;_sdt=1%2C29&as;_sdtp= 

I and  (talk are right. We are Jewish and we are right and we will never change our opinion whatever evidence you show.

""""",0
"Are you ok? 

Dear , I notice that you have been absent from Wikipedia for a few days. It's uncharacteristic, so I hope you are not ill. Please accept my good wishes. I just wanted to see if you are fine. Regards,",0
"Congratulations
for the Third of May 1808, reaching FA and it's still April, thanks for your input.....",0
"Paula White, Joel Osteen, Marbled Cat, and a few others 

These images were correctly retrived and all information was given about the images that were necessary. Some were even my own and I gave full permission for their use on wikipedia.  mcelite",0
"""""
It isn't about success. It's a phenomenon that goes back at least 100 years, to the days of Sousa and Johann Strauss. However, if you look at the """"""""Article Milestones"""""""" section above, you'll see it has survived no fewer than four deletion discussions. And we do require credible sources, and fancruft is removed on sight. andemu """"",0
"hate is my topic is hate
if you hate a person means you like that person. Your hate can turn into your love",0
PAGE I TRIED TO CREATE IS NOW AN ACTUAL PAGE LOL YOU BANNED ME FOR NOTHING,0
"""""

 Your Report 

Thank you for making a report  on Wikipedia:Administrator intervention against vandalism. Reporting and removing vandalism is vital to the functioning of Wikipedia and all users are encouraged to revert, warn, and report vandalism.  However, administrators are generally only able to block users if they have received a recent final warning (one that mentions that the user may be blocked) and they have recently vandalized after that warning was given.  The reported user has not yet been blocked because it appears this has not occurred yet. If this user continues to vandalize even after their final warning, please report them to the AIV noticeboard again. Thank you!  (talk) """"",0
"NPOV
Please stop adding not related Moroccan issues to Sahrawi articles while trying to look neutral. I will revert it again & again, as that editions are clear POV-pushing.",0
"Upgraded Human Language Families (wikicolors).png|Human Language Families (in wikicolors).
File:",0
"""""

 A kitten for you! 

you are  a good person

  
""""",0
"""""
Ok, here it is, peer viewed for 12 months and published at Academic archive On-line (DiVA), 
on a permanent URI: urn:nbn:se:kau:diva-2790

 Wallin H. 2008, 129 p: An investigation of friction graphs ranking ability regarding the galling phenomenon in dry SOFS contact  (Adhesive material transfer and friction), A free pdf document available here or www.diva-portal.org found here or at www.uppsok.libris.kb.se here use search words:""""""""galling & Harald Wallin"""""""" or the direct libris link here

  

""""",0
"POV pushing 

Faustian inserted this in the article: The UPA's cooperation with Jews was extensive enough that, according to former head of the Office to Counter Soviet Disinformation at the USIA, some Soviet propaganda works complained about Zionist membership in UPA. Seems to be a complete POV to muddy the waters - and picture UPA as an organisation friendly to Jews instead of an organisation which collaborated with the Germans on exterminating the Jewish people.",0
REDIRECT Talk:A Voice Within (album),0
"WP:BLP Violations 

I just removed another of your reverts which placed defamatory and uncited materials into Cherokee Freedmen Controversy.  WP:COI may apply to you since you seem to edit African American related articles and Freedmen controversies.  Your dishonest edit summary was over the top.",0
"Are they the anderthals? 

Are they the anderthals? the same discription as in quran? has anybody thought of this?",0
"The discussion of when there first were outdoor trees with electric lights is very strange. 1956? are you kidding? and some obscure town in NC? I don't think this makes much sense, especially since the sentences immediately preceding these establish that other cities had electrically lighted, outdoor Christmas trees in the early years of the 20th century. The article cited for the North Carolina town, if read carefully, really only states that the tradition of having outdoor lighted trees IN THAT SPECIFIC TOWN began in 1956, not that the town claims it was the first place to have such trees. I am old enough to have been around in 1956 (though I was a small boy) and I can tell you that we and our neighbors in Southern California had lighted, outdoor trees prior to 1956, and no one thought it remarkable or unusual. The history here is questionable, to say the least.",0
"""""

 What comes next 

Once we feel like we've gotten past the """"""""dispute"""""""" stage (I would say we have), someone should post a Request for page unprotection so that we can move the new version in. You might also mention that the admin should merge Naked short selling/Workshop in so that we can keep the page history. Or I'll do it later tonight - it doesn't really matter. ()(Talk) """"",0
REDIRECT Talk:The Best of Apocalypse,0
"""""
Just dropping by, I thought I'd leave a little feedback too. A featured picture is not always put on the main page, as noted by WP:POTD. For example, the semi-nude Michele Merkin was not used as it was found """"""""too cheesy"""""""". Wikipedia:Picture of the day/Unused notes several pictures that were not used because they depict too much gore or are of a scatological nature. A featured picture rating is essentially indicating that the community feels that the image is of high quality and high encyclopedic value. On a side note, POTD seems to be up to . 
Thanks for taking up the trace, Pink Oboe.   """"",0
"Some of the sources listed as NY Mag, CBS News, Fox News, an interview with Leighton speaking of the subject directly in Teen Vogue and US Weekly, a TV Guide interview, an article in the San Francisco Gate, the newspaper from the town Leighton grew up in (Naples Daily news).  If you do not consider those reliable sources, you have a problem.  If you want I can find 20 more sources from valid/reliable newspapers and magazines.  Everything is valid and sourced and should not be removed as it is the story of HER life.  Wikipedia is an encyclopedia for facts, and what is posted is FACT",0
The reason is the presence of a template based on inconclusiveness on my user page. The further presence of the template is to be contested.,0
"Ho ho ho! Merry Christmas 

I shoulda known the Piccirilli Brothers actiually executed Ward's pediment sculpture at the Stock Exchange! Happy Christmas, Carptrash.",0
"""""
I saw that reference, and I added a note (see note 10) by the name """"""""republic"""""""".  """"",0
"""""
Hey Jim. Good to see you around. You're right. I was on a no consensus tending towards delete, but not a clear delete because of the two Times of India sources (and one more source, again from the Times of India, that is visible on the search engines). What would you like me to do here? I can re-list the AfD if you might prefer that.  Message """"",0
"""""  And if he were a mere """"""""fellow editor,"""""""" I wouldn't have any problem with him.  But since he seems to let the power of being an admin go to his head, I have an issue with him.  Please read what remains of his Talk page if you need examples of this.  I'm a moderator on a very popular internet discussion board, and I would never ignore a valid question from a user.""""",0
is gonna help us to. He is logged in if you want to talk to him on his talk page.,0
"They look great to me! — 02:08, Mar 13, 2004 (UTC)",0
"April 2006 (UTC)

 Wikipedia:Colours 

much thanks for fixing/improving the table code.  
No reason, maybe add the info where you found the values, is that in common.css?   
all the styles are embedded. highly-repetitively. if you know your way around mediawiki, i've been asking everywhere for a css guru to clean up all the redundancy on the Main Page wikicode. (like we dont all have enough to do already, eh? ;) so many projects, so few minions... 10:52, 11",0
"Dear Mokele,
You have no right to tell people to die in a fire. Just because that IP address is being used for vandilism does not mean you can talk to people like that. You are in fact a bigger loser than the person who you block.",0
"""""""""""""You have new messages (last change)."""""""" and the notice below result from User:Arkyan and User:Avraham targeting this website as a result of an editorial dispute as to whether to include Theodore Roosevelt's view of US political corruption on the Unholy Alliance page, i.e.,

The unholy alliance, a phrase used in the platform of the Progressive Party (United States, 1912) written by him
The unholy alliance, a concept elaborated upon in his autobiography

Their recent edits may be reviewed at Special:Contributions/Arkyan and Special:Contributions/Avraham and reverted where appropriate.

""""",0
"""""

 Peter the Roman 

Can some one place this and remove the Argentinian Chap from the Prophecy which is not part of, and replace it with this information, and place his coat of arms. Any questions just e-mail me.   

""""""""Tarcisio Pietro Evasio Bertone was incharge of the Vatican from 28 February to 13 March 2013 thus the Prophesy of St Malachi is fulfilled.""""""""""""",0
"RfC

You pretty much blew through my respect when you tried to demand I give up my adminship. My position is very, very simple - the AfDs were invalid. They should not have been filed. I fixed the mistake.",0
"""""
...I don't delete material that complies with WP policy...(according to your own POV/interpretations)Wiki BADASS Woo 2U """"",0
and revert his edits,0
"""""

Canonicity in general

I've been involved in a long discussion over on Talk:Stargate (device) over whether the Stargate in the movie is """"""""the same thing"""""""" as the Stargate in the series, with Centrx arguing that they aren't and that discussing the Stargate in just one article was deceitful. I don't think his argument is at all valid, but in the course of looking stuff up on the web I've discovered that some fans of the movie apparently consider the SG-1 series to be somehow illegitimate or non-canon. I'm not familiar with the Stargate fan community, just the show itself, so I don't feel comfortable adding discussion of this directly to the article. Does anyone know any details about this, such as how widespread this apparent schism is?  06:52, 9 Jul 2004 (UTC)""""",0
"""""

 Capitalization 

Please stop changing lower-case common nouns to upper case, as in """"""""... the company has ..."""""""" -> """"""""... the Company has..."""""""". WP:MOSCAPS notes that Wikipedia avoids unnecessary capitalization; proper nouns and the first word in a sentence are capitalized, and not much more.  yack """"",0
See claim three here: http://onlinelibrary.wiley.com/doi/10.1111/mepo.12003/full#ss2 That is a reliable source.,0
"""""
If he is the community manager, then first of all it's a conflict of interest for him to be editing this, and second of all, he has the power to say explicitly on his site that there is no release date. Otherwise, despite who he may be, his position is incompatible with Wikipedia policies. SWATJester Son of the Defender """"",0
"""""

 Please do not vandalize pages, as you did with this edit to Boiling-point elevation. If you continue to do so, you will be blocked from editing.    """"",0
"Rants to policies 

Hi,

I think that you should reformat User:Shanes/Why tags are evil#The vandalism protection tags (or at least the idea) into some sort of proposal to reformat multiple distracting protection tags to less distracting corner icons; for example, redirecting  to  (well, probably move the later to the former, for this case). The corner icons work beautifully, are much less distracting, and clicking them will follow you to a page explaining what the lock is for.

I fully agree that the large box with text is very distracting and unnecessary. This is especially true when non-user Wikipedia users read the articles, which probably constitutes the majority of Wikipedia readers. They probably don't care that they can't edit the article, nor would they, and of most concern—they may confuse the tag with the article content.

Thanks! +",0
"Hi Collectonian, it obviously wasn't appropriate, and I agree with the warning given by  Vicenarian.",0
"""""

 A request... 

, in the future please sign after your  tags on the Photography workshop page. While a bot is currently doing it for you... i.e. """"""""— Preceding unsigned comment added by   """"",0
"I've revised the translation from the Spanish by going back to this earlier edit.  Subsequent edits on the Spanish-language Wikipedia seem to have been intended mainly to insert links, but have primarily succeeded in deleting chunks of the original text, rendering the result both ungrammatical and somewhat insensible.  I've taken 's translation and incorporated the previously omitted text, and gone over the whole to make it more idiomatic in English.  It's not quite there, yet, but is hopefully now serviceable.  ( )",0
"""""

I'm sorry if you will not like the answer, but I can not accept any wording, indeed any word in the article that does not reflect or is reflected in sources. Would any of your patients be happy with an almost successful operation?
I care even less about the Yugoslav Media then I do about Yugoslav politics. It may not be what you want to hear either. All I can do is repeat that there is no way in this world that the Yugoslav troops were operating under independent command during this offensive. Its is just laughable even if I had no way to substantiate what I said. Journalists may write what they want, but ask any military officer and he/she will tell you its inconceivable for the size of the op. (comms) ♠♥♦♣ """"",0
and Capital gains tax,0
"""""

This should be included in the Criticism summary section here, since that section's content so far is not a remotely truthful summary of the criticism point of view fork """"""""article"""""""". It clearly suggests to readers that basically all criticism of Apple is related to product management in some way or other.

Now that Apple Inc. has admitted that they did in fact use child labour, this is clearly a far, far more serious type of criticism than everything currently mentioned in this main article's criticism summary section. The explicit word """"""""child labor"""""""" should be mentioned in this article. 78.34.240.197  """"",0
"""""

Merge
Both articles should be merged.  (Operibus anteire) """"",0
"""""
Everywhere. Though I might just start going thru the secure server all the time, because I have a similar issue with the popups userinfo grabber. –xenotalk """"",0
"""""

I agree with , there's no need to keep unclear concepts and wording when a better alternative exists. Also I'd ask  to not revert using source as a reason, when source is actually a book of his authorship. WP:COI and WP:SPS comes to mind...  TxT """"",0
"Hi. The routes to Japan are often mis read. First, I had the argument that JAL flew to Tokyo, not JALways. But now I would like to challenge a route that Jetstar takes. It said the Jetstar flew to Kansai from Brisbane. This is true but you must connect through Sydney. Although you would stay on the same aeroplane, the flight number between BNE-KIX changes in Sydney meaning it is not a direct flight. EG: Flight 001, SYD-KIX. FLIGHT 002, KIX-SYD via BNE. That is how it works. If you are not sure, please check Qantas schedualing. I wont edit the page now in fear that I will be banned.",0
"Support

I and all the other Sikh Wikipedians on Wikipedia support you on Singh you are correct. I completely agree with Sikh Historian. I'm busy at the moment but if we need to get Harrybabar permanently blocked then it should happen because his vandalism is unacceptable.",0
"Thank you for your RACIST experimenting with the page Katherine Heigl on Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our encyclopedia. Now go FUCK YOURSELF YOU RACIST CANUCK ASSHOLE1  U HAVE NOTHING BETTER TO DO THAN CENSOR THE TRUTH U GODDAMN KKKKANUCK PIECE O TRASH///  DICKHEAD MORON MOTHERFUCKER111LOL  YOU CANUCKS R REAL RETARDS1  FUK OFF DICKWEED!  EDIT ANOTHER 1 OF MY EIDTS AND YOU'LL BE EXPEL FROM WIKI BY JIMBO YOU SOB DICKHEAD11 
SO WATCH IT MOFO PIECE OF GARBAGE RACIST MOFO ASSHOLE.  IM TRYINBG TO BE NICE HERE SO TAKE WHAT i SAY AS A COMPLIMENT!Yamla",0
"""""

 Bulgars 

omg!! you are an admin and you protect the people who vandalise the """"""""Bulgars"""""""" article. these attackers are pan-slavic ultra-nationalists and they dont want to see the word beginning with """"""""Turk"""""""". you help them remove reliable sources. Old Bulgars are changing into slavs by your hand... great!  """"",0
"You must be logged in to upload files. 

So In other words I have to sign up just to add 3 things to 1 entry.

To hell with that!!!!! This place can ROT for all I care!!!

75.8.35.177",0
"McKinsey & Company ==

I think the best route would be to drop a note at WP:BUSINESS. (T / C / WP:FOUR / WP:CHICAGO / WP:WAWARD) 

==",0
"Message- Long time, no talk 

I was just pottering around on Wiki, and suddenly I thought of you. So anyway, how ya going? I hope we can get along now.

Anyway, there is an issue that I have, that has to do with Wikipedia. A user on here had been stalking me and asking some innapprpriate questions. Do you have any ideas of what I could do. I know that user is also from Australia. Could the police here do any thing?

Cheers for now!

122.106.27.175",0
"""""

  Thanks. From my point of view there are differences and parallels between the two concepts: One parallel is that both concepts are intending a territory with a homogeneous population. The difference is: the concept of racial hygiene is intending a homogeneous population regarding the criterium """"""""race"""""""" (whatever """"""""race"""""""" might be), the concept of ethnically homogeneous states is intending a homogeneous population regarding the criterium """"""""ethnicity"""""""". A second difference is that the concept of racial hygiene has led to more extreme forms and methods in political practice in history (example: the holocaust - not only expulsion but also extinction of millions of people in an industrially organised process). (User, Nov. 17th, 2006)""""",0
"Well, I see FutPerf is getting quite angry now, insulting other editors also. And again their goal is make the point that the First Bulgarian Empire and the Second Bulgarian Empire are not Bulgarian or at least not related, which helps their long term strategy for the invention of a Macedonian nation and state, think Bulgarian Tsar Samuel, etc. which existed from antiquity and the middle ages. That's it. Tropcho, correctly pointed out that direct political continuity is completely unimportant for the info box, no other country cares for this in their info box, neither Spain, Germany, Ireland, Poland, etc. What is important is to show how Bulgaria formed thru the ages.",0
"Salutations J.A.P., welcome to Wikipedia. Perhaps you might find WP:HOCKEY of interest.",0
Be careful who you call a moron.,0
"""""

 Leadbeater Biography 

SmackBot problem

Rich-  Regarding the C.W.Leadbeater biography article,http://en.wikipedia.org/wiki/Charles_Webster_Leadbeater, on 12 Dec """"""""Philosophus"""""""" improperly reverted my extensive revision of Dec 9. I removed all the smears and slanders from the article yet he accuses me of having a NPOV problem. No editor has the right to revert the good faith contribution of another editor, I will undo his improper revert.  As you made a minor edit or two since then, your edits will probably be lost, also. Please communicate specifically what faults you find in the text and maybe we can work out some compromise wording, if you are knowledgeable in the subject.  If you are not knowledgeable you have no business editing this article.        

""""",0
"""""

Quoting Hoppe first; Detailing Kinsella's important points
At this diff I put in the """"""""Democracy"""""""" section Hoppe's earlier comment first and followed with more about what Kinsella said, i.e.,:
Stephan Kinsella writes that Hoppe's critics have accused Hoppe of """"""""homophobia, bigotry, and the like"""""""" based on these passages. Kinsella wrote that that Hoppe's discussion of """"""""physically removing"""""""" homosexuals and other groups only applied to """"""""private, covenant-based communities"""""""" centered around traditional values. He shared a letter Hope wrote to him saying """"""""the gay couple down the street who mind their own business would not be expelled, but only those who are openly hostile to the basic heterosexual or private property basis of society.""""""""
As I said in my edit summary, just because some choose to totally take his comments about of context and attack him, does NOT mean that Wikipedia should be used for the same purpose. '' - talkie talkie🗽 """"",0
"""""
The fact of the matter is that Toei and Bandai have been using """"""""Gorenger"""""""" to exclusively refer to the first Super Sentai series since at least 2006. Every subsequent series that has the レンジャー ending has been """"""""-ranger"""""""". You can see this sort of thing on any of the print material released by them lately has it as """"""""Gorenger"""""""", while all the others have been """"""""Turboranger"""""""", """"""""Zyuranger"""""""", """"""""Dairanger"""""""", """"""""Kakuranger"""""""", """"""""Ohranger"""""""", """"""""Carranger"""""""", """"""""Megaranger"""""""", """"""""Timeranger"""""""", """"""""Gaoranger"""""""", """"""""Abaranger"""""""", """"""""Dekaranger"""""""", """"""""Magiranger"""""""", and """"""""Gekiranger"""""""". I believe """"""""Gorenger"""""""" is also plastered across their vehicles.—Ryulong (竜龙) """"",0
""""" 
|-
|}
mark nutley has suggested, """"""""Instead of people edit warring they really ought to use the newest sources. """"""""Three to five million of this number died in Ukraine and in the heavily Ukrainian-populated northern Kuban, among the richest grain producing areas in Europe.""""""""""""""""
[Norman M. Naimark. Stalin's Genocides Princeton University Press, 27 August 2010, p. 70][http://books.google.com/books?id=F3UwF1eqb0AC&lpg;=PP1&pg;=PA70#v=onepage&q;&f;=false""""",0
"I see that you just can't help yourself. If you saw my being blocked as a reason to be victorious and now feel like keep 'telling' on me to the administrator please do not use my talk page for that, go the administrators' noticeboard where the initial complaint was posted and add yet another post. Concerning your advice on what I need to 'familiarize myself with' apply it right back at yourself, especially regarding WP:CONS and please understand that consensus is a product of a prior discussion not just any piece Wikipedia text that stayed unedited for a while.",0
"Gay 

The existence of CDVF is further proof that  is a sad twat. He is also very ugly, and has a willy for a face.",0
"""""
Unfortunately, judging from previous """"""""warnings,"""""""" some people here have a rather unusual view of what personal attacks are. Pointing out that the individuals accusing me of using sockpuppets were incorrect  and in fact the two main people making the accusations have been harassing me for months and had used sockpuppets and meat puppets themselves for getting around edit conflicts and to stack votes on a Request for Admin proceding, as pointed out by several editors at the time  certainly cannot be considered a personal attack. Pointing out that admins did not have any actual policy basis to make the blocks is not a personal attack (and it has, in fact, been confirmed by the overruling of the blocks more than once). 

Frankly, if you are looking for personal attacks, try yourself for your AGF-violating attacks on my actions based upon limited information and actually misleading information given to you by other individuals, or David Gerard for claiming that I am """"""""trolling"""""""" when all i am doing is defending myself from false accusations of others. It's very clear that a number of people here need to realize that the very things they are accusing me of and trying to justify for a block are exactly what they themselves are doing from behind the pretense of trying to solve things.

If you want to start blocking for incivility, I might suggest removing David Gerard for a while for his actions, or Elonka for falsely claiming that I was using sockpuppets or that I was harassing her, or the sysop whose very talk page says he's going to go around blocking people no questions asked and in fact did so after I caught him restoring placing illegal information on how to pirate software an article talk page. Rules should apply to everyone, and a number of people have been getting away with pretty flagrant violations and trying to rationalize them away by just labeling me as an alleged problem editor and not taking any sort of responsibility for their own actions.  """"",0
"Looks good to me. I think a nice pic of Midtown from across the East River would be the best possible addition to the montage, but there isn't one currently available on wiki commons.",0
"Perhaps the question is more of philosophy than of mathematics, and we don't have any regulars at WikiProject Math who are philosophers of mathematics?  (t | c)",0
"Except for the fact that there's no information for the table, NO confirmation on number of episodes (why don't you just put 50 in?), so it's just clutter - and NOT vandalism. 220.245.146.235",0
"Right  on may 26, 1863 which is not the stars and bars ( )",0
Perhaps GoodDay you could provide a diff for this thought as I am unaware of it. BTW I hope the move is going/went ok!,0
"""""
 It is also unfair that I can't respond to the allegations.  (talk) """"",0
I NEVER FUCKING MADE THIS MOTHER FUCKING ARTICLE I JUST FUCKING EDITED IT AND THAT WAS A FUCKING LONG TIME AGO FUCKING ASSHOLES! PISSING ME OFF @,0
"Has anyone ever considered including tag-team edit warring as a 3RR violation? When two people act in tandem (unintentionally or intentionally) to make the same revert four times, they may not technically violate the 3RR rule, but they certainly do so in spirit.  This was the problem on both sides in the edit war on the Canada page, and precisely what I wanted to avoid on the Dominion page. Would it not be easier to warn editors as you did here rather than shut down pages for weeks at a time as was done in the Canada case? I'm sure this would cure the escalation problem without blocking access to pages. Any comments on this?",0
"Fucked with the wrong muchacho.  21:19, July 23, 2005 (UTC)",0
"Thanks but an unblock would be a compromise.  I live on the margins here, creating articles on various subjects, then see them deleted. It's a form of performance art.  Many of them don't get deleted.  Medieval philosophy is still there and History of Logic, to name a few.  I'm one of those people they just don't know what to do with, and I like it like that.  86.184.133.167",0
""""":Yes, I do hope to get it to GA status in the future. ) WP:MOSTV states that for fictional characters, their storylines should come first, and then the information on their creation and characterization. It makes more sense to read about what storylines the character has been involved in, before going into the production of it all. The same style is used for articles on books, films and television shows/episodes. '''16 

""""",0
"Hi 

Im a fucking bitch.

50.180.208.181",0
"Please educate me as to how this article is a copyright infringement and, if so, from which source. Once this has been established could you explain how best to rectify the situation. Thank you",0
"Men's ranking Figure: While nice to look at, misses key time between 2010 Olympics and 2010 World Championships 

That's all there is to it in the title. IIHF lists a 2010 post-olympics ranking, and 2010 ranking (presumably post-WC). To exclude this period is incorrect, as it is a time where Canada was ranked 1st overall, Russia 2nd. The same issue will happen this year as rankings will change twice (after Olympics and again after WC).70.73.141.146",0
There are many broken nostrils in this pancreas,0
"That last line (the new version is better) is YPOV.  This 'new'(your) version just complicates the issue and makes the article less simple to read.  Tell me, why MUST Boston be mentioned as a cultural and business hub at all?  This seems to be at the heart of your bias.  It appears as you want the viewers to get from reading it that Boston is somehow the nerve center and city that New England revolves around and looks up to.  Why MUST this illusion be on the page?",0
"(UTC)
It sounds wrong because first it reads are which is present-tense-ee and then it reads used which is the past tense, i reworded the whole thing to past-tense because we are discussing already published works as opposed to works being published or yet to be published.   Arnfjörð [ Bjarmason]  10:21, 2004 Sep 12",0
And you took your time to answer.,0
"""""

 Yobot: incorrect DEFAULTSORT 

Hi, Yobot  an incorrect DEFAULTSORT. It's puzzling as to why it didn't recognize the article as being about a person. Among other clues, it included birth and death dates at the top, as well as a  (which Yobot substituted to additionally include the correct DEFAULTSORT).  • XAЯAbИAM """"",0
"Biased, unreliable,emotionally written by armenin wiki editors==
Pls, stop using the wikipedia for your dirty propaganda and lobbying purposes. There was no genocide. THis is a amyth advanced by the armenian church and armenian fundamentalist fascists. A nation can not be subject to a egnocide when it has several heros for whom you can see statues in yerevan (Irevan),. jews don't have it. The resolution is the act of some sold congressmen who want to appease the armenian lobby. it has no reliable, valid and neutral content. It is kjust a piece of dirty and lie facts presented and written by christian missionaries working to kill Turks and Kurds in 1910s. You can claim to be subject to genocide as much as you want. But this thing did never happen. Some armenian fundamentalists and fascists, who were killing Kurds, Turks and Azerbaijanis, were killed by great sons of the Turkic nation and I am proud of them. Go and propogate your lie as much as you can. YOu will achieve nothing. raman

==",0
Add Mobile porn as additional WP:ALSO link,0
"Smer-SD 

Why is the Slovak party Smer-SD between Non-Inscrits? They are regular Socialists. They used to be out of PES, but that was settled pretty long ago. Liberal Nationalist",0
"2007 (UTC)

Has anyone considered how matter (the stuff we are all made from) actually interact with time and time travel? If I were to travel back in time, would I be 'frozen' and isolated in spacetime, whilst everything else around me travel backwards in time, or will I also physically and biologically travel back in time, that is I get younger and younger, and then disappear because I was not yet created, thus defeating the Grandfather Paradox? Although if it were possible for signals (or information) to travel backwards and forwards in time, does this possibility automatically extend to matter as we know it (ie particles giving rise to electrons, protons and neutrons, and ultimately biological beings such as ourselves)?  02:30, 30 July",0
"""""
I want to offer you a tremendous """"""""thank you"""""""" for your suggestions, which I believe will be paramount to the successful inclusion of RantMedia.  I've vastly improved the article since the AfD nomination as well as  since yesterday afternoon.  I wasn't clear to me what was necessary to be done with the article, and you were truly the first to really answer my question of """"""""what is it going to take?"""""""".  So from the bottom of my heart, thank you.  ₪—  (T·C) """""""" """"",0
"""""

I have to laugh when watching the supposedly BRITISH national news, with guys barely up to their ankles in snow implying that Ragnarok is upon us, yet on the same day, when trees are being blown down and main roads being blocked by snow in Scotland, it doesn't seem to be noteworthy. Scotland routinely gets ignored on the """"""""national"""""""" news, and even people from the north of England were complaining about the fuss made by the southern oriented news. Tourists appear to be amazed that things are falling apart because of something like this. My mother had a very good giggle at the reporters live in Trafalgar Square in a couple of inches of snow, or beside a main road, barely ankle deep.194.106.220.19  Lance Tyrell""""",0
"A friendly advice, if you have to refer to me, kindly use Cult Free and not only Cult. )",0
"""""

Great links, IMO the American people are on the whole good and decent, but the so called leaders are fully controlled by an Elite bent on domination and control. This whistelblower says the same. .  talk """"",0
"Queen's University 

As stated previously, I am quite pertrubed and to be quite honest, frustrated that you would remove the section pertaining to the university's traditions. Do you have a personal vendetta against the institution or dislike it? For whatever reason you removed the compliation of material regarding the Jackets and other traditions, which I find odd considering similar traditions have been allowed to remain on other university Wikipedia pages. Mindlessly deleting material without group consent constitutes vandalism and, while I am sure that your intention was not malicious, it was a short-sighted move on your part. Please allow us to discuss this in greater detail.",0
""""", 20 January 2013 (UTC)
The argument at WP:NATURAL seems to rely on showing that the other name is common, so you need to prove that the other name is common. Numbers might help a bit. Also, above we are told that """"""""Gohatto"""""""" rather than 御法度 is the name of the film in Japan, but this turned out to be false. Incidentally, Ryuhei Matsuda, it seems to me, looks more like his mother than his father. What do you think? Also, how authentic is the portrayal of the Shinsengumi in this film? Do you have any historical insights?   15:12""""",0
"""""

Unspecified source for Image:Metropolitan_of_Moscow_Makariy_Nevskiy.jpg

Thanks for uploading Image:Metropolitan_of_Moscow_Makariy_Nevskiy.jpg. I noticed that the file's description page currently doesn't specify who created the content, so the copyright status is unclear. If you did not create this file yourself, then you will need to specify the owner of the copyright. If you obtained it from a website, then a link to the website from which it was taken, together with a restatement of that website's terms of use of its content, is usually sufficient information. However, if the copyright holder is different from the website's publisher, then their copyright should also be acknowledged.

As well as adding the source, please add a proper copyright licensing tag if the file doesn't have one already. If you created/took the picture, audio, or video then the  tag can be used to release it under the GFDL. If you believe the media meets the criteria at Wikipedia:Fair use, use a tag such as  or one of the other tags listed at Wikipedia:Image copyright tags#Fair use. See Wikipedia:Image copyright tags for the full list of copyright tags that you can use.

If you have uploaded other files, consider checking that you have specified their source and tagged them, too. You can find a list of files you have uploaded by following [ this link]. Unsourced and untagged images may be deleted one week after they have been tagged, as described on criteria for speedy deletion. If the image is copyrighted under a non-free license (per Wikipedia:Fair use) then the image will be deleted 48 hours after . If you have any questions please ask them at the Media copyright questions page. Thank you. Do you want to opt out of receiving this notice?  hi! """"",0
"40 Percent Koreans eat Dog Meat ( Koreans have tried). Not regular Korean Food Diet.
Don't genearalize or finger point that all Koreans eat Dogmeat. That isn't true.",0
Support Lets protect and save this page from User:Balagonj786. This page has full of errors and invalid references.,0
"Apparently - I thought Tom was offline and filed an edit-warring report, and YellowMonkey picked it up before Tom mentioned the page protection.  We'll see if it sticks.",0
"Newsletter draft ready 

Hi Dank,

I have prepared an initial draft of our drive wrap-up newsletter at Wikipedia:WikiProject Guild of Copy Editors/Newsletters/April 2012; if you could find the time to check it over before it goes out, that would be super. Thanks.",0
should be omitted entirely''.,0
"Is that not a true description on a booger, if not then prove to me what is!",0
"Stay off my talk page, stalker. 12.39.2.83",0
"Anthony de Mello 

Hi I need this page written: Anthony de Mello. It currently redirects to a priest. Do you have any suggestions on the dab title (cricketer)?",0
"""""
Thanks! And happy new year to you too!   ''''''  Let's talk about it! """"",0
more mature way. Central posted 6,0
"Stop Vandalizing my USERPAGE! 

I know it's someone from here.",0
Oppose. I do not think a merge is a good idea.,0
"Maybe, but that does not lead to the conclusion that the TAIP aircraft remained in Africa and did not return back after ferrying the soldiers. The article on colaco.net also does not shed any light on this.",0
"Thanks 

Thanks for the thanks. I just leave them in my watchlist after I found an archive full of vandalism a while back. Given that it was slashdotted, I suspect we will see a bit more of it. I might get someone else to fully protect it if it continues (I can't do it because of COI). I would also like to thank you for keeping an open mind. Changing !votes is an encouraging sign of Good Faith. Regards.",0
"Hello...

(If you're interested... we could really use your help!)",0
"F**K ALL RIDES AT WORLDS OF FUN  

I hate all rides at Worlds of Fun because they are sh_tty and boring. All ride operators at WOF should be fired sued and hanged. Burn all WOF coasters. Arrest all WOF park operators! Assassinate all WOF customers! I heard that a boy died on Timberwolf on August, 2014. That's stupid! Worlds of Fun should have nown better to built that sh_t ride. Worlds Of Fun cares about money and prophet moar than they're customers. Burn that sh_t park down! F**K YOU RIDES! WorldS Of Fun is dangerouser than GRround Zero and Area 51. 

Worlds of Fun should burn in Hell!",0
"As to Job for you 

Sure thing - as soon as I find time for that. Also, I notifyed NovaNova asking him to start editing the http://en.wikipedia.org/wiki/Croatisation. This guy knows a lot about Croats and their history.",0
"Oh ok, I just wanted to see what people thought. Anyway its up for CSD. Hey do you like my talk page? I hope you don't mind )    talk ER",0
"Wrong! The capital is Podgorica as it has always been since July 13, 1946. The seat of government, parliament, AND PRESIDENT is in Podgorica. Cetinje is only the seat of the Kingdom of Montenegro in exile. And besides, only capital cities have embassies, and Podgorica has them and do you see any in Cetinje, no. Besides, no one in Montenegro nor in the world say that Cetinje is the capital of Montenenegro, but instead, they say it is Podgorica. And also, that consitution was adopted in 1992, very outdated, and a new one is due next year.",0
"Mark II subsec
I removed the Mark IIx subsections and made them bulleted lists.  There was no reason, in my eyes, to subsec one line of information. //",0
"""""

 Can there be a more concise listing? 

The listing of """"""""other inventions"""""""" is profoundly vague. Why group 4 different categories together? Why even mention things that the chinese received purely from outside sources? There should be a much more complete, well managed list of chinese developments, which I've yet to find- along with how these were transmitted globally, and whether or not places like Europe got them purely from the Chinese.

This really needs the attention of people with some remote expertise, which I guess is somewhat there when Needham's work, which is profoundly rare in private collections was cited- not like the arrogant bigoted ass who was crying about chinese nationalism, yet then went onto say that they only invented noodles.

And besides, why are things like the cannon and porcelain listed under """"""""other inventions""""""""? Who developed these independently?""""",0
"In history there could be a consensus view or a mainstream view, in theology there is no mainstream or consensus view, since most of theology depends upon the church membership of the theologian. Historical scholarship aims at universality and objectivity, while theology makes no such claims. It is true that there are millions who believe that JEDP was birthed in hell (or would believe it if they knew what JEDP means), so in principle their view is notable, but as Enns said, it is a fringe view in the academe, even among scholars who actually disagree with JEDP. The sources used to build Wikipedia are academic sources, therefore JEDP and its 20-21st century offspring are given by default the weight they have inside the academia, while the view of the fundamentalists is treated according to WP:UNDUE. This does not mean that Wikipedia could say that the fundamentalists are theologically wrong (Wikipedia has no theology of its own), but it is entitled to say that inside historical scholarship they are a fringe view. Of course, this does not exclude serious scholarship done at religious faculties, since as Ehrman said in one of his bestsellers, US mainline Protestant and Catholic theological seminaries and divinity schools do teach mandatory historical criticism classes. So, in a sense, scholars from such faculties are thoroughly acquainted with historical criticism and built their careers upon its assumptions. Only fundamentalist seminaries and divinity schools choose to default against historical criticism. They are free to do this, but this cuts against their claims of being mainstream historians.",0
"Well, i'm sorry, but attacking me and my edits is exactly what you're doing...wow, there's some seriously snotty people on wikipedia!!! And yes, there is a need to separate the featured single, 100% DEFINITLY!!!!!!!!!",0
"""""== TfD nomination of Template:SilentRedirect ==

Template:SilentRedirect has been nominated for deletion. You are invited to comment on the discussion at Wikipedia:Templates for deletion#Template:SilentRedirect. Thank you.   | (talk) 

 Watermarks 

I shall remove the obvious ones, the less obvious ones stay. I am allowed to watermark images with anything whatsoever I wish to, even if it's a contradiction, and if you wish me to use up further WP  bandwidth by re-uploading them, that has no effect on me. I can't do anything until this evening, and if any get deleted, I shall reupload them. Yours without respect (talk|email) 
You could have the grace to reply. I said that I'd deal with them this evening, but only the ones where the watermark is visible from the page. So *** off (talk|email) 
I am planning to re-upload them with less obtrusive watermarks, such as that on Image:Bliss parody.jpg. (talk|email) 
It wasn't vandalism; I used an external link as per your instructions, which incidentally I'm not bound to follow. I am certainly on the verge of requesting mediation, as you are disrupting my life, never mind WP, to make a point. I will tell you one more time: any images are better than none. If you wish to get your own pix of all the concerned images, you're damn welcome to try, but they are GFDL therefore there's no grounds for removal. (talk|email) 
PS - I shall add the external link again, not as an image, and if you remove it I shall make a formal complaint to the Wikimedia Foundation, and the Information Commissioner in London. (talk|email) 

, your conduct is a little off in this matter. While I'm all for discussing the issues with users, let's keep it civil please? Thanks.  (talk) 

 I disagree, Rob - it is far more than """"""""a little"""""""" off. Images watermarked as such are not in any way appropriate for Wikipedia. This is an encyclopædia, not a pet image project. If """"""""TheDoctor10"""""""" isn't happy to play ball, he can go elsewhere.
  (talk) 

I am proposing a change to the image use policy to forbid watermarked images. Please voice an opinion at Wikipedia_talk:Image_use_policy#User-created_images -Thanks - talk 

I edit from the United Kingdom, and under the 1990 Computer Misuse Act, the editing of information online is illegal, without permission. The button at the top of every page that says """"""""Edit this page"""""""", among other things, constitutes that permission, while the policies and guidelines form conditions. Since there is no condition against my image, it has a legal right to be there. Q.E.D. (talk|email) 
True, but therefore your addition fails under the same logic. Also, Wikimedia own the servers, it's their right to delete it. 13ID:540053 
Apologies to Ed for invading his talk page, but what a load of rubbish! Wikipedia are under no legal obligation whatsoever to host your images, regardless of whether they meet any policy. I have no idea under what flawed logic you presume that the fact you can edit Wikipedia means that your edits must legally be accepted. If the Computer Misuse Act states that the editing of information online is illegal without permission, that implies that editing with permission is legal, and nothing more. Furthermore, by your logic, I have the legal right to edit Wikipedia, and remove your images... I fail to see what on earth you intend to tell your lawyer, but I don't imagine the Wikimedia board are too concerned... └''''''/talk┐ 

Ignoring the gibberish i",0
"""""

 ARTPOP (2012 album) 

Hello, thank you for all your contributions! I make this message in good-faith. Please do not make hidden comments like this stating that an editor will be blocked if they remove a redirect. I am in no position to be asking this but I am saying this as it could turnaway new contributors (who aren't aware of the rules) feeling they have been bitten. In this case, I think a kind [user] talk page message would be more appropriate and effective. Also, you edit was reverted so I reverted it back to your version but also removed the block warning as it is not appropriate (no admin will/should block just because a user removed a redirect, specially if that hidden message was their only warning.) Feel free to correct me if wrong.Again, I write this in good faith. )  Cheers,  Huntley """"",0
"Crown Prince 

Wouldn't it have been Prince-Elect? Denmark was a elective monarchy during this time.",0
"Hamish MacDonald (disambiguation)
Hello. Just to let you know that as this now only has two entries - one of this name and one with a very similar name, I have tagged it for deletion using Template:db-disambig. If you have any questions about this, please let me know. Best wishes,",0
"""""

 My 2-cents, as someone close to the Korean-American community: It's pretty standard practice to give both an """"""""American"""""""" and a Korean name at first. I don't know for sure that that's the case here, but wouldn't be surprised. It's probably explained in her book.   """"",0
"""""

 Died in 2014 or not? 

I think it's better to settle the matter here instead of going back and forth. So, the IP user claims that the whole thing is a hoax; that she died in Europe years ago and that there's no Hawaii obit. First of all, is the """"""""Forevermissed"""""""" a user-submitted website? 24.206.199.151: Do you know her family personally or do you know somebody who knows the family? We'd like to get a more elaborate explainantion behind the claim that she's been dead years ago. I see that her supposed obituary is pretty detailed. Are the rest of the biographical information accurate, though? And the picture?  """"",0
""""" August 2007 (UTC)

Dear  The 24 hour block that you placed on my account yesterday for personal attacks has just expired, and while I must say that I was not happy about the block, I harbor no hard feelings towards you. If you check my previous contributions, you can see that I have been a productive editor on Wikipedia. I'd just like to let you know that while I was guilty of personal attacks against  and , I was goaded into doing so by these two individuals. In order to avoid future blocks, I promise not to engage in anymore personal attacks, and if I am goaded by trolls such as these two individuals, I will simply ignore them. 

 was repeatedly reverting a comment which I made concerning statements made in the Hugo Chavez article which I found to be biased. My issue with  concerns his nastiness and uncivility. He is far too possessive of articles which he has created, and he becomes very angry when edits are made to such articles. After multiple revisions of LEGITIMATE edits which I made to """"""""his"""""""" articles, I told him to leave me alone. He proceeded to foul my discussion page with unwanted and unsolicited comments. When I objected to this, he goaded me into calling him a profanity.

While I respect your role as a Wikipedia Administrator, I'd like to respectfully request that in the future, you exercise better discretion when blocking a user based on one-sided information. Thank you for your understanding!   19:53, 15""""",0
"Links in Results 
A mess, links anywhere except the actual book.",0
"It wasn't me that added the Glebe Park link, though I might've wikified it. I've never actually been there, so I'm afraid I won't be of much help at the moment...though I've been meaning to go look for a while.",0
"Go away

Why did you revert my edit on Blowdart's user talk page? Surely thats his privelege. Users like you give wikipedia a bad name. Stop being such a busybody. 134.226.1.194",0
"the head  

waysssssssssss 76 pounds and feels like play dow . dont tuch them they will fall off",0
"Sarek of Vulcan: Unfortunately for you, you cannot ban a fact. 

Sarek of Vulcan: Unfortunately for you, you cannot ban a fact.

Fact: Lawrencenkhoo told me here on Wikipedia that companies keep their retained profits in the bank. 

Fact: That is absolutely untrue.

Fact: Sarek of Vulcan bans me for stating that. 

Fact: Sarek of Vulcan can ban me but cannot ban facts.",0
"Keep your chin up! Darwinism was not accepted over-night. There appears to be more sense in  the  AAT origins, than the sort-cut hypothesis that our  ancestors went from swinging in trees to the prairies (and then, eons later, take up a sedentary life style so they could edit Wikipedia and face book etc., all day). One only has to watch little kids on the beach.  The first time a wave throws them bottom-over-elbow they may well cry – but after a time,  they can't wait to get into the water again. It is as if  being at home on a sea-edge environment is hard-wired into their genes.  Unfortunately, the rise in sea level since these times means that evidence of these coastal communities may never be found.  Keep plugging away until the old hypothesis fade away.",0
"""""""""""""Nazi filth"""""""" is impolite  04:27, 20 Jan 2004 (UTC)

""""",0
"Interesting. I checked the other case number Kunzang Lhamo cited  which can't be used for Wiki since it's original research. But going a step further, I can't find that case number on San Bernadino's Open Access, either in civil or criminal records.",0
"The transcluded part of the GA review doesn't seem to update into the main talk page of the article correctly. May have to click to go to the subpage to get the most up-to-date version. Sorry, its looong. You can skim most of the content-related stuff, I guess.",0
